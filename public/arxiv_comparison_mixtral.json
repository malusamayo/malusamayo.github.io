{"metadata": {"source_path": "Arxiv Summarization", "custom_fields_schema": [{"name": "evaluation", "type": "per_model_number"}, {"name": "The summary should accurately reflect the main findings and contributions of the paper.", "type": "per_model_number"}, {"name": "The summary must be concise, ideally not exceeding 250 words.", "type": "per_model_number"}, {"name": "It should highlight the research problem or question addressed by the paper.", "type": "per_model_number"}, {"name": "The summary should mention the methodology or approach used in the paper.", "type": "per_model_number"}, {"name": "It should include any significant results or conclusions drawn by the authors.", "type": "per_model_number"}, {"name": "The summary must be written in clear and professional language.", "type": "per_model_number"}, {"name": "It should avoid technical jargon unless necessary, and explain any used terms.", "type": "per_model_number"}, {"name": "The summary should be structured logically, with a clear beginning, middle, and end.", "type": "per_model_number"}, {"name": "It should mention any key experiments or data used in the research.", "type": "per_model_number"}, {"name": "The summary should reflect the paper's significance or potential impact in its field.", "type": "per_model_number"}]}, "models": [{"name": "gpt-4o"}, {"name": "llama3-2-11b"}], "examples": [{"input_text": "many statistical measures have been developed to distinguish between the various cosmological models , ranging from direct measures of the power spectrum and correlation function from redshift surveys , to measures of velocity dispersion , bulk flows , and mach number from peculiar velocity surveys ( cf . , @xcite for a review ) . each of these measures is designed to be sensitive to different aspects of various models , such as @xmath0 , the initial power spectrum , or the gaussian character of the initial phase distribution . one can get an intuitive understanding of the dependencies of different statistics by considering the following example . compare n - body simulations of four different cosmological models : standard cdm , open cdm , cdm + @xmath1 , and a pure hdm model , the details of which are given in  3 . each simulation is normalized to have the same value of @xmath3 , the standard deviation of the mass fluctuations within an 8 @xmath4 sphere , where @xmath5 is the hubble parameter in units of 100 @xmath6 . the two point correlation function , @xmath7 , for each model is presented in figure 1a . despite their differences in initial power spectra , the final correlation functions are similar in all models . in general , the correlation function does not depend strongly on @xmath0 if one retains the freedom to set the @xmath3 normalization . in contrast , figure 1b shows the pairwise velocity dispersion , @xmath8 , as a function of separation for the same set of models . a strong differentiation between the low and high @xmath0 models is apparent . the velocity dispersion is easy to compute in simulations , but is difficult to measure in the geometric projection of phase space that is measured by redshift surveys . the traditional way to measure the small - scale velocity dispersion of galaxies is via the anisotropy it introduces in the redshift - space two - point correlation function ( @xcite ; @xcite ; @xcite ; @xcite ) . however , as it is a pair - weighted statistic , it is dominated by the densest regions , which are necessarily rare . thus one finds large variance between estimates of the small - scale velocity dispersion between different samples ( @xcite ; @xcite ; @xcite ; @xcite ) , indicating that the small - scale velocity dispersion measured in this way is not very robust . attempts have been made to use direct measures of peculiar velocities of galaxies as a constraint on @xmath9 ( e.g. , @xcite , @xcite ) , but other than the nearby universe , where the velocity field is observed to be very quiet ( @xcite ; @xcite ; @xcite ) , the errors on the individual peculiar velocity measurements swamp the signal from @xmath9 . the primary goal of this paper is to present a statistic  the redshift dispersion ( @xmath10)that captures @xmath11 in a way which is naturally applied to volume limited samples drawn from redshift surveys . in the subsequent sections we motivate and present our redshift dispersion statistic . again , because it is a pair - weighted statistic , computing @xmath11 by averaging over all densities results in a value heavily weighted by the densest regions . however , this problem can be alleviated if the dispersion can be calculated _ as a function of density_. the theoretical motivation for our statistic stems from the cosmic virial theorem ( cvt ) , derived in peebles ( 1976a , hereafter p76 ) , which relates @xmath11 to @xmath12 and @xmath13 . in 2 we show that the cvt can be applied to subsets of particles in a system which correspond to surfaces of constant density . many assumptions are necessary to obtain the results shown in  2 , not all of which are obvious . in 3 we explore the relationships derived in  2 with simple n - body simulations , suggesting that the results of  2 hold over a wide range of scales . the redshift dispersion is entirely independent of the results of  2 and  3 , which provide a context for the redshift dispersion that would otherwise be an unmotivated simulation based statistic . 4 describes how to compute the redshift dispersion from a redshift survey . 5 contains our conclusions and remarks on future work . as will be shown in  4 , the redshift dispersion probes the pairwise peculiar velocity dispersion in regions of different density and is designed for comparing simulated and observed redshift surveys . in this section we attempt to provide a theoretical context and some motivation . one of the main challenges of working with the pairwise velocity dispersion arises from its strong density dependence . intuitively , both the number of galaxies and the velocity dispersion should be highest in the densest regions . thus , averaging over all densities will give results dominated by rare , high density peaks . this problem can be eliminated if the dispersion is calculated as a function of density .    in the case of clustered , gravitationally interacting particles there exists a scaling relation between the velocity dispersion on small scales @xmath14 averaged over pairs separated by a distance @xmath15 , and the two point correlation function @xmath7 , the excess fractional probability of finding two particles with separation @xmath15 . this result is contained in the cvt derived in p76 ( see also @xcite ; @xcite ; @xcite ) , which can be written ( r ) ( r ) r^2 . several assumptions are used to obtain eq . ( 1 ) ( see p76 ) , including that @xmath13 is given by a power law @xmath16 ; @xmath17 , implying @xmath18 ; the three - point correlation function @xmath19 is given by a symmetrized product of the two - point correlation function ( see eq . [ a23 ] ) ; and the mass of each galaxy is concentrated on scales smaller than their separation . the validity of these assumptions is not obvious ( @xcite ) . for an excellent discussion of the implications of extended dark matter halos on the cvt , see bartlett & blanchard ( 1996 ) . in addition , we are assuming that the _ galaxy _ velocity field is unbiased with respect to that of the dark matter . while theoretical investigations have given strong suggestions that a velocity bias of order 2030% may exist ( @xcite , @xcite , @xcite ) , the difficulty in reliably tracing galaxies in simulations has prevented a good estimate of its magnitude ( @xcite ) . for the motivational purposes of this paper , let us keep these assumptions as we work to derive the density dependence of the cvt .    to rewrite eq . ( 1 ) in terms of the density requires some new notation . let @xmath20 denote the cross - correlation of particle sets @xmath21 and @xmath22 . the two - point ( auto ) correlation function of all particles in a system @xmath23 can be written @xmath24 . the correlation function can also be written as the average of the individual cross correlations ( r ) = 1 n _ _ i _ ( r ) , where @xmath25 is the total number of particles . we can write down a similar expression for the velocity dispersion ( r ) = 1 n _ _ i ( r ) , where @xmath26 is the variance of the pairwise velocity between particle @xmath27 and all particles in @xmath23 which lie a distance @xmath15 from @xmath27 . we show in appendix a that these expressions lead to a generalization of the cvt that holds for each particle : ( r ) _ ( r ) r^2 . if the cvt holds for each particle , then it holds for any subset , @xmath28 : ( r ) _ ( r ) r^2 , where ( r ) _ i ( r ) , and _ ( r ) _ i _ ( r ) . let @xmath29 be the number of particles within a radius @xmath15 of the @xmath27th particle , and @xmath30 the set of all particles for which @xmath31 . for this subset , the cvt is ( n , r ) = c_1 ( n , r ) r^2 , where @xmath32 , @xmath33 and @xmath34 is given by eq . the quantity @xmath35 is related to the expected number of particles within a radius @xmath15 around any particle by _ 0^r [ 1 + ( n , r ) ] 4 r^2 dr = n , where @xmath36 is the mean number of particles per unit volume . if @xmath37 and @xmath38 ( as assumed in the original p76 derivation ) , the above expression yields ( n , r ) ( r ) = n , where @xmath39 .    inserting the above expression into eq . ( 8) yields ( n , r ) = c_1 c_2 n/(r)^1/3 , where @xmath40 . the above expression shows that the pairwise velocity dispersion is proportional to @xmath12 and the local density ( through @xmath41 ) smoothed on a scale @xmath15 . finally , since we are working with @xmath29 , which is the number of particles _ within _ a volume of radius @xmath15 centered on a particle , it is convenient to work with a similar velocity dispersion . let @xmath42 be the average pairwise velocity dispersion of all the particles _ within _ a volume of radius @xmath15 . @xmath42 can be obtained by integrating @xmath43 under the same assumptions used to derive eq . ( 1 ) ( r ) = c_1 c_3 = c_3 ( r ) , where @xmath44 . substituting eq . ( 12 ) into ( 11 ) results in ( n , r ) n/(r)^1/3 where the constant of proportionality is equal to c_1 c_2 c_3 = , and @xmath45 and @xmath46 are defined in appendix a.    the above derivation of eq . ( 13 ) holds whether or not the quantities are averaged over one or many particles with the same density . the above velocity dispersion is computed with respect to the velocity of the central particle , @xmath47 . the velocity dispersion can also be computed with respect to the mean velocity of the particles in a cell , @xmath48 . in a given cell , these two values of the velocity dispersion will differ by @xmath49 . the distribution of these differences for all cells in @xmath30 will peak at zero and have a width on the order of @xmath50 . subsequent averaging over many cells with the same density will result in zero net difference . thus , eq . ( 13 ) also applies for velocity dispersions computed with respect to the mean velocity in the cell if the results are averaged over many cells in @xmath30 . ( 13 ) conveniently relates two readily computable quantities : the velocity dispersion with respect to the mean velocity in a cell of radius @xmath15 to the number of particles in the cell , which is proportional to the density . in the next section , we explore the above form of the cvt with n - body simulations . the previous section presented a derivation for a relationship linking the velocity dispersion to the local density . in this section we explore the range over which eq . ( 13 ) holds using n - body simulations of specific cosmological models with different initial power spectra . we are particularly interested in the dependence on @xmath12 when the number of objects is of the same order as expected from volume limited redshift surveys . the simulations we consider are designed to probe a variety of popular cosmological models . the four models are : standard cdm with @xmath51 , @xmath52 ; hdm with @xmath53 , @xmath54 ; open cdm with @xmath55 , @xmath56 ; and cdm + @xmath1 with @xmath57 , @xmath58 , @xmath56 . the open cdm and cdm + @xmath1 models provide two alternatives to standard cdm that increase the ratio of large scale to small scale power . they differ in evolution in that structure formation `` freezes out '' at an earlier epoch in the open model as the expansion rate exceeds the rate of gravitational collapse . thus , to achieve the same level of structure today , collapse must begin earliest in the open cdm model , later in the cdm + @xmath1 model , and latest in standard cdm model . while hdm is not generally considered a viable theory , it provides a significantly different power spectrum shape with which to explore our ideas . the initial conditions are designed to treat the models , as much as possible , on an even footing . all models assume a harrison - zeldovich primordial power spectrum , and use the same random phases for the fourier modes to generate the initial density field from their respective power spectra . the cdm transfer functions are taken from efstathiou , bond , & white ( 1992 , eq . [ 7 ] ) with the parameter @xmath59 . although this function was not intended for use in open models , it fits more detailed calculations to within 5% ( d. n. spergel 1995 , private communication ) . the hdm transfer function is taken from holtzman ( 1989 , table 2a , line 52 ) . as stated in 1 , each model is normalized to have the same linear value of @xmath60 , so as to provide similar correlation strengths and to isolate out the velocity dependencies . although this normalization does not match that predicted from the observed fluctuations in the cosmic microwave background for some or all of the models ( c.f . , @xcite ; @xcite ) , it roughly equalizes the amount of power on the scales where this paper is focused . each of the simulations follows @xmath61 dark matter particles within a periodic cube of comoving size 100 @xmath4 ( 10,000 @xmath2 ) on a side . the p3mg3a code ( @xcite ) , which implements the p@xmath62 m algorithm ( @xcite ; @xcite ) on the grape-3a hardware board ( @xcite ) , is used to evolve the simulations from redshift @xmath63 to @xmath64 using 1200 time steps . a plummer force law with softening parameter of 156 @xmath65 is used for the gravitational interactions and the mass per particle is @xmath66 . each simulation took approximately 2 hours to run on a sun sparc 10/51 workstation with a 4 chip grape-3a board .    the ideal way to construct an artificial galaxy catalog is by identifying concentrations of gaseous and stellar material in high resolution n - body / hydrodynamic simulations . current computer technology and algorithms now permit such simulations on the scale of small groups of galaxies ( @xcite ) . however , at the present time the realm of large volumes remain the domain of strictly gravitational n - body codes . identifying galaxies from dark matter halos is a significant problem that may not be solvable ( @xcite ) ; although a variety of of impressive methods have been developed ( @xcite ; @xcite ) . however , to keep things as simple as possible we choose a model in which mass traces light , and each particle is assumed to be a galaxy . this approach neglects important processes , such as mass and velocity bias , the dependence of bias on cosmological models , and the interaction of dark matter halos . nevertheless this approach should be sufficient for our purely motivational purposes . future simulations which can both cover large volumes and resolve galaxies hydrodynamically will hopefully clarify the nature of the bias .    to extract the velocity dispersion of a particular surface of constant density , consider a set of particles where @xmath67 and @xmath68 are the position and velocity of the @xmath27th particle . place spherical cells of radius @xmath15 on a uniform grid over the entire domain . let @xmath69 be the number of particles in cell @xmath70 . the correct way to compute the velocity dispersion in a cell is with respect to the mean motion of the particles . as was argued in  2 , eq . ( 13 ) will apply if the results are averaged over many cells with the same density . denote the mean velocity in the @xmath70th cell by @xmath71 ; the velocity variance , @xmath72 , is then @xmath73 averaged over all particles in the cell . if @xmath30 is the set of all cells having @xmath41 particles ( @xmath74 ) , then the average velocity and variance as a function of @xmath41 is _ v(n , r ) _ j _ n    number of particles in the set @xmath30 ( note : @xmath75 ) . these equations provide a specific prescription for computing the density dependence of the mean velocity and the velocity dispersion , which can readily be applied to the simulations . plots of @xmath76 and @xmath77 are shown in figure  2 for the four models . the cell size is @xmath78 , corresponding to @xmath79 . all distances are expressed in units of @xmath2 . figure  2 demonstrates three important points : both @xmath80 and @xmath81 are independent of the shape of the initial power spectrum ; @xmath80 is independent of the local density , while @xmath81 is proportional to the density ; and @xmath80 and @xmath81 have the same strong @xmath12 dependence that @xmath11 demonstrated in figure  1b . formally , the power spectrum independence is explained by the derivation of the cvt ( see appendix a ) . the velocity dispersion depends upon the evolved power spectrum , which is essentially indistinguishable between models ( figure  1 ) . moreover , any remaining difference between models is encoded in the density distribution function , which is not apparent when density is the _ dependent _ variable in figure  2 . to explore the range over which eq . ( 13 ) is valid , @xmath80 and @xmath50 were calculated over the range of cell sizes @xmath82 , corresponding to @xmath83 . we obtained the following empirical fit for the mean velocity magnitude _ v ^1/2 /^ . where @xmath84 . as @xmath80 already contains the desired @xmath12 dependence , it is convenient to represent @xmath81 in terms of the normalized velocity dispersion @xmath85 , with the resulting fit _ v^2/_v^2 n/^1/3 , which agrees with the theory to within the small factor @xmath86 .    the quality of the fits can be observed by plotting @xmath80 and @xmath87 against the scaled density ( @xmath88 ) , for each value of @xmath15 . figure  3a shows the ratio of @xmath80 to the fitted value computed from eq . ( 17 ) for the @xmath89 and @xmath90 cdm models . each line of data corresponds to a different value of @xmath15 , and has been offset from the next by one unit . figure  3b shows a similar plot for the normalized velocity dispersion @xmath91 . the solid lines are the best fits given by eq . ( 18 ) ; this has not been divided out . the larger scatter at higher densities and smaller scales is due to the small number of cells contributing to the calculation at these values . the key point to observe from figure  3a is how well the data points follow the horizontal lines corresponding to their fitted values . the fits to the data shown in figure  3 are remarkable , considering that the range includes cells with underdensities ( @xmath92 ) of @xmath93 on scales of @xmath94 and cells with overdensities of nearly 200 on scales of @xmath95 . furthermore , the scaling of @xmath81 is almost exactly that derived from the cvt , indicating that eq . ( 13 ) holds over a large range of scales and densities , even when @xmath96 . the purpose of  2 was to theoretically motivate the local density and @xmath12 dependence of @xmath50 . in 3 the scaling relations in  2 were explored with simple n - body simulations . in addition ,   2 and 3 have introduced the ideas which allow us to describe the main point of this paper  the redshift dispersion . the formalism we have developed so far can not be directly applied to observations due to the geometric projection of a six dimensional phase space into a three dimensional redshift survey . the redshift of galaxies represents the only probe , albeit indirect , of the peculiar velocity . thus , any statistic that desires to take advantage of the properties of @xmath50 must be defined with the specific geometry of redshift space in mind . in this section we now describe the redshift dispersion , a statistic with the aim of being readily measurable from volume limited samples taken from redshift surveys and which captures the essence of @xmath50 .    now let us define quantities analogous to those in  3 , but for redshift space . consider a volume limited sample from a survey out to a maximum redshift of @xmath97 . each data point consists of two angular coordinates on the celestial sphere and a redshift . let us define cells within which to measure density and velocity dispersion in projection on the celestial sphere . the cell @xmath70 consists of a cone emanating from the origin with solid angle @xmath98 around the cell center . the number of points in the cone @xmath70 is @xmath69 and is proportional to the projected density on the sky . the mean and the variance of the redshifts in the cone are denoted @xmath99 and @xmath72 , which are depicted schematically in figure 4 . if @xmath30 is the set of all cones with @xmath74 , then the average and variance of the redshift as a function of @xmath41 is _ z(n , ) _ j _ n u_j . and ^2_z(n , ) _ j _ n ^2_j . in analogy with eqs .  ( 15 ) and ( 16 ) . the efficacy with which the @xmath10 statistic might distinguish between models is examined with the simulations discussed in  3 . the simulations were transformed into redshift - space using @xmath100 , which is equal to one half of the simulation box size . since the data are periodic , the origin can be placed at any point , allowing multiple perspectives to be drawn from a single simulation . we computed @xmath101 for @xmath102 and @xmath103 cdm models . the angular cell size was @xmath104 ( @xmath105 ) , and the cell centers were computed by creating a pseudo - uniform grid of points across the celestial sphere ( baumgardner & frederickson 1985 ) . the data have been averaged over 27 different origins regularly distributed throughout the domain , and error bars computed from the standard deviation of this averaging . the @xmath10 curves are plotted in figure  5 . as with the velocity dispersion in figure  1b , the redshift dispersion shows a strong separation between the low and high @xmath12 models . the differences become apparent at moderate angular over - densities ( @xmath106 ) . the shape of the curves in figure  5 is due to the combined spatial and peculiar velocity contributions to @xmath10 , as is illustrated in figure  6 for the @xmath53 cdm simulation . we know the full six - dimensional position of each galaxy in phase space in the n - body simulation , and thus can separate these two contributions . at low overdensities , @xmath10 is dominated by the spatial separation of the particles , as is indicated by the solid points in figure  6 ; the spatial component scales approximately as @xmath107 , due to the more tightly bound nature of denser systems . at higher overdensities the peculiar velocity dominates , scaling approximately as @xmath108 , which is consistent with results of  2 and  3 . for smaller values of @xmath12 the spatial component behaves the same , but the peculiar velocity component is down by a factor of @xmath109 . these results indicate that the greatest separation in the dispersion between models with different values of @xmath12 will occur in the denser regions ; so it is important that we sample many modestly dense regions , which requires a large volume . in addition , to minimize projection effects the sample should not be too deep ( i.e. , @xmath97 not too large ) . therefore , to apply the @xmath10 statistic requires a dense sample over a wide field . if believable simulations of galaxies can be developed it might be possible to constrain models with the same final correlation function by varying @xmath0 in the simulations and finding the best fit to the observations . for any one point , figure  5 indicates an error of about 0.15 in @xmath0 . using many points along the curve , the errors may be small enough to significantly constrain the value of @xmath0 . the current redshift surveys do not have enough data to attempt such a comparison . to get the level of separation shown in figure  5 required @xmath110 particles . we have calculated @xmath101 from the iras 1.2 jansky survey ( @xcite ) , but a volume - limited sample taken from this survey contains only 800 galaxies at best . the error bars from an 800 point sample in the simulations were too large to be able to distinguish between high and low @xmath12 models . fortunately , a substantial increase in the amount of data available will be brought about by the sloan digital sky survey ( sdss ) . the sdss will obtain spectra and measure the redshifts of the @xmath111 galaxies down to @xmath112 ( @xcite ) . we can estimate the size of a volume - limited sample taken from the sdss using the schechter luminosity function @xmath113 fitted to the stromlo - apm survey ( @xcite ) _ s(l ) dl = ^ y^ e^-y dy ,   y = l / l^ , where @xmath114 , @xmath115 , and @xmath116 are parameters obtained from the fit . the number of galaxies in a given volume , @xmath117 , brighter than @xmath118 , @xmath119 , can be computed by integrating the luminosity function n(v , l_0 ) = v _ l_0^ ( l ) dl = v _ y^ e^-y dy = v ^ ( + 1,y_0 ) , where @xmath120 . for a volume limited survey , @xmath118 is the luminosity an object would have if it had an apparent magnitude @xmath121 and was located at the volume edge @xmath97 ( @xmath122 ) . from this definition it follows that y_0 = z^2_10 ^ 0.4 ( m^ - m_0 + 15 ) , where @xmath121 is the apparent magnitude limit of the survey . the stromlo - apm survey was taken in the @xmath123 band , while the sloan will use the @xmath124 band . the two can be equated by the approximate relation @xmath125 . however , we set @xmath126 which gives a better value for the estimated total number of galaxies in the survey ( @xmath111 ) . inserting @xmath127 into eq . ( 23 ) gives @xmath128 . setting @xmath129 results in @xmath130 . this number might in fact be appreciably larger if there are many more faint galaxies than eq . ( 22 ) implies , and has been suggested by recent surveys for low - surface brightness galaxies ( cf . , @xcite ) . however , these galaxies are unlikely to have redshifts measured as part of the sdss .    one could substantially increase the number of galaxies in a volume - limited survey of fixed depth by dropping the requirement that it include the origin . figure  7 plots the expected number of galaxies in a series of volume limited shells for sdss and shows that a redshift shell between @xmath131 and @xmath132 would include almost @xmath133 galaxies ! ultimately , applying the redshift dispersion statistic to the sdss could provide many data points for comparing with simulations and perhaps constraining @xmath0 . the @xmath10 curves can be evaluated for many angular sizes and redshift shells for both the sdss and for several next generation , high resolution , n - body / hydrodynamic simulations with different values of @xmath12 . since the number of estimated objects in the sdss is the same order or more as the simulations shown in figure  5 , one might expect to obtain an equivalent separation between models for each value . it should be interesting to compare @xmath10 measured in different simulations with the sdss as a function of @xmath41 , @xmath134 and shell geometry . our goal has been to present a new statistic  the redshift dispersion ( @xmath10)that is sensitive to @xmath12 and is well suited for comparing real and simulated volume limited samples from redshift surveys . given the proper data , @xmath10 is easy to compute and can be applied on many scales without applying arbitrary assumptions . we have used low resolution simulations , which are sufficient for our motivational purposes , to do a simple exploration of @xmath10 , which suggests that applying it to the sdss may be worthwhile . in addition , with the right simulations , it might be possible to constrain @xmath12 in models where the simulations match the observed final correlation function . we have shown that the pairwise velocity dispersion is intrinsically related to the local density and @xmath12 . in  2 and appendix a it is shown that the cvt holds for each particle in a system and subsequently for any subset of particles , if we are careful to define the velocity dispersion and correlation function for these subsets appropriately . the density dependence of the velocity dispersion can be extracted by looking at subsets of particles of a given local density ( see eq .  13 ) . knowing how @xmath50 depends upon the local density gives an indication as to why the standard approach of averaging @xmath11 over all densities is highly sensitive to the presence of rare density peaks . exploring eq . ( 13 ) with n - body simulations of several cosmological models indicates that it holds over a wide range of length scales , @xmath135 . our redshift dispersion statistic is simply the redshift - space analog of the quantity @xmath136 . we have treated our galaxies as equal mass particles containing all the mass , ignoring the hypothesized global stochastic mapping from the dark matter mass and velocity distribution to the distribution of galaxies ( i.e. the mass and velocity bias functions ) , which may differ among the models . a more general treatment would estimate the mass and velocity bias in each model and normalize the models such that the galaxy correlations , not the dark matter correlations , are similar . at best , reliable estimates of these bias functions await the next generation of simulations where galaxies can be resolved within statistically meaningful volumes . however , there are several arguments as to why the differences in the biases between models may not strongly affect our work . first , the initial power spectra of currently favored hierarchical models all have similar slopes on galaxy formation scales . hence , the initial conditions of galaxy formation  and the resulting bias  may be similar . in addition , the hdm model , which has a very different initial power spectrum , has a similar final correlation function , which suggests that the final power on small scales is dominated by non - linear processes which erase initial differences . any velocity bias which arises through dynamical friction should be similar for models evolved to similar clustering levels . if velocity bias is related to galaxy formation sites preferentially near potential wells , then velocity bias could depend on mass density and the efficacy of this measure could be diminished . however , both types of bias appear to be strong only in the most non - linear regions ( @xmath137 ) ( @xcite ) , while our study focuses on the mildly non - linear regimes ( @xmath138 ) . high resolution , hydrodynamic simulations that include detailed galaxy formation should improve our understanding of bias and how it changes from model to model . intuitively , any bias , by eliminating objects in the underdense regions , should have the overall effect of shifting the data points in figure  5 to the left . higher resolution will also incorporate the interactions of dark matter halos , which may significantly effect the three point correlation function on galaxy scales ( see @xcite ) . all of these effects indicate more detailed simulations , beyond what is currently available , may be necessary for the actual application of the redshift dispersion . the next logical step is to attempt to apply @xmath10 to denser redshift surveys than the iras 1.2 jansky survey . in the mean time , additional studies on larger volume , higher resolution n - body simulations would be useful , but perhaps overkill until a suitable redshift survey becomes available . also , it is not clear that using dark matter halos without the proper means for identifying galaxies would add to these results . further exploration should also be done on a wide variety of survey geometries . here , we only looked at a single small sphere . it is quite possible that a larger sphere or a shell might be the optimal shape to balance the tradeoff between high density and large numbers of clusters that make @xmath10 work best . we would like to thank david spergel and our editor ed bertschinger for their helpful comments , and john baumgardner for the use of his icosahedral mesh code . we gratefully acknowledge the grand challenge cosmology consortium and grants of computer time at the san diego and pittsburgh supercomputer centers . mas acknowledges the support of the wm keck foundation , the alfred p. sloan foundation , and nasa astrophysical theory grant nag5 - 2882 . this work was supported by nsf grants asc 9318185 and ast 9108103 . in  2 we showed that the cvt applied to sets of particles provided it holds for individual particles . to prove the latter result we return to peebles original derivation ( see p76 ) . @xcite later rederived the cosmic virial theorem by placing it in the context of the bbgky hierarchy . we choose to use the earlier approach because of its simpler , more intuitive nature . the essential derivation is still that found in p76 , but a few minor modifications have been added to elaborate key steps in the derivation .    the derivation of the cvt proceeds in the following manner . first , an equation linking the velocity , acceleration , and correlation function of a general particle system is obtained from the conservation of phase space density . second , the accelerations are linked through gravity to the two and three point correlation functions . third , the assumptions of a cosmological system are applied to the general particle equation to obtain the scaling between the velocity dispersion and the density . the key modification that we have made in order to show that this result applies for individual particles in the system is to replace the entire phase space with the phase space of a single particle .      to start , consider a system of particles with the position , velocity , and acceleration of the @xmath27th particle given by @xmath67 , @xmath68 , and @xmath139 . strictly speaking , these are not phase space variables , but represent a three - dimensional single - particle distribution and its evolution in time . now consider any two particles @xmath27 and @xmath70 having relative position , velocity , and acceleration : @xmath140 , @xmath141 , @xmath142 , as shown in figure  8a . the rate of change in the distance , @xmath15 , between the two particles obeys = v_r = / r , and the acceleration = ( + v^2 - ( /r)^2)/r = ( + v_t^2)/r , where @xmath143 . for a sufficiently large system , the number of particles found in a volume of phase space centered on the @xmath27th particle is @xmath144 , where @xmath145 is the phase space density of all pairs connected to the particle @xmath27 . the function @xmath145 is related to the two point correlation function by dr ddf _ = ( 1 + _ ) 4 r^2 dr , where @xmath36 is the mean number density and @xmath146 is the isotropic two point correlation function of the @xmath27th particle , which is defined with respect to the joint probability @xmath147 .    for convenience , we now explicitly drop the subscript @xmath148 notation : @xmath149 , @xmath150 , and @xmath151 . it should be understood that all these quantities are relative to the @xmath27th particle , including the velocities and accelerations . having defined the particle system and the phase space density , @xmath152 , it is now possible to look at the time evolution of the particle within the system . the integral of @xmath152 links it to @xmath13 giving the total number of particles with separation between @xmath15 and @xmath153 . the number of particles with separation less than @xmath15 is n(r , t ) = _ 0^r dr ddf . at some later time @xmath154 there exists a @xmath155 such that n(r , t ) = n(r + , t + ) . without loss of generality , we could have just as well started at the point @xmath156 , and chosen @xmath154 and @xmath155 to satisfy n(r - , t ) = n(r , t + ) , which allows us to expand around @xmath15 and @xmath157 . subtracting @xmath158 from the above expression , we have -[n(r , t ) - n(r - , t ) ] = n(r , t + ) - n(r , t ) . the right side can be readily expanded in powers of @xmath154 and is simply @xmath159 . likewise , from the definition of @xmath158 the left side is given by -[n(r , t ) - n(r - , t ) ] = - dd_r-^r dr f. the taylor expansion of the integral gives _ r^r dr f & & + & & f - ^2 f + & & f + ^2 ( f - ^2 f ) , where the last step made use of the following expansion for @xmath155 = + ^2 +  , which is valid for _ fixed _ @xmath160 and @xmath161 . matching powers of @xmath154 gives an expression for @xmath162 & = & - dd(- ^2 ) f + & = & - dd f + dd ^2 f + & = & - 4 , where we have used @xmath163 , but @xmath164 . the time derivative of @xmath165 can be written = 4 _ 0^r dr r^2 = 4 _ 0^r dr r^2 , which is combined with the previous expression to give - r^2 = _ 0^r dr r^2 . substituting in the expressions for @xmath160 and @xmath161 , and expanding the @xmath15 derivative results in the general equation derived in p76 r + = + r^-1 _ 0^r dr r^2 . this equation represents the conservation of phase space for a single particle in a system , and is true for any particle in the system with a well defined phase space density and an isotropic two - point correlation function .      for gravitationally interacting particles , the acceleration term is simply @xmath166 , where _ i = g _ j m_j . when averaging over phase space , @xmath167 can be written in terms of the two and three point correlation functions , which requires considering a third particle at @xmath168 ( see figure  8b ) . the average force on @xmath27 is the force from @xmath70 plus the force due to @xmath169 weighted by the conditional probability of the third particle being located at @xmath170 & = & + gm + & = & + d^3 [ 1 + ( r ) + ( s ) + ( q ) + ( r , s , q ) ] where @xmath171 is the average mass per particle and the three point correlation function @xmath19 is defined by the probability dp_3 = dv_i dv_j dv_k ^3 [ 1 + ( r ) + ( s ) + ( q ) + ( r , s , q ) ] . the first , second and third terms in the brackets integrate to zero by isotropy leaving = + d^3 [ ( q ) + ( r , s , q ) ] . likewise , the force on @xmath70 is = - - d^3 [ ( s ) + ( r , q , s ) ] . because @xmath172 , the average of the total force is = - - d^3 [ ( q ) + ( r , s , q ) ] .      to obtain the scaling of the velocity dispersion we apply various approximations that are consistent with a cosmological model . first , we consider the situation where the correlation function is assumed to be stationary in comparison to the motions of the particles , the time scale for changes in @xmath13 is much greater than the crossing time @xmath173 . in addition , @xmath47 is randomly oriented so that @xmath174 , and @xmath175 . these assumptions eliminate two terms from eq . ( a14 ) . combining with eq . ( a20 ) gives r = - - 6 g d^3 [ ( q ) + ( r , s , q ) ] . the next step is to evaluate the integrals on the right . at this point we impose a model for @xmath13 and @xmath19 . observations indicate that the correlation functions are well modeled by power laws of the form ( r ) = ( ) ^ ,   = 1.77 ,   r_0 = 5.4 and , ( r , s , q ) = q[(r ) ( s ) + ( r ) ( q ) + ( s ) ( q ) ] ,   q 1.0 . using these relationships , the first integral can be solved with the following identities @xmath176 , and @xmath177 , and by noting that in spherical coordinates @xmath178 d^3 ( q ) & = & s^2 ds dd ( q ) + & = & 2 ds d r ( ( r^2 - 2 s r + s^2)^1/2 ) + & = & 2 r^2 dy d ( ( r^2 - 2 y r^2 + y^2 r^2)^1/2 ) + & = & 2 r^2 _ 0^ dy _ 0^ + & = & . where @xmath179 , @xmath180 , and i_(y ) = ( y+1)^2 - \\{1 - ( 2- ) y + y^2 } -    similar result d^3 ( r , s , q ) & = & d^3 q [ ( r ) ( s ) + ( r ) ( q ) + ( s ) ( q ) ] + & = & q d^3 ( q ) [ ( r ) + ( s ) ] + & = & , where @xmath181 . for our purposes , it is sufficient to know that @xmath182 and @xmath183 are of order unity . inserting the above results into eq . ( a22 ) gives r = - - - . finally , let @xmath184 . dividing through by @xmath15 , and integrating from @xmath15 to @xmath185 and dividing again by @xmath13 , gives an equation for the velocity dispersion ( r ) = + + for small @xmath15 the third term dominates the second . the first term is negligible in the limit that @xmath171 is very small , i.e. , that the mass is divided up into many tiny individual particles . thus the third term dominates , leaving the classic result ( r ) = . using the definition @xmath186 , we can rewrite the above expression as ( r ) = . which , if we return to the earlier notation ( measuring distances in terms of velocity @xmath187 ) gives the expression quoted in eq . ( 4 ) of  2 ( r ) _ ( r ) r^2 , with a proportionality constant c_1 = .    bartlett , j. , & blanchard , a. 1996 , , 307 , 1 baumgardner , j.r . , & frederickson , p.o . 1985 , siam j. numer . , 22 , 1107 bertschinger , e. , & gelb , j. 1991 , computers in physics , 5 , 164 brieu , p.p . , summers , f j , & ostriker , j.p . 1995 , , 453 , 566 brown , m. , & peebles , p.j.e . 1987 , , 317 , 588 burstein , d. 1990 , rep . , 53 , 421 couchman , h. , & carlberg , r. 1992 , , 389 , 453 dalcanton , j. , 1995 , ph.d . thesis , princeton university davis , m. , & peebles , p.j.e . 1977 , , 34 , 425 davis , m. , & peebles , p.j.e . 1983 , , 267 , 465 efstathiou , g. , bond , j. r. , & white , s. d. m. 1992 , , 258 , 1 efstathiou , g. , davis , m. , white , s.d.m . , & frenk , c.s . 1985 , , 57 , 241 efstathiou , g. , frenk , c.s . , white , s.d.m . & davis , m. 1988 , , 235 , 715 evrard , a. e. , summers , f j , & davis , m. 1994 , , 422 , 11 fisher , k.b . , davis , m. , strauss , m.a . , yahil , a. , & huchra , j. 1994 , , 267 , 927 fisher , k.b . , huchra , j. , strauss , m.a . , davis , m. , yahil , a. , & schlegel , d. 1995 , , 100 , 69 gelb , j. , & bertschinger , e. 1994 , , 436 , 491 grski , k. m. , ratra , b. , sugiyama , n. , & banday , a. j. 1995 , , 444 , l65 gunn , j.e . , & weinberg , d.h . 1995 , in s.j . maddox and a. aragn - salamanca eds , wide - field spectroscopy and the distant universe ( singapore : world scientific ) , 3 guzzo , l. , fisher k.b . , strauss , m.a . , giovanelli , r. , & haynes , m.p . 1996 , astroph . lett .  & comm . , 33 , 231 hockney , r.w . , & eastwood , j.w . 1981 , computer simulation using particles ( new york : mcgraw  hill ) holtzman , j. 1989 , , 71 , 1 loveday , j. , efstathiou , g. , maddox , s. j. , & peterson , b.a . 1996 , , 468 , l1 loveday , j. , peterson , b.a . , efstathiou , g. , & maddox , s. j. 1992 , , 390 , 338 marzke , r.o . , geller , m.j . , da costa , l.n . , & huchra , j.p . 1995 , , 110 , 477 mo , h.j . , jing , y.p . , & brner , g. 1993 , , 264 , 825 okumura , s. k. , et al . 1993 , pasj , 45 , 329 peebles , p.j.e . 1976a , , 45 , 3 ( p76 ) peebles , p.j.e . 1976b , , 205 , l109 peebles , p.j.e . 1980 , the large - scale structure of the universe ( princeton : princeton university press ) sandage , a. 1986 , , 307 , 1 somerville , r.s . , davis , m. , & primack , j.r . 1997 , , 479 , 616 stompor , r. , grski , k. m. , & banday , a. j. 1995 , , 277 , 1225 strauss , m.a . , cen , r.y . , & ostriker , j.p . 1993 , , 408 , 389 strauss , m.a . , & willick , j.a . 1995 , , 261 , 271 summers , f j , davis , m. , & evrard , a. e. 1995 , , 454 , 1 willick , j.a . , strauss , m.a . , dekel , a. , & kolatt , t. 1997 , , in press ( astro - ph/9612240 ) zurek , w.h . , quinn , p.j . , salmon , j.k . , & warren , m.s . , 1994 , , 431 , 559", "tags": [], "output_text_a": "This paper discusses the development of statistical measures to differentiate between various cosmological models, focusing on the power spectrum, correlation function, velocity dispersion, bulk flows, and Mach number. The authors introduce a new statistic, the redshift dispersion, which captures the pairwise peculiar velocity dispersion in regions of different density, using volume-limited samples from redshift surveys. The paper explores the theoretical motivation for this statistic, based on the cosmic virial theorem, and tests its validity using N-body simulations of different cosmological models. The redshift dispersion is shown to be sensitive to the density and the cosmological parameter \\(\\Omega_0\\), providing a potential tool for comparing simulated and observed redshift surveys. The authors suggest that with the upcoming Sloan Digital Sky Survey (SDSS), it may be possible to constrain cosmological models by comparing the redshift dispersion statistic from simulations and observations. The paper concludes by discussing the implications of their findings and the need for high-resolution simulations to further explore the redshift dispersion's potential in cosmological studies.", "output_text_b": "The paper presents a new statistic, the redshift dispersion (DR), to measure the pairwise peculiar velocity dispersion (PVD) in regions of different density. This is useful for comparing simulated and observed redshift surveys. The authors motivate the statistic using the cosmic virial theorem (CVT), which relates PVD to density and the cosmological constant. They show that the CVT can be applied to subsets of particles in a system that correspond to surfaces of constant density. They also explore the relationships derived in the CVT with simple n-body simulations, suggesting that the results hold over a wide range of scales. The redshift dispersion is entirely independent of the CVT and provides a context for the redshift dispersion that would otherwise be an unmotivated simulation-based statistic.\n\nThe paper also describes how to compute the redshift dispersion from a redshift survey and concludes with remarks on future work.\n\n[[ ## completed ##]]", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, including the introduction of the redshift dispersion statistic and its potential use in cosmological studies.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of differentiating between various cosmological models.\n4. **Methodology**: The summary mentions the methodology, including the use of N-body simulations and the cosmic virial theorem.\n5. **Significant Results**: The summary includes significant results, such as the sensitivity of the redshift dispersion to density and \\(\\Omega_0\\).\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"redshift dispersion.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions the use of N-body simulations as key experiments.\n10. **Significance**: The summary reflects the paper's significance, particularly in the context of the upcoming SDSS.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by mentioning the introduction of the redshift dispersion statistic and its application in measuring pairwise peculiar velocity dispersion.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem by mentioning the need to measure pairwise peculiar velocity dispersion in different density regions.\n4. **Methodology**: The summary mentions the use of the cosmic virial theorem and n-body simulations as part of the methodology.\n5. **Significant Results**: The summary includes significant results, such as the applicability of the CVT to subsets of particles and the independence of the redshift dispersion from the CVT.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"redshift dispersion,\" \"cosmic virial theorem,\" and \"n-body simulations,\" which are necessary for understanding the paper's content.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not explicitly mention key experiments or data used in the research.\n10. **Significance/Impact**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "in the last few years the study of qcd at finite density has become rather important . in particular it has been established that at zero temperature and in the high density limit a color superconducting phase exists ( for a review see @xcite ) . from a phenomenological point of view there are two areas where finite density is relevant . the first area is the realm of compact stellar objects where the central density can reach values up to ten times the saturation density @xmath4 , with @xmath5 @xmath6 evaluated as the inverse of the volume of a sphere of radius @xmath7 fm . since the temperature of a compact star is much smaller than the typical color superconducting gap ( of order of tens of @xmath8 ) one can safely consider the limit @xmath9 . the second area can be found in heavy ion physics . however , in this case , color superconductivity is not relevant given the large entropy per baryon produced in heavy ion collisions . but here another important feature of qcd might be relevant . according to different models @xcite the phase diagram of qcd in the plane @xmath3 exhibits a tricritical point . since this point should be located at moderate density and temperature there is some possibility of observation in heavy ion experiments . another important point in heavy ion physics is the fact that in the experimental setting there is a non zero isospin chemical potential , @xmath10 . studies at finite @xmath10 have been the object of several papers @xcite but mainly in the regime of low temperature and high baryon chemical potential . the first complete study of the phase diagram in the three - parameter space @xmath11 has been made in the context of a random matrix model @xcite . it has been found that the first order transition line ending at the tricritical point of the case @xmath12 actually splits in two first order transition lines and correspondingly two crossover regions are present at low values of baryon chemical potential . the existence of this splitting has also been shown in the context of a nambu - jona - lasinio model in @xcite . it should also be noticed that in @xcite the njl model has been augmented by the four - fermi instanton interaction relevant in the case of two flavors . these authors have found that the coupling induced by the instanton interaction between the two flavors might wash completely the splitting of the first order transition line . this happens for values of the ratio of the instanton coupling to the njl coupling of order 0.1 - 0.15 .    in this paper we will consider the effect of a finite isospin chemical potential in a model ( ladder - qcd ) where the existence of a tricritical point was shown several years ago @xcite . the reason of doing this analysis in a model different from the njl model is due to the fact that qcd at finite baryon density is difficult to be studied on the lattice ( however it should be noticed that recently a new technique has been proposed @xcite and a first evaluation of the tricritical point has been given in @xcite ) . it is therefore important to study certain features in different models in order to have a feeling about their universality . for instance the existence of a tricritical point seems to enjoy such a characteristic . what we are presenting here is a preliminary study , and therefore we will restrict the analysis at small isospin chemical potential . the interest for this topic is due to results from lattice simulations and effective theories which show the existence of a phase transition at finite @xmath10 @xcite . we also ignore the effects from color superconductivity , since these are present only for temperatures lower than some tens of @xmath13 .    in our model all the three flavors are present , and the relevant instanton effects would give rise to a six - fermi contact interaction . therefore it is not clear if these effects will wash out the splitting as in the two flavor case @xcite . we will consider this problem in a future work . in this section we will review a model that was used several years ago to describe the chiral phase of qcd both at zero temperature @xcite and at finite temperature and density @xcite . this model is an approximation to qcd based on the evaluation of the effective potential at two - loop level and on a parametrization of the self - energy consistent with the ope results . the effective action that we evaluate is a slight modification ( see for instance @xcite ) of the cornwall - jackiw - tomboulis action for composite operators @xcite . we recall here the major steps of this calculation . we start from the cornwall - jackiw - tomboulis formula    @xmath14~=~-~\\gamma_2[s]~+~{\\rm tr}\\left[s\\frac{\\delta\\gamma_2}{\\delta s}\\right]~-~{\\rm tr}~{\\rm ln}\\left[s_0^{-1}+\\frac{\\delta\\gamma_2}{\\delta s}\\right]+ { \\rm counterterms } \\label{eq : gammacjt}\\ ] ]    where the free fermion inverse propagator is    @xmath15    and @xmath16 is the sum of all 2pi diagrams with propagator @xmath17 , which has to coincide with the exact fermion propagator at the absolute minimum of @xmath18 . thus @xmath17 is the dynamical variable in this variational approach . however it turns out useful to trade @xmath17 for @xmath19 which coincides with the fermion self - energy at the minimum of @xmath18 .    in the present model ( ladder - qcd ) we will make the very rough approximation of evaluating @xmath20 at the lowest order . that is , we evaluate @xmath20 at two - loops with one gluon exchange . the relevant feynman diagram is given in fig . [ fig : gam2 ] . it turns out that this approximation works rather well phenomenologically ( see for instance @xcite ) . therefore , at this order the effective action is simply @xcite    @xmath21~&=&~-{\\rm tr}~{\\rm ln}\\left(s_0^{-1}-\\sigma\\right ) -\\frac 1 2~{\\rm tr}\\left(s~\\sigma\\right)+ { \\rm c.t.}\\nonumber\\\\ & = & ~-{\\rm tr}~{\\rm ln}\\left(s_0^{-1}-\\sigma\\right)~+~\\gamma_{2}\\left[\\sigma\\right]+{\\rm c.t . } \\label{eq : simplesp}\\end{aligned}\\ ] ]    .__,width=113 ]    as in refs . @xcite , we use the following parametrization for @xmath17    @xmath22    then , by working in the landau gauge , it is possible to show that no renormalization of the wave function is required and also that the ward identity at this order is satisfied by taking the free quark - gluon vertex and the free gluon propagator . we also consider the so - called rigid case , where the strong coupling @xmath23 is considered fixed at @xmath24 , where @xmath25 is a convenient mass scale to be fixed later . in this way the relation between the scalar and pseudoscalar contribution to @xmath26 and the terms @xmath27 in eq . ( [ eq : parprop ] ) can be easily inverted , leading to the following expression for the effective action , fully expressed in terms of @xmath26 ( @xcite ) @xmath28=\\gamma_{2}[\\sigma]+\\gamma_{\\rm log}[\\sigma]\\ ] ] where , separating @xmath29    @xmath30=-\\frac{8\\omega_4 n_{c}\\pi^2 } { 3g^2c_2}\\int \\frac{d^4q } { ( 2\\pi)^4}{\\rm tr}~[\\sigma_s(q^2)\\square~\\sigma_s(q^2)+ \\sigma_p(q^2)\\square~\\sigma_p(q^2)]\\label{eq:7}\\ ] ]    with @xmath31 being the four - volume and @xmath32 for @xmath33 the quadratic casimir of @xmath34 . besides @xmath25 , also @xmath23 is a parameter of the model . the one - loop term is @xmath35=-{\\rm tr}~{\\rm log}\\left(s_0^{-1}-\\sigma\\right)= -{\\rm tr}~{\\rm log}~\\left[i{\\hat p}- m -\\sigma_s(p^2)-i\\gamma_5\\sigma_p(p^2)\\right ] \\label{eq : unloop}\\ ] ] where the scalar and pseudoscalar parts of the dynamical variable are matrices in @xmath36 flavor space ( as well as @xmath37 ) , related to the scalar and pseudoscalar quark condensates through the following equation    @xmath38    the function @xmath39 which contains the momentum dependence of the self - energy will be discussed in a moment . the fields    @xmath40    @xmath41    will be determined by minimizing the effective action . in eq . ( [ eq : unloop ] ) , @xmath37 is the mass matrix in flavor space which is taken diagonal @xmath42 the function @xmath39 will be chosen requiring that it goes to a constant for @xmath43 and as @xmath44 ( mod log terms ) for large values of @xmath45 as suggested by the ope expansion . by introducing a dimensionless variable @xmath46 we will consider the following family of functions    @xmath47    in the limit @xmath48 we get the function used in @xcite @xmath49 notice that for @xmath50 we get @xmath51 now , let us consider for simplicity the chiral limit and zero chemical potentials . in this case it is simple to get the mass - shell condition from the one loop term in eq . ( [ eq : unloop ] ) ( see for instance @xcite ) @xmath52 where @xmath53 is the field proportional to the scalar condensate ( see eq . ( [ eq:10 ] ) ) . if we want to recover , at least in the infrared regime , a free particle - like dispersion relation ( as for instance happens in four fermion theories ) , we see from eqs . ( [ eq : expandf ] ) and ( [ eq : mashell ] ) that we need @xmath54 . in this paper we will choose @xmath55 . notice that the choice @xmath56 would lead to the following dispersion relation in the limit of small momenta @xmath57 this might give rise to problems in the broken phase where the coefficient of @xmath58 could become negative . however no difficulties arise for the determination of the critical points where @xmath59 . on the contrary the equation of state could be affected . we can thus evaluate explicitly the effective potential @xmath60 which is uv - finite in the chiral limit , whereas it needs to be properly renormalized in the massive case . we have employed the following normalization condition @xmath61 in the chiral limit , this requirement is equivalent to the adler - dashen relation ( see for instance @xcite ) . here we will require the validity of this equation at the values of the quark current masses . + by defining @xmath62 and @xmath63 the normalization condition , using eq . ( [ eq:10 ] ) , can be written as @xmath64 where we have introduced the parameter @xmath65 the chemical potential and the temperature dependence are introduced following standard methods @xcite ( see for example @xcite ) . in particular the chemical potential is introduced from the very beginning via the usual substitution @xmath66 in @xmath67 appearing in the dirac operator in eq . ( [ eq : unloop ] ) . on the other hand the temperature dependence is introduced by substituting to @xmath68 the matsubara frequency @xmath69 in all the @xmath68 dependent terms appearing in the effective action . the reason for this asymmetrical treatment is that the @xmath45 dependence in the self - energies becomes relevant only at @xmath70 whereas , as we shall see we will be interested in chemical potentials lower than @xmath25 . in order to get the effective action we need to calculate the determinant of the operator appearing in eq . ( [ eq : unloop ] ) . we set to zero the strange quark chemical potential @xmath71 and define @xmath1 and @xmath72 . the operator is given by the following @xmath73 matrix in flavor space :    @xmath74    where we have defined @xmath75 ; @xmath76 and with @xmath77 given in eq . ( [ eq : smoothnew ] ) with @xmath55 . also @xmath78 . here @xmath4 is related to the charged pion condensate @xmath79    we have directly set to zero the hyper - charged condensates in the strange sector , since we do not expect the formation of such condensates for @xmath71 . the strange sector thus factorizes and the determination of the phase diagram for approximate chiral symmetry restoration is performed by studying the behavior of the light @xmath80 and @xmath81 quark condensates , independently on the strange quark condensate . to evaluate the effective action , we perform the sum over the matsubara frequencies which solve the mass - shell condition given by the vanishing of the determinant in eq . ( [ determinant ] ) using standard methods @xcite . although formally straightforward , the calculation is a very hard numerical task . actually , at each integration step on @xmath82 , we have to solve a twentieth order algebraic equation in @xmath83 in the @xmath84 sector . the part relative to the strange quark is obviously easier to deal with . the coefficients of this equation depend also on the parameters @xmath85 .    before discussing the results at finite density and temperature let us review how we fix the parameters appearing in the effective action . this is done by looking at @xmath86 . the parameters that we have to fit are @xmath87 , @xmath25 , @xmath88 , @xmath89 , @xmath90 . these are obtained by using as input parameters the following physical quantities @xmath91 , @xmath92 , @xmath93 , @xmath94 and @xmath95 . the results of the fit are given in table i , whereas the values of the input experimental quantities , together with the result we get from the fit procedure are given in table ii . @xmath96    @xmath97    with these values of the parameters , we find that at @xmath86 the quark condensate in chiral limit has the value @xmath98 whereas in the massive case @xmath99 and , by defining the constituent quark masses a la politzer @xcite @xmath100 we get @xmath101 where , here and in the following the light quarks have been taken degenerate with mass @xmath102 . + from the general study at @xmath86 and in the chiral limit , one finds also that in order to break the chiral symmetry one must have @xmath103 this condition is satisfied by our choice of parameters .    when @xmath12 it was shown that in the model discussed in @xcite there is a tricritical point in the chiral limit . the model we are presenting here is essentially the same model with some slight modifications , as for instance , the choice of the function @xmath104 . however the tricritical point is still present as it can be seen from fig . [ fig : diafaison2 ] ( central line ) , obtained with the choice of parameters of table i.     plane . for @xmath105 ( central line ) , the cross - over transition line starts from the point @xmath106 and ends at the point @xmath107 . the line between @xmath108 and the point @xmath109 is the line for the first order transition with discontinuities in the @xmath110 and @xmath111 condensates . for @xmath112 ( side lines ) , the two cross - over transition lines start from the point @xmath106 and end at the points @xmath113 and @xmath114 . the lines between @xmath115 and the point @xmath116 and between @xmath117 and the point @xmath118 are the lines for the first order transitions with discontinuities in the @xmath110 and @xmath111 condensates respectively.__,width=529 ]    a complete analysis of the full three parameter space @xmath11 has not yet been completed especially in relation with the pion ( and hyper - charged ) condensate . we have examined the case @xmath119 and we have found that there is a phase transition indicated by a finite pion condensate starting at @xmath120 mev . since in our model @xmath121 mev we agree with the results found in the literature @xcite . we found also that for @xmath122 the critical @xmath10 is zero . therefore we will limit our considerations at small isospin chemical potential , say @xmath123 mev , where we expect the pion condensate @xmath4 to vanish . in this situation the determinant in eq . ( [ determinant ] ) factorizes and the effective action is given by a sum of three independent terms , one for each flavor . therefore the action is the same as for @xmath12 , with each flavor evaluated at its own chemical potential . it follows that the light flavor terms show the same tricritical structure exhibited from the central line in fig . [ fig : diafaison2 ] for @xmath12 . consequently the phase diagram we obtain for a small , fixed isospin chemical potential ( @xmath112 ) is described by the two side lines in fig . [ fig : diafaison2 ] with each flavor @xmath124 and @xmath125 showing the same structure as the central line but with a split chemical potential @xmath126 . notice also that although the figure extends up to zero temperature , this part should not be taken too seriously due to the existence of color superconductivity . in this paper we have discussed an approximate model of qcd ( ladder - qcd ) at finite temperature and densities . in particular we have considered the experimentally important situation of a non - vanishing isospin chemical potential . this situation has been already explored by various authors previously and we confirm , in particular , the results found in @xcite and @xcite about the splitting of the first order transition line in the plane @xmath3 , for small @xmath10 . as pointed out in @xcite this result could be relevant for ion physics since the first order transition line is split symmetrically with respect to the original line at @xmath12 . this implies a reduction of the value of the baryon chemical potential at the tricritical point of an amount given by @xmath10 , making easier the possibility of discovering it experimentally . since it is very difficult to perform first principle analysis of qcd at finite baryon density , we think that it is important to show that certain features as the existence of the tricritical point and the possible splitting of the first order transition line are common to several models . this suggests that these features might possess some universal character . however we should stress that the result of the splitting of the first order transition line is strictly related to the factorization in flavor space . for instance , in the two flavor case , the four - fermi interaction due to the instanton effects leads to a mixing of the flavors that , if sufficiently large , might wash out the mixing . we think that this point needs further analysis in the more complete scheme with three flavors . k.  rajagopal and f.  wilczek , in _ at the frontier of physics / handbook of qcd _ , m. shifman ( ed . ) , world scientific , singapore , vol . 3 , p. 2061 , [ arxiv : hep - ph/0011333 ] . a.  barducci , r.  casalbuoni , s.  de curtis , r.  gatto and g.  pettini , phys .  lett . b * 231 * , 463 ( 1989 ) ; phys . d * 41 * , 1610 ( 1990 ) . t. hatsuda and t. kunihiro , phys . rep . * 247 * , 221 ( 1994 ) . m.  a.  halasz , a.  d.  jackson , r.  e.  shrock , m.  a.  stephanov and j.  j.  verbaarschot , phys . d * 58 * , 096007 ( 1998 ) [ arxiv : hep - ph/9804290 ] . j.  berges and k.  rajagopal , nucl . b * 538 * , 215 ( 1999 ) [ arxiv : hep - ph/9804233 ] . f.  bedaque , nucl . a * 697 * , 569 ( 2002 ) [ arxiv : hep - ph/9910247 ] . m.  g.  alford , j.  a.  bowers and k.  rajagopal , phys . d * 63 * , 074016 ( 2001 ) [ arxiv : hep - ph/0008208 ] . m.  buballa and m.  oertel , phys . b * 457 * , 261 ( 1999 ) [ arxiv : hep - ph/9810529 ] . f.  neumann , m.  buballa and m.  oertel , nucl . a * 714 * , 481 ( 2003 ) [ arxiv : hep - ph/0210078 ] . a.  steiner , m.  prakash and j.  m.  lattimer , phys . b * 486 * , 239 ( 2000 ) [ arxiv : nucl - th/0003066 ] . a.  w.  steiner , s.  reddy and m.  prakash , phys . d * 66 * , 094007 ( 2002 ) [ arxiv : hep - ph/0205201 ] . b.  klein , d.  toublan and j.  j.  verbaarschot , arxiv : hep - ph/0301143 . d.  toublan and j.  b.  kogut , arxiv : hep - ph/0301183 . m.  frank , m.  buballa and m.  oertel , arxiv : hep - ph/0303109 . z.  fodor and s.  d.  katz , phys . b * 534 * , 87 ( 2002 ) [ arxiv : hep - lat/0104001 ] . z.  fodor and s.  d.  katz , jhep * 0203 * , 014 ( 2002 ) [ arxiv : hep - lat/0106002 ] . j.  b.  kogut and d.  k.  sinclair , phys . d * 66 * , 014508 ( 2002 ) [ arxiv : hep - lat/0201017 ] . j.  b.  kogut and d.  k.  sinclair , phys . d * 66 * , 034505 ( 2002 ) [ arxiv : hep - lat/0202028 ] . d.  t.  son and m.  a.  stephanov , phys . * 86 * , 592 ( 2001 ) [ arxiv : hep - ph/0005225 ] . a.  barducci , r.  casalbuoni , s.  de curtis , d.  dominici and r.  gatto , phys . b * 147 * , 460 ( 1984 ) ; phys . d * 38 * , 238 ( 1988 ) . a.  barducci , r.  casalbuoni , g.  pettini and r.  gatto , phys . d * 49 * , 426 ( 1994 ) .", "tags": [], "output_text_a": "This paper explores the effects of finite isospin chemical potential in a model known as ladder-QCD, which previously demonstrated the existence of a tricritical point in the chiral phase of QCD. The study is motivated by the challenges of studying QCD at finite baryon density on the lattice and aims to investigate the universality of certain features across different models. The paper focuses on the phase diagram in the three-parameter space of temperature, baryon chemical potential, and isospin chemical potential, particularly at small isospin chemical potential. The authors confirm the existence of a phase transition at finite isospin chemical potential and discuss the splitting of the first-order transition line in the QCD phase diagram, which could have implications for heavy ion physics. The study suggests that certain features, such as the tricritical point and the splitting of the transition line, may possess universal characteristics across different models. However, the paper notes that the results are preliminary and further analysis is needed, especially regarding the effects of instanton interactions in a more complete three-flavor scheme.", "output_text_b": "The study of QCD at finite density has become important in recent years, with the discovery of a color superconducting phase at zero temperature and high density. This phase is relevant in the context of compact stellar objects, where central densities can reach up to ten times the saturation density. The paper also discusses the possibility of observing a tricritical point in heavy ion experiments, where there is a non-zero isospin chemical potential. The authors study the phase diagram in a three-parameter space using a random matrix model and a Nambu-Jona-Lasinio model, and find that the first order transition line ending at the tricritical point splits into two first order transition lines at low values of baryon chemical potential. They also study the effect of a finite isospin chemical potential in a model (ladder-QCD) where the existence of a tricritical point was shown several years ago.", "score": 0.30000000000000004, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the exploration of finite isospin chemical potential in ladder-QCD and the confirmation of a phase transition.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of studying QCD at finite baryon density and the investigation of universality in phase transitions.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of ladder-QCD as the model for the study.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the confirmation of a phase transition and the potential universality of certain features.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"tricritical point.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data, which is a requirement.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in understanding QCD phase transitions and its implications for heavy ion physics.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings related to the study of QCD at finite density, the color superconducting phase, and the tricritical point. However, it misses some details about the specific models used and the significance of the findings.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the study of QCD at finite density and the observation of a tricritical point as the research problems.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary briefly mentions the use of a random matrix model and a Nambu-Jona-Lasinio model, but does not detail the ladder-QCD model or the specific methodologies used.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results about the splitting of the first order transition line and the study of finite isospin chemical potential.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"tricritical point\" and \"isospin chemical potential\" without explanation, which might not be clear to all readers.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is logically structured with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the significance of the findings in the context of compact stellar objects and heavy ion experiments."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "with the advent of chandra x - ray observations of radio jets , evidence supporting the synchrotron process for the origin of the x - ray emission from the jets of low luminosity radio galaxies has grown . one line of evidence is the similarity of the x - ray morphology to the radio and optical structures which are most likely synchrotron emission because of the detection of linear polarization . another argument is that the values of the spectral index of power law fits to the x - ray spectra are generally steeper than the radio spectra whereas inverse compton ( ic ) models predict @xmath2 , is defined by flux density , s  @xmath3 . ] ( e.g. hardcastle et al . 2002 ; harris & krawczynski , 2002 ) .    in this paper we exploit another fundamental difference between ic and synchrotron emission : the variability time scale . although the injection of new relativistic electrons can produce the same rise time for both processes , the characteristic loss timescales are vastly different . all ic models require relatively low energy relativistic electrons . for synchrotron self compton ( ssc ) models , lorentz energy factors , @xmath4 , are normally comparable to the values of a few thousand which are responsible for the observed radio emission . for ic scattering between the relativistic electrons and photons of the cosmic microwave background ( ic / cmb ) , @xmath51000 ( harris & krawczynski 2002 ) . synchrotron models however require @xmath6 with corresponding half - lives of order a year for the sorts of magnetic field strengths commonly estimated for features in radio jets . our data show strong intensity variability from the unresolved core and hst-1 . we use the flux doubling time to derive an upper limit to the source size and the decay time to constrain the timescale for e@xmath7 losses , and in turn , @xmath1 . we take the distance to m87 to be 16 mpc so that one arcsec  =  77pc . in 2002 we obtained five observations of 5ks each on jan16 , feb12 , mar30 , jun08 , and jul24 . to minimize pileup , we used a readout time of 0.4s for the standard 1/8th subarray on the acis - s3 chip ( pug 2001 ) . data reduction followed the threads ( ciao2.2 ) . to recover the inherent resolution of chandra , we removed pixel randomization and rebinned the data to 0.1 native acis pixels . for 3 energy bands ( soft , s=0.2 - 0.75kev , medium , m=0.75 - 2kev , and hard , h=2 - 6kev ) flux maps were obtained by standard procedures ; a correction was applied for degradation of the quantum efficiency by measurement of fixed regions of hot gas emission near the jet . a wide band image was made by adding the 3 energy bands and fig . [ fig : sum6 ] shows the result of averaging our fluxmaps . our monitoring shows striking variability in both hst-1 and the unresolved core ( which could well come from jet segments closer than 0.4@xmath8 to the nucleus ) . the other knots show weak or no variability and will be analyzed in a future paper . contour diagrams of the core and hst-1 for each observation can be found in harris ( 2003a ) ; here we show lightcurves for the core and hst-1 ( fig . [ fig : lc ] ) . the photometry was obtained by taking small circles with radii 0.44@xmath8 and subtracting the background from rectangles above and below the jet ( with a total area of 13.6  arcsec@xmath7 ) . the largest increase occurs for hst-1 between mar and jul with over a factor of two brightening in 116d . this implies that the emitting volume of the variable component has a characteristic size @xmath9  the light travel time which is 0.1pc for a stationary source . the brightening in the core between our last two observations showed a similar rate of increase with a 20% gain in 46 days . the relative increases in the three energy bands demonstrate a hardening of the spectrum for hst-1 between march and july 2002 ( compare the rates of increase in each band in fig . [ fig : lc ] ) . the intensity increase was a factor of 2.7@xmath100.3 for the hard , 1.7@xmath100.1 for the medium , and 1.6@xmath100.1 for the soft band . although we defer spectral analysis to a later paper , this hardening produced a change in the x - ray spectral index from @xmath11 ( prior to 2002 may ) to @xmath12 ( for 2002 july ) . the cleanest drop occurs for hst-1 between the 2002 january and february observations . the intensity ratios ( feb over jan ) for these 27 days are : 0.79@xmath100.09 ( h ) , 0.83@xmath100.04 ( m ) , and 0.87@xmath100.05 ( s ) . while these values are the same within the errors , there is a progression consistent with expectations for e@xmath7 losses ( but contrary to that of increased absorption ) : the hard band is dropping faster than the soft band . a similar effect is seen in the core decay between mar and jun : the hard band dropped 32@xmath107% while the medium band dropped 14@xmath105% . all of these timescales are subject to considerable error . although the statistical errors for the flux values are less than 10% , there will always be some flux present which is not part of the variable component and our sampling interval is not small enough to determine shorter variations . variability of a synchrotron source can result from a number of effects such as changes in any of the absorption along the line of sight , the magnetic field strength , b , the number of particles contributing to the radiation in a given band , or the beaming factor ( protheroe 2002 ) . adiabatic compression or expansion is particularly effective in changing the radiated power since the electrons gain or lose energy and at the same time , b changes to augment the effect . given a power law electron energy distribution n(e)@xmath13e@xmath14 , there should be no change in p. on the other hand , if the effects of a high energy cutoff extend down to the energy range of interest , a compression would cause an increase of intensity accompanied by a spectral hardening since the emission from a fixed observing band would come from lower energy electrons and the spectral curvature would be shifted to higher energies . however , for the remainder of this paper we focus on an alternative synchrotron model based on changes to the number of radiating particles .    for this model , increased intensity arises from the injection of new radiating particles with a spectrum flatter than that which existed previously . the spectral softening which accompanies flux decline comes from normal @xmath15 losses . the chief difference in these models is that the compression / expansion model requires that n(e ) departs from a power law . our data allow spectral curvature but the statistics are not good enough to demand curvature . in order to derive synchrotron model parameters , we need to know the overall spectral distribution of the emitted energy . both the radio and optical morphologies of the inner jet are shown in fig . 3 of perlman et al . ( 1999 ) with 0.2@xmath8 resolution . at higher resolution ( fig . 1 of biretta , zhou , & owen 1995 ) it can be seen that there are a series of several knots between 0.8@xmath8 and 1.2@xmath8 from the core . hst data demonstrate that the brightest upstream knot is slowly moving but the downstream knots are moving with an apparent speed of 6c ( biretta , sparks , & macchetto 1999 ) . our feature hst-1 ( fig . [ fig : sum6 ] ) corresponds to the upstream , optically brighter part of this segment of the jet . we take the radio flux density corresponding to the x - ray knot to be 3.8 mjy , as measured on the high resolution 15 ghz map . from a new vla observation , . ] we derive an upper limit of 2 mjy at 43 ghz . the optical flux densities come from the detailed spectral analysis at 0.15@xmath8 resolution based on data obtained in 1998 february by perlman et al . the spectrum is shown in fig .  [ fig : spec ] , and for the purposes of sec . [ sec : sync ] , we approximate these data with a single power law between 10@xmath16 and 10@xmath17  hz with @xmath18=0.68 and amplitude determined by s(2kev)=100njy , parameters which describe the observables to within a factor of two . previous analyses have demonstrated that the x - ray jet emission of m87 is not thermal emission ( wilson & yang 2002 ; marshall et al . 2002 ; biretta , stern , & harris 1991 ) ; is not ssc emission ( ibid . ) ; and is not ic / cmb emission because of the large values of @xmath19 and small angles to the line of sight required ( harris & krawczynski 2002 ) . the x - ray spectra of the knots are much steeper than in the radio or optical and strongly favor synchrotron radiation ( wilson & yang 2002 ) , confirming the conclusion of biretta , stern , & harris ( 1991 ) . our variability data is fully consistent with x - ray synchrotron emission and it remains only to demonstrate that plausible physical parameters can be found with a simple model which posits that the jet has a relativistic bulk velocity , as implied by the one - sided emission at all frequencies . in this section , we do that for hst-1 . using the time required for the flux to double provides an upper limit to the source size . to use the observed decline , we take the observed variables back to the jet frame , calculate the properties of the synchrotron source assuming equipartition conditions ( pacholczyk 1970 ) , and then evaluate the halflife of the electrons responsible for the x - ray emission , both in the jet frame and as observed at the earth . we also compare energy densities in the magnetic field and in the synchrotron photons . we performed these calculations for 8 values of @xmath1 between 1 and 16 . for converting various quantities to the jet frame and back , we used expressions from the appendix of harris and krawczynski ( 2002 ) . the results for representative values of @xmath1 are shown in table  [ tab : results ] . lcccccc radius ( arcsec ) & 0.0012 & 0.0024 & 0.0048 & 0.0072 & 0.0096 & 0.0192 + l@xmath20 ( erg  s@xmath21 ) & 6.5e40 & 4.1e39 & 2.5e38 & 5.3e37 & 1.6e37 & 1.0e36 + log e@xmath22 ( ergs ) & 48.55 & 48.40 & 48.17 & 48.04 & 47.96 & 47.75 + @xmath23 & 135 & 181 & 244 & 274 & 328 & 443 + @xmath24 & 4.2e6 & 5.7e6 & 7.7e6 & 8.7e6 & 1.0e7 & 1.4e7 + b@xmath25 ( mg ) & 13 & 3.7 & 1.0 & 0.51 & 0.28 & 0.077 + u@xmath25(b ) ( erg  @xmath26 ) & 6.9e-6 & 5.4e-7 & 4.0e-8 & 1.0e-8 & 3.7e-9 & 2.4e-10 + u@xmath25(sync ) ( erg  @xmath26 ) & 7.5e-6 & 1.2e-7 & 1.8e-9 & 1.9e-10 & 2.9e-11 & 4.5e-13 + @xmath27 ( yr ) & 0.011 & 0.126 & 1.3 & 4.3 & 12.1 & 81.9 + @xmath28(earth ) ( yr ) & 0.011 & 0.063 & 0.32 & 0.72 & 1.5 & 5.1 +    we have made model specific estimates of how to relate an observed decline of 21% ( in the hard band in 27 days ) to the effects of e@xmath7 losses on the electron distribution ( harris 2003b ) . we find consistency for @xmath1 in the range 2 to 5 . however , the main conclusion is that regardless of the precise model and the actual values found for the rate of decline , the observed timescales for decay are fully consistent with the beaming parameters for a jet angle of order 10@xmath29 to 17@xmath29 ( to the line of sight ) suggested by the hst proper motion studies of biretta et al . ( 1999 ) in their table 3 . larger beaming factors imply weaker fields and longer halflives , and vice - versa . a recent hst observation shows the varying region to be unresolved in the optical / uv , independently placing an upper limit of @xmath30 ( 1.5pc ) on its size ( cf . table  [ tab : results ] ) . values of @xmath1 in the range 2 to 5 involve very modest synchrotron luminosities in the jet frame , equipartition magnetic field strengths of order 1 mg , and a total energy stored in particles and fields which can be supplied by a low drain on the jet kinetic energy , @xmath31erg  s@xmath21 , a value @xmath91% of the jet power estimated by young , wilson , & mundell ( 2002 ) . with these parameters , the effective energy density of the cmb as seen by the jet is less than the synchrotron energy density for most choices of allowed @xmath19 , and the combined photon energy density @xmath90.2 of that in the magnetic field for all @xmath322 . thus the bulk of the energy loss is via the synchrotron , not the ic channel . the model predicts that the optical emission will decay with a timescale of order ten times longer than that we observe for the x - rays since @xmath33 . for a straight jet , an angle to the line of sight of @xmath34 implies a total jet length of just under 10 kpc . these estimates are based on decay timescales and our results would change if the actual decay time is shorter than our current estimate , in which case we would choose a smaller value of @xmath1 ; if the magnetic field is substantially less than the equipartition value and thus @xmath35 would be larger than calculated because of the weaker field and we would again choose a smaller @xmath1 ; or if the source size is substantially less than the light travel time which would mean that the field is larger than calculated , halflives would be shorter , and we would select a larger @xmath1 . we find that a synchrotron model with a beaming factor of @xmath1=2 - 5 gives a good fit to our observations for hst-1 and is compatible with radio and optical interpretations . it remains to be seen if similar models can be constructed for powerful jets such as that in 3c  273 . many of the gross features such as the progressions of x - ray emission being stronger close to the core , whereas the radio intensity increases moving out along the jet ; and the slight shifts in brightness ( radio brighter downstream of the x - ray peak for some knots ) are the same in m87 and 3c273 . it is also worth noting that if m87 were further away or observed with poor resolution , the variability which we now know arises from a knot in the jet might well be ascribed to conditions very close to the black hole ( as in blazar variability studies ) . we shall continue to monitor the jet of m87 with chandra between 2002 november and 2003 july with 8 observations and the jet will also be monitored at similar intervals with the hst . these data should provide refined estimates of variability timescales , spectral evolution for the core and hst-1 , and variability in the other knots . we thank the vla and hst staffs for accommodating our ad hoc requests on short notice . the national radio astronomy observatory is operated by associated universities , inc . , under contract with the national science foundation . we thank o. stohlman for assistance in the data reduction and the referee for intelligent suggestions for improvement . work at sao was supported by nasa contract nas8 - 39073 and grant go2 - 3144x , and at u. maryland by nasa grants nag81027 and nag81755 .              harris , d. e. 2003a , proceedings of the conference `` the physics of relativistic jets in the chandra and xmm era '' , 23 - 27 september 2002 , bologna ; brunetti , harris , sambruna , and setti , editors . new ast rev ( in press )", "tags": [], "output_text_a": "The paper discusses the origin of X-ray emissions from the jets of low luminosity radio galaxies, focusing on the synchrotron process as supported by Chandra X-ray observations. The study highlights the similarity in X-ray, radio, and optical morphologies, suggesting synchrotron emission due to detected linear polarization. The paper contrasts synchrotron and inverse Compton (IC) models, emphasizing the variability time scale as a distinguishing factor. Synchrotron models require high-energy electrons with shorter loss timescales compared to IC models. The study presents data showing strong intensity variability in the core and HST-1 of the M87 galaxy, using flux doubling time to estimate source size and decay time to constrain electron loss timescales. The analysis supports synchrotron emission, with variability consistent with beaming parameters for a jet angle of 10\u00b0 to 17\u00b0 to the line of sight. The paper concludes that a synchrotron model with a beaming factor of 2-5 fits the observations for HST-1 and is compatible with radio and optical data. Future observations with Chandra and HST aim to refine variability timescales and spectral evolution estimates.", "output_text_b": "This article discusses the use of Chandra X-ray observations to study radio jets and the origin of X-ray emission from low luminosity radio galaxies. The authors exploit the difference in variability time scales between synchrotron and inverse Compton (IC) emission to support the synchrotron process for X-ray emission. IC models require low energy relativistic electrons, while synchrotron models require higher energy electrons with corresponding shorter half-lives. The authors present data on the intensity variability of the unresolved core and HST-1 in the M87 galaxy, and use these observations to derive upper limits for the source size and constraints for electron loss timescales.", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the origin of X-ray emissions, the focus on the synchrotron process, and the comparison with IC models. It also mentions the variability in the core and HST-1 of the M87 galaxy and the conclusion supporting the synchrotron model.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the origin of X-ray emissions from radio galaxy jets, is highlighted.\n4. The methodology, including the use of Chandra X-ray observations and the analysis of variability time scales, is mentioned.\n5. Significant results, such as the support for synchrotron emission and the compatibility with radio and optical data, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like synchrotron and IC models.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments or data, such as the Chandra X-ray observations and the analysis of variability in the M87 galaxy, are mentioned.\n10. The summary reflects the paper's significance by discussing the potential impact of the findings on understanding X-ray emissions in radio galaxies.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings regarding the use of Chandra X-ray observations to study radio jets and supports the synchrotron process for X-ray emission.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of determining the origin of X-ray emission from low luminosity radio galaxies.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of variability time scales between synchrotron and IC emission as the approach.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results about intensity variability and constraints on electron loss timescales.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"synchrotron\" and \"inverse Compton\" but does not explain them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions data on intensity variability of the unresolved core and HST-1.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly reflect the paper's significance or potential impact."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "in spring 2006 , the potential threat of bird flu dominated headlines in uk newspapers . on 26 march 2006 the sun has called it  the day we all dreaded \" , while the guardian says avian flu is  almost certain to spread to wild birds across the uk \" . the daily telegraph adds that the most likely human victims will be poultry farmers , who will be bankrupted . but the mirror calls for calm , saying people have a better chance of winning the lottery than catching the virus . interestingly , given a certain amount of clustering of wealth residents and correlation between wealth and readers preference , this would translate into a differently informed neighborhood . when the epidemic is over its peak or other news has just peaked or media has  cried wolf \" too many times over unfounded health scares , there is a quick drop in the attention to that disease ( something similar is reported nowadays for hiv ) . in other parts of the world , for example indonesia , a country with 18000 islands , people reacted differently to the bird flu epidemics . despite awareness campaigns in the media and even door - to - door visits in some of the islands , many indonesians remained oblivious to the dangers of being in contact with diseased birds , and aware of the need to inform the authorities and implement a cull . note that awareness campaigns , such as during the sars epidemics , are expensive and may result in culling , reductions in commerce , travels and tourism . the media hype over epidemics threat has a close similarity in how worried or fatalist , resilient , skeptical or cheeky may be friends and neighborhood . therefore , the individual perception of the risk of becoming infected is a key factor influencing the spreading of an epidemics and , toward realistic inference , epidemiological models should incorporate such parameter  @xcite .    in order to investigate the effect of risk perception in influencing the spreading of a disease , let us start from simple , yet meaningful models , such sis or sir ones . these models are defined on a network where individuals or groups of individuals corresponds to the nodes and links represent social contacts and relationships among them . most of classical studies used either a regular lattice , or a random one . both of those choices are characterized by a well defined value of the mean connectivity @xmath0 , and small variance @xmath1 . as shown by watts and strogatz  @xcite , the simple rewiring of a small fraction of links in an otherwise regular lattice results in a sudden lowering of the diameter of the graph , without affecting the average connectivity or the degree of clustering . this _ small world _ effect manifests itself in a dramatic shortage of the distance between any two individuals , almost without affecting the local perception of the network of contacts . the consequences for epidemics spreading are important : just a few long - distance connections may promote the spreading of a disease in rural areas , whereby an epidemic would otherwise diffuse very slowly . however , the investigations of social networks have shown that they are quite different from regular and random graphs  @xcite . the probability distribution of contacts often exhibits a power - law behavior ( @xmath2 ) , with an exponent @xmath3 between two and three  @xcite . this distribution is characterized by a relatively large number of highly connected hubs , which are presumably responsible for epidemics spreading . moreover , such distributions have a diverging second moment @xmath4 for @xmath5 and a diverging average connectivity @xmath6 for @xmath7 . the influence of the connectivity on the spreading dynamics is well outlined by a simple mean - field analysis . let us consider for the moment a tree with fixed connectivity @xmath8 . in a sis model with immediate recovery dynamics , a single infected individual may infect up to @xmath8 neighbors  @xcite , each one with probability @xmath9 . the temporal behavior of the mean fraction @xmath10 of infected individuals is given by @xmath11 where @xmath12 , @xmath13 and the sum runs over the number @xmath14 of infected individuals . the basic reproductive ratio @xmath15  @xcite is simply given by @xmath16 , so that the epidemic threshold @xmath17 corresponds to @xmath18 . this means that for a fixed connectivity , only diseases with an infectivity less than @xmath19 do not spread .    in heterogeneous networks ( nodes with different connectivity ) the mean field analysis , reported in section  [ meanfield ] , gives @xmath20 . in the case @xmath21 , @xmath22 is again equal to @xmath23 .    in summary , the result is that on very non homogeneous networks , with diverging second moment @xmath4 ( and even worse on those with diverging average connectivity @xmath0 ) , a disease will always spread regardless of its intrinsic morbidity  @xcite . this result can be modified by the assortativity degree of the network and by the presence of loops , not considered in tyhe mean - field analysis . in networks with assortative connections ( hubs are preferentially connected to other hubs ) , it may happen that epidemics spread for any finite infectivity even when the second moment is not diverging  @xcite , while for disassortative networks the reverse is true , epidemics may be stopped by lowering the infectivity with random vaccination campaigns , even in the presence of a diverging second moment  @xcite . this is particularly evident in networks lacking the small - world property ( consequence of high disassortativity )  @xcite .    in small - world networks with diverging second moment , it is quite difficult to stop an epidemics . the most common recipes are vaccination campaigns ( removal of nodes ) or modification of the social structure ( removal of links ) , that mathematically corresponds to site and bond percolation problems . to be efficient , a vaccination camping must be targeted to hubs , either directly  @xcite or implicitly , for instance by exploiting the fact that hubs are the most probable neighbors of many nodes  @xcite . the modification of the social structure can be obtained by cohercitive methods ( quarantine , etc . ) or by rising alerts so to modify travelling and business patterns , but this option may be so expensive that the amount of money put into restoring the previous situation may exceed that used to cure ill people  @xcite . however , epidemics in modern world are relatively uncommon , and most of them are stopped quite easily in spite of the presence of high network connectivity . the existence of an epidemic threshold on such networks has motivated the investigation of the effects of connectivity - dependent infectivity  @xcite . in this latter case , most of investigations have been performed using mean - field techniques , thus disregarding the presence of loops . loops are irrelevant at and near the percolation threshold  @xcite , and therefore one can threat the network as a tree in these conditions . however , for processes evolving on percolating networks , this assumption may not hold .    at present , the basic models used do not take into consideration the _ knowledge _ that all human beings have nowadays about the mechanisms of diffusion of diseases . in fact , even in the absence of vaccination campaigns , a disease that manifests itself in a visible way induces modifications in the social network : lower frequency of contacts ( usage of mass transportation systems ) , higher level of personal hygiene , prevention measures ( masks ) , etc . indeed , recent works stress the importance of using a time - dependent bare infectivity to reproduce real patterns of epidemics  @xcite .    viruses with high mutation rates ( like computer viruses ) follow a dynamics which is more similar to sis than to sir  @xcite , even in the presence of immunization . on the other hand , the origin of vaccination come from cross - immunization conferred by strains with lower pathogenicity . we shall study here a sis model in which the bare infectivity of the spreading agent is modulated by a term that tries to model the effects of the perception of the risk of being infected . we assume that this perception is just an increasing function of the fraction of ill people in the neighborhood , given that the illness presents visible symptoms . this assumption is modeled after the heuristic - systematic information - processing model  @xcite , that simply states that attitudes are formed and modified as people gain information about a process . in the absence of explicit alarm or communication , the only way of gaining this information is though examination of people in the neighborhood . individuals can process information in two ways : either heuristically , using simple an semi - unconscious schemes , or carefully examining them in a rational way . investigations about the effects of advertisements , especially those exploiting fear , show that the first way is rather common and predictable , except in the limit of high level of fear , that may induce repulsion towards the brand , or very low level , that may trigger the reflexive mechanism and a more careful evaluation of the message .    in this work we simply assume that the local information ( not enhanced by alarms ) about the incidence of the illness translates into a lowering of the infection probability , implementing only the `` linear part '' of the information - processing model . in principle , is possible to compare the effective susceptibility to infection for diseases that manifest themselves in a visible and in an invisible way and test experimentally this hypothesis .    in our model , the infectivity is a dynamical quantity . although the idea of modulating the infectivity of the infection process is not new , it is generally studied ( mostly in the mean - field approximation ) as as a function of time  @xcite , of connectivity  @xcite and/or depending on the total infection level  @xcite . in this latter approach , a nonlinear growing dependence of the infection rate on the total number of infected people may originate bifurcation and chaotic oscillations . as we shall show in the following , mean - field analysis may not capture the essential phenomena in highly connected networks . moreover , we study the case of decreasing infection rate with increasing local infection level , that might also induce chaotic oscillations at the mean - field level ( see ref . @xcite and section  [ model ] ) . however , one should consider that chaotic oscillations on networks easily desynchronize , and the resulting `` microscopic chaos '' is quite different from the synchronous oscillations predicted by mean - field analysis  @xcite , that may nevertheless be observed in lattice models the presence of long - range coupling  @xcite . we explicitly describe the model in section  [ model ] , analyze it using mean - field techniques in section  [ meanfield ] and study numerically its behavior on different types of networks in section  [ numerics ] . conclusions and perspectives are drawn in the last section . in this paper we study the dynamics of an infection spreading over a network of @xmath24 individuals . we use different kinds of networks : regular , with long - range rewiring  @xcite , random and scale - free  @xcite . the network structure is considered not to depend on the infection level . let us denote by @xmath25 the probability distribution of connectivity @xmath8 . we shall denote by @xmath26 the average connectivity ( first moment of the distribution ) , @xmath27 , and by @xmath28 the second moment , @xmath29 . in the case of regular lattice with eventual rewiring , @xmath30 and @xmath31 . the rewiring of the network is performed by starting from a regular lattice in one dimension , detaching a fraction @xmath32 of links from one end and attaching them to randomly chosen nodes . the regular case is studied numerically in one dimension . simulations on the rewired network are performed both in the quenched and in the annealed cases .    for random graphs , studied only at the mean - field level , the probability distribution is assumed to be poissonian , @xmath33 corresponding to drawing @xmath34 links at random among the @xmath24 nodes ( @xmath35 ) .    the scale - free network that we study numerically is asymmetric : each node @xmath36 has a certain number @xmath37 of input contacts and @xmath38 of output ones , and was grown using the following rule . we start with a ring of @xmath39 nodes , and we add the other @xmath40 nodes by choosing , for each of them , @xmath39 connected nodes @xmath41 , with probability @xmath42 ( preferential attachment ) . the node being attached is added to the _ inputs _ of the chosen nodes . we also choose another node at random and add it to the list of input nodes of the new node . this process simulates the growing of a social network in which a new node ( a family or an individual ) is born from another one ( the ones that is added as input of the newborn node ) and joins the society according with the popularity of nodes . distribution of input and output connections for the scale - free network used in simulations . ] our procedure allows to generate a network that has a power - law distribution of input contacts , @xmath43 , with @xmath44 ( see figure  [ pk ] ) , while the distribution of output connections , @xmath45 , is found to be exponentially distributed . this is an interesting feature of the model as the input connections represent the total number of contacts to which an individual is exposed , while the output connections represent the actively pursued contacts , e.g. familiar ones . a customer , for instance , is exposed to a large number of obliged contacts , and may become infected with a large probability . these are considered `` input '' links . on the other hand , people in a public position is more monitored , and it is not plausible that they can infect a comparable large number of people . infection is limited to the private sphere , where contacts are more intense . these are the `` output '' links . we choose this algorithm in order to have a `` worst - case '' scenario , with an exponent corresponding to a diverging average of input connectivity    we have not studied the case of dynamic dependence of the network on the infection level , however a high - level of infection of a severe disease may surely induce changes in the social network . it is reasonable to assume that , for mild diseases ( or diseases considered harmless , like most of computer viruses ) , the social network is not affected and only the level of prevention is increased .    in the present paper we assume the effects of the infection to be immediately visible , with no latency nor `` hidden infectivity '' . we also assume as temporal unit the time required to recover from illness without immunization and thus we explore the case of a sis dynamics . mean field return map for fixed connectivity @xmath46 , parameters @xmath47 , @xmath48 , @xmath49 and varying values of precaution level @xmath50 . the effect of risk perception ( @xmath50 ) is to lower the infectivity at high concentrations of infected individuals . ] an individual can be infected separately by each of his neighbors with a probability @xmath9 per unit of time ( see eq .  ) . we model the effects of the perception of the risk of being infected replacing the bare infection probability @xmath9 with @xmath51 , @xmath52 \\right\\},\\ ] ] where @xmath8 is the number of neighbors of a given site and @xmath14 is the number of them that are ill . we assume the perception of the risk of being infected to depend on the fraction of infected individuals among the neighbors , @xmath53 , on the level of precaution measures adopted , @xmath50 , and on the use of special prophylaxis , @xmath54 . the quantity @xmath55 models a global influence over the population , either alarm of broadcasting media news , in which case it could depend on the average level of the infection . its effect is that of reducing the bare infectivity @xmath9 , so in the following we only consider the case @xmath47 . for the moment , we consider @xmath48 ; the role of this parameter will be clear in the following . differently from ref @xcite , in our model the infectivity is not exclusively related to the connectivity .    the mean - field return map ( for fixed connectivity @xmath56 ) is shown in figure  [ campomedio ] . the effect of the introduction of risk perception is evident : for high concentrations of infected individuals the probability of being infected is diminished . therefore , while for @xmath57 and @xmath58 there is only one stable fixed point @xmath59 ( all individuals infected ) , by increasing @xmath50 one can have stable fixed points @xmath60 , limit cycles and even chaotic behavior  @xcite . the simplest mean - field approximation of the evolution of disease on a network consists in neglecting correlations among variables . this is essentially equivalent in considering the evolution on a tree , i.e. , in assuming the absence of loops . let us denote with @xmath61 the probability of having an infected site of degree @xmath8 ( with @xmath8 connections ) at time @xmath62 , and with @xmath63 the probability at a subsequent time step . the mean evolution of the system is generically given by @xmath64 where @xmath65 indicates the local configuration ( degrees and healthy status ) at time @xmath62 around a site of degree @xmath8 . @xmath66 is the probability of occurrence of the healthy status of such configuration , @xmath67 is the probability that the local configuration is connected to the site under examination , and @xmath68 is the probability that the disease propagates in one time step from @xmath65 to the site .    in our case , the local configuration is given by a set of @xmath8 nodes , of degree @xmath69 , and status @xmath70 ) , where @xmath71 ( 1 ) indicates that the site @xmath36 is healthy ( ill ) . thus @xmath72 and @xmath73 since we assume decorrelation among sites . @xmath67 depends on the assortativity of the network . let us define @xmath74 as the probability that a site of degree @xmath8 is attached to a link connected to a site of degree @xmath75 . @xmath74 is computed in an existing network as the number of links that connects sites of degree @xmath75 and @xmath8 , divided by the total number of links that are connected to sites of degree @xmath8 , and @xmath76 . the detailed balance condition gives @xmath77 . for non - assortative networks , @xmath78 , and summing over the detailed balance condition one gets @xmath79 , where @xmath56 is the average number of links per node , @xmath80 . assuming again a decorrelated network , we have @xmath81 for non - assortative networks . @xmath68 is the infection probability . in the case without risk perception , it is @xmath82 where @xmath83 . the risk perception is modeled by replacing @xmath9 with @xmath84 , which makes the equations hard to be managed analytically except in the limit of vanishing infection probability @xmath85 , for which only the case @xmath86 is relevant . we shall consider this point later . putting all together , one gets @xmath87    using the relation @xmath88 we obtain after some simplifications @xmath89 this expression could be obtained directly by noticing that @xmath90 is the probability of not being ill , which corresponds to the combined probability of not being infected by any of the @xmath8 neighbors . neglecting correlations , these are @xmath8 independent processes ( although they depend on @xmath8 ) . each of these process is 1 minus the probability of being infected , which is the sum , over all possible degree @xmath75 of the neighboring node , of the probability that it is ill ( @xmath91 ) times the probability that is is connected to the node under investigation , @xmath74 . let us denote by @xmath92 the asymptotic value of @xmath93 . assuming that the transition between the quiescent ( @xmath94 ) and active ( @xmath95 ) is continuous , its boundary is given by the values of parameters for which @xmath96 in the limit @xmath97 . in this limit @xmath98 and we can now consider the case with risk perception , with @xmath9 replaced by @xmath99 .    in the case of non - assortative networks , @xmath100 calling @xmath101 ( that does not depend on @xmath8 ) , we have @xmath102 and thus @xmath103 the critical boundary is therefore given by @xmath104 from which one could obtain @xmath105 as a function of @xmath9 ( we replaced @xmath75 by @xmath8 for consistency with the rest of the paper ) . in the case @xmath57 ( no risk perception ) , the formula gives @xmath106 which is a well - known result  @xcite .    in the case of fixed connectivity , @xmath30 , and for @xmath48 @xmath107 in the absence of perception ( @xmath57 ) one has @xmath108 . the mean - field dependence of the critical value of precaution level @xmath105 with respect to the bare infectivity @xmath9 for poissonian networks , with average connectivity @xmath56 and @xmath48 ]    for poissonian networks ( random graphs ) , @xmath110 numerical integration of eq .   for @xmath48 gives the results shown in figure  [ fig : poissonianjc ] . one can notice that for every value of @xmath9 and finite average connectivity @xmath56 , there is always a value of the precaution level @xmath105 that leads to the extinction of the epidemics .    for non - assortative scale - free networks with exponent @xmath3 , @xmath111 , the sum in eq .   diverges unless @xmath112 , irrespective of @xmath113 . this implies that at the mean - field level , any level of precaution is not sufficient to extinguish the epidemics . the mean - field approximation disregards the effects of ( correlated ) fluctuations in the real system . indeed , the effects of random and/or long - range connections may disrupt correlations . we found that the behavior of microscopic simulations with random rewiring , both in the quenched and annealed version , is well reproduced by mean field simulations with a white noise term , with amplitude proportional to @xmath114 . the noise term ( or the fluctuations in microscopic simulations ) may bring the infection to extinction if the average ( or mean - field ) oscillations come close to @xmath115 , as is often the case for a choice of @xmath50 for which chaotic behavior appears in the mean - field approximation . critical value @xmath105 of the precaution level as a function of the base infectivity @xmath9 average connectivity @xmath116 for the poissonian mean - field ( p ) , fixed connectivity mean field , eq . ( f ) , and numerically ( @xmath117 ) , for the annealed rewired @xmath118 ( w ) and regular one - dimensional ( r ) cases . ]    for regular ( fraction of rewired links @xmath119 ) and rewired ( @xmath120 ) lattices , it is always possible to observe a continuous transition towards a critical level @xmath121 , such that the infection become extincted , for every value of the bare infectivity @xmath9 , as shown in figure  [ fig : jc ] .    for scale - free networks , we concentrated on the case illustrated in section  [ model ] , which can be considered a worst - case scenario ( @xmath122 , diverging second and first moments of input distribution ) . simulations show that for @xmath48 ( eq .  ) , there is no value of @xmath105 for which the infection may be stopped ( although not all population is always infected ) , for any value of @xmath9 , in agreement with the mean - field analysis . fraction of time spent ill ( @xmath123 ) in the scale - free case , as a function of @xmath8 for @xmath124 , @xmath125 . ] the investigation of nodes that are _ more responsible _ of the spreading of the infection reveals , as expected , that the nodes with higher input connectivity ( hubs ) stay ill most of time , figure  [ hubs ] . notice that also nodes with high input connectivity have finite output connectivity , so the above relation is not trivially related to the infection level . dependence of the critical value of the perception , @xmath105 , as a function of the _ exposure - enhanced _ perception parameter @xmath113 , @xmath126 , @xmath49 , @xmath127 . ]    in real life , however , public service workers who are exposed to many contacts ( like medical doctors , for instance ) use additional safety measures . in order to include this effect in the model , we use the parameter @xmath113 , eq .  , that up to now have been set to one . the effect of this parameter is to increase the perception of the risk ( or the safety measures ) for nodes with higher connectivity . as shown in figure  [ jalpha ] , as soon as @xmath128 , a finite critical value of @xmath105 appears . the transition from the active ( @xmath129 ) to the absorbing ( @xmath115 ) state occurs suddenly , due to fluctuations . essentially , nodes with high connectivity may fail to be infected due to their increased perception of the infection , and this stops efficiently the spreading . this effect is similar to targeted immunization , but is not captured by the mean - field analysis . it is a dynamical effect over a network far from the percolation threshold , and thus containing loops . the transition may be a finite - size effect , related to the unavoidable cut - off in the degree distribution for finite populations , although simulations with populations from @xmath130 up to @xmath131 do not show any systematic change in the transition point . in conclusion , we have studied the effects of risk perception in a simple sis model for epidemics spreading . these effects are modulated by two parameters , @xmath50 and @xmath113 , that reduce the infectivity of the disease as a function of the fraction of people in the neighborhood that are manifestly ill . the first parameter modulates the linear response , while the second models non - linear effects like the increasing of prevention due to a public exposed role . we found that for fixed or peaked connectivity there is always a finite value @xmath105 of perception that makes the epidemics go extinct . we studied the evolution of the disease in a `` worst case '' social networks , with scale - free input connectivity and an exponent @xmath132 , for which both the average input connectivity and fluctuations diverge . in this case a linear perception can not stop the disease , but we found that , as soon as the perception is increased in a non - linear way ( @xmath133 ) , the epidemics may get extincted by increasing the perception level . this latter transition is not continuous and is presumably induced by fluctuations in hubs . it may be due to the finiteness of population . the mechanism that we propose is somehow analogous to vaccination of hubs , except that is is a dynamics effect due to the local level of diffusion of the disease , and is not exclusively related to local connectivity . we think that a similar mechanism is at the basis of the robustness of human population with respect to epidemics , even in the absence of immunization procedures . one may speculate if , in consequence of such robustness , humans have been selected to exhibit visual signs of the most common diseases , which certainly does not favors the spreading of infective agents . another common symptom of an illness is the tendency to isolation , which again could be the result of selection . l.s . research is supported by the embo organization under the contract astf 12 - 2007 . authors acknowledge fruitful discussions with f. di patti and a. guazzini . eagly and s. chaiken , _ the psychology of attitudes _ ( harcourt , fort worth , tx 1993 ) . a.h . eagly and s. chaiken , _ attitude structure and function _ , in d. t. gilbert , s. t. fiske and g. lindzey ( eds ) , _ the handbook of social psychology _ , ( mcgraw - hill , new york 1998 ) vol . 269 - 322 . l. sguanci , p. li and f. bagnoli , _ the influence of risk perception in epidemics : a cellular agent model _ , in _ cellular automata _ , s. el yacoubi , b. chopard and s. bandini , editors ( lecture notes in computer science lncs 4173 , springer , berlin 2006 ) pp .", "tags": [], "output_text_a": "The paper explores the impact of risk perception on the spread of infectious diseases using epidemiological models, specifically SIS (Susceptible-Infected-Susceptible) and SIR (Susceptible-Infected-Recovered) models. It highlights how media coverage and public awareness can influence individual behavior and, consequently, the dynamics of disease spread. The study uses network theory to model social interactions, showing that networks with high connectivity, such as scale-free networks, are particularly susceptible to rapid disease spread. The authors propose that incorporating risk perception into these models can alter the infection dynamics, potentially leading to the extinction of an epidemic under certain conditions. They find that in networks with fixed or peaked connectivity, a finite level of risk perception can halt the spread of disease. However, in scale-free networks, where connectivity and fluctuations diverge, a linear perception is insufficient, but a non-linear increase in perception can lead to epidemic extinction. The study suggests that human populations may have evolved mechanisms, such as visible symptoms and isolation tendencies, to mitigate the spread of infectious diseases. The research is supported by the EMBO organization and acknowledges contributions from various collaborators.", "output_text_b": "The article discusses the impact of risk perception on the spreading of diseases, using simple models such as SIS or SIR. The authors investigate the effect of risk perception in influencing the spreading of a disease by starting from simple models defined on a network. Classical studies have used regular or random networks, both of which have a well-defined mean connectivity and small variance. However, real-world social networks are quite different, often exhibiting a power-law behavior in the probability distribution of contacts.\n\nThe paper highlights the importance of considering the individual perception of risk in epidemiological models, as it significantly influences the spreading of diseases. The authors propose that incorporating a risk perception parameter into epidemiological models can lead to more accurate predictions and help in understanding the dynamics of disease spreading.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings about the impact of risk perception on disease spread and the use of network theory in modeling these dynamics.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the research problem of how risk perception affects the spread of infectious diseases.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of SIS and SIR models and network theory.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the conditions under which an epidemic can be halted.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"scale-free networks.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing the potential impact of incorporating risk perception into epidemiological models.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper by discussing the impact of risk perception on disease spreading and the use of SIS or SIR models.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the influence of risk perception on disease spreading.\n4. **Methodology**: The summary mentions the use of simple models defined on a network, such as SIS or SIR, to investigate the effect of risk perception.\n5. **Significant Results**: The summary notes the importance of incorporating a risk perception parameter into epidemiological models for more accurate predictions.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"risk perception parameter.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance by discussing the potential impact of incorporating risk perception into epidemiological models."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the chemical composition of extremely metal - poor stars is expected to reflect the yields from a quite small number of nucleosynthesis processes . recent abundance analyses for extremely metal - poor stars have provided quite valuable information on the origin of the elements , ( in particular when combined with galactic chemical evolution studies , e.g. , * ? ? ? * ; * ? ? ? * ) , and the individual nucleosynthesis processes involved .    the rapid neutron capture process ( r - process ) is known to be responsible for about half of the abundances of elements heavier than the iron - group in solar system material . although observational data have been rapidly increasing in the past decade , the astrophysical site of the r - process is still unclear . previous nucleosynthesis studies suggest several possibilities , e.g. , neutrino - driven winds @xcite or prompt explosions @xcite of core - collapse ( type  ii / ibc ) supernovae , neutron star mergers @xcite , jets from gamma - ray burst accretion discs @xcite . all the scenarios proposed above involve , however , severe problems that remain to be solved , and no consensus has yet been achieved . models of the r - process nucleosynthesis are usually examined by comparison with the abundance pattern of the r - process component in solar - system material . recent measurements for abundances of neutron - capture elements in very metal - poor stars have been providing useful constraints on these models . @xcite have studied the chemical abundances of the extremely metal - poor star cs  22892052 , the first example of a small but growing class of metal - poor stars that exhibit very large excesses of r - process elements relative to iron ( [ r - process / fe ] @xmath0 ) . an important result of their work is that the relative abundance pattern of the neutron - capture elements from the 2nd to the 3rd peak ( 56 @xmath1 _ z _ @xmath1 76 ) in this star is identical , within observational errors , to that of the ( inferred ) solar system r - process component . this phenomenon is sometimes referred to as `` universality '' of the r - process , having a large impact on the studies of the nature of the r - process , and its astrophysical site .    however , the abundance patterns of light neutron - capture elements ( 38 @xmath1 z @xmath1 48 ) in r - process enhanced stars exhibit clear deviations from that of the solar system r - process component @xcite . this suggests the existence of another r - process site which has contributed to the light r - process elements in solar - system material . this process is sometimes called as `` weak r - process '' , while the process that is responsible for heavy neutron - capture elements ( ba @xmath2 u ) is referred to `` main r - process '' .    following the previous studies ( e.g. , * ? ? ? * ; * ? ? ? * ) , @xcite and @xcite have investigated the correlation of sr and ba abundances in very metal - poor stars ( [ fe / h ] @xmath3 ) in some detail . they showed that the dispersion of the sr abundances clearly decreases with increasing ba abundance . this correlation indicates the existence of ( at least ) two processes : one enriches both heavy and light neutron - capture elements , while the other yields light neutron - capture elements with only small production of heavy ones . @xcite discuss the contribution of a primary process which has produced light neutron - capture elements in our galaxy . the abundance patterns produced by the main r - process have been studied previously based on high resolution spectroscopy of metal - poor stars ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) as mentioned above . by way of contrast , the abundance pattern of neutron - capture elements produced by the weak r - process is still unclear . since the abundances of heavy neutron - capture elements yielded by this process are very low , it is quite difficult to accurately measure their abundances in metal - poor stars . in addition , most spectral lines of light neutron - capture elements , in particular those with @xmath4 exist in the near - uv region , in which atmospheric extinction makes the observation with ground - based telescopes difficult . we have been investigating light neutron - capture elements in very metal - deficient stars from near - uv spectroscopy with the 8.2  m subaru telescope . ishimaru et al . ( 2006 , in preparation ) studied the abundances of pd and ag , which exist between the first and second abundance peaks produced by neutron - capture processes , for several metal - poor stars . one of the targets is hd  122563 , a well - studied bright metal - poor ( [ fe / h ] @xmath5 ) giant . this object has very low abundances of heavy neutron - capture elements ( e.g. [ ba / fe ] @xmath6 * ? ? ? * ) , while light neutron - capture elements show large excesses relative to heavy ones ( e.g. [ sr / ba ] @xmath7 ) . therefore , the abundance pattern of neutron - capture elements in this star might well represent the yields of the process producing light neutron - capture elements at low metallicity . in this paper we report the abundance pattern of light and heavy neutron - capture elements in hd  122563 . in 2 we present our near - uv spectroscopy with subaru / hds , while we describe in detail the abundance analysis of neutron - capture elements in  3 . our results are compared with the previous studies in  4 . we discuss the derived abundances of hd  122563 , and the source of neutron - capture elements in  5 . finally , our conclusions are presented in  6 . high dispersion spectroscopy of hd  122563 was carried out with the subaru telescope high dispersion spectrograph ( hds : * ? ? ? * ) in 30 april , 2004 . our spectrum covers the wavelength range from 3070 to 4780  with a resolving power of @xmath8 = 90,000 . the total exposure time is 5400 seconds ( one 600  s exposure plus four 1200  s ones ) . the reduction was carried out in a standard manner using the iraf echelle package . the signal to noise ratio ( s / n ) of the spectrum ( per 0.9 km s@xmath9 pixel ) estimated from the photon counts is 140 at 3100  ; 480 at 3500  ; 860 at 3900  ; 1080 at 4200  and 1340 at 4500  .    in order to measure ba lines at 5853   and 6141   , a spectrum obtained during the hds commissioning covering 5090 6410 was used . the s / n ratio of this spectrum is 350 at 6000   . we adopted the line list used in previous studies for line identifications and analyses of neutron - capture elements ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? in addition , the recent measurements of transition probabilities and hyperfine splitting reported for some elements ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) are incorporated . the line list used in the analysis is given in table [ tab : table1 - 4 ] . + equivalent widths of clean , isolated lines are measured by fitting gaussian profile . the results are given in table [ tab : table1 - 4 ] . for our quantitative abundance measurements , we used the analysis program sptool developed by y. takeda , based on kurucz s atlas9/width9 @xcite . sptool calculates synthetic spectra and equivalent widths of lines on the basis of the given model atmosphere , line data , and chemical composition , under the assumption of lte . we adopted the model atmosphere parameters ( effective temperature : @xmath10 , gravity : @xmath11 , micro - turbulent velocity : @xmath12 , and metallicity : [ fe / h ] ) derived by @xcite : @xmath10 = 4570 k , @xmath13 = 1.1 , @xmath12 = 2.2 km s@xmath9 , and [ fe / h ] @xmath14 . the estimated uncertainties are @xmath15 = 100 k , @xmath16 = 0.3 dex , @xmath17 = 0.5 km s@xmath9 , and @xmath18[fe / h ] = 0.19 dex ( honda et al . 2004 ) . the abundance analyses were attempted for 24 neutron - capture elements from sr to th . the effects of hyperfine and isotopic splitting are taken into account in the analysis of ba , la , eu , and yb ( see references in table 1 ) . the derived abundances are given in table [ tab : table2 ] . the abundances determined from individual lines are given in table [ tab : table1 - 4 ] . we used the solar system abundances obtained by @xcite to derive [ x / fe ] values . the size of the random errors are estimated from the standard deviation ( 1@xmath19 ) of the abundances derived from individual lines for elements that have three or more lines available for the abundance analysis . for the abundances of elements based only on one or two lines , we employ the mean of the random errors estimated from those elements with three or more lines available . the uncertainties of model atmosphere parameters result in systematic errors in the abundances of neutron - capture elements . the effects of these uncertainties on the abundance measurements are given in table [ tab : error ] . the behavior of the errors is slightly different for abundances derived from neutral species and those from ionized ones . this should be borne in mind in the discussion on the abundances of light neutron - capture elements , some of which were determined using lines of neutral species . by contrast , such differences do not significantly affect our discussion of the abundance ratios of heavy neutron - capture elements , which were all measured from ionized species . the details of the analysis for individual neutron - capture elements are presented below . for comparison purposes , the abundances of cu and zn were also determined . in addition to the cu 5105  and zn 4810  lines , the uv lines ( 3250 - 3350  ) are also used in the abundance analyses ( table [ tab : table1 - 4 ] ) .      although the abundances of sr , y , and zr have been determined by a number of previous studies for hd  122563 , measurements for other light neutron - capture elements are quite limited so far . we have newly detected 5 elements ( nb , mo , ru , pd , and ag ) in our spectrum , and derived an upper limit for a sixth element ( rh ) .    two strong lines of ( 4077 and 4215 ) and the weak line of ( 4607 ) were measured . the two resonance lines are so strong that the abundance derived from these lines is sensitive to the microturbulent velocity and treatment of damping . however , the agreement of the abundances derived from and ( see table [ tab : table1 - 4 ] ) suggests the reliability of our measurements .    two ( @xmath21 ) lines are detected . the detection of the 3163 line is reported only for canopus by @xcite and for the sun . this line would be useful for abundance analyses because of its strength ( figure [ fig : spectra ] ) . we note , however , that the abundance determined from this line is slightly higher ( by 0.25 dex ) than that from the 3215   line , possibly suggesting a small contamination by other spectral features . however , here we simply adopt the mean of the abundances derived from the two lines .    the ( @xmath22 ) 3864 line is detected in cs  22892 - 052 by @xcite . although a blend of a cn line is reported by these authors , that is not severe in hd  122563 , because the carbon abundance of this star is more than 1  dex lower than that of cs  22892052 . we have detected two lines of ( @xmath23 ) . the equivalent width of the 3498   line is measurable due to there being no ( apparent ) blend with other lines . since a strong line exists in the bluer region of the other line at 3728   , we applied the spectrum synthesis technique to the analysis of that line . the ( @xmath24 ) 3692   line exists in the wing of h i line , but is not detected in our spectrum . we determined only an upper limit on the abundance of this element . we have detected two lines of pd . the 3242   line blends with oh lines . the contamination was estimated using the oh line list of @xcite , adjusting the oxygen abundance to match the strengths of neighboring oh lines ( [ o / fe ] @xmath250.4 ) . the 3404   line is clearly detected with no severe blend ( figure [ fig : spectra ] ) . two lines have been measured in some metal - poor stars . the 3280   line is detected , while the 3383   line is not . since nh lines blend with the 3280   line @xcite , we included the nh lines adopted from @xcite in the spectrum synthesis , calibrating the n abundance to reproduce the nh features around the line ( [ n / fe]@xmath26 ) . we note that the n abundance adopted is much lower than those derived by previous works ( e.g.,[n / fe]@xmath7 * ? ? ? this discrepancy is partially due to the inaccurate gf - values used in our analysis . recent studies of n abundances based on nh lines applied corrections of gf - values to the kurucz s list ( e.g. , * ? ? ? in addition to the nh lines , some unidentified feature appears in the red part of this line ( figure [ fig : spectra ] ) . if such unknown lines also affect the line , the values derived from this line must be regarded as an upper limit on the ag abundance . the abundances of ba , la , eu , and yb were derived by a spectrum synthesis technique , taking into account hyperfine splitting . the abundances of other elements were determined by applying a single line approximation , which is justified by the fact that the absorption lines are quite weak in general . in addition to the two resonance lines at 4554 and 4934   , two ba lines in the red region were measured . the line data of @xcite were used for the analysis of ba lines , assuming the isotope ratios of r - process component in solar - system material . there is a small discrepancy between the ba abundances from the two resonance lines and others . a possible reason for this discrepancy is the non - lte effect ( e.g. , * ? ? ? however , we here simply adopt the average of the ba abundances from the four lines . we detected three lines at 3819   , 4129   and 4205   . however , the 4205   line blends with a line , while the 3819   one is affected by a wing component of a strong fe line at 3820   . since these eu lines are quite weak in the spectrum of hd  122563 , in contrast to those in r - process enhanced stars , the effect of the blending is significant . hence , we adopt the result from the 4129   . we note that the eu abundances derived from the excluded lines , within their relatively large errors , agree with the value from the 4129   line . the effect of isotope shift for gd lines was included in the analysis by @xcite for the s - process enhanced star cs  31062 - 050 . this effect is , however , neglected in the present analysis , because the gd lines of hd  122563 are very weak . we have detected three gd lines ( table [ tab : table1 - 4 ] ) . the gd abundance derived from the 3481  line is significantly higher than those from the other two , and an upper limit estimated from another line ( 3331   ) . we regard this as a result of contamination of the 3481   line by some unidentified lines , and exclude this line in the determination of the final gd abundance . yb is the heaviest element detected in our spectrum . we measured two yb lines at 3220 and 3694 . a spectrum synthesis technique was applied to the analysis including the effect of hyperfine splitting for these lines ( sneden et al . 2003 , private communication ) . agreement of the results from the two lines is fairly good . the upper limits of ir and th abundances are obtained from the analyses of 3800   and 4019   line . the line of 4019   is affected by contamination by other lines ( figure [ fig : th ] ) . we analyzed this line using the line list of @xcite for this wavelength region . we adopted @xmath28c/@xmath29c = 5 to estimated the blending of @xmath29ch lines . since the blends of fe and co lines are severe , no clear th feature is identified , although the quality of the spectrum is very high ( s / n = 950 at 4020   ) . we derived the upper limit of the th abundance ( log @xmath30 ( th ) @xmath31 ) from the fitting of synthetic spectra by eye . neutron - capture elements have been studied for this object by many authors . recently , @xcite , @xcite , @xcite , and @xcite performed detailed abundance analyses based on high resolution spectroscopy ( @xmath32 ) for this object . @xcite also determined the abundances of eight neutron - capture elements , though their resolving power ( @xmath33 ) is not as high as those in the above studies . recently , @xcite derived the abundances of ge , zr , la and eu from the uv region ( 2410 @xmath2 3070   ) of this object using hubble space telescope , and also uv - blue region ( 3150 @xmath2  4600   ) with keck i hires . figure [ fig : comp ] shows comparisons of the abundances of neutron - capture elements derived by the present analysis with those of previous work . our results are in good agreement with @xcite , @xcite and @xcite . however , the abundances of neutron - capture elements determined by the present analysis are systematically lower than those by @xcite and @xcite . here we inspect the discrepancy between the results of @xcite and ours in some detail , because their work determined abundances of a larger number of elements than @xcite , and they reported the equivalent widths used in the abundance analysis for some lines ( unfortunately , the equivalent widths were not given for the lines for which spectrum synthesis technique was applied ) . the atmospheric parameters adopted in our analysis are in good agreement with theirs : the differences ( our results minus those of @xcite ) of @xmath10 , @xmath13 , [ fe / h ] and @xmath12 are + 70  k , 0.2  dex , 0.07  dex and 0.3  km  s@xmath9 , respectively . these differences results in differences of abundances smaller than 0.1 dex for heavy neutron - capture elements ( see table [ tab : error ] ) . therefore , the difference of the adopted atmospheric parameters is not a reason for the abundance discrepancy . we also found good agreements in the equivalent widths of the lines reported by both works . however , the @xmath34 value of the nd 4061   line used by @xcite is lower by 0.25  dex than ours . though the @xmath34 values of la adopted by the two works are quite similar , no information on the treatment of the hyperfine splitting was given by @xcite , while the effect is fully included in our analysis . we adopted recent line data for @xcite and @xcite , which should be more accurate than those used by @xcite . thus , the discrepancy between the results of the two work might be partially explained by the difference of the adopted line data . however , there seems to exist small ( @xmath20.2  dex ) systematic differences , for which no clear reason is identified . we investigated a high quality uv - blue spectrum of hd  122563 , and have detected 19 neutron - capture elements including nb , mo , ru , pd , ag , pr , and sm , which are detected for the first time by our study for this object , and upper - limits for 5 elements including th . the derived abundances are given in table [ tab : table2 ] . in this section , we discuss the abundance pattern of the neutron - capture elements , along with cu and zn , to investigate the origin of neutron - capture elements in this object . the abundance ratio between ba ( or la ) and eu is used as an indicator of the origin of neutron - capture elements . the value of [ ba / eu ] of the solar system r - process component is 0.81 , while that of the s - process component is + 1.45 @xcite . the value of the [ ba / eu ] is 0.50 in hd  122563 . in addition , the value of [ la / eu ] of the solar system r - process component is 0.59 , while that in hd  122563 is 0.50 . these results indicate that the heavy ( @xmath35 @xmath36 56 ) neutron - capture elements of this object are principally associated with the r - process , and the contribution of the ( main ) s - process is small if any . we recall that this object is very metal - poor ( [ fe / h]@xmath37 ) with no excess of carbon ( [ c / fe]=@xmath38 ) . figure [ fig : r ] shows the abundance pattern of hd  122563 , comparing with that of the solar - system r - process component . the solar system r - process abundance pattern is scaled to the eu abundance of hd  122563 . this figure clearly shows that the abundances of light neutron - capture elements ( 38 @xmath1 z @xmath1 47 ) are much higher than those of heavy ones in hd  122563 , compared to the solar - system r - process pattern . this behavior is very different from that found in r - process enhanced stars ( e.g. cs  22892 - 052 , cs 31082 - 001 : * ? ? ? * ; * ? ? ? although we indicated above that the heavy neutron - capture elements are principally associated with the r - process , figure [ fig : r ] indicates that even in the range 56 @xmath39 @xmath35 @xmath39 59 the abundances in hd  122563 exceed those of the scaled solar r - process , with only la falling on the eu - normalised curve . this suggests that the tendency for the light neutron - capture elements ( 38 @xmath1 @xmath35 @xmath1 47 ) to fall above the scaled solar r - process curve is part of a general , atomic - number dependent , trend .    in order to demonstrate this behavior more clearly , figure [ fig : f7 ] shows the logarithmic difference of the abundances of this object from the solar system r - process pattern as a function of atomic number . we also show that of the r - process enhanced star cs  22892 - 052 @xcite in the same way . we find good agreement between the abundance pattern of cs  22892 - 052 and the solar - system r - process one , at least for elements with 56@xmath40 . by way of contrast , our new measurements for hd  122563 clearly demonstrate a quite different abundance pattern from that of the solar - system r - process component and of cs  22892052 . the excess of light neutron - capture elements ( e.g. sr ) with respect to the heavy ones ( e.g. ba ) was known for hd  122563 by previous studies ( see section 1 ) . however , the abundances of elements having intermediate mass ( e.g. mo , pd ) were measured in detail for the first time by the present work . the abundances of these elements are intermediate , and , hence , the abundances of neutron - capture elements gradually and continuously decrease with increasing atomic number from @xmath41 to @xmath42 . this trend is a key to investigating the nucleosynthesis process that is responsible for neutron - capture elements in this object .    for comparison purposes , we also attempted to compare the abundances of hd  122563 with the solar system s - process distribution ( figure [ fig : s ] ) . in this case , ba , la , ce , and eu show large deviations from the solar system s - process curve , although the overall abundance pattern from sr to yb seems to be similar . since the s - process abundance pattern in the solar - system is a result of a combination of some individual processes ( at least the weak and main components of the s - process ) , we presume this apparent `` agreement '' is physically not important . we also have detected four neutron - capture elements heavier than eu ( gd , dy , er , yb : @xmath43 64 ) . the abundances of these elements also show a decreasing trend as a function of atomic number , with respect to the solar - system r - process pattern . this also has an impact on the understanding of the origin of neutron - capture elements in this object . th is a radioactive element and is synthesized only by the r - process . the upper limit of the th abundance determined by the present work indicated that this object does not show an excess of th with respect to eu ( and other heavy neutron - capture elements ) , compared to most r - process enhanced stars . the cu and zn abundances of hd  122563 are typical values found in very metal - poor stars ( e.g. , * ? ? ? * ; * ? ? ? that is , no clear difference is found in the abundances of these elements between the stars having high and low abundances of light neutron - capture elements . this result may give a hint for the origins of cu and zn , as well as of light neutron - capture elements , which are still unclear . here we consider the origin of neutron - capture elements in this object based on the abundance pattern determined by the present work . the abundance ratios between light and heavy neutron - capture elements ( e.g. , sr / ba ) in hd  122563 are clearly different from those in r - process enhanced stars , as already mentioned in  1 . therefore , the r - process responsible for the heavy neutron - capture elements in the solar system ( the so - called `` main '' r - process ) is not an important source of , at least , light neutron - capture elements in hd  122563 . the main s - process is also excluded from the possible source of light neutron - capture elements , because that yields even lower abundance ratios between light and heavy neutron - capture elements at low metallicity ( e.g. * ? ? ? * ; * ? ? ? the weak component of the s - process was introduced to interpret the light s - process nuclei in the solar system . however , the gradually decreasing trend of elemental abundances from sr to ba found in hd  122563 does not resemble that of the weak s - process , which predicts a rapid drop of abundances at @xmath44 ( i.e. y or zr ) . it should be noted in addition that the weak s - process is expected to be inefficient at low metallicity , because of the lack of the neutron source @xmath45ne ( e.g. * ? ? ? * ; * ? ? ? * ) in addition to the lack of iron seeds . thus , another process that has efficiently yielded light neutron - capture elements at low metallicity is required to explain the abundance pattern of neutron - capture elements in hd  122563 . the presence of such a process has been indicated by recent observational studies of metal - deficient stars with no excess of heavy neutron - capture elements ( * ? ? ? * and references therein ) . this process was called the `` light element primary process '' ( lepp ) by @xcite , who estimated its contribution to the solar abundances . @xcite have shown that such light r - process nuclei ( up to @xmath46 ) are produced in neutrino winds as a result of  weak \" ( or failed ) r - processing ( see also * ? ? ? it is likely , therefore , that these light neutron - capture elements originate from the core - collapse supernovae , although a contribution from other sources can not be excluded . the abundance pattern of light to heavy neutron - capture elements measured for hd  122563 provides a unique constraint on such model calculations . the abundance pattern of heavy neutron - capture elements of hd  122563 shows a significant departure from the r - process component in solar - system material , though the departure is not as large as that found for light neutron - capture elements ( figure [ fig : r ] ) . figure [ fig : r+s ] shows a comparison between the abundances of elements with @xmath47 measured for hd  122563 ( filled circles ) and the solar - system r - process abundance pattern @xcite , which is scaled to achieve the best fit to the observed data ( the solid line ) . ( recall that the scaling in figure  [ fig : r ] was to eu . ) significant disagreements are found for ce and pr , as well as for dy , er and yb . given the fact that the abundance patterns of heavy elements measured for r - process enhanced stars show excellent agreement with that of the solar - system , the different abundance pattern of hd  122563 must be significant . some process that produces a different abundance pattern of heavy neutron - capture elements from that of the main r - process is at least required to explain the abundance pattern of this star . one possibility is to assume a small contribution of the ( main ) s - process . in order to examine this possibility , we adopted the r - process and s - process abundance patterns in the solar - system as determined by @xcite , and searched for the combination that gives the best fit to the abundance pattern of hd  122563 . the result is shown by the dashed line in figure [ fig : r+s ] . in this case , the contributions of the s - process to ba , la , and ce are significant ( @xmath2 70% ) , while those to elements heavier than nd are small ( @xmath48 10% ) . it should be noted that such a small contribution of the main s - process does not affect the abundance pattern of light neutron - capture elements discussed in the previous subsection . the root - mean - square ( rms ) of the logarithmic abundance difference between the observed and calculated abundance patterns is 0.29  dex for the case that a contribution from the s - process is introduced , compared with 0.34  dex if only the r - process is assumed . thus , the fit is slightly better if an s - process contribution is introduced . however , the improved fit comes at the cost of an additional free parameter ( the relative contribution of the s- and r - processes ) , and it is not clear that assuming an s - process contribution is justifiable from the point of view of the star s nucleosynthetic history . in particular , the discrepancy found in the abundance pattern of elements heavier than sm can not be explained by this approach , because the production of such heavy elements by the s - process is very small . this discrepancy leads us to consider an alternative possibility that the heavy neutron - capture elements of this star are also a result of the unidentified ( single ) process that is responsible for the large enhancement of the light neutron - capture elements discussed in   5.2.1 . @xcite have suggested that the small ( but non - negligible ) amount of heavy r - process nuclei ( @xmath49 ) with non solar r - process abundance pattern can be produced in neutrino winds if the entropy of the neutrino - heated matter is enough high ( but smaller than that required for the main r - process ) , in addition to the light r - process nuclei . if this is true , the abundance pattern of heavy neutron - capture elements in this object may give another hint for , or constraint on , the modeling of this process . the differences between the abundance patterns of heavy neutron - capture elements in hd  122563 and the solar - system r - process abundance pattern are not large . further observational data are clearly required to derive definitive conclusions . however , it would be very difficult to improve the measurement of abundances for hd  122563 , because the quality of the spectrum used in the present work is extremely high . one possibility is to reconsider the atomic line data to reduce the uncertainties in abundance measurements . another important observational study is to apply similar analysis to other metal - poor stars having high abundance ratios of light to heavy neutron - capture elements . in particular , measurements for stars with lower metallicity than hd  122563 are important , because no s - process contribution is expected for such stars . we obtained a high resolution , high s / n uv - blue spectrum of the very metal - poor star hd  122563 with subaru / hds . the abundances were measured for 19 neutron - capture elements , among which seven elements are detected for the first time in this star . our new measurements for hd  122563 clearly demonstrate that the elemental abundances gradually decrease relative to the scaled solar r - process abundances with increasing atomic number , at least from sr to yb . we have considered whether the higher abundances of lighter elements can be explained by contributions from the weak s- or main s - processes , and find these not to provide satisfactory explanations . the abundance pattern of elements with @xmath50 does not agree with any prediction of neutron - capture process models known . the abundance pattern of a wide range of neutron - capture elements determined for hd  122563 therefore provides new strong constraints on models of nucleosynthesis for very metal - poor stars , in particular those with excesses of light neutron - capture elements but without enhancement of heavy ones . this work was supported in part by a grant - in - aid for the japan - france integrated action program ( sakura ) , awarded by the japan society for the promotion of science , and scientific research ( 17740108 ) from the ministry of education , culture , sports , science , and technology of japan . most of the data reduction was carried out at the astronomical data analysis center ( adac ) of the national astronomical observatory of japan . aoki , w. , et al . 2002 , apj , 580 , 1149 aoki , w. , et al . 2005 , apj , 632 , 611 asplund , m. , grevesse , n. , & sauval , a. j. 2005 , in asp conf . 336 , cosmic abundances as records of stellar evolution and nucleosynthesis , ed . t. g. barnes iii & f. n. bash ( san francisco : asp ) , 25 asplund , m. 2005 , ara&a , 43 , 481 burris , d. l. , pilachowski , c. a. , armandroff , t. e. , sneden , c. , cowan , j. j. , & roe , h 2000 , apj , 544 , 302 busso , m. , gallino , r. , & wasserburg , g. j. 1999 , ara&a , 37 , 239 cameron , a. g. w. 2001 , apj , 562 , 456 cayrel , r , et al . 2004 , a&a , 416 , 1117 cowan , j. j. , et al . 2002 , apj , 572 , 861 cowan , j. j. , et al . 2005 , apj , 627 , 238 den hartog , e. a. , lawler , j. e. , sneden , c. & cowan , j. j. 2003 , apjs , 148 , 543 ecuvillon , a. , israelian , g. , santos , n. c. , mayor , m. , garcia lopez , r. j. , & randich , s. 2004 , a&a , 418 , 703 freiburghaus , c. , rosswog , s. , & thielemann , f. -k . 1999 , , 525 , l121 hill , v. , et al . 2002 , a&a , 387 , 560 honda , s. , et al . 2004 , apj , 607 , 474 ishimaru , y. & wanajo , s. 1999 , , 511 , l33 ishimaru , y. , wanajo , s. , aoki , w. , & ryan , s. g. 2004 , , 600 , l47 johnson , j. a. & bolte , m. 2001 , apj , 554 , 888 johnson , j. a. 2002 , apjs , 139 , 219 johnson , j. a. & bolte , m. 2002 , apj , 579 , 616 johnson , j. a. & bolte , m. 2004 , apj , 605 , 462 kurucz , r. l. , & bell . b 1995 , kurucz cd - rom , no.23 ( harvard - smithsonian center for astrophysics ) kurucz , r. l. 1993 , kurucz cd - rom , no.13 ( harvard - smithsonian center for astrophysics ) lawler , j. e. , sneden , c. , & cowan , j. j. , 2004 , apj , 604 , 850 lawler , j. e. , bonvallet , g. , & sneden , c. 2001a , apj , 556 , 452 lawler , j. e. , wickliffe , m. e. , den hartog , e. a. , & sneden , c. 2001b , apj , 563 , 1075 mcwilliam , a , preston , g. w. , sneden , c , & searle , l 1995 , aj , 109 , 27 mcwilliam , a 1998 , aj , 115 , 1640 noguchi , k.,et al . 2002 , pasj , 54 , 855 prantzos , n. , hashimoto , m. , & nomoto , k. 1990 , a&a , 234 , 211 sneden , c. , mcwilliam , a. , preston , g. w. , cowan , j. j. , burris , d. l. , & armosky , b. j. 1996 , apj , 467 , 819 sneden , c , cowan , j. j. , ivans , i. i. , fuller , g. m. , burles , s , beers , t. c. , & lawler , j. e. 2000 , apj , 533l , 139 sneden , c. , et al . 2003 , apj , 591 , 936 sumiyoshi , k. , et al . 2001 , apj , 562 , 880 surman , r. , mclaughlin , g. c. , & hix , w. r. 2005 , submitted to ( astro - ph/0509365 ) raiteri , c. m. , gallino , r. , busso , m. , neuberger , d. , & kappeler , f. 1993 , apj , 419 , 207 reynolds , s. e. , hearnshaw , j. b. , & cottrell , p. l. 1988 , mnras , 235 , 1423 rosswog , s. , liebendorfer , m. , thielemann , f .- k . , davies , m. b. , benz , w. , & piran , t. 1999 , a&a , 341 , 499 travaglio et al . 2004 , apj , 114 , 1293 truran , j. w. , cowan , j. j. , pilachowski , c. a. , & sneden , c. 2002 , pasp , 114 , 1293 wanajo , s. , kajino , t. , mathews , g. j. , & otsuki , k. 2001 , , 554 , 578 wanajo , s. , tamamura , m. , itoh , n. , nomoto , k. , ishimaru , y. , beers , t. c. , & nozawa , s. 2003 , apj , 593,968 wanajo , s. & ishimaru , i. 2005 , , in press westin , j. , sneden , c. , gustafsson , b. , & cowan , j. j. 2000 , apj , 530 , 783 woosley , s. e. , wilson , j. r. , mathews , g. j. , hoffman , r. d. , & meyer , b. s. 1994 , , 433 , 229    lcccccc wavelength & l.e.p.(ev ) & log@xmath34 & log@xmath30 & _ w_(m ) & ref + , @xmath51 & & & & & + 3247.53 & 0.000 & 0.060 & 1.04 & 115.1 * & 8 + 3273.95 & 0.000 & 0.360 & 1.24 & 112.3 & 8 + 5105.55 & 1.390 & 1.520 & 0.66 & 3.3 & 2 + , @xmath52 & & & & & + 3302.98 & 4.030 & 0.057 & 2.07 & 20.3 * & 1 + 3345.02 & 4.078 & 0.246 & 1.78 & 19.5 * & 1 + 4722.15 & 4.030 & 0.390 & 2.09 & 14.5 & 5 + 4810.54 & 4.080 & 0.170 & 2.10 & 20.5 & 5 + , @xmath41 & & & & & + 4607.33 & 0.000 & 0.280 & 0.14 & 2.4 & 7 + , @xmath41 & & & & & + 4077.71 & 0.000 & 0.170 & 0.18 & 163.3 & 6 + 4215.52 & 0.000 & 0.170 & 0.03 & 155.6 & 6 + , @xmath53 & & & & & + 3327.88 & 0.410 & 0.130 & 0.98 & 49.3 * & 8 + 3549.01 & 0.130 & 0.280 & 0.97 & 49.0 & 7 + 3584.52 & 0.100 & 0.410 & 0.98 & 44.1 * & 10 + 3600.74 & 0.180 & 0.280 & 1.06 & 68.2 & 7 + 3611.04 & 0.130 & 0.010 & 1.06 & 59.0 & 7 + 3628.70 & 0.130 & 0.710 & 0.90 & 31.8 & 10 + 3710.29 & 0.180 & 0.460 & 0.98 & 82.3 & 10 + 3747.55 & 0.100 & 0.910 & 0.98 & 22.8 & 7 + 3774.33 & 0.130 & 0.210 & 0.91 & 79.0 & 6 + 3788.70 & 0.100 & 0.070 & 0.95 & 66.6 & 6 + 3818.34 & 0.130 & 0.980 & 0.74 & 29.4 & 6 + 3950.36 & 0.100 & 0.490 & 0.94 & 47.4 & 6 + 4398.01 & 0.130 & 1.000 & 0.82 & 28.0 & 6 + 4883.69 & 1.080 & 0.070 & 0.82 & 25.0 & 6 + 5087.43 & 1.080 & 0.170 & 0.91 & 13.8 & 6 + , @xmath54 & & & & & + 3438.23 & 0.090 & 0.420 & 0.57 & 76.8 * & 7 + 3457.56 & 0.560 & 0.530 & 0.17 & 27.3 & 7 + 3479.02 & 0.530 & 0.690 & 0.34 & 16.7 & 7 + 3479.39 & 0.710 & 0.170 & 0.40 & 40.2 * & 7 + 3499.58 & 0.410 & 0.810 & 0.48 & 13.6 * & 7 + 3505.67 & 0.160 & 0.360 & 0.42 & 47.0 * & 7 + 3536.94 & 0.360 & 1.310 & 0.33 & 7.6 * & 7 + 3551.96 & 0.090 & 0.310 & 0.35 & 57.3 * & 8 + 3573.08 & 0.320 & 1.040 & 0.26 & 16.4 & 7 + 3578.23 & 1.220 & 0.610 & 0.29 & 3.8 * & 7 + 3630.02 & 0.360 & 1.110 & 0.28 & 12.8 & 7 + 3714.78 & 0.530 & 0.930 & 0.25 & 13.6 & 7 + 3836.77 & 0.560 & 0.060 & 0.31 & 47.3 & 6 + 3998.97 & 0.560 & 0.670 & 0.07 & 36.1 & 7 + 4050.33 & 0.710 & 1.000 & 0.09 & 11.0 & 7 + 4208.98 & 0.710 & 0.460 & 0.16 & 27.1 & 6 + 4317.32 & 0.710 & 1.380 & 0.08 & 5.3 & 6 + , @xmath21 & & & & & + 3163.40 & 0.376 & 0.260 & 1.30 & 24.2 * & 1 + 3215.59 & 0.440 & 0.190 & 1.65 & 4.5 * & 6 + , @xmath22 & & & & & + 3864.10 & 0.000 & 0.010 & 0.87 & 3.3 & 8 + , @xmath23 & & & & & + 3498.94 & 0.000 & 0.310 & 0.90 & 4.1 & 6 + 3728.03 & 0.000 & 0.270 & 0.82 & 4.7 * & 6 + , @xmath24 & & & & & + 3692.36 & 0.000 & 0.174 & @xmath48 - 1.20 & syn & 6 + , @xmath55 & & & & & + 3404.58 & 0.810 & 0.320 & 1.31 & 6.7 * & 6 + , @xmath56 & & & & & + 3280.68 & 0.000 & 0.050 & 1.88 & 6.5 * & 6 + , @xmath42 & & & & & + 4554.04 & 0.000 & 0.170 & 1.76 & 95.4 * & 6 + 4934.10 & 0.000 & 0.150 & 1.76 & 82.2 * & 6 + 5853.70 & 0.604 & 1.010 & 1.54 & 8.5 * & 6 + 6141.70 & 0.704 & 0.070 & 1.55 & 40.6 * & 6 + @xmath57 & & & & & + 3794.77 & 0.240 & 0.210 & 2.35 & 5.9 * & 7 + 3988.52 & 0.400 & 0.210 & 2.75 & 1.7 * & 4 + 3995.75 & 0.170 & 0.060 & 2.65 & 2.1 * & 4 + 4086.71 & 0.000 & 0.070 & 2.53 & 4.6 * & 4 + 4123.23 & 0.320 & 0.130 & 2.70 & 2.0 * & 4 + @xmath58 & & & & & + 4222.60 & 0.120 & 0.180 & 1.90 & 2.0 * & 6 + 4523.08 & 0.520 & 0.080 & 1.62 & 1.6 * & 10 + 4539.78 & 0.330 & 0.080 & 2.03 & 1.1 & 10 + 4562.37 & 0.480 & 0.190 & 2.01 & 1.4 & 10 + 4572.28 & 0.680 & 0.290 & 1.98 & 1.1 * & 8 + @xmath59 & & & & & + 4179.40 & 0.200 & 0.480 & 2.15 & 7.8 * & 7 + 4189.48 & 0.370 & 0.380 & @xmath48 - 2.15 & & 8 + @xmath60 & & & & & + 3784.25 & 0.380 & 0.150 & 2.14 & 2.0 & 9 + 3826.42 & 0.064 & 0.410 & 2.00 & 2.0 * & 9 + 4061.08 & 0.471 & 0.550 & 2.00 & 5.5 & 9 + 4232.38 & 0.064 & 0.470 & 1.89 & 2.3 * & 9 + @xmath61 & & & & & + 4318.94 & 0.280 & 0.270 & 2.16 & 1.8 * & 7 + 4642.23 & 0.380 & 0.520 & 2.16 & 0.8 & 7 + @xmath62 & & & & & + 3819.67 & 0.000 & 0.510 & 2.95 & syn & 5 + 4129.70 & 0.000 & 0.220 & 2.77 & 9.0 * & 5 + 4205.05 & 0.000 & 0.210 & 2.92 & syn & 5 + @xmath63 & & & & & + 3331.40 & 0.000 & 0.140 & @xmath48 - 2.15 & syn & 7 + 3481.80 & 0.490 & 0.230 & 1.79 & 4.0 * & 7 + 3549.37 & 0.240 & 0.260 & 2.40 & 2.1 & 7 + 3768.40 & 0.080 & 0.360 & 2.48 & 3.8 * & 7 + @xmath64 & & & & & + 3460.97 & 0.000 & 0.070 & 2.42 & 3.2 * & 7 + 3531.71 & 0.000 & 0.770 & 2.81 & 8.3 * & 8 + @xmath65 & & & & & + 3398.94 & 0.000 & 0.410 & @xmath48 - 2.00 & syn & 11 + @xmath66 & & & & & + 3499.10 & 0.060 & 0.136 & 2.75 & 2.7 & 10 + 3692.65 & 0.050 & 0.138 & 2.57 & 4.5 * & 6 + @xmath67 & & & & & + 3701.36 & 0.000 & 0.540 & @xmath483.00 & syn & 8 + @xmath68 & & & & & + 3289.37 & 0.000 & 0.020 & 2.70 & 27.5 * & 8 + 3694.19 & 0.000 & 0.300 & 2.86 & 13.3 * & 8 + @xmath69 & & & & & + 3220.76 & 0.350 & 0.510 & @xmath48 - 1.12 & syn & 7 + 3800.12 & 0.000 & 1.450 & @xmath48 - 1.60 & syn & 7 + @xmath70 & & & & & + 4019.12 & 0.000 & 0.270 & @xmath483.05 & syn & 7 +    lccccc species & _ z _ & log@xmath30 & @xmath19 & [ x / fe ] & n + cu & 29 & 0.98 & 0.29 & 1.15 & 3 + zn & 30 & 2.01 & 0.16 & + 0.18 & 4 + sr & 38 & 0.11 & 0.08 & 0.26 & 3 + y & 39 & 0.93 & 0.09 & 0.37 & 15 + zr & 40 & 0.28 & 0.16 & 0.10 & 17 + nb & 41 & 1.48 & 0.17 & 0.13 & 2 + mo & 42 & 0.87 & 0.17 & 0.02 & 1 + ru & 44 & 0.86 & 0.17 & + 0.07 & 2 + rh & 45 & @xmath481.20 & & @xmath48 + 0.45 & 1 + pd & 46 & 1.36 & 0.17 & 0.28 & 2 + ag & 47 & 1.88 & 0.17 & 0.05 & 1 + ba & 56 & 1.62 & 0.12 & 1.02 & 4 + la & 57 & 2.66 & 0.10 & 1.02 & 5 + ce & 58 & 1.83 & 0.18 & 0.64 & 6 + pr & 59 & 2.15 & 0.17 & 0.09 & 1 + nd & 60 & 2.01 & 0.10 & 0.69 & 4 + sm & 62 & 2.16 & 0.17 & 0.40 & 2 + eu & 63 & 2.77 & 0.17 & 0.52 & 1 + gd & 64 & 2.44 & 0.17 & 0.76 & 2 + dy & 66 & 2.62 & 0.17 & 0.99 & 2 + ho & 67 & @xmath482.00 & & @xmath48 + 0.26 & 1 + er & 68 & 2.66 & 0.17 & 0.82 & 2 + tm & 69 & @xmath483.00 & & @xmath480.23 & 1 + yb & 70 & 2.78 & 0.17 & 1.09 & 2 + ir & 77 & @xmath481.60 & & @xmath480.21 & 2 + th & 90 & @xmath483.05 & & @xmath480.34 & 1 +    lccccccccccc species & & & & & & & + & @xmath71 & @xmath72 & & @xmath73 & @xmath74 & & @xmath75 & @xmath76 & & @xmath76 & @xmath75 + & @xmath770.22 & @xmath780.17 & & @xmath780.06 & @xmath770.07 & & @xmath770.15 & @xmath780.06 & & @xmath780.23 & @xmath770.26 + & @xmath770.05 & @xmath780.04 & & @xmath770.05 & @xmath780.04 & & 0.00 & @xmath770.01 & & @xmath780.03 & @xmath770.02 + & @xmath770.13 & @xmath780.12 & & @xmath780.02 & @xmath770.03 & & @xmath770.04 & 0.00 & & @xmath780.01 & 0.00 + & @xmath770.12 & @xmath780.11 & & @xmath770.05 & @xmath780.03 & & @xmath770.03 & @xmath780.05 & & @xmath780.31 & @xmath770.39 + & @xmath770.08 & @xmath780.07 & & @xmath770.08 & @xmath780.08 & & @xmath780.02 & @xmath770.01 & & @xmath780.16 & @xmath770.09 + & @xmath770.08 & @xmath780.07 & & @xmath770.09 & @xmath780.08 & & @xmath780.03 & @xmath770.02 & & @xmath780.08 & @xmath770.05 + & @xmath770.09 & @xmath780.09 & & @xmath770.10 & @xmath780.10 & & @xmath780.04 & @xmath770.02 & & @xmath780.03 & @xmath770.02 + & @xmath770.19 & @xmath780.17 & & @xmath780.02 & @xmath770.01 & & @xmath770.03 & @xmath780.00 & & @xmath780.00 & 0.00 + & @xmath770.20 & @xmath780.17 & & @xmath780.01 & @xmath770.02 & & @xmath770.04 & @xmath780.00 & & @xmath780.01 & 0.00 + & @xmath770.20 & @xmath780.17 & & @xmath780.01 & @xmath770.03 & & @xmath770.04 & @xmath770.01 & & @xmath780.01 & @xmath770.01 + & @xmath770.21 & @xmath780.17 & & @xmath780.00 & @xmath770.01 & & @xmath770.04 & @xmath780.00 & & @xmath780.01 & @xmath770.01 + & @xmath770.09 & @xmath780.07 & & @xmath770.09 & @xmath780.07 & & @xmath780.01 & @xmath770.01 & & @xmath780.08 & @xmath770.06 + & @xmath770.08 & @xmath780.07 & & @xmath770.10 & @xmath780.09 & & @xmath780.03 & @xmath770.02 & & @xmath780.00 & @xmath770.00 + & @xmath770.08 & @xmath780.07 & & @xmath770.09 & @xmath780.09 & & @xmath780.02 & @xmath770.02 & & @xmath780.00 & 0.00 + & @xmath770.10 & @xmath780.08 & & @xmath770.10 & @xmath780.09 & & @xmath780.03 & @xmath770.02 & & @xmath780.01 & @xmath770.01 + & @xmath770.08 & @xmath780.08 & & @xmath770.09 & @xmath780.10 & & @xmath780.04 & @xmath770.02 & & @xmath780.00 & 0.00 + & @xmath770.09 & @xmath780.07 & & @xmath770.09 & @xmath780.08 & & @xmath780.03 & @xmath770.02 & & @xmath780.00 & @xmath780.00 + & @xmath770.09 & @xmath780.09 & & @xmath770.10 & @xmath780.10 & & @xmath780.04 & @xmath770.02 & & @xmath780.00 & @xmath770.00 + & @xmath770.10 & @xmath780.08 & & @xmath770.11 & @xmath780.09 & & @xmath780.03 & @xmath770.02 & & @xmath780.00 & 0.00 + & @xmath770.09 & @xmath780.10 & & @xmath770.10 & @xmath780.10 & & @xmath780.05 & @xmath770.02 & & @xmath780.01 & @xmath770.01 + & @xmath770.09 & @xmath780.09 & & @xmath770.10 & @xmath780.09 & & @xmath780.04 & @xmath770.03 & & @xmath780.00 & @xmath780.00 + & @xmath770.09 & @xmath780.08 & & @xmath770.10 & @xmath780.10 & & @xmath780.04 & @xmath770.02 & & @xmath780.03 & @xmath770.02 +", "tags": [], "output_text_a": "The paper investigates the chemical composition of extremely metal-poor stars, focusing on the nucleosynthesis processes that contribute to the abundance of neutron-capture elements. The study highlights the rapid neutron capture process (r-process) as a key mechanism for producing elements heavier than iron. However, the exact astrophysical site of the r-process remains unclear, with several proposed scenarios such as supernovae, neutron star mergers, and gamma-ray bursts, each facing unresolved challenges.\n\nRecent observations of extremely metal-poor stars, like HD 122563, reveal significant deviations in the abundance patterns of light neutron-capture elements compared to the solar system's r-process component. This suggests the existence of a \"weak r-process\" distinct from the \"main r-process\" responsible for heavier elements. The study uses high-resolution spectroscopy from the Subaru telescope to analyze the abundance of 24 neutron-capture elements in HD 122563, finding that light elements are more abundant relative to heavy ones, unlike in r-process enhanced stars.\n\nThe findings indicate that the main r-process and s-process are not the primary sources of light neutron-capture elements in HD 122563. Instead, a different process, possibly related to core-collapse supernovae, is suggested. The study provides new constraints on nucleosynthesis models, emphasizing the need for further observational data and refined atomic line data to better understand the origins of neutron-capture elements in metal-poor stars.", "output_text_b": "The article discusses the chemical composition of extremely metal-poor stars and the rapid neutron capture process (r-process) responsible for the production of approximately half of the abundances of elements heavier than the iron-group in solar system material. The astrophysical site of the r-process remains uncertain, with several proposed scenarios such as neutrino-driven winds, prompt explosions of core-collapse supernovae, neutron star mergers, and jets from gamma-ray burst accretion discs. However, each scenario has its own problems that remain to be solved.\n\nThe authors focus on the abundance patterns of light and heavy neutron-capture elements in the metal-poor star HD 122563. The abundance pattern of light neutron-capture elements in this star might represent the yields of the process producing light neutron-capture elements at low metallicity. The paper reports the abundance pattern of light and heavy neutron-capture elements in HD 122563, comparing it with previous studies and discussing the derived abundances and the source of neutron-capture elements.\n\nHigh dispersion spectroscopy of HD 122563 was carried out with the Subaru Telescope High Dispersion Spectrograph (HDS), and equivalent widths of clean, isolated lines were measured by fitting Gaussian profiles. The abundances of 24 neutron-capture elements from Sr to Th were determined using the analysis program SPTOOL, which calculates synthetic spectra and equivalent widths of lines based on the given model atmosphere, line data, and chemical composition under the assumption of LTE.\n\nThe authors found that the abundances of light neutron-capture elements, some of which were determined using lines of neutral species, have uncertainties affected by the behavior of errors, which is slightly different from abundances derived from ionized species. The abundance patterns of neutron-capture elements in HD 122563 are compared with those of the solar system r-process component and the solar system s-process distribution. The results indicate that the heavy neutron-capture elements of this object are primarily associated with the r-process, and the contribution of the (main) s-process is small.\n\nThe abundance ratios between light and heavy neutron-capture elements in HD 122563 are different from those in r-process enhanced stars, suggesting that the r-process responsible for the heavy neutron-capture elements in the solar system is not an important source of light neutron-capture elements in HD 122563. The gradually decreasing trend of elemental abundances from Sr to Ba found in HD 122563 does not resemble that of the weak s-process, which predicts a rapid drop of abundances at Y or Zr. Thus, another process that has efficiently yielded light neutron-capture elements at low metallicity is required to explain the abundance pattern of neutron-capture elements in HD 122563.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, discussing the chemical composition of extremely metal-poor stars and the nucleosynthesis processes involved, particularly the r-process and the potential existence of a weak r-process.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem, which is understanding the nucleosynthesis processes contributing to the abundance of neutron-capture elements in extremely metal-poor stars.\n\n4. **Methodology or Approach**: The summary mentions the use of high-resolution spectroscopy from the Subaru telescope to analyze the abundance of neutron-capture elements.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the finding that light elements are more abundant relative to heavy ones in HD 122563, and the suggestion of a different process for light neutron-capture elements.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"r-process\" and \"weak r-process.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the key experiment of using high-resolution spectroscopy to gather data.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance by emphasizing the need for further observational data and refined atomic line data to understand neutron-capture elements in metal-poor stars.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the chemical composition of extremely metal-poor stars and the r-process.\n2. The summary is concise but exceeds the 250-word limit, which is not ideal.\n3. The research problem addressed by the paper is mentioned, focusing on the uncertainty of the astrophysical site of the r-process.\n4. The methodology, including the use of high dispersion spectroscopy and the SPTOOL analysis program, is mentioned.\n5. Significant results and conclusions, such as the association of heavy neutron-capture elements with the r-process and the need for another process for light elements, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"r-process\" and \"s-process\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the use of the Subaru Telescope High Dispersion Spectrograph, are mentioned.\n10. The summary reflects the paper's significance in understanding nucleosynthesis in metal-poor stars."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "recently there has been considerable progress in understanding the notion of ellipticity on noncompact manifolds and manifolds with singularities . for a wide class of manifolds , ellipticity conditions for operators were established and the corresponding finiteness theorems were proved ; the corresponding operator @xmath1-algebras were constructed . hence the study of _ topological _ aspects of the theory of elliptic operators becomes topical . here one mainly speaks of the classification problem and the index problem . note that gelfand s homotopy classification problem for elliptic operators can naturally be restated in modern language as the problem of computing the @xmath0-groups of symbol algebras , which prove noncommutative in most cases . thus gelfand s problem naturally fits in the framework of topical problems of connes s noncommutative geometry  @xcite . this paper deals with elliptic theory on manifolds with corners . operators on manifolds with corners have been actively studied , and a number of important interesting results emerged recently . for example , the @xmath1-closure of symbol algebras was studied in  @xcite , and a spectral sequence converging to the @xmath0-theory of the @xmath1-algebra of symbols was constructed . monthubert  @xcite obtained a description of the operator algebra in the spirit of noncommutative geometry in terms of a special groupoid that can be associated with a manifold with corners ( see also @xcite ) . bunke  @xcite constructed index theory of atiyah  patodi  singer type for dirac operators and studied cohomological obstructions to elliptic problems ( see also @xcite ) ; monthubert and nistor  @xcite produced a formula for the boundary map in the @xmath0-theory of symbol algebras in topological terms . krainer  @xcite studied boundary value problems in this setting . although these results permitted finding the group classifying the homotopy classes of elliptic operators in a number of special cases ( e.g. , see  @xcite or @xcite ) , the homotopy classification problem remained open . we solve gelfand s problem for _ manifolds with corners_. our goal is to obtain a simple explicit formula for the classifying group in terms of atiyah s @xmath0-homology functor @xcite . note that the idea of classifying elliptic operators by the @xmath0-homology functor has long been known . for the reader s convenience , we recall it using operators on a smooth compact manifold @xmath2 as an example . the commutator of an elliptic zero - order operator @xmath3 on @xmath2 with the operator of multiplication by a continuous function @xmath4 is compact @xmath5\\in \\mathcal{k}.\\ ] ] by one definition , the _ contravariant @xmath0-theory _ @xmath6 of the algebra @xmath7 just consists of fredholm operators for which the commutators   are compact . thus @xmath3 determines an element of the group @xmath6 , which is isomorphic to the @xmath0-homology group of @xmath2 : @xmath8 by the atiyah  brown  douglas  fillmore  kasparov theorem . thus , assigning the corresponding class in the @xmath0-homology to each elliptic operator , we obtain a mapping @xmath9 where @xmath10 is the group of elliptic operators in sections of bundles on @xmath2 modulo stable homotopy and @xmath11 is the even @xmath0-homology group of @xmath12 . kasparov showed this mapping to be an isomorphism . in other words , the @xmath0-homology group of a smooth manifold classifies elliptic operators on this manifold modulo stable homotopy . this approach to classification also proved fruitful in the case of compact stratified manifolds with singularities . namely , it was shown in  @xcite that in this case the even @xmath0-homology group of the underlying compact topological space classifies elliptic operators on this manifold .    however , no classification results were known for manifolds with corners of codimension @xmath13 . the classification in the form of the @xmath0-homology of the manifold with corners , which suggests itself , is too meagre to be true : one can always smooth the corners , and we see that the @xmath0-homology of the manifold with corners is too coarse an invariant , for it does not take into account the structure of a manifold with corners . moreover even the space whose @xmath0-homology would classify elliptic operators was unknown . we establish the isomorphism @xmath14 where @xmath2 is a manifold with corners and @xmath15 is the dual manifold ( see @xcite ) which is a stratified manifold with singularities . more precisely , the isomorphism will be established under the following assumption concerning the combinatorial structure of the faces of our manifold :    _ the normal bundles of all faces of @xmath2 are trivial . _ if this assumption fails , then , generally speaking , the isomorphism does not hold . in this case , one should abandon the search for a classifying _ space _ and seek some _ algebra _ whose @xmath0-cohomology classifies elliptic operators . this algebra proves to be noncommutative , and one needs to use ideas on noncommutative geometry . these results will be considered elsewhere . note an interesting special case : if a manifold with corners is a polyhedron with a given triangulation of the boundary , then the dual stratified space is also a polyhedron , namely , the one used in the classical proof of poincar duality in cohomology ! for example , if @xmath2 is a cube , then @xmath15 is an octahedron . thus the construction of the dual manifold in the first part  @xcite of the present paper generalizes the _ poincar dual polyhedron _ to the case of noncontractible faces . note that there is a different perspective on the theory of operators on manifolds with corners . an application of a logarithmic change of variables in a neighborhood of the boundary taking the boundary to infinity ( see fig .  [ ris4 ] , where this is shown for manifolds with boundary ) results in the class of so - called _ manifolds with multicylindrical ends_. these two pictures give the same operator algebras . thus the results of the present paper also provide classification on manifolds with multicylindrical ends . this is the second of the two parts of the paper . in the first part @xcite , the dual manifold of a manifold with corners was constructed and calculus of pseudodifferential operators ( @xmath16do ) on manifolds with corners was developed in the @xmath1-algebraic context .    the present part has the following structure .    in the first section , we recall some information from  @xcite . in sec .  2 , we state the classification theorem . the proof occupies the next three sections . note that the general scheme of the proof is the same as in  @xcite , and we proceed by induction , passing from a smooth manifold to increasingly complex manifolds with singularities . in sec . 6 we discuss the relationship with some results due to monthubert and nistor . as a consequence of the classification theorem , we obtain a @xmath0-homology criterion for the vanishing of the index and a formula for the @xmath0-group of the @xmath1-algebra of @xmath16do with zero interior symbol ( this algebra corresponds to the @xmath1-algebra of the groupoid constructed by monthubert ) . in the appendix , we prove a higher analog of the relative index theorem , which naturally arises when we obtain the classification of operators . here we recall some information given in  @xcite .    consider a manifold @xmath2 with corners of depth @xmath17 . it has a natural stratification @xmath18 where the stratum @xmath19 is just the interior of @xmath2 and each stratum @xmath20 is the union of connected components , open faces @xmath21 of codimension @xmath22 in @xmath2 . each face @xmath23 in the stratum @xmath20 is isomorphic to the interior of a manifold @xmath24 , which will be called a closed face of @xmath2 . faces of codimension one are called _ hyperfaces_.      the main results of the paper will be obtained under the following assumption . [ assa1 ] the normal bundle @xmath25 of each face @xmath26 is trivial .    in this case , the local defining functions @xmath27 of @xmath26 are globally defined as functions on the normal bundle @xmath25 . assumption [ assa1 ] holds if all hyperfaces are _ embedded _ , i.e. , if there exists a global defining function for each hyperface @xmath28 . however , it also holds , for some manifolds with nonembedded hyperfaces , say , for the raindrop . the simplest example of a manifold with corners that does not satisfy assumption  [ assa1 ] is the klein bottle with raindrop instead of the circle as the base . the dual space @xmath29 of a manifold @xmath2 with corners was introduced in  @xcite . if the original manifold is represented as the union @xmath30 then @xmath15 is the union of _ dual faces _ , @xmath31 each of which is isomorphic to the interior of a simplex @xmath32 here , by definition , @xmath33 is the interior of @xmath2 . thus to each face @xmath26 of codimension @xmath22 in @xmath2 there corresponds a simplex @xmath34 of dimension @xmath35 in the dual space . it was proved in  @xcite that a neighborhood @xmath36 of the stratum @xmath37 is homeomorphic to the product of @xmath37 by the cone @xmath38 whose base @xmath39 is the dual space @xmath40 of the closed face @xmath41 ( which is well defined , since @xmath41 itself is a manifold with corners ) . as a result , we find that @xmath15 is a stratified manifold with singularities . let @xmath2 be a manifold with corners satisfying assumption [ assa1 ] , and let @xmath42 be the @xmath1-algebra of zero - order @xmath16do in the space @xmath43 ( see  @xcite ) . the notion of a @xmath16do acting on sections of finite - dimensional vector bundles on @xmath2 is introduced in the usual way . there is a natural equivalence relation , _ stable homotopy _ , on the set of elliptic operators . recall the definition . two elliptic operators @xmath44 on @xmath2 are said to be _ stably homotopic _ if there exists a continuous homotopy @xmath45 of elliptic operators , where @xmath46 are vector bundles and @xmath47 are bundle isomorphisms .    here ellipticity is understood as the invertibility of all components of the symbol of the operator , and only homotopies of @xmath16do preserving ellipticity are considered . stable homotopy is an equivalence relation on the set of elliptic @xmath16do acting in sections of vector bundles . by @xmath48 we denote the corresponding quotient set . it is a group with respect to the direct sum of operators , and the inverse in this group is given by the coset of the almost inverse operator ( i.e. , an inverse modulo compact operators ) . odd elliptic theory @xmath49 is defined in a similar way as the group of stable homotopy classes of elliptic self - adjoint operators . stabilization is defined in terms of the operators @xmath50 . an equivalent definition of the odd @xmath51-group can be given in terms of smooth operator families on @xmath12 with parameter space @xmath52 modulo constant families . we shall compute the groups @xmath53 for @xmath54 and @xmath55 , i.e. , find the classification of elliptic operators modulo stable homotopy . our approach is based on the following fact ( see the definition of @xmath16do in  @xcite ) :    _ @xmath16do on @xmath2 can be viewed as local operators in the sense of atiyah on the dual manifold @xmath15 . _    thus an elliptic @xmath16do defines a fredholm module on the space @xmath43 viewed as a @xmath56-module . ( for fredholm modules and @xmath0-theory , see  @xcite or @xcite ) . the following theorem is the main result of this paper . [ th1 ] the mapping that takes each elliptic @xmath16do to the corresponding fredholm module defines the group isomorphism @xmath57    we shall obtain this theorem as a special case of the following more general theorem . let @xmath58 be the group generated by operators whose symbols are invertible on the main stratum and all faces of codimension @xmath59 . thus we consider operators satisfying the ellipticity condition on part of the faces . the corresponding dual space @xmath60 is obtained from @xmath15 by deleting all simplices of dimension @xmath61 . [ lem1a ] an operator @xmath3 such that @xmath62\\in \\operatorname{ell}_*\\left(m_{\\ge j}\\right)$ ] defines a fredholm module over the algebra @xmath63 of functions on the dual space . we should verify the following properties of a fredholm module : the expression @xmath64 is compact for all @xmath65 ( here we assume that @xmath3 is normalized by the condition @xmath66 for @xmath67 ) . the compactness follows from the fact that , by construction , on each face @xmath28 either the corresponding symbol of our operator is invertible or the functions in the algebra @xmath68 are zero .    by lemma  [ lem1a ] , the mapping @xmath69 that takes partially elliptic operators to the corresponding fredholm modules is well defined ( cf . @xcite ) . [ th2 ] for each @xmath70 , the mapping is an isomorphism . theorem [ th1 ] is the special case of theorem [ th2 ] for @xmath71 . we prove theorem  [ th2 ] by induction on @xmath22 decreasing from @xmath72 ( where @xmath17 is the depth of @xmath2 ) to  @xmath73 .      for @xmath74 , the group @xmath75 classifies elliptic interior symbols and hence is isomorphic to @xmath76 . moreover , the mapping taking the symbol to the corresponding operator determines an isomorphism @xmath77 ( e.g. , see  @xcite ) . on the other hand , the right - hand side of in this case just contains the group @xmath78 . thus the theorem holds for @xmath74 .      to justify the inductive step , we need to study exact sequences in @xmath0-homology and @xmath0-theory permitting one to relate the maps @xmath79 in for two values of the subscript , @xmath22 and @xmath80 . consider the embedding @xmath81 the complement @xmath82 is obviously equal to @xmath83 , and we have the exact sequence of the pair   in @xmath0-homology @xmath84 all maps but the boundary map @xmath85 in this sequence correspond to a change of module structure on the corresponding fredholm modules . the boundary map @xmath85 can be reduced to a form convenient for computations by the following standard method . let @xmath86 be the open neighborhood of the stratum @xmath87 constructed is defined as the union of neighborhoods of all simplices @xmath88 . by construction , these neighborhoods are disjoint . ] in  ( * ? ? we have the homeomorphism @xmath89 where the cone @xmath90 is the disjoint union of the cones corresponding to the connected components of the base @xmath91 . then we have the mappings @xmath92 ( by @xmath93 we denote the embedding of an open manifold , and @xmath94 is the projection onto the first two factors ) , which permit us to represent the boundary map @xmath85 in as the composition @xmath95 of the restriction @xmath96 of operators to an open set , the push - forward @xmath97 , and the periodicity isomorphism @xmath98 . this representation follows from the fact that @xmath85 is natural . let @xmath2 be a manifold with corners of depth @xmath99 , and let @xmath22 , @xmath100 , be some number . we denote the algebra formed by the symbols @xmath101 of all @xmath16do on @xmath2 by @xmath102 then we have the short exact sequence of @xmath1-algebras @xmath103 here the ideal @xmath104 consists of the symbols @xmath101 in which all components but @xmath105 are zero . from the compactness criterion for @xmath16do and compatibility conditions for symbols ( see  @xcite ) , we see that under these conditions the symbol @xmath105 is a tuple of compact - valued families decaying at infinity , so that one has the isomorphism @xmath106 where the sum is taken over faces @xmath26 of codimension @xmath22 in @xmath2 .    by virtue of this isomorphism , we can write out the exact sequence in @xmath0-theory corresponding to the short sequence in the form @xmath107 clearly , @xmath108 where @xmath93 is the number of connected components in @xmath20 . in terms of this isomorphism , the boundary map @xmath109 can be represented ( for @xmath55 ) in the following simple form . an arbitrary class @xmath110\\in k_1(\\sigma_{j+1})\\ ] ] is realized by an invertible symbol @xmath111 ( from now on , for brevity we carry out the computations only for @xmath0-theory elements representable by scalar operators ; the consideration of the matrix case differs only in the awkwardness of formulas . ) take an arbitrary symbol @xmath112 compatible with @xmath113 . the symbol @xmath105 defines an elliptic family with parameters in @xmath114 , and the index of that family is a well - defined element of the @xmath0-group with compact supports of the parameter space . one has @xmath115=\\operatorname{ind}\\sigma_j\\in \\bigoplus_{f\\subset m_j}k_0(c_0(\\mathbb{r}^j)).\\ ] ] there is a similar expression for the boundary map for the case @xmath54 . ( to obtain it , one can pass to the suspension . ) let us show that the sequences and can be combined into the commutative diagram @xmath116 ( the construction of this diagram and the verification of its commutativity will be finished in sec . [ compare1 ] . )      without loss of generality , we can assume that @xmath2 has no connected components with empty boundary . ( everybody knows the classification on such components . ) then for all @xmath22 we have the isomorphism @xcite on a smooth closed manifold @xmath2 on which there exists a nonzero vector field . elimination of closed components permits us to claim that there exists a nonzero vector field in our situation . ] @xmath117 hence we define the maps @xmath79 , @xmath118 , in diagram as the composition @xmath119 of the projection onto the @xmath51-group and the quantization . thus these maps are induced by quantization , which takes symbols to operators . it remains to define the map @xmath120 . just as the other vertical arrows in the diagram , it is defined by quantization , namely , by quantization of symbols @xmath121 in the ideal @xmath104 . the quantization of elements of the ideal differs from the quantization of general elements of the algebra @xmath122 only in that the operator is considered in the @xmath123 space in a small neighborhood @xmath124 of the stratum @xmath125 in @xmath2 constructed in  ( * ? ? ? * lemma  1.9 ) . we denote the operator by @xmath126 . let us define a module structure on @xmath127 . to this end recall that @xmath124 can be considered also as a subset of the positive quadrant @xmath128 of the logarithmic normal bundle . thus , this space is naturally a @xmath129-module . ( elements of @xmath129 act on @xmath128 as operators of multiplication by radially constant functions @xmath130 , in logarithmic coordinates @xmath131 . ) the verification of locality of operator with respect to this module structure ( i.e. , proving that the operator @xmath126 commutes with operators of multiplication by functions modulo compact operators ) is immediate , and hence for the element @xmath132\\in k_{*+1}(j)$ ] we define the element @xmath133:=[\\widehat{\\sigma}_j]\\in k_*({m}^\\#_j).\\ ] ]      the commutativity of the middle square of the diagram follows directly from definitions . the left square of diagram commutes . indeed , consider the composition of mappings passing through the right upper corner of the square @xmath134 it takes an elliptic symbol @xmath112 to the operator @xmath126 , which acts outside a neighborhood @xmath124 of the stratum @xmath135 as the identity operator ( modulo compact operators ) in the space @xmath43 with the natural structure of a @xmath136-module . now if we restrict the operator to a neighborhood of @xmath137 ( the element in @xmath0-homology remains unchanged , since the corresponding fredholm module changes by a degenerate module ) and then use a homotopy to reduce the module structure to the composition @xmath138 where @xmath139 is a projection and @xmath140 is an embedding , then we obtain the fredholm module assigned to the symbol @xmath112 by the composition of maps passing through left bottom corner of the square . the commutativity of the square is thereby established . verification of the commutativity of the square containing the boundary maps is rather cumbersome , and so we make it in a separate section . in this section , we establish the commutativity of the square @xmath141 containing the boundary maps in diagram . the scheme of proof is as follows . we    1 .   compute the composition @xmath142 . 2 .   compute the composition @xmath143 . 3 .   compare the resulting expressions . let @xmath144\\in k_*(\\sigma_{j+1})$ ] be the element defined by some symbol @xmath145 . take a symbol @xmath112 on @xmath20 compatible with @xmath113 and denote by @xmath146 the corresponding translation - invariant infinitesimal operator . ( it is conjugate to @xmath112 by the fourier transform . ) representing the space @xmath128 as the product @xmath147 , we see that @xmath148 is a @xmath149-module . here @xmath150 is the disjoint union of as many open quadrants as there are faces of codimension @xmath22 in @xmath2 . the operator @xmath126 is local with respect to this module structure . we denote the corresponding element of the @xmath0-homology group by @xmath151\\in k_{*+1}(\\bigsqcup\\mathbb{r}^j_+).\\ ] ]    [ l1 ] the element @xmath144\\in k_*(\\sigma_{j+1})$ ] satisfies the chain of relations @xmath152=\\varphi_0(\\operatorname{ind}\\sigma_j)=\\beta[\\widehat{\\sigma}_j]\\in k_*({m}^\\#_{j}),\\ ] ] where @xmath153 is the bott periodicity isomorphism , and the index is understood as the index @xmath154 of the elliptic operator - valued symbol @xmath112 .    for brevity , we assume that @xmath20 consists of exactly one stratum . in this case , we have @xmath155 .    the first relation in follows from definitions ( since the boundary map in @xmath0-theory of algebras is the index map ) . let us establish the second relation @xmath156 $ ] . the proof is based on the diagram @xmath157    \\ar[r]^{\\operatorname{ind}\\sigma_j } & k_*(j)\\ar[rd]^{\\varphi_0}\\ar[d]_q\\\\    &    k_*({m}^\\#_j\\times \\mathbb{r}_+)\\ar[r]^\\beta &    k_{*+1}({m}^\\#_j ) ,   } \\ ] ] where the map @xmath158 is induced by the map that takes the symbol @xmath159 to the operator @xmath126 in . finally , the group @xmath160 is interpreted as the @xmath0-group of the cotangent bundle to @xmath161 , and the map @xmath162 is induced by standard quantization ( to a symbol on the cosphere bundle , one assigns a pseudodifferential operator ) . we claim that diagram   commutes . indeed , let us verify the commutativity of the left triangle , i.e. , the relation @xmath163=q[\\operatorname{ind}\\sigma_j].\\ ] ] note that the operator @xmath126 is given over the product @xmath164 . moreover , it can be viewed as a @xmath16do on @xmath165 with operator - valued symbol @xmath166 @xmath167 . this symbol is independent of the physical variables @xmath168 . without loss of generality , it can be assumed to be smooth with respect to the parameter @xmath169 ( since @xmath170 , just as any @xmath16do with a parameter , can be arbitrarily closely approximated by a smooth @xmath16do with a parameter ; see  @xcite ) . hence @xmath170 is an operator - valued symbol in the sense of @xcite , i.e. , has a compact variation with respect to @xmath169 and all of its derivatives starting from the first decay at infinity . now relation follows by analogy with the generalized luke theorem in  @xcite . the commutativity of the right triangle follows ( see corollary  [ aux1 ] in the appendix ) from the higher relative index theorem . the commutativity of diagram   implies the second relation . ( the right - hand side is obtained if from the left top corner of the diagram we go directly to the group @xmath171 and then apply the periodicity isomorphism @xmath98 . ) the image of the positive quadrant @xmath128 under the inverse of the logarithmic map is the set @xmath173 . hence we treat @xmath128 as the interior of a manifold with corners , denoted by @xmath174 . we denote the corresponding dual space by @xmath175 . on the complement @xmath176 , there is a well - defined projection @xmath177 whose fiber is the space @xmath178 . we have the diagram of embeddings @xmath179    let @xmath144\\in k_{*+1}(\\sigma_{j+1})$ ] be the element determined by the symbol @xmath159 as above . by passing to the corresponding operators , we obtain the element @xmath180\\in k_*({m}^\\#_{\\ge j+1}).\\ ] ] on the other hand , the infinitesimal operator @xmath126 compatible with @xmath159 ( see  ) defines the element @xmath181'\\in k_*({\\overline{n_+m}_j}^\\#\\setminus { m}^\\#_j).\\ ] ] this element is well defined , since the components of its symbol are elliptic on the corresponding strata . we use primes to distinguish this element from the element : although they are determined by one and the same operator , the module structures on the @xmath123-spaces are different .    the naturality of the boundary map in @xmath0-homology results in the following lemma . [ l2 ] one has @xmath182=\\partial'[\\widehat{\\sigma}_j]',\\ ] ] where @xmath183 is the boundary map for the pair @xmath184 . let @xmath3 be some operator on @xmath2 with symbol @xmath159 . \\1 . the infinitesimal operator @xmath126 is obtained from @xmath3 by localization to the set @xmath185 . hence the restrictions @xmath186 and @xmath187 of these operators to a small space @xmath124 of @xmath20 are connected by a linear homotopy ; i.e. , one has @xmath188=[\\widehat{\\sigma}_j|_u]\\in k_*({u}^\\#).\\ ] ]    \\2 . by applying the naturality of the boundary map in @xmath0-homology to the embedding diagram , we obtain @xmath182\\equiv\\partial [ d]=\\partial''[d|_{u}],\\ ] ] where @xmath189 is the boundary map for the pair @xmath190 . now if on the right - hand side of the last relation we replace the element @xmath191 $ ] according to and once more use the naturality of the boundary map , then we obtain the desired relation @xmath182=\\partial''[\\widehat{\\sigma}_j|_u]= \\partial'[\\widehat{\\sigma}_j]'.\\ ] ]    thus in what follows , when computing the composition @xmath192 , we can ( and will ) work with the operator @xmath126 on @xmath128 .      by , the boundary map @xmath193 in lemma  [ l2 ] can be represented as the composition @xmath194 of the push - forward with respect to the projection @xmath94 and the periodicity isomorphism .    unfortunately , although the classes @xmath195 $ ] and @xmath196'$ ] are determined by the same operator @xmath126 , they have different module structures on the space @xmath148 : in the first case , the structure is independent of the coordinate @xmath197 , while in the second case it depends on ( see  ) .    let us make a homotopy of module structures . to this end , we define a homotopy @xmath198 of projections by the formula ( cf .  ) @xmath199 this formula defines a continuous family of maps for @xmath200 . however , the family is not continuous as @xmath201 . is not defined on the @xmath0-group . ] nevertheless , continuity takes place for the fredholm modules , as shown by the following lemma . [ l3 ] the family @xmath202 of fredholm modules obtained by the change of module structure defines a homotopy in the sense of @xmath203-theory , and one has @xmath204 whence it follows that @xmath196'=[\\pi_*^0 ( \\widehat{\\sigma}_j)]'\\in k_*(m_j^\\#\\times\\mathbb{r}_+)$ ] .    for brevity , we assume that @xmath20 consists of a single face , i.e. , is connected . then the homotopy in the sense of @xmath203-theory means ( e.g. , see @xcite ) that for each function @xmath205 the family @xmath206 of operators of multiplication by the functions @xmath207 is strongly @xmath208-continuous and that the operator families @xmath209,\\quad g^\\varepsilon(\\widehat{\\sigma}_j\\widehat{\\sigma}_j^{-1}-1)\\ ] ] in @xmath148 are continuous families of compact operators as @xmath201 . it suffices to prove all these facts for ( a dense set of ) smooth functions @xmath210 . if @xmath210 is smooth , then one should smooth the family @xmath211 and use the composition formulas , which provide the desired compactness and continuity . now let us use lemmas [ l1][l3 ] . we obtain the chain of relations @xmath212\\stackrel{\\text{lemma \\ref{l2}}}= \\partial'[\\widehat{\\sigma}_j]'\\stackrel{\\text{formula \\eqref{kompa1 } } } = \\beta \\pi^1_*[\\widehat{\\sigma}_j ] ' \\stackrel{\\text{lemma \\ref{l3}}}=\\beta [ \\pi^0_*\\widehat{\\sigma}_j]'=\\\\ = \\beta[\\widehat{\\sigma}_j ] \\stackrel{\\text{lemma \\ref{l1}}}=\\varphi_0\\delta[\\sigma].\\end{gathered}\\ ] ] the equality at the end of the first row corresponds to the identical coincidence of the corresponding fredholm modules . thus the square commutes , and we have established the commutativity of diagram . by virtue of the isomorphism , we can single out and cancel the summand @xmath213 in diagram in the terms @xmath214 and @xmath215 . we obtain the diagram @xmath216 the map @xmath217 is an isomorphism by the inductive assumption . the map @xmath120 is also an isomorphism ( see corollary  [ aux1 ] in the appendix ) . since the diagram commutes , we can apply the @xmath218-lemma and obtain the desired justification of the induction step in theorem [ th2 ] : if the map @xmath217 is isomorphic on the @xmath51-group , then so is the map @xmath219 . the proof of theorem [ th2 ] is complete . let us discuss the relationship with the problems considered by monthubert and nistor @xcite . in the notation of the present paper , for the case of manifolds with embedded corners they considered the short exact sequence @xmath220 where @xmath221 is the interior symbol map , and the ideal @xmath104 consists of operators with zero interior symbol . they studied the boundary map corresponding to this sequence : @xmath222 for a closed manifold @xmath104 is the ideal of compact operators ( hence @xmath223 ) and the boundary map coincides with the analytic index . moreover , monthubert and nistor showed that in the general case this map has an important topological meaning : it gives the obstruction to the existence of an invertible operator with a given interior symbol . for these reasons , monthubert and nistor call this map the _ analytic index of manifolds with corners_.    we claim that the classification theorem readily implies a @xmath0-homology criterion for the vanishing of the analytic index . indeed , consider the diagram @xmath224 where the lower row is the sequence induced by the short exact sequence and the upper row is the exact sequence of the pair @xmath225 in @xmath0-homology . the maps @xmath226 and @xmath227 are induced by quantization of elliptic symbols on @xmath29 and @xmath228 correspondingly ( cf .  ) . the diagram is obviously commutative .    from the exactness of the sequences and the obvious commutativity of the diagram , we obtain the following assertion . let us assume for simplicity that @xmath2 has no connected components with empty boundary .    the analytic index @xmath229 of @xmath230 vanishes if and only if @xmath231 . . there are splittings ( cf .  ) @xmath232 where @xmath233 is the _ reduced _ @xmath51-group generated by operators of index zero . moreover , the direct summands @xmath234 can be cancelled in  . this does not affect the boundary map . hence , we obtain the commutative diagram @xmath235 where @xmath236 is the reduced @xmath0-homology group generated by operators of index zero . \\3 . by the classification theorem , the quantization maps @xmath237 in induce isomorphisms . hence , the commutativity of the diagram readily shows that vanishing of @xmath109 is equivalent to the vanishing of the boundary map @xmath85 in @xmath0-homology . the reader can readily rewrite this formula in a more explicit form as a condition on the interior symbol @xmath221 . there is also a cohomological form of this condition . needless to say , the cohomological formula is only valid modulo torsion . one actually has the group isomorphism @xmath238 determined by quantization of operators with zero interior symbol . ( one can readily obtain this isomorphism by reproducing the proof of our classification theorem . in the proof , only the inductive assumption is changed : now for @xmath74 we claim that @xmath239 . ) consider the map ( see sec . [ compare1 ] ) @xmath240 induced by the map taking a symbol @xmath241 @xmath167 , to the corresponding translation - invariant operator @xmath242 here the space @xmath243 is equipped with the following module structure over the algebra @xmath244 of functions on the interior of the simplex : a function @xmath245 is viewed as a radially constant function equal to zero outside the positive quadrant @xmath246 .    for the index pairing of the element @xmath247\\in k_{j-1}(\\delta^\\circ_{j-1})$ ] with an arbitrary element @xmath248\\in k_{j-1}(c_0(\\delta^\\circ_{j-1}))\\simeq \\widetilde{k}^{j-1}(\\mathbb{s}^{j-1}),\\ ] ] where @xmath249 is the reduced @xmath0-group , one has the formula @xmath250,a\\rangle=\\operatorname{ind}_t\\bigl([\\sigma]\\times [ a]\\bigr),\\ ] ] where the product @xmath144\\times [ a]$ ] is defined as the composition @xmath251 and @xmath252 is the topological atiyah singer index for @xmath165 .    for @xmath71 , this assertion is reduced to the relative index theorem for operators on manifolds with conical points . we mean the formula for the difference of indices of operators with equal interior symbols , or , equivalently , for the index of elliptic operators of the form @xmath253 @xmath254 where the interior symbol of @xmath255 is zero and @xmath256 is the winding number of the conormal symbol @xmath257 . hence the index formula   in the general case can be referred to as the _ higher relative index formula_. \\1 . the element @xmath110\\in k_0(c_0(\\mathbb{r}^j))\\ ] ] is determined by some projection - valued function @xmath258 on @xmath165 equal to the diagonal projection @xmath259 at infinity . conversely , the element @xmath248\\in k_{j-1}(c_0(\\delta^\\circ_{j-1}))\\simeq \\widetilde{k}^{j-1}(\\mathbb{s}^{j-1})\\ ] ] is determined by some invertible function @xmath260 on the sphere @xmath261 . to simplify the notation , we assume that this is a scalar function . the matrix case can be considered in a similar way . \\2 . in this notation , the index pairing @xmath262,a\\rangle$ ] is by definition equal to the index of the toeplitz operator ( e.g. , see @xcite ) @xmath263 where @xmath264  is the projection determined by the symbol @xmath265 , as in . \\3 . to compute the index of the operator , we make the fourier transform . then the operator @xmath266 becomes the projection @xmath258 , and the space @xmath267 becomes the space of sections of the bundle given by the range of @xmath258 . conversely , the operator of multiplication by @xmath268 passes into a translation - invariant @xmath16do in @xmath165 with principal symbol @xmath269 . hence we obtain @xmath270,a\\rangle=\\operatorname{ind}\\left (   p\\widehat{a}:\\operatorname{im}{p}\\longrightarrow   \\operatorname{im}{p }   \\right).\\ ] ]    \\4 . the last operator coincides at infinity with a direct sum of the invertible operator @xmath271 acting on functions . by the index locality property , the difference of their indices is given by the atiyah singer formula , which gives the desired expression . [ aux1 ] the following triangle commutes : @xmath272^{\\varphi_0}\\ar[d]_q\\\\    k_*(\\delta^\\circ_{j-1}\\times ( 0,\\infty))\\ar[r]^\\beta &    k_{*+1}(\\delta^\\circ_{j-1 } ) ,   } \\ ] ] where @xmath98 is the bott periodicity isomorphism and @xmath273 is the standard pseudodifferential quantization in @xmath274 . all groups in the triangle are isomorphic to @xmath275 and have natural bott generators . it is known that the maps @xmath162 and @xmath98 take bott elements to bott elements . hence to verify the commutativity of the diagram it suffices to verify this property for @xmath120 . but this readily follows from the index formula .", "tags": [], "output_text_a": "This paper addresses the classification problem for elliptic operators on manifolds with corners, a topic that has seen significant progress in recent years. The authors solve Gelfand's problem for manifolds with corners by providing a simple explicit formula for the classifying group in terms of Atiyah's K-homology functor. The paper builds on previous work in noncommutative geometry and the study of pseudodifferential operators on such manifolds. The main result is an isomorphism between the group of elliptic operators on a manifold with corners and the K-homology of a dual stratified manifold with singularities, under the assumption that the normal bundles of all faces are trivial. The paper also discusses the implications of this classification for manifolds with multicylindrical ends and provides a K-homology criterion for the vanishing of the analytic index. The results are significant for understanding the topological aspects of elliptic operators on complex manifolds and contribute to the broader field of noncommutative geometry.", "output_text_b": "This arXiv paper discusses elliptic theory on manifolds with corners, which have been actively studied with several important results emerging recently. The paper aims to solve Gelfand's problem for manifolds with corners by obtaining a simple explicit formula for the classifying group in terms of Atiyah's K-homology functor. The idea of classifying elliptic operators by the K-homology functor has been known, and the paper recalls this using operators on a smooth compact manifold as an example. The commutator of an elliptic zero-order operator with the operator of multiplication by a continuous function is compact, determining an element of the group K(A) that is isomorphic to the K-homology group of the manifold. The K-homology group of a smooth manifold classifies elliptic operators on this manifold modulo stable homotopy.\n\nThe paper also discusses the classification of elliptic operators on compact stratified manifolds with singularities, where the even K-homology group of the underlying compact topological space classifies elliptic operators on this manifold. However, no classification results were known for manifolds with corners of codimension greater than or equal to 2. The paper establishes an isomorphism between the K-homology group of a manifold with corners and the dual manifold, which is a stratified manifold with singularities, under the assumption that the normal bundles of all faces of the manifold are trivial.\n\nThe paper also discusses the relationship between the classification theorem and some results due to Monthubert and Nistor, providing a K-homology criterion for the vanishing of the analytic index and a formula for the K-group of the algebra of pseudodifferential operators with zero interior symbol.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by mentioning the classification problem for elliptic operators on manifolds with corners and the solution to Gelfand's problem.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is clearly highlighted, focusing on the classification of elliptic operators on manifolds with corners.\n4. The methodology or approach used in the paper is mentioned, including the use of Atiyah's K-homology functor and the assumption about normal bundles.\n5. Significant results or conclusions drawn by the authors are included, such as the isomorphism and the K-homology criterion for the vanishing of the analytic index.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"K-homology\" and \"manifolds with corners.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance or potential impact in its field by discussing its contributions to noncommutative geometry.", "1. **Accurate Reflection**: The summary reflects the main findings and contributions of the paper, such as solving Gelfand's problem for manifolds with corners and establishing an isomorphism between the K-homology group of a manifold with corners and the dual manifold.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of classifying elliptic operators on manifolds with corners.\n4. **Methodology**: The summary mentions the use of Atiyah's K-homology functor and the assumption regarding the normal bundles of faces.\n5. **Significant Results**: The summary includes significant results, such as the isomorphism established and the K-homology criterion for the vanishing of the analytic index.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"K-homology\" and \"elliptic operators\" but does not explain them, which might be necessary for a broader audience.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in the field of elliptic theory on manifolds with corners."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "interstellar gas in the solar neighborhood has a variety of thermal and chemical phases , including cold atomic gas inside or mixed with cold molecular clouds ( e.g. , sato & fukui 1978 ) , cool and warm atomic gas on the envelopes of molecular clouds ( chromey et al . 1989 ; andersson & wannier 1993 ; wannier et al . 1993 ) and in the diffuse , low density medium ( kulkarni & heiles 1987 ) , cold molecules in dark and dense clouds ( combes 1991 ) and in translucent clouds ( magnani , blitz & mundy 1985 ) , warm molecules in dense clouds near embedded luminous stars ( e.g. , cesaroni et al . 1994 ) , dense photo - ionized gas in the neighborhoods of o and b - type stars , low - density ionized gas between these stars ( walterbos & braun 1994 ; reynolds 1995 ; ferguson et al . 1996 ) , and hot , shock - heated gas near supernovae and windy stars ( ostriker & mckee 1988 ) . there is also considerable variety in the types of molecules that are present inside dark clouds , ranging from primarily h@xmath0 in translucent clouds ( spitzer & jenkins 1975 ; magnani et al . 1998 ) , with a possible trace of pah or long - chain molecules ( leger & puget 1984 ; tulej et al . 1998 ) , to a mixture of complex molecules in dense clouds ( e.g. , langer et al . 1997 ; see reviews by van dishoeck and thaddeus , this conference ) . the thermal and chemical states of the cold and cool gas have such a great variety because the clouds shield themselves to different levels from photodissociative radiation and radiant heating . this makes the molecular abundance and temperature depend on density , column density , metallicity , age , and local radiation field , all of which vary from cloud to cloud and with radius in the galaxy . the nature of cloud _ structure _ does not change this much , because it is largely the result of turbulence , self - gravity , and local explosions , which seem to act the same way everywhere . here we discuss the dominant processes that affect the molecular and thermal states of the gas , and we review the some of the aspects of cloud structure that are likely to arise from turbulence . interstellar clouds shield themselves from photo - dissociative radiation when the molecular formation rate ( in @xmath1 ) integrated over the cloud radius exceeds the molecular dissociation flux ( in @xmath2 ) from incident starlight ( jura 1975 ; federman , glassgold , & kwan 1979 ; van dishoeck & black 1988 ; sternberg 1989 ; hollenbach & tielens 1997 ) . this means that clouds determine their own molecular abundances for any particular radiation field , depending on their density , column density , and metallicity . dense clouds with only moderate column densities can have the same h@xmath0/h ratio as lower density clouds with larger column densities . as a result , _ regions with larger pressures tend to be more molecular _ , i.e. , higher pressures lead to higher densities and greater self - shielding at all cloud masses . one implication of this result is that most galaxies have a radial gradient in the molecular fraction outside the nuclear or barred region because the pressure is lower at larger radii ( elmegreen 1993 ; honma , sofue , & arimoto 1995 ) . the total ( turbulent+magnetic+thermal ) interstellar medium pressure varies approximately as @xmath3 for gas column density @xmath4 and total gas+star column density in the gas layer , @xmath5 . typically , @xmath6 , so @xmath7 . this means that as @xmath4 decreases exponentially with radius in a typical spiral galaxy , the total pressure decreases with radius too , and it has half the scale length . this corresponds to a rather rapid decrease of interstellar pressure with galactocentric radius . radial pressure gradients lead to the appearance of `` molecular rings '' in galaxies that have inner disk cutoffs from a bar or bulge . molecular rings are not true rings , like galactic resonance rings , but only molecular emission concentrations that result from smooth exponential disks with inner cutoffs . the rapid decrease of molecular fraction with increasing radius beyond the `` ring '' results primarily from large - scale pressure changes . high latitude clouds , shells , spiral - arm dust lanes , and other pressurized fronts should also have large molecular fractions compared to other clouds with the same column density . a good example of the influence of pressure on molecule formation is shown by the nearby l1457 cloud , which has h@xmath0 primarily in the southern part , where it was recently compressed ( moriarty - schieven , andersson & wannier 1997 ) . the _ thermal _ state in clouds is generally related to the _ molecular _ state , at least in the solar neighborhood , because once a cloud begins to shield itself in the h@xmath0 lines , it also becomes optically thick from dust . then it removes its principle quiescent heat source , which is the photoejection of electrons off grains ( de jong 1977 ; draine 1978 ; bakes & tielens 1994 ) . molecular clouds need not always be cold , though . different photons are involved with photodissocation , which is limited to spectral lines , and photoejection , which is a continuum process . besides , density and column density can vary separately . consequently , there are warm molecular clouds in the diffuse phase , i.e. , high density , low column - density clouds ( spitzer & cochran 1973 ) . these clouds tend to dominate the diffuse cloud population in the inner ( high pressure ) regions of bright galaxies ( polk et al . 1988 ; honma , sofue , & arimoto 1995 ) . there are also diffuse or dense molecular clouds in the high pressure regions of _ dim _ galaxies that are so cold they do not emit much co radiation ( allen et al . such temperature variations for molecular gas inversely affect the conversion factor from integrated co linewidth to molecular hydrogen . high temperature molecular clouds have proportionally less molecular matter per unit co emission than low temperature molecular clouds . figure [ fig : nn ] shows a schematic diagram of the cold and cool interstellar cloud phases in the parameter space that is defined by density and column density . the rising line that separates diffuse from self - gravitating gas comes from the relation @xmath8 for velocity dispersion @xmath9 . this is the threshold for strong self - gravity in a cloud . the falling line that separates molecular from atomic gas comes from the equation @xmath10 for metallicity @xmath11 and radiation field @xmath12 , normalized to solar neighborhood values . this relation is based on the balance between the h@xmath0 formation rate ( on dust , hence the @xmath11 dependence ) along a column of gas , @xmath13 , and the photodissociation rate per unit area , which is proportional to the absorbed photon flux , @xmath14 . the column density dependence in @xmath15 accounts for extra absorption in the line wings as @xmath16 increases ( federman , glassgold , & kwan 1979 ) . equation [ eq : mole ] was considered in more detail by sternberg ( 1989 ) , who included a temperature dependence for the molecule formation rate and dust extinction . sternberg also approximated the column density dependence of @xmath15 as @xmath17 for pure linewing absorption . according to sternberg , dust dominates molecules for the absorption of light in the shielding layer when @xmath18 , which translates to @xmath19\\left[z / z_0\\right]\\right)^{1/2}}}>>1 . \\label{eq : sternberg}\\ ] ] ( this assumes sternberg s molecule formation rate , @xmath20 , and dust cross section , @xmath21 , both scale with metallicity , @xmath11 . ) if we scale the federman , glassgold & kwan ( 1979 ) result with @xmath22 instead of @xmath23 and add a @xmath24 dependence to the molecule formation rate ( from the thermal speed at which h atoms impact grains ) , then the equation of detailed balance implied by equation [ eq : mole ] , @xmath25 , gives a molecular column density for self - shielding of @xmath26 , and a corresponding dust opacity @xmath27 . the square root of this opacity is essentially the quantity @xmath28 in sternberg ( 1989 ) , to within a factor of 2 . the column density at this opacity limit is approximately @xmath29 @xmath30 for standard interstellar extinction , which means that points to the right of @xmath31 @xmath30 at high density @xmath32 in figure [ fig : nn ] are primarily shielded by dust , and points to the left are _ self_-shielded by molecules . in both cases , the clouds are molecular , as indicated . low density clouds are generally atomic except at very high column density , at which point they may turn molecular if the conditions are right . however , real clouds with very low densities are not likely to turn molecular at high column density if their spatial extent is so large that they include many field stars inside them . in that case , there is no proper boundary for self - shielding . such clouds will still make a transition from diffuse to self - gravitating at moderate column densities , however . this explains why the largest hi clouds in spiral galaxies can be self - gravitating , and conversely , why the largest self - gravitating clouds are often atomic ( elmegreen & elmegreen 1983 ; 1987 ; rand 1995 ) . figure [ fig : nn ] also suggests that high density clouds are generally molecular , except at very low column density . when the density is high because of a high pressure , molecular clouds can be diffuse . the internal density can also be high in a region with a low ambient pressure provided the cloud is self - gravitating ; this makes the cloud molecular again .    in the solar neighborhood , most clouds make a transition from atomic and diffuse at low column density to molecular and self - gravitating at high column density , with relatively little total cloud mass in the form of molecular diffuse gas or atomic self - gravitating gas . however , in the spiral arms of our galaxy , atomic self - gravitating gas is prevalent in the form of giant hi cloud complexes ( @xmath33 m@xmath34 ) , which have relatively small molecular cores ( @xmath35 m@xmath34 ) that are also self - gravitating . such clouds are often regularly spaced along the spiral arms . in other galaxies such as m51 , these @xmath33 m@xmath34 spiral arm clouds are mostly molecular ( rand 1993 ) . this is a sensible result for m51 because it has a relatively high total gas column density , and therefore a high pressure ( @xmath36 ) . figure [ fig : nm ] makes these same points in a different way , showing the densities of diffuse and self - gravitating gas as functions of cloud mass . the larson ( 1981 ) relation between density and mass is used for the self - gravitating clouds . it comes from the two equations @xmath37 and @xmath38 .    at low mass , both diffuse and self - gravitating states are possible , as in the usual two - fold solution to the virial equation with external pressure : @xmath39 in this equation , for masses less than @xmath40 , there are stable states with low density and negligible self - gravity , bounded by external pressure , and there are stable states with high density and strong self - gravity , bounded by gravity , all at the same mass . similarly , in the interstellar medium , there are low mass diffuse clouds as well as low mass self - gravitating clouds , such as bok globules .    at high mass , equation [ eq : virial ] has only one stable solution and that is with self - gravity dominant . similarly in the interstellar medium , most massive clouds are strongly self - gravitating . this mass limit changes when a magnetic field is present , but only slightly if the field has the equipartition energy density ( mouschovias & spitzer 1976 ) .    also shown in figure [ fig : nm ] are short lines that indicate transitions from atomic to molecular phase as the mass increases ( @xmath41 ) , from a mixture of non - self - gravitating and self - gravitating clouds to pure self - gravitating clouds ( @xmath42 ) , and from molecular back to atomic gas ( @xmath43 . the origin of this latter transition , which occurs at around @xmath33 m@xmath34 for normal pressure , is that the density of a massive cloud is so low as a result of the high velocity dispersion and the requirement of pressure equilibrium , that the cloud can no longer shield itself from photodissociative radiation . the fact that the cloud is strongly self - gravitating does not matter . examples of such clouds are again the giant hi complexes in spiral arms . at higher pressures , this transition from molecular to atomic self - gravitating clouds occurs at higher masses . two thermal phases of atomic gas , cool and warm , can co - exist in the solar neighborhood at the _ same _ pressure and radiation field because of inflections in the thermal cooling rate as a function of temperature ( field , goldsmith & habing 1969 ) . at temperatures of around 100 k , ionized carbon and neutral oxygen cool the gas by collisions with neutral h , electrons , and , for oi , ionized h ( wolfire et al . 1995 ) . these collisions are very strong coolants at temperatures near the energy levels of cii and oi , which are 94 k and 228 k , easily balancing the photoelectric heating rate that scales primarily with density . thus the gas is thermally stable around 100 k. at lower temperatures , the cii and oi cooling transitions are barely excited , but the cooling rate does not drop much because the ci fine structure lines , which have lower excitation temperatures , become important coolants . thus the gas remains stable below 100 k too . at higher temperatures and lower densities with the same pressure , the collision rates and cooling rates decrease , leading to an unstable region until @xmath44k , at which point rapid cooling from ly@xmath45 emission and electron recombination onto grains makes the gas stable again ( wolfire et al . 1995 ) . figure [ fig : wolf ] shows the thermal pressure , heating and cooling rates , ionization fraction , temperature , and ionization parameter ( @xmath46 for radiation field @xmath47 scaled to the value in the solar neighborhood , temperature @xmath48 , and electron density @xmath49 ) for the `` standard '' model in wolfire et al . ( 1995 ) . the local coexistence of two stable thermal states should not apply everywhere in a disk galaxy . in the inner parts , where the pressure is very high and the ambient radiation field is only moderately high , there may not be a warm atomic phase at all , and a high fraction of the atomic gas can be cool . conversely , at large galactocentric radii , the pressure drops precipitously but the radiation field only a small amount , so there comes a point , at about 4 exponential scale lengths , where most of the hi becomes warm ( elmegreen & parravano 1994 ; braun 1997 ) . local variations in the atomic state can arise because of variations in the radiation field and pressure . these variations often follow a spiral density wave . for example , most of the gas between the spiral arms is at low pressure , so it should be highly atomic , mostly diffuse , and warm . a population of low - mass , self - gravitating molecular clouds typically remains as well , from the previous arm . when this gas shocks to form a dust lane in the arm , the density and opacity to starlight go up in the atomic gas , the temperature drops , and the gas should turn molecular , even ultra - cold molecular . but if massive star formation occurs inside or near this shocked gas , the enhanced radiation can warm it up again and dissociate it , forming a concentration of cool or warm hi near the resulting ob association , as observed in m83 ( allen , atherton & tilanus 1985 ; tilanus & allen 1993 ) , m51 ( tilanus & allen 1989 ) , m100 ( rand 1995 ) , and m81 ( allen et al . 1997 ) . cold dense molecular material can coexist with this warm atomic gas if the molecules are in strongly self - gravitating clouds ; the gravity preserves their high density and self - shielding even in the presence of strong radiation fields . the pressure , radiation field , and metallicity vary both systematically and randomly from place to place and time to time in any one galaxy , and from galaxy to galaxy along the hubble sequence . what applies to the solar neighborhood will not generally apply elsewhere , and what typifies the milky way can be relatively rare in galaxies with different hubble types . nevertheless , most of the variations that have been observed in other galaxies can be explained as a consequence of the simple rules given above . the hotter phases of interstellar gas require local excess energy sources such as hot stars and supernovae . these sources are relatively rare in a typical galactic disk ( not in a nuclear starburst disk , though ) , but each commands such a wide domain of influence that the locally heated regions can sometimes overlap with each other , making the hot gas pervasive ( cox & smith 1974 ; salpeter 1976 ; mckee & ostriker 1977 ) . the domain of influence increases at lower density , so a single massive star at a large distance off the galactic plane can ionize a large volume in the halo . for example , an o5 star in a gas with a halo - type density of 0.03 @xmath50 can ionize out to 3 kpc distance . the origin of structure in interstellar gas is far less tangible than the origin of thermal and chemical states , because some of the structure is caused by supersonic turbulence , and no one understands yet how this works . other structures , such as shells ( tenorio - tagle & bodenheimer 1988 ) and spiral shocks ( roberts 1969 ) , are somewhat easier to understand because they are regular and well defined . turbulent structures , on the other hand , are irregular , boundary - free , and extremely intricate .    for example , a single molecular cloud , such as the orion cloud , probably contains a total number of dense tiny clumps and cloud pieces ( each with masses of @xmath51 m@xmath34 in the @xmath52 m@xmath34 orion cloud ) that exceeds the total number of all other orion - type clouds in all of the galaxies out to and including the virgo cluster ( considering @xmath53 orion - type clouds per spiral galaxy the size of the milky way ) . obviously there are far too many pieces of structure in a typical molecular cloud to catalog or map at the present time , and far too many to simulate on a computer . yet these tiny pieces are very important : they probably contain most of the mass in the cloud , as demonstrated by the generally high excitation densities for many molecular transitions ( e.g. , falgarone , phillips , & walker 1991 ; lada , evans & falgarone 1997 ) , and therefore control most of the chemistry , and ultimately , star formation . how should we proceed to understand interstellar matter in the face of such complexity ( scalo 1990 ) ? one of the most fundamental properties of turbulent clouds seems to be the arrangement of gas into hierarchical structures that are fractal or multi - fractal , with increasing density and local volume filling factor on smaller scales . scale - free structures like this make a certain amount of sense for turbulent gas because the velocities that continuously form them have a scale - free nature as well , reminiscent of the kolmogorov velocity law in incompressible laboratory turbulence . scale - free velocities should make scale - free structures , as long as thermal pressure and gravity are not important structuring agents as well . when gravity is important , the gas becomes centrally condensed and builds up a pressure gradient . most star - forming clouds are centrally condensed already . we would like to know whether non - linear gas motions ( i.e. `` turbulence '' ) with a magnetic field can produce structures and velocities similar to what is observed in space . figure [ fig : sim ] shows one time step in a computer simulation of a supersonically turbulent , magnetic gas . the density is plotted as a grayscale , with two cycles of gray representing the span of density in the central `` cloudy '' region of a two - dimensional mhd simulation . the initial conditions are a uniform density ( value 1 ) , and pressure ( value 1 , giving a sound speed of 5/3 ) , with a uniform magnetic field oriented vertically in the figure . the initial alfven speed for this field is 10 in these units , which is supersonic . there is no self - gravity . the full grid measures 800 cells in the vertical direction , and 640 cells horizontally ( only the central 480 cells in the vertical direction are shown here ) . after this initial setup , the magnetic field lines at the top and bottom of the grid are accelerated back and forth , horizontally , with random accelerations for random durations at random times , taking big swaths of field lines all at once . the distribution of swath size is the same as we measured for the distribution of interstellar cloud sizes , namely a power law with @xmath54 ( elmegreen & falgarone 1996 ) . what this result simulates is the non - linear excitation of field lines by moving neighboring clouds . the gas in the simulation has two stable thermal states , one at a temperature corresponding to a sound speed of 1 , and another at a temperature corresponding to a sound speed of @xmath55 ( i.e. , 10 times hotter ) . the magnetic field - line excitations at the top and bottom of the grid heat up the gas there to the high temperature state , and also drive the motion of gas toward the grid center . this forms a dense `` cloud '' at the vertical center of the grid , and this cloud takes the cool thermal state . the simulation was run for @xmath52 timesteps , with each time step equal to one - tenth of the time it takes an initial alfven wave to travel over a distance of one cell . the figure shows the dense central part of the grid , measuring 640 cells horizontally and 480 cells vertically . substructure inside the dense part is apparently hierarchical , with some `` clumps '' containing 4 levels of substructure . the larger pieces move with a mildly supersonic speed , and last for about one sound crossing time ; during this time , they are `` bound '' by ram pressure from their constant motion . that is , the @xmath56 term in the equation of motion acts like a binding pressure . the thermal pressure is actually lower between the clumps than inside the clumps , so they are not bound by thermal pressure ; i.e. , there is no warm interclump medium . simulations like these suggest that hierarchical structure is a natural consequence of non - linear magnetic wave interactions . this gives an indication that perhaps turbulence is causing some of the structures seen in interstellar clouds . we have a long way to go before the picture is complete . optical images of galaxies like ours show such dominance by spiral arms that we should always question whether any local interstellar structures might have been caused by density waves . obviously , the string of giant molecular clouds along the sagittarius - carina arm , including the m17 and m16 clouds in the first quadrant , the eta carina cloud in the third quadrant , and many others ( e.g. , cohen et al . 1985 ) , should look like pieces in a giant spiral arm _ dust lane _ if viewed from outside the galaxy . there are probably streaming motions along this dustlane too . spiral arm streaming motions ( roberts 1969 ) are well documented for other galaxies ( e.g. , kuno & nakai 1997 ) and for some regions in our galaxy , particularly along the tangent points of the inner spiral arms ( burton 1992 ) . these streaming motions affect our estimates for the kinematic distances to molecular clouds . for example , the longitude and velocity of the m17 cloud , @xmath57 and @xmath58 km s@xmath59 , give it a kinematic distance of 2.5 kpc in the standard galactic rotation model . but hanson , howarth & conti ( 1997 ) found a spectroscopic distance in the range of 1.1 to 1.7 kpc . at the preferred distance of 1.3 kpc , its radial velocity should be only 10 km s@xmath59 . this implies that the m17 molecular cloud has a streaming motion in the radial direction of @xmath60 km s@xmath59 , moving away from the sun . this is consistent with the expected sense of spiral wave streaming , i.e. , directed radially inward along the arm inside corotation , or it corresponds to a purely azimuthal streaming of @xmath61 km s@xmath59 . thus , the true streaming speed is somewhere between 10 and 30 km s@xmath59 . in any case , the observed radial speed gives it a kinematic distance that is wrong by nearly a factor of 2 ! such an error affects the mass estimate for m17 and other clouds as well as our perception of galactic spiral structure . if turbulence makes some clouds and cloud clumps , then it also makes some of the low density regions between these clouds and clumps . these are the spaces cleared out by the turbulent motions when the gas is moved into denser regions . for a fractal cloud population , the intercloud medium has certain regular properties that also come from fractal geometry . one of these properties is the size distribution of holes . in a hierarchical model with clumps inside other clumps , each level in the hierarchy has a constant proportion of the number of empty regions of a particular size to the number of clumps of that size . this means that the hole size distribution is the same as the clump size distribution , which is @xmath62 for size @xmath63 and fractal dimension @xmath64 ( mandelbrot 1982 ) . the dimension for this type of fractal is defined by the relation @xmath65 for number of subclumps in a clump , @xmath16 , and for size ratio of clump to subclump @xmath66 . it may also be defined from the scaling of mass with size @xmath67 . if @xmath68 from the cloud size distribution and mass - size relation ( elmegreen & falgarone 1996 ) , then the hole size distribution should be @xmath69 too . the fractal brownian motion model proposed by stutzki et al . ( 1998 ) also has a size distribution for clouds equal to the size distribution for holes . this model begins with a white noise spectrum , and then convolves this with a power law that has decreasing power at high frequencies . the result is a noise model with the large scale features emphasized . these features , like the original noise , are equally likely to have positive or negative excursions around the mean density . if we identify the positive excursions with clouds and cloud clumps and the negative excursions with holes between the clouds , then the size distribution for holes will be the same as the size distribution for clumps . these predicted size distributions are steeper than the shell size distribution found by oey & clarke ( 1997 ) , who got a power law with a slope of @xmath70 ( instead of @xmath71 ) on a @xmath72 plot . oey & clarke s objects are real shells , however , not just random regions with locally low densities . there are no studies yet of the distribution of hole sizes , but consideration of this might prove fruitful . the volume filling factor of low density gas is another important consideration for comparisons with observations . for the hierarchical fractal model discussed above , the low density volume filling factor equals @xmath73 for density contrast @xmath74 between the highest and lowest levels ( elmegreen 1997 ) . to evaluate this , we used @xmath75 considering densities from 0.1 cm @xmath76 to 100 @xmath50 in the diffuse medium , or from 100 @xmath50 to @xmath52 @xmath50 in molecular clouds . the large value of this filling factor indicates that _ a turbulent interstellar medium should be mostly empty , with most of the mass in the form of clouds that occupy only a small fraction of the volume_.    this result challenges the usual interpretation of the open frothy structure of the interstellar medium as an indication of stellar winds and supernovae ( brand & zealey 1975 ; hunter & gallagher 1990 ) . more likely , the frothy structure is from a combination of these direct stellar processes plus pervasive turbulent motions . for the turbulent motions , the energy can be put into the gas in non - explosive forms ( e.g. , shear , magnetic wave interactions , etc . ) , although some of it may ultimately come from explosions around stars too . a recent fractal interpretation of the frothy structure in hi maps of the smc was made by stanimirovic et al . ( 1998 ) . equation [ eq : ficm ] gives the total filling factor of low density gas from all levels in the hierarchy . there is another filling factor for a hierarchical cloud distribution and that is the filling factor of regions with a certain average gas density , @xmath77 , @xmath78\\right ) d\\log s \\propto { { 1}\\over{<\\rho>}}d\\log < \\rho>. \\label{eq : fave}\\ ] ] this result is easily derived using the intermediate step shown , along with the size distribution function @xmath79 and the density - size relation @xmath80 , which comes from the mass - size relation that defines the fractal dimension @xmath64 in this model , @xmath67 . equation [ eq : fave ] indicates that the summed volume of regions with a certain average density occupies a smaller and smaller fraction of the total volume as that density increases . equation [ eq : ficm ] above suggests further that as this average density increases ( and @xmath81 ) , the gas inside each dense piece becomes more and more uniform . thus we recover the standard model of _ interstellar clouds composed of numerous , tiny , near - uniform clumps , arranged in a fractal pattern with the average gas density varying inversely with size _ ( for @xmath64 near 2 ) . we also get an explanation for the common perception that clumps in emission line surveys generally occupy 110% of the volume ( e.g. , blitz 1993 ) . evidently , this is a selection effect caused by the limitations of molecular emission maps which are typically sensitive to only a factor of @xmath82 range in density for any one survey . berkhuijsen ( 1998 ) has obtained a remarkable result recently in plotting the volume filling factor of ionized interstellar gas as a function of its local average density . the result , shown in figure [ fig : berk ] , is a @xmath83 distribution , as expected for a turbulent fluid with any fractal dimension . this does not mean that the ionized fluid itself is turbulent in this way ; in most regions , the ionization structure is probably just a reflection of the neutral structure of the gas before it was ionized . hierarchical or fractal structure in the intestellar medium implies that clouds are highly clumped , i.e. , that any one cloud is likely to have another cloud nearby , and , conversely , any empty region is not particularly likely to have a cloud nearby . such clumping makes the mean free path for intersecting a cloud on the line of sight different for regions near clouds than for regions between clouds . thus the _ intercloud _ mean free path can be larger than the _ average _ mean free , which has always been obtained in the past by assuming a uniform density . this result has important implications for the distance ionizing photons can travel once they leave a molecular cloud / ob association complex . the mean free path is generally defined as @xmath84 for number density of clouds @xmath32 and cross sectional area @xmath85 . when @xmath32 is not uniform , but clumped instead , this expression has a different value on lines of sight near cloud complexes than it does on lines of sight between cloud complexes . the hierarchical cloud model discussed above ( elmegreen 1997 ) can be used to show that the number of sub - clouds on a line of sight through a fractal cloud is @xmath86 if there are 8 interstellar absorption lines kpc@xmath59 on _ average _ ( blaauw 1952 ) , then these correspond to @xmath87 fractal cloud complexes per kiloparsec . indeed , most of the local gas is not randomly distributed with a constant space density of clouds everywhere . it is highly clumped into cloud complexes associated with the ob associations in orion , sco - cen , and perseus , and with the taurus clouds . these are the types of clouds that occur with the rate of 3 kpc@xmath59 . the average mean free path on lines of sight _ between _ the fractal cloud complexes should be @xmath88 pc . this may be defined as the pure intercloud mean free path . it exceeds the galactic scale height , which means that once photons get into the disk intercloud medium , they are likely to reach the halo . for this reason , the ionization of the halo , giving the `` reynolds '' layer ( reynolds 1995 ) , may be much easier than previously thought ( compare this result to the uniform cloud model by miller & cox 1993 ) . hii regions expand away from giant molecular clouds into the intercloud medium . for fractal clouds , the neutral density varies inversely with distance @xmath20 as @xmath89 for @xmath68 . when the ionization front reaches this neutral density , it heats and ionizes the gas , causing the smallest pieces to expand and mix with each other . this makes the local density more uniform on a timescale equal to the sound crossing time for the small pieces , but it does not affect the overall density gradient much because the sound crossing time is large on a large scale . thus a young hii region should have a radial density gradient reflecting the @xmath90 gradient in the initial neutral cloud . as a result , there should be an extended component of _ diffuse ionized gas _ surrounding most hii regions . the fraction of the ionization outside the conventional strmgren sphere can be large , perhaps 50% ( elmegreen 1997 ) . such extended ionization around hii regions presumably corresponds to the observations of diffuse ionized gas in our galaxy ( reynolds 1995 ) and other galaxies ( walterbos & braun 1994 ; ferguson et al . this diffuse ionized gas is clearly associated with the outlying parts of individual hii regions in many cases ( walterbos & braun 1994 ) . the mass distribution of purely hierarchical structures should scale as @xmath91 constant , or ( fleck 1996 ) : @xmath92 actually , @xmath93 from clump surveys ( stutzki et al . 1998 ; heithausen et al . 1998 ) . elmegreen & falgarone ( 1997 ) got @xmath94 with @xmath95 from a model of hierarchical cloud structure using the observed @xmath96 for size @xmath63 with @xmath97 , and the observed @xmath98 with @xmath99 , and then combining these relations with the standard conversion @xmath100 , which gives @xmath101 . stutzki et al . ( 1998 ) got @xmath102 with a cloud model based on fractal brownian motion , using @xmath103 and the same @xmath64 and @xmath104 . the physical difference between these two models is that hierarchical clouds have all their small clumps inside larger clumps , whereas fractal brownian motion clouds have small structure with equal probability everywhere , although it is weaker outside the larger clumps . in theory , the brownian motion model makes more sense for turbulence , which should have some density structure everywhere , but in practice , the low density regions outside of the main hierarchy in an interstellar cloud may be ionized or invisible in co , in which case only the dense hierarchical core , which is common to both models , will be seen . the @xmath105 function also applies to the probability of choosing part of a hierarchical cloud from any level . if stars form at all levels in a hierarchy because all levels have dense gas in tiny clumps , then the resulting stars will be hierarchically clumped too . such a distribution for stars is in fact commonly observed ( elmegreen & efremov 1997 , 1998 ) . if , in addition , bound clusters form with some high and nearly constant efficiency , so @xmath106 , then the mass distribution for star _ clusters _ will be about the same as the mass distribution for cloud structure ( elmegreen & falgarone 1996 ) .    battinelli et al . ( 1994 ) found cluster mass functions from two samples that had power law slopes equal to @xmath107 and @xmath108 . elmegreen & efremov ( 1997 ) similarly found @xmath109 for three different age groups in the lmc . these cluster mass functions are very similar to the expectations from hierarchical clouds , given by equation [ eq : fleck ] . berkhuijsen , e. m. 1998 , `` the volume filling factor of the wim , '' in _ the local bubble and beyond _ , iau colloquium no . 166 , d. breitschwerdt , m. j. freyberg , and j. truemper ( eds . ) , berlin : springer - verlag , p. 301304 elmegreen , b.g . 1995 , `` large scale star formation , '' in _ the 7th gou shoujing summer school on astrophysics : molecular clouds and star formation _ , c. yuan and hunhan you ( eds . ) , singapore : world press , p. 149205 elmegreen , b.g . , & efremov , y.n . 1998 , `` hierarchy of interstellar and stellar structures and the case of the orion star - forming region , '' in _ the orion complex revisited _ , mccaughrean , m.j . & burkert , a. ( eds . ) san francisco : asp conference series , in press                heithausen , a. , bensch , f. , stutzki , j. , falgarone , e. , & panis , j.f . 1998 , `` the iram key project : small scale structure of pre - star forming cores . combined mass spectra and scaling laws , '' _ a&a _ * 331 * 6568                  langer , w. d. , velusamy , t. , kuiper , t.b.h . , peng , r. , mccarthy , m.c . , travers , m.j . , kovacs , a. , gottleib , c.a . , thaddeus , p. 1997 , `` first astronomical detection of the cumulene carbon chain molecule h2c6 in tmc-1 , '' _ apj _ * 480 * , l63l66                                reynolds , r.j . 1995 , `` diffuse optical emission lines as probes of the interstellar and intergalactic ionizing radiation , '' in the physics of the interstellar medium and intergalactic medium , asp conf . series 80 , ed . a. ferrara , c.f . mckee , c. heiles , and p.r . shapiro , san francisco , astron.soc.pacific , p. 388397          scalo , j. 1990 in physical processes in fragmentation and star formation , `` perception of interstellar structure : facing complexity , '' r. capuzzo - dolcetta , c. chiosi , & a. di fazio ( eds . ) dordrecht : kluwer , p. 151178 stanimirovic , s. , staveley - smith , l. , sault , r. j. , dickey , j. , & snowden , s. 1998 , `` fractal structure in the interstellar medium of the smc ? '' _ iau symposium 190 , new views of the magellanic clouds _ , cu , yuo - hua , et al . ( eds . ) , asp conference series , in press                  wannier , p.g . , andersson , b .- g . , federman , s. r. , lewis , b. m. , viala , y. p. , & shaya , e. 1993 , `` warm neutral halos around molecular clouds . v - oh ( 1665 and 1667 mhz ) observations , '' _ apj _ * 407 * , 163174", "tags": [], "output_text_a": "The paper discusses the complex thermal and chemical phases of interstellar gas in the solar neighborhood, highlighting the variety of molecular and atomic states present in different types of clouds. It explains how these states are influenced by factors such as density, column density, metallicity, and local radiation fields. The paper also explores the role of turbulence, self-gravity, and local explosions in shaping cloud structures, and how these processes contribute to the formation of molecular rings and pressure gradients in galaxies. Additionally, it examines the thermal stability of atomic gas and the influence of pressure and radiation on molecular cloud formation. The paper further delves into the hierarchical and fractal nature of interstellar clouds, suggesting that turbulence plays a significant role in creating the observed structures. The study also considers the implications of these findings for understanding star formation and the distribution of ionized gas in galaxies. Overall, the paper provides a comprehensive overview of the factors affecting the molecular and thermal states of interstellar gas and the resulting cloud structures.", "output_text_b": "The article discusses the various thermal and chemical phases of interstellar gas in the solar neighborhood. These phases include cold atomic gas, cool and warm atomic gas, cold molecules in dark and dense clouds, warm molecules in dense clouds, dense photo-ionized gas, low-density ionized gas, and hot shock-heated gas. The molecular content of the gas depends on factors such as density, column density, metallicity, age, and local radiation field. The structure of the clouds is largely determined by turbulence, self-gravity, and local explosions. The paper also discusses the processes that affect the molecular and thermal states of the gas and reviews some aspects of cloud structure that are likely to arise from turbulence.", "score": 0.29999999999999993, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, discussing the thermal and chemical phases of interstellar gas, the influence of various factors on these states, and the role of turbulence and other processes in shaping cloud structures.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary does not explicitly highlight the research problem or question addressed by the paper.\n4. **Methodology**: The summary does not mention the methodology or approach used in the paper.\n5. **Significant Results**: The summary includes significant results and conclusions, such as the influence of pressure and radiation on molecular cloud formation and the hierarchical nature of interstellar clouds.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids excessive technical jargon and explains terms in a general sense.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding star formation and the distribution of ionized gas in galaxies.", "1. **Accurate Reflection**: The summary captures the various thermal and chemical phases of interstellar gas and mentions factors affecting molecular content, which aligns with the paper's content. However, it lacks specific details on the main findings and contributions, such as the implications of pressure on molecular formation and the hierarchical structure of clouds.\n   \n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem**: The summary does not explicitly highlight the research problem or question addressed by the paper.\n\n4. **Methodology**: The summary does not mention the methodology or approach used in the paper, such as the use of simulations or theoretical models.\n\n5. **Significant Results**: The summary briefly mentions the factors affecting molecular content but does not include significant results or conclusions drawn by the authors, such as the impact of pressure gradients or the fractal nature of cloud structures.\n\n6. **Language**: The summary is written in clear and professional language.\n\n7. **Technical Jargon**: The summary avoids technical jargon and does not explain terms, which is appropriate given the context.\n\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n\n10. **Significance/Impact**: The summary does not reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [false, false], "The summary should mention the methodology or approach used in the paper.": [false, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the cosmic evolution survey ( cosmos ) is a treasury program on the _ hubble space telescope _ ( _ hst _ ) , awarded a total of 590 _ hst _ orbits , carried out in cycles 12 and 13 ( scoville et al . 2007a , 2007b ; koekemoer et al . 2007 ) . in total , a sky area of 1.64 square degree is covered with advanced camera for surveys ( acs ) f814w filter around the central position @xmath6 and @xmath7 . note that we originally proposed to map a @xmath8  square degree field . however , due to the observational constraints , the sky area of 1.64  square degree was mapped ( koekemoer et al . 2007 ) . on the other hand , the subaru cosmos 20 project has covered the whole 2  square degree field . the comparison between the _ hst _ acs field and the subaru cosmos 20 field is shown in figure  [ fig : field ] . a point source limiting magnitude is down to @xmath9 ( @xmath10 , 024 diameter aperture ) . these acs observations provide us a large sample of galaxies with a spatial resolution of 0.1  arcsec covering a redshift range between @xmath11 to @xmath12 ( e.g. , taniguchi et al . 2009 ; murata et al . 2014 ; kobayashi et al . 2015 ) . ( red line ) and the acs field of @xmath13 ( blue line ) overlaid on the ia427 band image.[fig : field],width=302 ]    the main purpose of the cosmos project is to understand the evolution of galaxies , active galactic nuclei ( or super massive black holes ) , and dark matter halos together with the evolution of large scale structures in the universe . in order to carry out this project , we also need multi - wavelength data from x - ray , ultraviolet though optical to infrared and radio . indeed , such multi - wavelength campaign has been made intensively : x - ray ( hasinger et al . 2007 ; elvis et al . 2009 ) , ultraviolet ( zamojski et al . 2007 ) , optical ( taniguchi et al . 2007 ; capak et al . 2007 ) , infrared ( sanders et al . 2007 ) , and radio ( schinnerer et al . 2007 ; smoli et al . 2012 ) . among them , optical imaging observations made by use of suprime - cam ( miyazaki et al . 2002 ) on the subaru telescope ( kaifu et al . 2000 ; iye et al . 2004 ) are highly useful to investigate both photometric properties and photometric redshifts of the galaxies found in the cosmos field ( mobasher et al . 2007 ; ilbert et al . 2009 ; salvato et al . 2009 ) . in our subaru cosmos 20 project , we used 20 filters in the optical covering from 400  nm to 900  nm : six broad - band ( @xmath0 , @xmath1 , @xmath2 , @xmath3 , @xmath4 , and @xmath5 ) , twelve intermediate - band ( ia427 , ia464 , ia484 , ia505 , ia527 , ia574 , ia624 , ia679 , ia709 , ia738 , ia767 , and ia827 ) , and two narrow - band filters ( nb711 and nb816 ) . this is the origin of the project s name , `` subaru cosmos 20 '' . since we have already given a detailed description on the broad - band and nb816 imaging of the cosmos field ( taniguchi et al . 2007 ; hereafter paper  i ) , we present details of observations , data reductions , calibration , and quality assessment for the twelve intermediate - band filters and nb711 in this paper ( see also capak et al . 2007 ) . as for the nb711 imaging of the cosmos field , see also shioya et al . ( 2009 ) and kajisawa et al . ( 2013 ) . in appendix , we present a summary of the optical properties of the suprime - cam ia filter system . throughout this paper , we use the ab magnitude system . the twelve intermediate - band filters are selected from the suprime - cam ia filter set ( hayashino et al . 2000 ; taniguchi et al . the spectral resolution of all the ia filters is @xmath14 , being just intermediate between typical broad - band filters ( @xmath15 ) and narrow - band filters ( @xmath16100 ) . therefore , imaging with multi - ia filters is equivalent to low - resolution spectroscopy with an @xmath17 ( see , for example , yamada et al . it is also mentioned that the use of ia filters makes it possible to detect very strong emission - line objects ( galaxies or active galactic nuclei ) . although such objects tend to be rare , some examples have been discovered to date : ultra strong emission line galaxies ( usels ) defined as @xmath18   ( kakazu et al . 2007 ) , and green pea objects found in the galaxy zoo project ( cardamone et al . 2009 ) .    since such very strong emission lines in galaxies affect broad - band colors of the galaxies ( e.g. , nagao et al . 2007 ) , careful analyses are recommended to make any sample selection of a particular class of galaxies . for example , in the case of color selection of very high redshift galaxies at @xmath198 , strong emission line galaxies at @xmath20 with little stellar continuum can act as interlopers ( see taniguchi et al . 2010 ; atek et al . 2011 ) . on the other hand , such very strong emission line galaxies themselves are important populations , because most of them are very metal poor galaxies ( kakazu et al . 2007 ; amorn et al . 2014 , 2015 ) . therefore , surveys of such objects contribute to the understanding chemical evolution of galaxies .    in our subaru cosmos 20 project , we also use the two narrow - band filters , nb711 and nb816 . imaging with such narrow - band filters provides us samples of targeted emission line galaxies . for example , nb816 has been used to find ly@xmath21 emitters at @xmath22 ( e.g. , hu et al . 2004 , 2010 ; shimasaku et al . 2005 ; murayama et al . 2007 ) . however , the use of nb816 also provides us samples of h@xmath21 emitters at @xmath23 ( shioya et al . 2008 ) and [ o  ii ] emitters at @xmath24 ( takahashi et al . 2007 ; ideue et al . 2009 , 2012 ) . in the case of cosmos project , nb711 has also been used to sample both ly@xmath21 emitters at @xmath25 ( shioya et al . 2009 ) and [ o  ii ] emitters at @xmath26 ( kajisawa et al . 2013 ) . therefore , if we combine imaging surveys with multiple nb filters , we can trace the cosmic star formation history from high to low redshifts ( e.g. , hopkins 2004 ; shioya et al . 2008 ) . moreover , multi - band optical imaging such as our subaru cosmos 20 improves the accuracy of photometric redshifts of galaxies ( ilbert et al . 2009 ) and active galactic nuclei ( salvato et al . 2009 , 2011 ) . the accurate photometric redshifts for the large sample of galaxies allow us to map the large - scale structure at various redshifts and to study the environmental effects of the galaxy evolution ( feruglio et al . 2010 ; scoville et al . one can also combine such photometric redshifts with a smaller spectroscopic sample to estimate the overdensity of galaxies with high accuracy ( e.g. , kova et al . 2014 ) and to measure the clustering strength of agns ( georgakakis et al . the cosmos field covers an area of @xmath27 , centered at @xmath28 and @xmath29 . the suprime - cam consists of ten @xmath30  ccd chips and provides a very wide field of view , @xmath31 in @xmath32  pixels ( 0202  pixel@xmath33 ) ( miyazaki et al . although the field of view of the suprime - cam had been the widest one among available imagers on the 810  m class telescopes before hyper suprime cam on the subaru telescope ( miyazaki et al . 2012 ) , we needed multiple pointings to cover the entire cosmos field .    in our previous suprime - cam observations , we used the two dithering patterns , pattern  a and pattern  c ( paper  i ) . pattern  a consists of @xmath34  sets ( 48  shots in total ) to cover the whole cosmos field ( see figure  1 in paper  i ) . this dithering pattern is a half - array shifted mapping method to obtain accurate astrometry and a self - consistent photometric solution across the entire field . another dithering method is pattern  c that consists of @xmath35  sets ( 36  shots in total ) to cover the whole cosmos field efficiently ( see figure  2 in paper  i ) . it is noted that both patterns are designed to take care of spatial gaps ( @xmath36@xmath37 or @xmath38@xmath39 ) between the ccd chips of the suprime - cam . after our previous observations , we confirmed that observations with pattern  c only are enough to obtain accurate photometry and astrometry . the flat frames generated using only pattern  c in the broad bands are consistent with those created with both pattern  a and pattern  c within 1% root mean square . therefore , our new observations with the intermediate and narrow - band filters were made by using pattern  c. this made our observations more efficient than our previous observations .        in this paper , we used twelve intermediate - band filters ( ia427 , ia464 , ia484 , ia505 , ia527 , ia574 , ia624 , ia679 , ia709 , ia738 , ia767 , and ia827 ) and one narrow - band filter ( nb711 ) . note that we intended to use another nb filter , nb921 , whose effective wavelength and the full width at half maximum ( fwhm ) are @xmath40   and @xmath41   , respectively ( kodaira et al . 2003 ; kashikawa et al . 2004 ; taniguchi et al . 2005 ) . however , we did not have enough time to take any nb921 data . the filter response curves including the ccd sensitivity and the atmospheric transmission are shown in figure  [ filter_response ] for the twelve ia filters and nb711 ( see also section 3.2 for details ) . in figure  [ filter_iabbnb3 ] , we also show those for the 20 filters used in subaru cosmos 20 . in order to see the wavelength coverage fairly , all the response curves are normalized ; i.e. , all the peak values are set to be unity . note that the current ccd chips installed on suprime - cam are different from those used in our subaru cosmos 20 project . @xmath42the figure `` i '' given in the last of i d number means an intensive program . @xmath43@xmath44 , and @xmath45 . @xmath46suprime - cam imaging of the _ hst _ cosmos 2-degree acs survey deep field ( intensive program ) . @xmath47wide - field search for ly@xmath21 emitters at @xmath48 in the _ hst_/cosmos field . @xmath49cosmos-21 : deep intermediate & narrow - band survey of the cosmos field ( intensive program ) . @xmath50cosmos-21 : deep intermediate - band survey of the cosmos field . @xmath42the figure `` i '' given in the last of i d number means an intensive program . @xmath43@xmath44 , and @xmath51 . @xmath46first half night was used in every night . @xmath47compensation nights because of the poor weather in s04b-142 jan and feb runs .    @xmath49observing time exchange with dave jewitt ( ifa , uh ) . @xmath50second half night was used in every night . @xmath52three hours @xmath53 3 . our suprime - cam observations of the cosmos field have been made during a period between 2006 january and 2007 march , consisting of two open - use observing programs : s05b-013i ( cosmos-21 : deep intermediate & narrow - band survey of the cosmos field ) and s06b-026 ( cosmos-21 : deep intermediate - band survey of the cosmos field ) . the first one is an intensive program on the subaru telescope . fourteen and half nights were allocated for these two proposals ( tables  [ observational_programs ] and [ observational_runs ] ) . with 28.5  nights ( including 4 compensation nights ) allocated for our cosmos observations in paper  i , 43  nights were allocated in total .    our observations in the available nights shown in table  [ observational_runs ] were made under the photometric conditions except for the ia505- and ia679-bands observations on feb . 24 , 2006 . we observed the spectrophotometric standard stars immediately before and after the target observations for the photometric calibration . these standard stars have been observed at various airmass , defocussing the telescope to avoid saturation . the observed standard stars are summarized in table  [ standard_star ] . although we also observed gd  71 with several ia filters , all the data were saturated and we did not use gd  71 for the photometric calibration . [ standard_star ] all the individual ccd data were reduced using imcat with the same manner as the suprime - cam broad - band data of the cosmos survey ( capak et al . 2007 ) . at first , we performed the bias subtraction and the masking of bad or saturated pixels . then the flat fielding was carried out with the median dome flats . we subtracted the median sky frames from the flat - fielded object frames to remove the night sky illumination and fringe pattern . the residual background was measured in a grid of @xmath54  pixel squares after masking objects and subtracted . after the sky subtraction , we calculated an astrometric solution for each ccd chip in all frames using the cosmos astrometric reference catalog . this catalog was build in 2004 using the megacam @xmath55-band data ( capak et al . 2007 ) , a dataset with bright enough saturation magnitude on individual exposures ( @xmath56 ) to be registered on classical astrometric references , and deep enough ( reaching @xmath57 ) to allow for the registration of all other subaru and acs cosmos data . the cosmos astrometric reference catalog was build iteratively via the following four steps : 1 ) the astrometric solution for the megacam images was computed using the astrometrix software ( radovich et al . 2001 ) , that was at the time part of the terapix pipeline ( scamp was only introduced in 2005 ) , using the usno - b1.0 catalog ( monet et al . 2003 ) as reference . 2 ) the @xmath55-band catalog obtained from the megacam stack was cross - matched to the cosmos vla pre survey ( schinnerer et al . 2004 ) , and we measured offsets of @xmath58  mas and @xmath59  mas , without any indication of variation across the field . 3 ) the measured offsets were applied to the input usno - b1.0 catalog , and the astrometric solution of the megacam @xmath55-band images was recomputed in the same manner as step  1 . 4 ) the final cosmos astrometric reference catalog was obtained from the @xmath55-band megacam stack produced at step  3 . the internal accuracy of the cosmos astrometric reference , i.e. , the maximum value of the residual of the astrometric solution derived by astrometrix when fitting the shifted usno - b1.0 catalog is @xmath60  mas and @xmath61  mas , and the absolute offset to the full survey vla astrometry is @xmath62  mas and @xmath63  mas . all our cosmos 20 images were forced to the cosmos astrometric reference using a 35th order polynomial . the polynomial order was increased until the astrometric errors were consistent with the seeing size in the data . the internal scatter of the resulting astrometry is always less than 0.2  arcsec . we then performed the scattered light correction for the flat as described in capak et al . the dome and sky flat can be affected by the scattered light at 35% level . the correction factor for this effect was calculated in each @xmath54  pixel grid so that the background subtracted fluxes of an object at different positions of the detector in the different frames have the same values . objects in the all frames were simultaneously used in the fitting procedure for each band . in this process , we also added the additional correction factor for each frame to take account of the effects of the airmass and non - photometric condition . these correction factors for the scattered light in each region and for the atmospheric condition in each frame were simultaneously determined in the fitting for each band ( equations ( 1 ) and ( 2 ) in capak et al . thus we made the corrected flat frames and applied them to the object frames . then the frame to frame offsets of the background - subtracted fluxes of objects were examined as a function of airmass and modified julian date . if the data followed the airmass trend estimated from the standard star observations within the expected 12% error due to point spread function ( psf ) variation , the data were deemed photometric . if data stopped following the expected trend , or did not follow it for a night , the data were deemed non photometric . the non - photometric frames were scaled to the mean of the airmass corrected photometric data . the frames with extinction greater than 0.5  mag were discarded . in the case of the ia679 band , where no photometric data were obtained , all the object frames were scaled to the least extinct frame . therefore the photometry in the ia679 band should be used with caution . the flux - matched frames were then smoothed to the same psf fwhm using a gaussian kernel . after the resampling onto the final astrometric grid , the psf - matched frames were combined with a weight of the inverse variance of each frame , clipping outlier values at more than @xmath10 from the median value in the calculation of each pixel . in this procedure , we also generated a root mean square ( rms ) map that reflects the true pixel - to - pixel rms , which is the value expected if the effects of the resampling and smoothing do not exist . the rms measured in a given area on this rms map represents the variance that would be measured in the background of the same area if the variance was calculated on the individual images that went into the final mosaiced image . the psf sizes of final images are summarized in table  [ optical_imaging ] . in addition to these psf - matched combined images , we also provided the original - psf images for each band from the frames that were not convolved in order to provide a maximum sensitivity for detection of ( compact ) sources . note that the psf varies as a function of position in these original - psf images , and therefore the color measurements with a relatively small aperture can be less reliable . these reduced images were divided into tiles with a dimension of @xmath64 as shown in figure  5 of paper  i.    for the color measurements and generating the official multi - band photometric catalog , we additionally convolved the psf - matched combined images to match the psf among all the optical nir data from @xmath65 to @xmath66 band . these data were convolved with a gaussian kernel so that the flux ratio between a @xmath36 and @xmath67 aperture for a point source in each band is the same as that of ctio / kpno @xmath66-band data , which have the lowest flux ratio of @xmath68 ( capak et al . the width ( @xmath69-value ) of the gaussian kernel used in the convolution of the ia and @xmath70-band data is shown in the last column of table  4 . using these convolved data , we carried out the multi - band photometry with a @xmath36 diameter aperture and the results are presented in the official photometric catalog . note that the matching of the flux ratio between @xmath36 and @xmath67 apertures for point sources does not necessarily guarantee the same flux ratio for extended sources , because the detailed shapes of the psf are not the same among the different bands . if one needs to measure colors for extended sources with high accuracy , the photometric values in the official catalog should be used with caution .          since we used the original intermediate- and narrow - band filters in this project , the theoretical synthetic magnitudes of the spectrophotometric standard stars are necessary for the photometric calibration . the theoretical complete system response in each band was computed by multiplying the filter transmission , the subaru telescope mirror reflectivity , the prime focus unit s transmission , the ccd quantum efficiency , and the atmosphere transmission for an airmass of 1.2 . for the atmosphere , we used the same model as the one used for the broad - band suprime - cam filters ( k. shimasaku , private communication ) . we computed the theoretical synthetic magnitude in the ab system of our standard stars using the available calspec spectra , i.e. , gd50_004.fits for gd  50 , gd108_005.fits for gd  108 , hz4_stis_001.fits for hz  4 , hz21_stis_001.fits for hz  21 and hz44_stis_001.fits for hz  44 ( bohlin 1996 ; bohlin et al . we present these theoretical magnitudes in the appendix  [ sec : app - b ] . note that for the hz stars , the calspec spectra have been interpolated between 5150   and 5212   , resulting in a larger overall uncertainty in the calibration of the ia505 and ia527 bands , because this more uncertain region lies on the edges of these two passbands . these standard stars have been observed at various airmass as mentioned above , and we determined the zero point for each band taking account of the airmass dependence . if @xmath71 are the counts measured from the standard star under an airmass @xmath72 , the relation between the standard magnitude @xmath73 and the zero point @xmath74 is : @xmath75 so that the airmass term @xmath76 is the slope of the expected linear fit to the data of the standard stars and its intercept gives the zero point . figure  [ fig : standards ] shows typical examples of the calibration for the ia624 and the ia738 bands . for most bands , our zero point determination is accurate within 0.02  mag . in a few cases , there was a lack of standard star observations at high airmass that prevented us to derive the airmass term from the standard star data . in this case , we used the airmass point of the object data for the zero - point determination . note that for the ia679 band , we obtained no photometric data both for the cosmos field and the standard stars , and we scaled to the photometry of the neighboring bands ( i.e. , ia624 and ia709 ) assuming the objects were flat in @xmath77 for the interpolation . after the photometric calibration , all the reduced images are converted to be in units of nanojanskys per pixel ( the zero point of 31.4  mag in the ab magnitude system ) . we also checked the consistency among the zero points in the different bands through the spectral energy distribution fitting for a large number of galaxies with spectroscopic redshift ( ilbert et al . the multi - band photometry from uv to mir wavelength including the ia- and narrow - band data were fitted with population synthesis models , and the systematic difference between the model and observed magnitudes in a certain band is considered to reflect the zero - point offset . the details of the method to determine the zero - point offsets are described in ilbert et al . ( 2006 , 2009 ) . these offsets of the photometric zero points are shown in the second - last column of table  [ optical_imaging ] . we note that the offset for the ia679 band is much higher than the other ia bands , which probably reflect the larger uncertainty in the photometric calibration for this band mentioned above . the zero - point offsets in table  [ optical_imaging ] are calculated for the upgraded version ( v2.0 ) of the photometric redshift catalog from ilbert et al . ( 2009 ) including the new ultravista data from the dr1 ( mccracken et al . therefore , the offsets in table  [ optical_imaging ] are slightly different from those in table  1 of ilbert et al . ( 2009 ) . @xmath42effective wavelength calculated from the filter response curve including the effects of the ccd sensitivity , the atmospheric transmission , and the transmission of the telescope and the instrument shown in figure  [ filter_response ] . @xmath43fwhm of the filter response curve mentioned above . @xmath46the target dedicated time . @xmath47the average 3@xmath69 limiting magnitude in the ab system within @xmath36 diameter aperture . @xmath49the standard deviation of @xmath78 measured in the 81 tiles . @xmath50the psf size of the final images . note that the psf of each filter band is finally matched so that the flux ratio between a @xmath36 and @xmath67 apertures is the same as that in the ctio / kpno @xmath66-band data to provide official photometric catalog ( see text ) . @xmath52systematic offset of the photometric zero point for each filter ( see text ) . @xmath79the @xmath69-value of the gaussian kernel used for the psf matching among the different bands ( see text in section  [ subsec : datareduction ] ) . note that the magnitudes in the public catalog are not corrected for the galactic extinction . instead , we provide the galactic extinction value , @xmath80 , from schlegel et al . ( 1998 ) for each object in the catalog . the correction for the galactic extinction in each band can be calculated from these values . we estimated the limiting magnitudes using the 81 tiles ( the cosmos _ hst_/acs field ) for each band . for each tile , we set 50,000 random points and performed aperture photometry with a @xmath36 diameter aperture on the psf - matched images which were convolved to the resolution of the cosmos @xmath66-band image . in order to measure the background fluctuation properly , we masked objects on the images . we used sextractor version 2.3.2 ( bertin & arnouts 1996 ) with the detection criteria of 5-pix connection above the @xmath81 significance . then we replaced the masked regions with pseudo noise images , which were provided from randomly - shifted object - masked images . then we evaluated the limiting magnitudes from the standard deviation for the distribution of the random photometry . the average limiting magnitudes of the 81  tiles for the ia and nb711 bands are listed in table  [ optical_imaging ] . as shown in table  [ optical_imaging ] and figures  [ fig : limitmag_ia1 ] and [ fig : limitmag_ia2 ] , the @xmath82 limiting magnitudes are @xmath8325.9  mag in ia427ia827 bands . the nb711 data reach to the limiting magnitude of @xmath84  mag as shown in table  [ optical_imaging ] and figure  [ fig : limitmag_nb711 ] . the standard deviation of the limiting magnitudes among the 81 tiles for each band is @xmath850.16  mag . as seen in figures  [ fig : limitmag_ia1][fig : limitmag_nb711 ] , the limiting magnitudes are brighter in the tiles at the edge of our survey field , because the total exposure time is smaller in these regions . some tiles where very bright stars illuminate surrounding sky region also show brighter limiting magnitudes .            , but for @xmath70band data.[fig : limitmag_nb711 ] ] we present deep optical imaging observations made with the suprime - cam on the subaru telescope with 20 filters [ 6 broad - band , 12 intermediate - band ( ia ) , and 2 narrow - band ( nb ) filters ] : subaru cosmos 20 . in this paper , we describe the details of our imaging with the 12 ia filters and nb711 . note that those of the other seven filters are given in paper  i.    the use of intermediate - band filters has generally a couple of scientific merits : ( 1 ) improvement of the accuracy of photometric redshifts and ( 2 ) selection of very strong emitters . first , we discuss the improvement of the accuracy of photometric redshifts . as described in mobasher et al . ( 2007 ) , our previous accuracy of photometric redshifts based on six subaru broad band , cfht @xmath86 band , acs f814w , nb816 , and ctio / kpno @xmath66 photometric data is @xmath87 where @xmath88 ; note that @xmath89 and @xmath90 are photometric and spectroscopic redshifts , respectively . since both @xmath86 and @xmath66 are used together with optical data , the accuracy of @xmath89 is better than that of typical optical studies ( e.g. , hogg et al . however , in the cosmos project , thanks to its multi - wavelength campaign , 30 band photometric data including subaru cosmos 20 data are accumulated to obtain much more accurate estimates of @xmath89 ( ilbert et al . 2009 ; see also salvato et al . 2009 , 2011 ) . the accuracy of @xmath89 is improved to @xmath91 for @xmath92 . even at fainter magnitudes of @xmath93 , the accuracy is found to be still high as @xmath94 for the galaxies at @xmath95 ( ilbert et al . 2009 ) . there are several similar surveys with the use of intermediate band filters . [ 1 ] combo-17 ( classifying objects by medium - band observations in 17 filters ) : this is a pioneering optical survey with multi - band filters ( wolf et al . 2003 ) . the combo-17 covers three @xmath96 fields , including the extended chandra deep field south ( ecdf - s ) . in this survey , twelve intermediate - band filters were used together with five broad - band ones ( @xmath65 , @xmath0 , @xmath2 , @xmath97 , and @xmath98 ) by using the wide field imager at the mpg / eso 2.2  m telescope on la silla , chile . their intermediate - band filters cover 410  nm to 920  nm . the spectral resolution is not fixed for all the filters but ranges from @xmath99 to 61 ( mostly from 30 to 40 ) . the use of intermediate - band filters improves the accuracy of photometric redshifts to @xmath91 for @xmath100 ( wolf et al . this enables them to construct a large sample of agns at @xmath1015 . [ 2 ] musyc ( the multiwavelength survey by yale - chile ) : in this project , 18 intermediate - band filters in the ia filter system for suprime - cam on the subaru telescope were used together with 14 board - band data from optical to mid - infrared ( seven optical filters from @xmath65 to @xmath102 , three near - infrared filters , @xmath103 , @xmath104 , and @xmath105 , and four spitzer irac bands , 3.6 , 4.5 , 5.8 , and 8.0  @xmath106 m ) ( cardamone et al . 2010 ) . these data cover a @xmath107 field of the ecdf - s , which is one of the musyc fields . the use of ia filters improves the accuracy of photometric redshifts at @xmath108 to 1.2 and @xmath109 : @xmath110 for @xmath111 , see table  8 in cardamone et al . ( 2010 ) in more detail . this is attributed that the balmer break ( 3648   ) or lyman break ( 912   ) falls in wavelength interval covered by the 18 ia filters . according to cardamone et al . ( 2010 ) , _ the use of ia filters not only tightens the accuracy of photometric redshifts but also can help to rule out false redshift solution ( so called catastrophic failures)_.    [ 3 ] mahoroba-11 : this survey is a scaled down version of subaru cosmos 20 ( yamada et al . 2005 ) . in this survey seven ia filters are used together with five broad - band filters . these data cover a @xmath112 area in the subaru xmm - newton deep survey field . their main purpose is to search for ly@xmath21 emitters at @xmath113 by using a photometric redshift method . they showed that the fraction of false detection is only 10% . [ 4 ] alhambra ( the advanced large homogeneous area medium - band redshift astronomilca ) : this survey has been carried out by using the wide - field optical camera , large area imager for calar alto ( laica ) on the calar alto 3.5  m telescope with 20 intermediate - band filters with 300   spacing ( moles et al . 2008 ; molino et al . the surveyed area size is 2.79  deg@xmath114 . the accuracy of photometric redshifts is @xmath110 for @xmath115 and @xmath116 for @xmath117 .    in this way , a number of optical wide - field deep surveys have been carried out by using their original intermediate - band filter systems . the main reason for this is to obtain more reliable photometric redshifts for large numbers of objects in the individual surveys ; see figure  1b in molino et al . ( 2014 ) for a comprehensive comparison among available optical surveys including surveys with broad - band filters only such as hdf , sdss , and so on . the subaru cosmos 20 is the widest survey among the deep ( @xmath118 ) optical intermediate - band surveys . some efficient multiple - object spectrographs are available on 8  m class telescopes ( e.g. , vimos on the vlts and fmos on the subaru telescope ) . however , imaging surveys with intermediate - band filters are more efficient to obtain redshift information for large numbers of objects . we mention about our future works on study of strong emission - line objects . the wide imaging with the ia filter set of the subaru cosmos 20 enables us to detect very strong emission - line objects ( star forming galaxies and agns ) over a extremely large volume . in our forthcoming papers , we will present a large sample of ia - excess strong emission - line objects ( kajisawa et al . 2015 , in preparation ) and a new population of maestlo ( @xmath119 massive extremely strong ly@xmath21 emitters ) at @xmath120 with rest - frame ly@xmath21 equivalent width of @xmath121   and @xmath122 ( taniguchi et al . 2015 ) . finally , we note that the major cosmos datasets including the subaru images and catalogs are publicly available ( following calibration and validation ) through the web site for ipac / irsa : + * http://irsa.ipac.caltech.edu / data / cosmos/*. the _ hst _ cosmos treasury program was supported through nasa grant hst - go-09822 . we gratefully acknowledge the contributions of the entire cosmos collaboration consisting of more than 70 scientists . more information on the cosmos survey is available at * http://www.astro.caltech.edu/~cosmos*. it is a pleasure the acknowledge the excellent services provided by the nasa ipac / irsa staff ( anastasia laity , anastasia alexov , bruce berriman and john good ) in providing online archive and server capabilities for the cosmos datasets . we are deeply grateful to the referee for his / her useful comments and excellent refereeing , which helped us to improve this paper very much . we would also like to thank the staff at the subaru telescope for their invaluable help . in particular , we would like to thank hisanori furusawa because his professional help as a support scientist made our suprime - cam observations successful . data analysis were in part carried out on common use data analysis computer system at the astronomy data center , adc , of the national astronomical observatory of japan . this work was financially supported in part by jsps ( yt : 15340059 , 17253001 , 19340046 , 23244031 , tn : 23654068 and 25707010 ) and by the yamada science foundation ( tn ) . ajiki , m. , taniguchi , y. , fujita , s.  s. , et al . 2004 , , 56 , 597    amorn , r. , grazian , a. , castellano , m. , et al . 2014 , , 788 , l4    amorn , r. , prez - montero , e. , contini , t. , et al . 2015 , , 578 , a105    atek , h. , siana , b.,scarlata , c. , et al . 2011 , , 743 , 121    bertin , e. , & arnouts , s.  1996 , , 117 , 393    bohlin , r.  c.  1996 , , 111 , 1743    bohlin , r.  c. , dickinson , m.  e. , & calzetti , d.  2001 , , 122 , 2118    capak , p. , aussel , h. , ajiki , m. , et al . 2007 , , 172 , 99    cardamone , c. , schawinski , k. , sarzi , m. , et al . 2009 , , 399 , 1191    cardamone , c.  n. , van dokkum , p.  g. , urry , c.  m. , et al . 2010 , , 189 , 270    elvis , m. , civano , f. , vignali , c. , et al . 2009 , , 184 , 158    feruglio , c. , aussel , h. , le floch , e. , et al . 2010 , , 721 , 607    fujita , s.  s. , ajiki , m. , shioya , y. , et al . 2003 , , 125 , 13    georgakakis , a. , mountrichas , g. , salvato , m. , et al . 2014 , , 443 , 3327    hasinger , g. , cappelluti , n. , brunner , h. , et al . 2007 , , 172 , 29    hayashino , t. , tamura , h. , matsuda , y. , et al . 2003 , publications of the national astronomical observatory of japan , 7 , 33    hayashino , t. , taniguchi , y. , yamada , t. , et al . 2000 , , 4008 , 397    hogg , d.  w. , cohen , j.  g. , blandford , r. , et al .  1998 , , 115 , 1418    hopkins , a.  m.  2004 , , 615 , 209    hu , e.  m. , cowie , l.  l. , barger , a.  j. , et al . 2010 , , 725 , 394    hu , e.  m. , cowie , l.  l. , capak , p. , et al . 2004 , , 127 , 563    ideue , y. , nagao , t. , taniguchi , y. , et al . 2009 , , 700 , 971    ideue , y. , taniguchi , y. , nagao , t. , et al . 2012 , , 747 , 42    iye , m. , karoji , h. , ando , h. , et al .  2004 , , 56 , 381    ilbert , o. , arnouts , s. , mccracken , h.  j. , et al . 2006 , , 457 , 841    ilbert , o. , capak , p. , salvato , m. , et al . 2009 , , 690 , 1236    kaifu , n. , usuda , t. , hayashi , s.  s. , et al . 2000 , , 52 , 1    kajisawa , m. , shioya , y. , aida , y. , et al . 2013 , , 768 , 51    kakazu , y. , cowie , l.  l. , & hu , e.  m.  2007 , , 668 , 853    kashikawa , n. , shimasaku , k. , yasuda , n. , et al . 2004 , , 56 , 1011    kobayashi , m. a. r. , murata , k. l. , koekemoer , a. m. , et al . 2015 , submitted to    kodaira , k. , taniguchi , y. , kashikawa , n. , et al . 2003 , , 55 , l17    koekemoer , a.  m. , aussel , h. , calzetti , d. , et al . 2007 , , 172 , 196    kova , k. , lilly , s.  j. , knobel , c. , et al . 2014 , , 438 , 717    mccracken , h.  j. , milvang - jensen , b. , dunlop , j. , et al . 2012 , , 544 , a156    miyazaki , s. , komiyama , y. , nakaya , h. , et al . 2012 , , 8446 ,    miyazaki , s. , komiyama , y. , sekiguchi , m. , et al . 2002 , , 54 , 833    mobasher , b. , capak , p. , scoville , n.  z. , et al . 2007 , , 172 , 117    moles , m. , bentez , n. , aguerri , j.  a.  l. , et al . 2008 , , 136 , 1325    molino , a. , bentez , n. , moles , m. , et al . 2014 , , 441 , 2891    monet , d.  g. , levine , s.  e. , canzian , b. , et al .  2003 , , 125 , 984    murata , k.  l. , kajisawa , m. , taniguchi , y. , et al . 2014 , , 786 , 15    murayama , t. , taniguchi , y. , scoville , n.  z. , et al . 2007 , , 172 , 523    nagao , t. , murayama , t. , maiolino , r. , et al . 2007 , , 468 , 877    nagao , t. , sasaki , s.  s. , maiolino , r. , et al . 2008 , , 680 , 100    radovich , m. , bonnarel , f. , mellier , y. , et al . 2001 , the new era of wide field astronomy , 232 , 297    salvato , m. , hasinger , g. , ilbert , o. , et al . 2009 , , 690 , 1250    salvato , m. , ilbert , o. , hasinger , g. , et al . 2011 , , 742 , 61    sanders , d.  b. , salvato , m. , aussel , h. , et al . 2007 , , 172 , 86    schinnerer , e. , carilli , c.  l. , scoville , n.  z. , et al . 2004 , , 128 , 1974    schinnerer , e. , smoli , v. , carilli , c.  l. , et al . 2007 , , 172 , 46    schlegel , d.  j. , finkbeiner , d.  p. , & davis , m.  1998 , , 500 , 525    scoville , n. , abraham , r.  g. , aussel , h. , et al . 2007a , , 172 , 38    scoville , n. , arnouts , s. , aussel , h. , et al . 2013 , , 206 , 3    scoville , n. , aussel , h. , brusa , m. , et al . 2007b , , 172 , 1    shimasaku , k. , ouchi , m. , furusawa , h. , et al . 2005 , , 57 , 447    shioya , y. , taniguchi , y. , ajiki , m. , et al . 2005 , , 57 , 287    shioya , y. , taniguchi , y. , sasaki , s.  s. , et al . 2008 , , 175 , 128    shioya , y. , taniguchi , y. , sasaki , s.  s. , et al . 2009 , , 696 , 546    smolv ci , v. , aravena , m. , navarrete , f. , et al . 2012 , , 548 , a4    takahashi , m.  i. , shioya , y. , taniguchi , y. , et al . 2007 , , 172 , 456    taniguchi , y.  2004 , studies of galaxies in the young universe with new generation telescope , proceedings of japan - german seminar , held in sendai , japan , july 24 - 28 , 2001 , eds . : n. arimoto and w. duschl , 2004 , p. 107 - 111 taniguchi , y. , ajiki , m. , nagao , t. , et al . 2005 , , 57 , 165    taniguchi , y. , kajisawa , m. , kobayashi , m.  a.  r. , et al . 2015 , , 809 , l7    taniguchi , y. , murayama , t. , scoville , n.  z. , et al . 2009 , , 701 , 915    taniguchi , y. , scoville , n. , murayama , t. , et al . 2007 , , 172 , 9 ( paper  i )    taniguchi , y. , shioya , y. , & trump , j.  r.  2010 , , 724 , 1480    wolf , c. , meisenheimer , k. , kleinheinrich , m. , et al . 2004 , , 421 , 913    wolf , c. , wisotzki , l. , borch , a. , et al . 2003 , , 408 , 499    yamada , s.  f. , sasaki , s.  s. , sumiya , r. , et al . 2005 , , 57 , 881    zamojski , m.  a. , schiminovich , d. , rich , r.  m. , et al .  2007 , , 172 , 468 in this section , we present optical properties of the ia filter system for suprime - cam on the subaru telescope . this filter system was developed as a private type of filters by the two authors ( th and yt ) . early short descriptions on this filter system are given in hayashino et al . ( 2000 ) and taniguchi ( 2004 ) . the ia filter system consists of 20 intermediate band filters with a spectral resolution of @xmath12326 , covering 410  nm to 1000  nm . ( table  [ iafilters ] ) . the filter response curves are shown in figure  [ filter_response_all ] . note that these response curves are those of the filters themselves ; that is , the effects of the ccd sensitivity , the atmospheric transmission , and the transmission of the telescope and the instrument are not included . [ iafilters ]    @xmath42center wavelength defined as the center of the two wavelengths at which the filter transmission becomes the half maximum . @xmath43fwhm calculated from the same filter response curve used to evaluate the center wavelength . all the ia filters were manufactured by barr associates co. ltd ( now , materion co. ltd ) . the specifications for the ia filters are summarized in table  [ specifications ] . although some of the specifications were found not to be fully satisfied , all the filters are highly useful for scientific observations ( e.g. , fujita et al . 2003 ; ajiki et al . 2004 ; shioya et al . 2005 ; yamada et al . 2005 ; nagao et al . details of measurements of the filter transmission is given in hayashino et al . the measured data are available at http://www.awa.tohoku.ac.jp/astro/filter.html . [ specifications ] in table  [ tab : standards ] , we summarize the theoretical ia - band magnitudes of the standard stars computed from the calspec spectra and the complete system response , in ab magnitudes . the uncertainty given here assumes a perfect knowledge of the system response and are based solely on the calspec statistical and systematic uncertainties .", "tags": [], "output_text_a": "The Cosmic Evolution Survey (COSMOS) is a comprehensive program conducted using the Hubble Space Telescope (HST) and the Subaru Telescope, aimed at understanding the evolution of galaxies, active galactic nuclei, and dark matter halos, along with the large-scale structures in the universe. The survey covers a 1.64 square degree area with the HST's Advanced Camera for Surveys (ACS) and a 2 square degree field with the Subaru Telescope's Suprime-Cam. The project utilizes multi-wavelength data from X-ray to radio frequencies to achieve its goals.\n\nThe Subaru COSMOS 20 project employs 20 filters, including six broad-band, twelve intermediate-band, and two narrow-band filters, to improve the accuracy of photometric redshifts and identify strong emission-line objects. The intermediate-band filters provide a spectral resolution that is between typical broad-band and narrow-band filters, allowing for low-resolution spectroscopy and the detection of strong emission-line galaxies.\n\nThe survey's data reduction process involves careful calibration and astrometric solutions to ensure high accuracy. The use of intermediate-band filters significantly enhances the precision of photometric redshifts, which is crucial for mapping large-scale structures and studying galaxy evolution. The COSMOS project is one of the largest and most detailed optical surveys, providing valuable insights into the cosmic star formation history and the chemical evolution of galaxies.\n\nThe COSMOS datasets, including images and catalogs, are publicly available through the IPAC/IRSA website, supporting further research and analysis by the scientific community. The project is supported by NASA and involves collaboration among over 70 scientists worldwide. Future work will focus on studying strong emission-line objects and exploring new populations of galaxies, contributing to a deeper understanding of the universe's evolution.", "output_text_b": "The Cosmic Evolution Survey (COSMOS) is a treasury program on the Hubble Space Telescope (HST) that was awarded 590 HST orbits in cycles 12 and 13. The survey covers a sky area of 1.64 square degrees with the Advanced Camera for Surveys (ACS) F814W filter around the central position @xmath6 and @xmath7. The HST ACS field is compared to the Subaru COSMOS 20 field, which covers the whole 2 square degree field. The HST ACS observations provide a large sample of galaxies with a spatial resolution of 0.1 arcsec covering a redshift range between @xmath11 to @xmath12. The main purpose of the COSMOS project is to understand the evolution of galaxies, active galactic nuclei (or supermassive black holes), and dark matter halos together with the evolution of large scale structures in the universe. To achieve this, multi-wavelength data from X-ray, ultraviolet, optical, infrared, and radio are required.\n\nThe Subaru COSMOS 20 project used 20 filters in the optical, covering from 400 nm to 900 nm: six broad-band, twelve intermediate-band, and two narrow-band filters. This paper focuses on the details of observations, data reductions, calibration, and quality assessment for the twelve intermediate-band filters and nb711. The intermediate-band filters are selected to have a spectral resolution of @xmath14, which is intermediate between typical broad-band filters and narrow-band filters. Imaging with multi-IA filters is equivalent to low-resolution spectroscopy with an @xmath17. The use of IA filters makes it possible to detect very strong emission-line objects, such as ultra-strong emission line galaxies and green pea objects.\n\nSurveys of such objects contribute to the understanding of chemical evolution in galaxies. In the Subaru COSMOS 20 project, the two narrow-band filters, nb711 and nb816, are used to provide samples of targeted emission-line galaxies. Imaging with such narrow-band filters provides samples of Ly\u03b1 emitters, H\u03b1 emitters, and [O II] emitters. By combining imaging surveys with multiple nb filters, the cosmic star formation history can be traced from high to low redshifts. Moreover, multi-band optical imaging improves the accuracy of photometric redshifts of galaxies and active galactic nuclei.\n\nThe accurate photometric redshifts for a large sample of galaxies allow for mapping large-scale structures at various redshifts and studying environmental effects on galaxy evolution. The cosmos field covers an area of @xmath27, centered at @xmath28 and @xmath29. The Suprime-Cam consists of ten 2k x 4k CCD chips and provides a very wide field of view, 34 x 27 arcmin (0.202 pixel@xmath33). The observations were made during a period between 2006 January and 2007 March, consisting of two open-use observing programs: s05b-013i and s06b-026. The observations were carried out under photometric conditions, except for the ia505- and ia679-bands observations on Feb. 24, 2006.\n\nThe individual CCD data were reduced using IMCAT with the same manner as the Suprime-Cam broad-band data of the COSMOS survey. The astrometric solution for each CCD chip in all frames was calculated using the COSMOS astrometric reference catalog, which was built in 2004 using the Megacam u-band data. The internal accuracy of the COSMOS astrometric reference is @xmath60 mas and @xmath61 mas, and the absolute offset to the full survey VLA astrometry is @xmath62 mas and @xmath63 mas. All the cosmos 20 images were forced to the COSMOS astrometric reference using a 35th order polynomial.\n\nThe scattered light correction for the flat was carried out, and the dome and sky flat can be affected by the scattered light at a 35% level. The correction factor for this effect was calculated in each @xmath5", "score": -0.20000000000000007, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings and Contributions**: The summary provides a general overview of the COSMOS project, mentioning its aim to understand galaxy evolution and large-scale structures. However, it lacks specific details about the findings and contributions of the paper, such as the improvements in photometric redshift accuracy and the identification of strong emission-line objects.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary mentions the project's aim to understand the evolution of galaxies, active galactic nuclei, and dark matter halos, which aligns with the research problem.\n\n4. **Methodology or Approach**: The summary briefly mentions the use of multi-wavelength data and the employment of 20 filters, including intermediate-band filters, but does not detail the specific methodologies or approaches used in the paper.\n\n5. **Significant Results or Conclusions**: The summary mentions the enhancement of photometric redshift precision and the project's contribution to understanding cosmic star formation history, but it lacks specific results or conclusions drawn by the authors.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"photometric redshifts\" and \"emission-line galaxies.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the use of multi-wavelength data and the employment of various filters but does not detail key experiments or specific data used.\n\n10. **Significance or Potential Impact**: The summary reflects the project's significance by mentioning its contribution to understanding galaxy evolution and its support for further research through publicly available datasets.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the use of the Hubble Space Telescope and Subaru COSMOS 20 project to study galaxy evolution and large-scale structures.\n2. **Conciseness**: The summary exceeds the 250-word limit, making it less concise than required.\n3. **Research Problem**: The summary mentions the research problem of understanding galaxy evolution and large-scale structures.\n4. **Methodology**: The summary describes the use of multi-wavelength data and specific filters for observations, which aligns with the methodology.\n5. **Significant Results**: The summary includes significant results, such as the improvement in photometric redshifts and the detection of emission-line objects.\n6. **Language**: The language is clear and professional, though it could be more concise.\n7. **Technical Jargon**: The summary uses technical terms like \"photometric redshifts\" and \"emission-line objects\" without sufficient explanation for a general audience.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions key data, such as the use of specific filters and the COSMOS field.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding galaxy evolution and improving photometric redshifts."], "The summary should accurately reflect the main findings and contributions of the paper.": [false, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [false, true], "It should include any significant results or conclusions drawn by the authors.": [false, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "binary bismuthide @xmath6-pdbi@xmath0 has attracted much interest recently as a promising candidate of topological superconductor ( ts)@xcite . topological superconductivity is a new state of matter possessing symmetry - protected surface states while the bulk states are fully gapped by superconducting pairing@xcite . the majorana fermions are believed to exist on the surface or vortex core in such tss , which may not only be of scientific importance , but also can lead to a wide - ranging applications in microelectronic devices and quantum computing . the centrosymmetric stoichiometric @xmath6-pdbi@xmath0 ( @xmath7@xmath8 5 k ) was claimed to be topologically nontrivial in view of the observation of the topologically - protected surface modes by spin- and angle - resolved arpes@xcite . however , no andreev bound states associated with majorana fermions are detectable through point - contact spectroscopy@xcite , in sharp contrast to the cases in cu - intercalated bi@xmath0se@xmath9@xcite and in - doped snte@xcite . on the other hand , it becomes the common wisdom that spin - orbit interaction ( soi ) in heavy elements is crucial for the topological states . it is therefore heuristic to ask what if we replace pd by heavier pt element with enhanced soi .    . ( a ) the primitive unit cell for hexagonal ptbi@xmath0 . the coordinates of pt(1 ) and pt(2 ) are ( @xmath10 and ( @xmath11 , respectively . ( b ) the structure as seen from a perspective along the @xmath1-axis . , width=340 ]    in this study , we substituted pt for pd in pdbi@xmath0 and found that this new material actually crystallizes in a distinct structure . unlike @xmath6-pdbi@xmath0 which has the tetragonal structure in an @xmath124/@xmath13 space group , ptbi@xmath0 crystallizes in space group p-3 with a hexagonal unit cell of @xmath2=@xmath3=6.553@xmath4 , @xmath1=6.165@xmath4@xcite it is also different from its homologue ptbi superconductor ( @xmath7=1 k ) with a monoclinic unit cell@xcite . the in - plane resistivity of ptbi@xmath0 shows metallic behaviors down to 2 k , the lowest temperature studied in this work . the intra - plane and inter - plane magnetization displays pronounced anisotropy , being diamagnetic with field aligned along the plane and paramagnetic when field is perpendicular to the plane . the magnetoresistance ( mr ) and hall resistivity measured on the same sample both show two types of carriers and the former one scales well to the semi - classical kohler s rule@xcite . ptbi@xmath0 single crystals were fabricated via a melt - growth method . the starting materials of high purity , bi powder(4n ) and pt powder ( 4n ) , were mixed thoroughly in the prescribed molar ratio of bi : pt = 2:1 ( 2 g in total weight ) . all these preparations were performed in a glove box filled with protective argon gas ( both h@xmath0o and o@xmath0 contents were limited below 0.1ppm ) . the mixtures were loaded and sealed in an evacuated quartz tube . this quartz tube was then heated to 700@xmath14c quickly in a sintering furnace and kept at this temperature for 48h , before being slowly cooled down to 450@xmath14c(3@xmath14c / h ) , and finally being quenched into cold water . large pieces of dark - gray plate - like ptbi@xmath0 single crystals of typical 7 - 8 mm in length were harvested . energy dispersive x - ray ( edx ) spectrometry confirms the stoichiometric ratio of the chemical composition ( 32.8 : 67.2 @xmath15 3.0% in molar percentage for pt : bi ) . the structure of crystals was characterized by powder x - ray diffraction ( xrd ) at room temperature using a rigaku diffractometer with cu @xmath16@xmath17 radiation and a graphite monochromator . lattice parameters were obtained by rietveld refinements . the magnetization was measured by vibrating sample magnetometry using a quantum design mpms-5 system . measurements of mr and hall effect were performed on the same sample by changing the field polarities . signal even in field was defined as mr and the odd component was calculated as hall resistivity . resistivity fits to @xmath18 very well below @xmath835k ( see the upper - left inset ) . ( b ) and ( c ) show the in - plane and inter - plane susceptibility under a field of 5koe , respectively.,width=347 ] the schematic view of the crystal structure of ptbi@xmath0 is shown in fig . it crystallizes in a hexagonal structure with the space group p-3 ( no.147 ) . its structure consists of alternate stacking of 2d pt layers and bismuth bilayers along the @xmath1-axis . in one primitive unit cell , there are three pt atoms , one being located at the corner of the polyhedron and the other two labelled as pt(1 ) and pt(2 ) in fig . 1 . the bi atoms are trigonally - coordinated . the xrd pattern of ptbi@xmath0 crystal is presented in fig.2 . a small trace of impurity phase , marked by the asterisks in panel ( a ) , was detectable in the powder x - ray pattern and only ( 00@xmath19 ) diffraction peaks were observed in the single - crystal x - ray , indicating good @xmath1-axis orientation of the as - grown samples . the calculated lattice parameters are @xmath2=@xmath3=6.553@xmath4 , @xmath1=6.165@xmath4 , in consistence with previous reported results@xcite .        zero - field in - plane resistivity is plotted in fig . the room temperature resistivity is about 0.12 m@xmath20 cm and it is metallic down to the lowest temperature we measured ( 2k ) . the residual resistivity ratio is approximately 50 for our samples , indicative of good sample quality . the sample is better characterized by the susceptibility measurements thereafter . remarkably , the magnetization of the sample shows large anisotropy with respect to the field orientations . as illustrated in fig . 3 , the in - plane magnetization @xmath21 is diamagnetic and varies little with @xmath5 down to 20k , below which it displays a significant upturn , whereas the inter - plane @xmath22 is paramagnetic instead and increases linearly with decreasing @xmath5 , followed by a downward trend below 20k . the origin of these intriguing magnetization behaviors is not clear . the magnetoresistive and hall response of a material can open a avenue for exploring the dispersion and dynamics of the charge carriers . first , in ptbi@xmath0 , it is noted that the absolute value of the mr , defined as @xmath23 , is rather large , reaching @xmath24400% at 2k in a magnetic field of 9 t . this large mr implies a rather large electron mean free path , hence a long relaxation time . however , this mr is damped very fast with increasing @xmath5 , as seen from the upper panels of fig . 4 . second , in single - band metals , the mr at small fields is usually quadratic and the hall resistivity varies linearly with field . however , in the two - band drude model , on the assumption of the field - independent carrier density and relaxation time , @xmath25 and @xmath26 can be written as@xcite    @xmath27    @xmath28    where @xmath29 and @xmath30 are electrical conductivity and hall coefficient for electron ( hole ) band , respectively . the mr and the hall signal for ptbi@xmath0 sample are exemplified in fig 4 at some selected temperatures . although the individual curves can be fitted with the above two - band equations reasonably well , plotted as the red solid line in each panel , we failed to model these two transport coefficients simultaneously with the same set of four parameters . these difficulties may arise from the simple assumption of the field independent charge carrier density and scattering , in analogy to the case in cuprates@xcite . nevertheless , given the quality of our fitting and the strong non - linearity of the hall resistivity , we strongly believe that the transport properties of this compound are governed by two - band charge carriers .    in standard metals , the mr @xmath31/@xmath32 at a certain temperature under a field @xmath33 has a general form known as the kohler s rule@xcite : @xmath31/@xmath32=@xmath34(@xmath35 ) . this rule can be derived from boltzmann transport theory , on the assumption of constant carrier number with @xmath5 and a single scattering rate on the fermi surface . from this rule , @xmath31/@xmath32 is literally independent of @xmath5 such that the plots of @xmath36 as a function of @xmath35 at distinct temperatures will collapse onto a single curve . interestingly , this rule , albeit its semiclassical origin , was found to be well obeyed in a large number of metals from conventional metals to some quantum matters . these involve the metals with two types of carriers@xcite , the pseudogap phase of the underdoped cuprates@xcite , quasi - one - dimensional metals@xcite as well as some topological semimetals@xcite . we examined this rule in ptbi@xmath0 ( fig . 5 ) and found that it is well obeyed in this material , over a wide field range ( up to 9 t ) and a broad @xmath5 window ( 2k-100k . above 100k , the mr tends to be negligible ) . moreover , the longitudinal mr in ptbi@xmath0 ( h @xmath37 i @xmath37 @xmath38 ) also shows two types of charge carriers and the validity of the kohler s rule ( data not shown ) . in recent work by sakano _ et al . _ , several topologically - protected surface states were observed by spin - resolved arpes in the ts candidate @xmath6-pdbi@xmath0@xcite . these non - trivial surface bands include one crossing the fermi level and the other one forming the dirac cone state 2 ev below the fermi level . it was noted that these topological surface states are _ all _ derived as a consequence of soi , although their respective microscopic details may be different . in ptbi@xmath0 , the soi ought to be stronger . owing to its good metallicity , however , the electrical transport is _ overall _ dominated by its bulk electrons and it looks more like a conventional good metal from transport perspective . in this material , the possible quantum linear mr arising from the degenerate dirac fermions in the quantum limit is not observed up to 9t@xcite . interestingly , this material was reported to superconduct below 150 mk@xcite , @xmath840 times lower than @xmath7 in pdbi@xmath0 . how the soi changes the electronic structure of ptbi@xmath0 , and induces the non - trivial surface states , if any , await more investigations , both theoretically and experimentally .    to summarize , we synthesized the single crystals of stoichiometric bismuthide ptbi@xmath0 by a solid - state reaction method . the samples were carefully characterized by combined procedures of xrd , ( magneto-)transport and susceptibility measurements . this compound shows prominent two - band transport behaviors with no clear signature from the possible surface states . however , the high - quality single crystals are now ready for prospective advanced experiments , especially for ones with more surface sensitivity . the authors would like to thank c. m. j. andrew , a. f. bangura for stimulating discussions . this work is sponsored by the national key basic research program of china ( grant no . 2014cb648400 ) , and by national natural science foundation of china ( grant no . 11474080 , u1432135 , 11611140101 ) . x.x . would also like to acknowledge the financial support from the distinguished young scientist funds of zhejiang province ( lr14a040001 ) and an open program from wuhan national high magnetic field center ( 2015kf15 ) . y. imai , f. nabeshima , t. yoshinaka , k. miyatani , r. kondo , s. komiya , i. tsukada , and a. maeda , j. phys . . jpn . * 81 * , 113708 ( 2012 ) . k. zhao , b. lv , y. xue , x. zhu , l. deng , z. wu , c. w. chu , phys . b * 92 * , 174404 ( 2015 ) . e. herrera , _ et al . b * 92 * , 054507 ( 2015 ) . m. sakano , k. okawa , m. kanou , h. sanjo , t. okuda , t. sasagawa , k. ishizaka , nat . comm . * 6 * , 8595 ( 2015 ) . j. kamark , _ et al . b * 93 * , 144502 ( 2016 ) . che , t. le , xiaofeng xu , xin lu , to appear in phys . hasan , c.l . kane , rev . phys . * 82 * , 3045 ( 2010 ) . hor , a.j . williams , j.g . checkelsky , p. roushan , j. seo , q. xu , h.w . zandbergen , a. yazdani , n.p . ong , and r.j . cava , phys . lett . * 104 * , 057001 ( 2010 ) . liang fu , c. l. kane , phys . b. * 76 * , 045302 ( 2007 ) . liang fu , c. l. kane , e. j. mele , phys . lett . * 98 * , 106803 ( 2007 ) . m. kriener , k. segawa , z. ren , s. sasaki , and y. ando , phys . * 106 * , 127004 ( 2011 ) . s. sasaki , m. kriener , k. segawa , k. yada , y. tanaka , m. sato , and y. ando , phys . 107 * , 217001 ( 2011 ) . m. novak , s. sasaki , m. kriener , k. segawa , and y. ando , phys . b * 88 * , 140502 ( 2013 ) . e. m. savitskii , v. v. baron , yu . v. efimov , m. i. bychkova , l. f. myzenkova , _ superconducting materials _ ( springer 1973 ) . matthias , phys . rev . * 92 * , 874 ( 1953 ) . m. kohler , ann . phys . * 32 * , 211 ( 1938 ) . n. luo , and g. h. miley physica c * 371 * , 259 ( 2002 ) . p. li , f. f. balakirev , and r. l. greene , phys . 99 * , 047003 ( 2007 ) . f. rullier - albenque , d. colson , a. forget , h. alloul , phys . * 103 * , 057001 ( 2009 ) . p. m. c. rourke , a. f. bangura , c. proust , j. levallois , n. doiron - leyraud , d. leboeuf , l. taillefer , s. adachi , m. l. sutherland , and n. e. hussey phys . b * 82 * , 020514(r ) ( 2010 ) . f. rullier - albenque , d. colson , a. forget , h. alloul , phys . rev 109 * , 187005 ( 2012 ) . chan , m.j . veit , c.j . dorow , y. ge , y. li , w. tabis , y. tang , x. zhao , n. barii and m. greven , phys . 113 * , 177005 ( 2014 ) . a. narduzzo , a. enayati - rad , s. horii , n.e . hussey phys . * 98 * , 146601 ( 2007 ) . x. xu , _ et al . _ , j. phys . : condens . matter * 27 * , 335701 ( 2015 ) . a. narayanan , m.d . watson , s.f . blake , n. bruyant , l. drigo , y.l . chen , d. prabhakaran , b. yan , c. felser , t. kong , p.c . canfield , a.i . coldea , phys . * 114 * , 117201 ( 2015 ) . abrikosov phys . b * 58 * , 2788 ( 1998 ) d.x . hor , j. xiong , r.j . cava , n.p . ong , science * 329 * , 821 ( 2010 ) . alkseevskii , yu . p. gaidkov , eksp . fiz * 25 * , 383 ( 1953 ) .", "tags": [], "output_text_a": "The paper investigates the properties of a new material, PtBi2, which is a potential candidate for topological superconductivity. Topological superconductors are materials that have symmetry-protected surface states while their bulk states are fully gapped by superconducting pairing, potentially hosting Majorana fermions on their surfaces or vortex cores. The study explores the substitution of Pt for Pd in PdBi2, resulting in a material with a distinct hexagonal structure and enhanced spin-orbit interaction due to the heavier Pt element. The PtBi2 crystals were synthesized using a melt-growth method and characterized through various techniques, including X-ray diffraction and magneto-transport measurements.\n\nThe study finds that PtBi2 exhibits metallic behavior down to 2 K, with significant anisotropy in magnetization and large magnetoresistance, indicating two types of charge carriers. The material follows Kohler's rule, suggesting a semiclassical transport behavior despite its potential topological nature. However, no clear signatures of topological surface states were observed in the transport measurements. The paper suggests that further investigations are needed to understand the electronic structure and potential non-trivial surface states in PtBi2, which could be influenced by its strong spin-orbit interaction. The research is supported by various Chinese research programs and acknowledges contributions from several scientists.", "output_text_b": "This article discusses the synthesis and characterization of single crystals of stoichiometric bismuthide PtBi2 by a solid-state reaction method. The samples were characterized using X-ray diffraction (XRD), transport, and susceptibility measurements. The compound exhibits prominent two-band transport behaviors with no clear signature from possible surface states. However, high-quality single crystals are now available for prospective advanced experiments, especially those with more surface sensitivity.\n\nThe article also explores the Kohler's rule in PtBi2, which is a semiclassical rule relating the magnetoresistance (MR) to the magnetic field at distinct temperatures. The rule is found to be well obeyed in PtBi2, suggesting that the material follows the standard behavior of metals.\n\nLastly, the article highlights the potential impact of spin-orbit interaction (SOI) on the electronic structure of PtBi2 and its possible non-trivial surface states, which require further theoretical and experimental investigations.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, discussing the properties of PtBi2 and its potential as a topological superconductor.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem or Question**: The summary highlights the research problem of investigating PtBi2 as a candidate for topological superconductivity.\n4. **Methodology or Approach**: The summary mentions the methodology, including the substitution of Pt for Pd and the use of a melt-growth method for synthesis.\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the metallic behavior, anisotropy in magnetization, and large magnetoresistance of PtBi2.\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"topological superconductors\" and \"Majorana fermions.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments or Data**: The summary mentions key experiments, such as X-ray diffraction and magneto-transport measurements.\n10. **Significance or Potential Impact**: The summary reflects the paper's significance by discussing the potential impact of PtBi2 in the field of topological superconductivity.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the synthesis and characterization of PtBi2, the exploration of Kohler's rule, and the potential impact of SOI, which are the main findings of the paper.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly state the research problem or question, which is the investigation of topological superconductivity in PtBi2.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of XRD, transport, and susceptibility measurements.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results such as the two-band transport behavior and the adherence to Kohler's rule.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like Kohler's rule.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions key experiments such as XRD and transport measurements.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary mentions the potential impact of SOI on electronic structure, indicating the paper's significance."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the factorization approach ( fa ) based on the non - relativistic qcd ( nrqcd ) represents a reliable framework to study heavy quarkonium production and decay processes @xcite . according to the fa the inclusive production cross section for a quarkonium state @xmath6 in the process @xmath7 can be factorized as @xmath8 where the short - distance coefficients , @xmath9 , are associated with the production of a heavy quark pair in the color and angular momentum state @xmath10 $ ] . this part of the cross section involves only momenta at least of the order of the heavy quark mass , @xmath11 , and can be calculated perturbatively . two distinct scales are introduced : the heavy quark - antiquark pair production process occurs at small distances , @xmath12 , and is factorized from the hadronization phase which takes place at large distances , @xmath13 . here @xmath14 is the average velocity of heavy constituents in the quarkonium , with @xmath15 for charmonium and @xmath16 for bottomonium systems . the vacuum matrix elements of nrqcd operators , @xmath17 , describe the evolution of the quark - antiquark state @xmath10 $ ] into the final hadronic state @xmath6 @xcite . these long distance matrix elements can not be calculated perturbatively , but their relative importance in powers of velocity @xmath14 can be estimated using the nrqcd velocity scaling rules @xcite . the important feature of this formalism is that the cross section of heavy quarkonium production can be organized as double expansion in powers of @xmath14 and @xmath18 . in higher order of @xmath14 the fa implies that the quark - antiquark color octet intermediate states are allowed to contribute to heavy quarkonium production and decay processes .    unlike the color singlet long distance matrix elements , each connected with the subsequent non - relativistic wave function at the origin , the color octet long distance matrix elements are unknown and have to be extracted from the experimental data . the nrqcd factorization approach implies universality , i.e. the values of long distance matrix elements extracted from different experimental data sets must be the same . however , due to the presently rather large theoretical uncertainties @xcite and the unknown size of higher twist process contributions @xcite the existing experimental data do not allow yet to check the fa universality . the data on direct @xmath19 and @xmath20 production at large transverse momenta at the tevatron indicates that the color octet contribution is dominating . the @xmath21 state charmonia are produced through the gluon fragmentation into the @xmath22 octet state @xcite . recent investigations have shown that the contribution of color octet states to the charmonium and bottomonium production cross sections is very important at fixed target energies , @xmath23 gev , and reduces existing discrepancies between experimental data and predictions of the color singlet model ( csm ) @xcite . however , some experimental data contradict the color octet model ( com ) predictions . in particular , theoretical predictions disagree with measurements of the polarization of @xmath19 and @xmath20 particles produced at fixed target energies @xcite and the com predicts a too low relative yield of the @xmath24 state compared to the @xmath25 @xcite . one possible solution of these discrepancies was proposed by brodsky et al . @xcite suggesting that higher twist processes , when more than one parton from projectile or target participates in the reaction , might give a significant contribution to low @xmath26 production of @xmath19 and @xmath24 states . problems exist also in charmonium photoproduction at hera . the color octet contribution underestimates the inelastic @xmath19 photoproduction cross section at large values of @xmath27 ( @xmath28 in the laboratory frame ) @xcite . spin effects in heavy quarkonia production are expected to provide tests for the different mechanisms of heavy quarkonium production @xcite . predictions for the polarization of direct @xmath29 s produced at large @xmath26 at the tevatron are free from theoretical uncertainties connected with higher twist effects and corresponding measurements will provide an excellent possibility to test the nrqcd factorization approach . the observation of opposite sign double spin asymmetries in the production of different charmonium states can also be used to discriminate the nrqcd fa from the color evaporation model ( cem ) which predicts the same spin asymmetries for all charmonium states @xcite . the cem also assumes a factorization between the production of a heavy quark pair and its hadronization phase . but unlike the nrqcd factorization approach the cem postulates that multiple soft gluon exchange in the hadronization phase destroys the initial polarization of the heavy quark pair and the heavy quarkonium is produced unpolarized @xcite .    at the same time it is not excluded that the mass of the charm quark is not large enough to apply the nrqcd factorization approach to charmonium production and decay processes . due to the rather large value of @xmath30 , about @xmath31 for the charmonium system , the fock states at higher order of @xmath30 may give the essential contribution and can then not be neglected . when fitting the values of the long distance parameters the heavy quark spin symmetries are used to reduce the number of independent parameters . these relations are valid up to @xmath30 and may get large corrections for charmonium production . in contrast , the nrqcd fa predictions for the bottomonium system are more reliable , since the expansion parameter @xmath30 is much smaller ( around @xmath32 ) , than for the charmonium system . higher twist processes are also expected to be suppressed as @xmath33 ( compare with @xmath34 ) . also the qcd coupling constant is smaller for bottomonium system . therefore , the characteristics of @xmath0 meson production are more appropriate for a correct test of the nrqcd factorization approach . in this article we consider the polarization of @xmath0 mesons produced at fixed target energies . it will be shown that in the nrqcd factorization approach @xmath0 mesons are produced transversely polarized , whereas the cem predicts unpolarized bottomonium production . we present also numerical estimates of the projected statistical errors for the measurement of @xmath0 polarization at the hera-@xmath2 experiment at desy .    in the next section the bottomonium production in the various subprocesses is discussed . in section 3 the @xmath0 polarization is calculated and numerical estimates for the expected @xmath0 signal to background ratio as well as for the errors of the polarization measurement are considered in the section 4 . in leading order in @xmath35 the different @xmath21- and @xmath36-wave quark - antiquark states can be produced in the following @xmath37 and @xmath38 subprocesses :    @xmath39 gluon - gluon fusion @xmath40 @xmath39 gluon - quark scattering @xmath41    @xmath39 quark - antiquark annihilation @xmath42 where the superscripts ( 1,8 ) denote the color singlet and color octet states , respectively . the total cross section of @xmath0 production is given by the sum of direct production cross section and the cross section of @xmath43 states decaying through @xmath0 mesons : @xmath44 the production of each quarkonium state receives contributions from both color octet and color singlet states . the relative velocity for the bottomonium system is small , @xmath16 , and hence the production cross sections can be calculated with only the leading order color octet contribution taken into account .    in table i the color singlet and color octet long distance matrix elements for the production of @xmath43 states are presented . the values of matrix elements are taken from @xcite . the color singlet matrix elements are computed from the wave functions of the buchmller - tye potential tabulated in @xcite . the matrix elements @xmath45 are fitted from the tevatron data @xcite . for the @xmath46 bottomonium state the value of this matrix element is obtained by extrapolation from @xmath47 and @xmath48 states @xcite .    [ cols=\"^,^,^,^\",options=\"header \" , ]     * table iii . * parameter @xmath49 obtained from the fit for different mc input values . we note that the expected statistical error on @xmath49 is largely dominated by the @xmath0 statistics rather than by the value of the background polarization and the signal to background ratio . figure 3 illustrates the statistical error @xmath50 as a function of the number of reconstructed @xmath0 events    l7.5 cm    for various @xmath49 s . as can be seen , an accuracy on the polarization parameter @xmath51 for @xmath52 can be achieved for one year of the hera-@xmath2 running . the expected error will allow to distinguish between @xmath53 ( cem ) and @xmath54 ( nrqcd fa ) with a @xmath55 significance . the polarization of @xmath0 mesons is calculated at fixed target energies ( @xmath56 gev ) . it is shown that in the nrqcd factorization approach @xmath0 mesons are expected to be produced transversely polarized ; the parameter @xmath49 for the polar angle distribution of quarkonium decay products is about @xmath57 . in contrast , the color evaporation model postulates that multiple soft gluon exchange in the hadronization phase destroys the initial polarization of the heavy quark pair and quarkonium is produced unpolarized . higher twist effects are expected to be small due to the large mass of the @xmath58-quark . the contribution of higher fock states in bottomonium production are more suppressed than in the charmonium case , the relative velocity for the bottomonium family is about @xmath16 . thus the measurement of the @xmath0 polarization provides an excellent opportunity to test different mechanisms of heavy quarkonium production . in particular , it allows to distinguish between the nrqcd fa @xcite and the cem @xcite . on the other side , the observation of an extremely large polarization will indicate that @xmath0 mesons are mainly produced through color singlet states and that the color octet parameters for @xmath43 production extracted from the tevatron data should be much smaller than known at present . the monte carlo simulation shows that the projected statistical error for the measurement of the polarization parameter @xmath49 is about @xmath59 for @xmath60 in one year running of the hera-@xmath2 experiment . the simulation is done only for the @xmath61 decay channel . a statistics gain of almost a factor 2 is expected from the @xmath62 channel . the simulation conservatively assume the lowest value for the @xmath0 production cross section measured in different experiments @xcite at @xmath63 gev which corresponds to a hera proton beam momentum of @xmath64 gev / c ( the current value for hera is 920 gev / c ) .      we are grateful to s.  brodsky , r.  mankel and m.  vnttinen for useful comments and discussions . we thank w .- d . nowak for helpful comments and careful reading of this manuscript . acknowledges the support by the alexander von humboldt foundation . is grateful to the dfg financial support ( iii gk - grk 271/1 ) . * * g.t . bodwin , e.  braaten , and g.p . lepage , phys .  rev . * d51 * ( 1995 ) 1125 . lepage , l.  magnea , c.  nakhleh , u.  magnea , and k.  hornbostel , phys .  rev . * d46 * ( 1992 ) 4052 . m.  mangano and a.  petrelli , int . j.  mod . * a12 * ( 1997 ) 3887 , + m.  beneke , in proceedings of the second workshop on continuous advances in qcd , minneapolis , m.  polikarpov ( ed . ) , world scientific , singapure , 1996 , p. 12 . + p.  ernstrm , l.  lnnblad , and m.  vnttinen , z.  phys . * c76 * ( 1997 ) 515 . + m.  beneke , i.z . rothshtein , and mark b.  wise , phys .  lett . * b408 * ( 1997 ) 373 . m.  beneke and m.  krmer , phys .  rev . * d55 * ( 1997 ) 5269 . m.  vnttinen , p.  hoyer , s.j . brodsky , and w .- k . tang , phys .  rev . * d51 * ( 1995 ) 3332 . e.  braaten and s.  fleming , phys . * 74 * ( 1995 ) 3327 . p.  cho and a.k . leibovich , phys.rev . * d53 * ( 1996 ) 150 , + p.  cho and a.k . leibovich , phys.rev . * d53 * ( 1996 ) 6203 . s.  gupta and k.  sridhar , tifr / th/96 - 04 , hep - ph/9601349 . + w .- k . tang and m.  vnttinen , phys .  rev . * d54 * ( 1996 ) 4349 . + l.  slepchenko and a.  tkabladze , in proceedings of 3rd german - russian workshop on progress in heavy quark physics , dubna , 20 - 22 may 1996 , hep - ph/9608296 ( 1996 ) . m.  beneke and i.z . rothstein , phys . * d54 * ( 1996 ) 2005 , + m.  beneke , cern - th/97 - 55 , hep - ph/9703429 . m.  cacciari and m.  krmer , phys.rev.lett . * 76 * ( 1996 ) 4128 . o.  teryaev and a.  tkabladze , phys . rev * 56 * ( 1997 ) 7331 . nowak and a tkabladze , desy 98 - 139 , hep - ph/9809413 ( 1998 ) . h.  fritzsch , phys .  lett . * b67 * ( 1977 ) 217 , + f.  halzen , phys .  lett . * b69 * ( 1977 ) 105 . eichten and c.  quigg , phys .  rev . * d52 * ( 1995 ) 1726 . m.  glck , e.  reya , and a.  vogt , z.phys . * c67 * ( 1995 ) 433 . alde _ et al . _ , phys . rev .  lett . * 66 * ( 1991 ) 2285 . t.  yoshida _ et al . _ , phys .  rev . * d39 * ( 1989 ) 3516 , + g.  moreno _ et al . _ , phys .  rev . * d43 * ( 1991 ) 2815 . t.  alexopoulos _ et al . _ , phys .  lett . * b374 * ( 1996 ) 271 . m.  beneke and i.z . rothstein , phys . b372 * ( 1996 ) 157 . tang and m.  vnttinen , phys .  rev . * d54 * ( 1996 ) 4349 . e.  braaten and y .- q . chen , phys . * d54 * ( 1996 ) 3216 . t.  lohse _ et al . _ , an experiment to study cp violation in the b system using an internal target at the hera proton ring ( proposal ) , desy - prc 94/02 ( 1994 ) . s.  nowak , _ hbgean and hbrcan _ , hera-@xmath2 internal note ( 1995 ) . t.  sjstrand , computer physics commun . * 82 * ( 1994 ) 74 .", "tags": [], "output_text_a": "The paper discusses the factorization approach (FA) based on non-relativistic QCD (NRQCD) as a framework for studying heavy quarkonium production and decay. The FA allows the inclusive production cross section for a quarkonium state to be factorized into short-distance coefficients and long-distance matrix elements. The short-distance coefficients are perturbatively calculable, while the long-distance matrix elements, which describe the hadronization phase, are not. The FA organizes the cross section as a double expansion in powers of the heavy quark velocity and the strong coupling constant. The paper highlights the importance of color octet contributions in quarkonium production, which are extracted from experimental data due to their unknown nature.\n\nThe paper also addresses discrepancies between theoretical predictions and experimental data, particularly in charmonium and bottomonium production. It suggests that higher twist processes and the mass of the charm quark might affect the applicability of NRQCD to charmonium. The paper emphasizes the reliability of NRQCD predictions for bottomonium due to smaller expansion parameters and suppressed higher twist processes.\n\nThe study focuses on the polarization of bottomonium mesons produced at fixed target energies, predicting transverse polarization in the NRQCD approach, contrasting with the unpolarized production predicted by the color evaporation model (CEM). The paper presents numerical estimates for the measurement of bottomonium polarization at the HERA-B experiment, suggesting that this measurement could test different quarkonium production mechanisms and distinguish between NRQCD and CEM. The authors acknowledge the support and contributions from various collaborators and funding bodies.", "output_text_b": "The factorization approach (FA) in Non-Relativistic Quantum Chromodynamics (NRQCD) is a reliable framework to study heavy quarkonium production and decay processes. The FA factorizes the inclusive production cross section for a quarkonium state into short-distance coefficients and long-distance matrix elements. Short-distance coefficients are associated with the production of a heavy quark pair and can be calculated perturbatively, while long-distance matrix elements, which describe the evolution of the quark-antiquark state into the final hadronic state, cannot be calculated perturbatively. The FA implies that the cross section of heavy quarkonium production can be organized as a double expansion in powers of the average velocity of heavy constituents in the quarkonium and the strong coupling constant. In higher orders of the velocity, the FA allows for color octet intermediate states to contribute to heavy quarkonium production and decay processes. The color octet long distance matrix elements are unknown and have to be extracted from experimental data. The FA implies universality, i.e. the values of long distance matrix elements extracted from different experimental data sets must be the same. However, due to the presently large theoretical uncertainties and the unknown size of higher twist process contributions, the existing experimental data do not allow yet to check the FA universality.\n\nThe data on direct and inclusive production at large transverse momenta at the Tevatron indicates that the color octet contribution is dominating. Recent investigations have shown that the contribution of color octet states to the charmonium and bottomonium production cross sections is very important at fixed target energies and reduces existing discrepancies between experimental data and predictions of the color singlet model. However, some experimental data contradict the color octet model predictions. In particular, theoretical predictions disagree with measurements of the polarization of particles produced at fixed target energies and the color octet model predicts a too low relative yield of certain charmonium states compared to others. One possible solution of these discrepancies is the contribution of higher twist processes, which give a significant contribution to low production of certain charmonium and bottomonium states.\n\nThe NRQCD factorization approach implies universality, i.e. the values of long distance matrix elements extracted from different experimental data sets must be the same. However, due to the presently rather large theoretical uncertainties and the unknown size of higher twist process contributions, the existing experimental data do not allow yet to check the FA universality. The data on direct and inclusive production at large transverse momenta at the Tevatron indicates that the color octet contribution is dominating. Recent investigations have shown that the contribution of color octet states to the charmonium and bottomonium production cross sections is very important at fixed target energies and reduces existing discrepancies between experimental data and predictions of the color singlet model. However, some experimental data contradict the color octet model predictions. In particular, theoretical predictions disagree with measurements of the polarization of particles produced at fixed target energies and the color octet model predicts a too low relative yield of certain charmonium states compared to others. One possible solution of these discrepancies is the contribution of higher twist processes, which give a significant contribution to low production of certain charmonium and bottomonium states.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the factorization approach (FA) and its application to heavy quarkonium production and decay.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the study of heavy quarkonium production and decay using the FA, is highlighted.\n4. The methodology, which involves the FA based on NRQCD, is mentioned.\n5. Significant results, such as the importance of color octet contributions and the prediction of transverse polarization in bottomonium mesons, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"factorization approach\" and \"color octet\" are explained.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The potential impact of the paper, such as testing different quarkonium production mechanisms, is mentioned.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the factorization approach (FA) in NRQCD and its implications for heavy quarkonium production and decay processes.\n2. The summary is concise but exceeds the ideal word limit of 250 words.\n3. It highlights the research problem of understanding heavy quarkonium production and decay processes.\n4. The methodology, which is the factorization approach in NRQCD, is mentioned.\n5. Significant results, such as the importance of color octet contributions and discrepancies with experimental data, are included.\n6. The language is clear and professional.\n7. The summary uses technical terms like \"color octet\" and \"factorization approach\" but does not explain them, which might be necessary for clarity.\n8. The structure is logical, with a clear beginning, middle, and end.\n9. Key experiments or data, such as those from the Tevatron, are mentioned.\n10. The summary reflects the paper's significance in understanding quarkonium production mechanisms."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "there is a long tradition in statistics in predicting many aspects of athletic events , in particular which teams will win , which players are the best , and the propensity of players to become injured . the tradition began in baseball , and was glorified in _ @xcite , but it has now extended to almost all other major sports . with the growing popularity of sports gambling and `` fantasy '' sites , there is more demand than ever for statistical information about which players will succeed and which teams will win .    this paper uses a simple , weighted , and penalized regression model ( see @xcite ) to predict the outcome of mlb , nba , nfl , and nhl games , using data going back more than thirty years scraped from the websites @xcite , @xcite , @xcite , and @xcite . it is similar to the model in @xcite , except it measures the ability of teams over games instead of players over possessions , and it does not take into account which team is at home . we intentionally limit our data use to the date , home and visiting teams , and score of each game , and we compare our predictions to a theoretically near - optimal indicator . doing so tells us what statistical information is contained just in the scores , and whether what are commonly referred to as `` statistics '' have real predictive power . in basketball , the statistics are largely made unnecessary by the record of game scores , whereas in football this is clearly not the case . baseball and hockey lie somewhere in the middle . this is likely because basketball has long seasons and high - scoring games , whereas baseball and hockey have long seasons but low - scoring games . football has short seasons and is effectively `` low - scoring , '' because what matters is the number of scores that take place , not the scores point values . the models are trained on even - numbered years and tested on odd - numbered years . the theoretically near - optimal indicator works as follows : since our data is historical , we can predict every game by looking at the eventual end - of - season rankings and always bet that the eventually higher - ranked team will win . this estimator does not adjust for schedule difficulty , but is nonetheless very hard to beat . we demonstrate the performance of our penalized regression compared to this estimator . furthermore , we show how it can be computed quickly using the woodbury matrix identity . we additionally prove that our model beats a `` straw man . '' to compute the straw man prediction of a game , look at the previous season s ranking and predict that the higher ranking team will win . our model almost always beats the straw man . earnshaw cook published the first major work on sabermetrics ( baseball statistics ) in 1964 , @xcite . @xcite uses a bayesian hierarchical model to predict major league baseball games , and @xcite does so using ensemble learning . @xcite and @xcite predict baseball games using a number of statistics . @xcite uses a @xmath0-nearest - neighbor algorithm to predict korean baseball games . @xcite models individual baseball games as markov processes and studies many aspects of the game , including batting order , but does not post predictions . @xcite studies winning and losing streaks in baseball . @xcite and @xcite use bayesian hierarchical models to study hitting performance in baseball . @xcite believes the most important trait in a baseball player is his propensity to get on base .    the first model for predicting the outcome of professional basketball games appeared in @xcite . @xcite and @xcite use player position data to predict how likely an nba team is to score on a given possession . @xcite uses many other statistics as well , and achieves better results than we do in basketball prediction , but over a shorter time period using many more statistics . @xcite does about as well as we do at nba prediction but also over a very short time span and using many statistics . @xcite and @xcite use a simple models to predict nba games , @xcite uses a kalman filter , and @xcite uses a naive bayes predictor . @xcite surveys many nba prediction methods . @xcite predicts the betting line in nba games . @xcite predicts the likelihood of making a three - pointer using a logistic regression . @xcite and @xcite study the `` hot hand '' effect , in which they do not believe . @xcite studies how to win the playoffs . @xcite uses several machine learning methods , decision trees , rule learners , neural networks , naive bayes , and random forests , and many statistics to predict ncaa basketball games . @xcite , @xcite , @xcite , @xcite , and @xcite use different methods to predict the ncaa men s basketball . in fact , the _ journal of quantitative analysis in sports _ ran an entire issue on ncaa prediction in 2015 @xcite . @xcite uses a probit regression to predict football games , and @xcite uses a neural network to predict football games . @xcite uses a bayesian hierarchical model to predict football games . @xcite uses numerous methods to predict nfl games . @xcite predicts college football games . @xcite uses neural networks to predict both professional and college football games . @xcite uses a stochastic process model to rate high school and college football teams . @xcite explains the extent to which casino betting lines predict nfl games , which raises interesting questions about the power of democracy in prediction . @xcite predicts the betting lines . @xcite predicts nfl games using twitter , another democratic approach . @xcite studies the nfl draft . there is also some past work done on nhl hockey , including one paper on game prediction @xcite using neural networks , and one paper on scoring rates @xcite . there are other papers using various factors to predict hockey games @xcite , @xcite . @xcite and @xcite survey a group of machine learning methods used in sports prediction in general . there is also a wealth of research on the statistics of soccer games . for @xmath1 denoting the year , let @xmath2 be a vector such that @xmath3 are the visiting and home scores , respectively , in the @xmath4-th game of the year @xmath1 season . let @xmath5 be twice the number of games in year @xmath1 and let @xmath6 be the total number of teams that have played in either the mlb , nba , nfl , or nhl since the @xmath7 season . let @xmath8 be a @xmath9 matrix that is all zeros except that if teams @xmath10 and @xmath0 are the visitors and home teams in game @xmath4 of the year @xmath1 season , @xmath11 . setting up the @xmath8 matrices in this way allows the model to take home - field advantage into account . let @xmath12 be the number of seasons considered other than the current season used to predict the current season , it is sport - dependent . in baseball , football , and hockey @xmath13 , and in basketball @xmath14 . let @xmath15 be a diagonal matrix such that @xmath16 where the @xmath17 are tuning parameters picked by maximizing the predictivity of the upcoming model on even - numbered years . we pick the logistic curve because if its versatility ; it can model a line , a concave - up curve , a concave - down curve , and a step function . for matrices @xmath18 , let their vertical concatenation be @xmath19,\\ ] ] with @xmath20 on top . we will now explain how to predict whether @xmath21 is positive or negative using only historical data ( if it is zero we say that we predicted it correctly one half of one time ) . we use a weighted regularized linear least squares regression , information about them can be found in @xcite . let @xmath22,\\ ] ] @xmath23,\\ ] ] and let @xmath24 . let @xmath25 @xmath26 typically there is a positive @xmath27 parameter in front of the @xmath28 , we omit it for it is absorbed by the @xmath15 . typically also @xmath29 and @xmath30 would be centered . empirically this appears unnecessary for our problem . it is not necessary to invert the whole matrix , gaussian elimination may be used ( backslash in matlab ) . to do prediction , set @xmath31 the sign of @xmath32 predicts the sign of @xmath21 , in other words , which team will win . remember , the teams playing are contained in rows @xmath33 of @xmath29 . the entries in the @xmath15 are picked so that the sum of the model s correct predictions is as high as possible on even years .    this process can be accelerated . first compute @xmath34 @xmath35 hypothesize that we know @xmath36 and @xmath37 , we will find them for @xmath38 . let @xmath39 , @xmath40 and @xmath41 . by the woodbury matrix identity , the following table shows the results of the model on all four sports , on the even years on which it was trained , on the odd years , and on all years . the form of the results is the probability of correctly predicting the winner of a game . the `` model '' column denotes the performance of our model , whereas the `` oracle '' column denotes the performance of the theoretically hard - to - beat model described in the introduction which uses information from the future to predict the past . the `` straw man '' was described in the introduction . the first four figures show the performance of our model ( in blue ) vs. the oracle ( in red ) and the straw man ( in green ) in every year from 1986 - 2015 . the performance is measured by the ratio of games predicted correctly . the figures are in the order mlb , nba , nfl , nhl . they show that the model performs well in basketball , which has long seasons and high - scoring games . it performs passably in baseball and hockey and poorly in football . these results indicate that most basketball statistics are subsumed by the game scores . this is somewhat the case in baseball and hockey and not the case in football . the hockey graph `` jumps '' during the strike in the 2005 season . the second four figures show the percentage of times that each team won in the 2015 season in red and the percentage of times they were predicted to win in blue . the x - axis is the end - of - season ranking of the team where @xmath44 ( leftmost ) is the best . the figures are in the order mlb , nba , nfl , nhl . andrew d. blaikie , gabriel j. abud , john a. david , r. drew pasteur , `` nfl & ncaa football prediction using artificial neural networks , '' _ proceedings of the 2011 midstates conference on undergraduate research in computer science and mathematics_.                        torin k. clark , aaron w. johnson , alexander j. stimpson , `` going for three : predicting the likelihood of field goal success with logistic regression , '' march 1 - 2 , 2013 , 7-th annual mit sloan sports analytics conference . wu - in jang , aziz nasridinov , young - ho park , `` analyzing and predicting patterns in baseball data using machine learning techniques , '' _ advanced science and technology letters _ , 62 ( sensor 2014 ) , pp . 37 - 40 . dennis moy , `` regression planes to improve the pythagorean percentage : a regression model using common baseball statistics to project offensive and defensive efficiency , '' undergraduate thesis , u.c . berkeley . joshua weissbock , diana inkpen , `` combining textual pre - game reports and statistical data for predicting success in the national hockey league , '' _ advances in artificial intelligence _ , volume 8436 of the series _ lecture notes in computer science _ pp . 251 - 262 , 2014 . brady t. west , madhur lamsal , `` a new application of linear modeling in the prediction of college football bowl outcomes and the development of team ratings , '' _ j. quant . sports _ , volume 4 , issue 3 , 2008 , article 3 .", "tags": [], "output_text_a": "This paper explores the use of a simple, weighted, and penalized regression model to predict the outcomes of MLB, NBA, NFL, and NHL games using historical data spanning over thirty years. The model focuses on game scores rather than player statistics and does not consider home-field advantage. The study compares the model's predictions to a theoretically near-optimal indicator, which predicts outcomes based on end-of-season rankings, and a \"straw man\" model that uses previous season rankings. The results show that the model performs well in predicting basketball outcomes, moderately well in baseball and hockey, and poorly in football. This suggests that basketball game scores contain most of the predictive information, while football requires more detailed statistics. The paper also discusses the computational efficiency of the model using the Woodbury matrix identity and highlights the model's ability to outperform the straw man approach. The findings contribute to the growing demand for statistical insights in sports gambling and fantasy sports.", "output_text_b": "This paper presents a weighted, penalized regression model to predict the outcome of MLB, NBA, NFL, and NHL games using historical data from the past thirty years. The model is compared to a theoretically near-optimal indicator and a \"straw man\" prediction method. The study finds that basketball statistics are largely made unnecessary by game scores, while football, baseball, and hockey performances can be better predicted with the proposed model. The model outperforms the \"straw man\" method and is shown to be effective in predicting the outcomes of games in these sports.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the use of a regression model to predict sports outcomes and the comparison with other models.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of predicting sports outcomes using historical data.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of a weighted, penalized regression model.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the model's performance in different sports.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids unnecessary technical jargon and explains terms like \"straw man.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of historical data spanning over thirty years.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in sports gambling and fantasy sports.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the use of a weighted, penalized regression model and its comparison to other prediction methods.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and well within the 250-word limit.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the research problem of predicting the outcomes of sports games.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary describes the use of a weighted, penalized regression model.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the model's effectiveness in predicting game outcomes and its performance compared to other methods.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids unnecessary technical jargon and explains terms like \"straw man.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is logically structured with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of historical data from the past thirty years.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by highlighting the model's effectiveness and potential impact on sports prediction."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the origins of the light elements li , be , and b ( libeb ) differ from that of the other nuclides . most elements are formed in stars , but libeb are rapidly consumed by radiative capture reactions in stellar centers and must therefore be synthesized in cooler or more tenuous environments . it had been generally accepted @xcite that @xmath0li , @xmath4be , @xmath5b , and some @xmath6b were made in the galactic cosmic rays ( gcr ) by the interaction of fast gcr protons and @xmath7 particles with interstellar targets of carbon , nitrogen , oxygen ( cno ) or he ( and vice - versa ) ; @xmath8h , @xmath9he , and the primeval abundance of @xmath1li were made in the big bang . recent measurements of abundances in metal - poor stars formed early in the life of the galaxy challenge the details of the gcr picture . the abundance of @xmath4be rises linearly with the iron abundance@xcite . it has been argued ( see @xcite and references therein ) that this means that heavy cosmic rays ( cno ) incident on interstellar hydrogen and helium are responsible for the synthesis of libeb . others@xcite argue that the original process remains viable . in any case the @xmath2 reaction plays a major role in production of @xmath10li , particularly if light cosmic rays are responsible for their synthesis@xcite , since the interstellar medium contains little cno in the early galaxy . recent models @xcite show that @xmath0li is marginally produced in the observed quantity , so that accurate estimates of the li - producing reactions are required for a rigorous test of these models . unfortunately , the @xmath2 cross sections@xcite are not known at high enough energies for such purposes  no data are available for @xmath0li production above 200 mev , although the cosmic ray @xmath7-particle flux remains strong beyond this energy @xcite . the predicted early - galaxy abundances of @xmath0li can vary significantly ( for example , by a factor of two in the model of ref . @xcite ) , depending on how the lower energy cross sections are extrapolated to higher energy .    to provide the necessary data , we measured angular distributions of @xmath11 ejectiles from the @xmath12 reaction for alpha energies between 159 and 620 mev , and integrated these distributions to obtain the total production cross sections for masses 6 and 7 . we find that the cross sections fall rapidly , essentially exponentially , with increasing bombarding energy , becoming small enough that @xmath13 will not contribute significantly to cosmic ray nucleosynthesis at energies above the measured range ( to 620 mev ) . the cross sections at bombarding energies above 160 mev were expected to be small , leading to potentially severe problems of background scattering and long collection times if a traditional gas cell approach was used , as in previous measurements@xcite . to avoid these problems , we employed two novel techniques : ( 1 ) the detectors were placed inside the target gas volume to eliminate background scattering from target cell walls and windows , and ( 2 ) a telescope system with a wide and continuous acceptance in laboratory scattering angle was used to reduce data collection time . details of the target , detector telescopes , beam , and angle and acceptance calibrations are given below . the target was natural helium gas , @xmath1499.99% pure , which filled the nscl 92-inch scattering chamber ; the gas pressure ranged from 370 to 408 torr ( measured to @xmath15 ) and the temperature was 23@xmath16c . a schematic of the chamber is shown in fig .  1 . the chamber housed a remotely operable turntable on which the detectors were mounted , and the effective target was a cylinder of gas extending approximately 135 cm upstream and 15 cm downstream from the center of the turntable . the entrance window was a 6.4 @xmath17 m havar foil which was located 150 cm upstream from the turntable center and was partially blocked from view of the detectors by lead shielding . the chamber was evacuated on several occasions to check background from the entrance foil . only at the most forward laboratory scattering angles ( @xmath18 ) were background subtractions for window scattering necessary , and these subtractions were smaller than 20% of the total observed yield at any angle . a target ladder was located at the center of the turntable , and held secondary targets used for beam monitoring and calibration : a 47 mg / cm@xmath8 carbon foil , a 0.5 mm diameter `` pinhole , '' a 1 mm diameter vertical steel  needle , \" a 2 mm thick aluminum target with a 20 mm diameter hole , and a scintillator . this ladder was lowered completely out of the beam path during data collection with the primary ( helium ) target . beams of @xmath7 particles were provided by the nscl k1200 cyclotron at nominal energies of 160 , 280 , and 620 mev . the lowest energy was chosen to allow direct comparison with results of @xcite , and the higher energies were chosen to span the region of astrophysical interest . all beams were fully stripped upon arrival at the scattering chamber . up to @xmath20 mev is deposited in the entrance foil and target gas prior to the reaction , depending on the initial energy and point of scatter . the average bombarding energies , accounting for these losses and the 0.2 mev uncertainty in the measured energy , were @xmath21 mev , @xmath22 mev , and @xmath23 mev . the beam spot was checked by periodic insertion of two scintillators viewed by tv cameras , located at the turntable center and 170 cm upstream of turntable center . the beam radius at the turntable was @xmath24 mm and the calculated half - angle divergence @xmath25 . possible beam halo was monitored by periodically inserting the aluminum  hole \" target and looking for scattered particles ; no significant halo was observed . the unscattered beam was collected in a vacuum - isolated faraday cup 2 meters downstream from the scattering chamber , and integrated beam current was found with @xmath265% uncertainty using a bic model 1000 current integrator . two detector telescopes were fixed to the turntable at beam height , one on each side of the beam . each telescope consisted of a stack of two @xmath27 cm tall @xmath28 @xmath29 cm wide charge - division position - sensitive silicon detectors ( psds ) and one 3 cm thick csi(tl ) scintillator viewed by photodiodes , as shown in fig .  2 . in telescope 1 the psds had thicknesses of 320 @xmath17 m ( front ) and 1000 @xmath17 m ( back ) , and were located 300 and 367 mm from the turntable center . in telescope 2 , the psds had thicknesses of 300 @xmath17 m ( front ) and 480 @xmath17 m ( back ) , and were located 300 and 363 mm from the turntable center , 80@xmath16 clockwise from telescope 1 . standard electronics were used for signal amplification and data acquisition .    with the turntable centered , each telescope viewed a laboratory scattering angle range of 7@xmath1660@xmath16 simultaneously . five different turntable settings were used during data collection ; at a given scattering angle this provided independent measurements with a variety of solid - angle acceptance conditions . the turntable settings were centered ( as shown in fig .  1 ) , rotated @xmath30 from the centered position , and rotated @xmath31 . the smallest laboratory angle observed was @xmath32 , seen only by the telescope rotated closest to the beam for @xmath33 settings .    the telescopes provided distinct particle identification for @xmath34 ejectiles from characteristic @xmath35-@xmath36 signatures in the psds . in some kinematic situations the ejectile penetrated both psds and stopped in the csi(tl ) scintillator ; in this case the energy deposited in the scintillator was also used to aid particle identification . the mass resolution was about 0.4 amu fwhm , sufficient to distinguish @xmath0li and @xmath1li . the energy resolution was sufficient to distinguish elastically scattered @xmath37he from @xmath37he produced in inelastic channels such as @xmath37he@xmath38he ( @xmath39mev ) ; however , discrimination between the @xmath37he@xmath40li channel ( @xmath41mev ) and the @xmath37he@xmath42li channel ( @xmath43mev ) was unreliable , particularly at the higher energies . it was not possible to distinguish the particle - stable first excited state in @xmath1li or @xmath1be ( 0.48 mev and 0.43 mev , respectively ) from the ground state . the first excited state in @xmath0li ( 2.18 mev ) decays immediately to @xmath44 and does not contribute significantly to @xmath0li production . the second excited state in @xmath0li ( 3.56 mev ) is particle - stable , but it was not possible to distinguish it from the ground state . since the primary concern of the present experiment is total production cross sections , these resolution limitations are not important .    for a valid event , both psds in a telescope must detect the scattered particle . the impact position on each psd is inferred using standard charge - division techniques ; from these impact positions and the known spacing between the psds it is possible to derive the scattering angle @xmath45 and the scattering position @xmath46 along the beam axis . the scattering angle is needed for computing the differential cross sections @xmath47 , and the @xmath46 position is needed to exclude particles that may have scattered in the havar entrance foil . angle calibration is performed by stepping each telescope through a pinhole - collimated @xmath7 beam . the calibration was tested by reconstructing the tracks of particles scattered from a  needle \" target protruding into the beam and from four @xmath48 m kapton foils that could be inserted at various locations along the beam path . angular resolution was about 1.2@xmath16 fwhm and was not degraded significantly when the chamber was filled with helium . differential cross sections are found from the observed yields according to @xmath49 where @xmath50 is the observed number of particles at the laboratory scattering angle @xmath51 . @xmath52 is the number of incident particles , @xmath53 is the detection system live fraction , and @xmath54 is the target density ( nuclei/@xmath55 ) . the detector acceptance is denoted by @xmath56 and has units of cm . @xmath57 , where @xmath58 is the effective solid angle , @xmath59 is the effective length of the target , @xmath60 is the detector efficiency , and @xmath61 is the transmission fraction of scattered particles . @xmath56 depends primarily on the geometry of the detector and the incident beam . it is determined by comparing our observed yields of elastically scattered @xmath37he at 160 mev with the laboratory cross sections reported by nadasen _ _ @xcite at a similar energy . the data of @xcite have better angular resolution than the present experiment , and had to be slightly degraded before the comparison . by solving equation ( 1 ) for @xmath56 in one degree ( laboratory frame ) bins , we calibrate the acceptance for all angles of interest . the process is repeated for each of the five turntable settings .    for practical purposes the @xmath56 calibration is independent of energy and particle species . energy or species dependence can occur because of transmission losses through the target gas or reactions in the si or csi detectors . the former is always less than 1% in the kinematic region of interest . reaction losses in the detectors can cause a loss of a few percent of detector efficiency in the worst cases . however , losses in the @xmath11 efficiency tend to offset the losses in the efficiency for @xmath37he particles used for calibration , and the net effects are much smaller than the quoted uncertainty . although different particles have different cutoff angles ( this occurs when the the particle energy is insufficient to penetrate the first psd ) , the cutoff angles are all in the backward c.m . hemisphere , which is not used in the analysis . several quality checks were applied to the @xmath56 calibration . ( 1 ) the differential cross sections derived from the five different turntable angles were compared , and were found to be consistent . ( 2 ) @xmath56 was compared with ( somewhat simplified ) monte carlo simulations of the detector geometry and were found to agree within 12% . ( 3 ) our @xmath62 differential cross sections at 160 mev are in excellent agreement with those by glagola , _ et al . _ @xcite , which lends confidence to our methods . we estimate a systematic uncertainty of 8% , which is dominated by the absolute uncertainty in the results of ref . @xcite . the differential and total cross sections were measured for the four reactions @xmath37he@xmath63he , @xmath37he@xmath64li , @xmath37he@xmath65li , and @xmath37he@xmath66be . because the target and projectile are identical , reaction products are distributed symmetrically about @xmath67 c.m . ; it is then sufficient to determine yields only for @xmath68 . detector acceptance for events from the backward c.m . hemisphere was rather low because the low energy ejectiles stopped in the 300 @xmath17 m or 320 @xmath17 m psds . in all four reactions of interest , the kinematics are `` folded '' so that each laboratory angle corresponds to two c.m . scattering angles . for the two - body final states leading to @xmath1li and @xmath1be , it is a simple matter to distinguish between the two c.m.angles , because a larger ejectile energy is always associated with the more forward angle . there is an added complication for @xmath0li and @xmath0he due to the three - body exit channels @xmath0he@xmath69 and @xmath0li@xmath70 . we determined a locus of ejectile energies corresponding to 90@xmath16 c.m . , as a function of laboratory scattering angle , from the kinematics result @xmath71 where @xmath72 is the momentum of @xmath0li and @xmath73 is the velocity of the center of mass ; all quantities are measured in the lab . the result is shown in fig . all @xmath0li ejectiles observed with energies above this locus were attributed to the forward c.m . hemisphere , and those with less energy were attributed to the backward hemisphere . a similar procedure was used for the @xmath0he data . one can , in principle , distinguish the @xmath37he@xmath40li reaction from the @xmath37he@xmath74li reaction , as it is restricted to a band labeled  0 mev \" in fig . this was done in refs.@xcite , but our energy resolution made it impossible ; this is not a limitation for use of these cross sections in calculations of cosmic ray nucleosynthesis . the differential cross sections ( forward c.m .  hemisphere only ) for @xmath0li and @xmath0he are shown in fig . the cross sections for @xmath0li are forward peaked at all three energies . the cross sections for @xmath0he are also forward peaked and are roughly @xmath75 as large as those for @xmath0li . it was not possible to measure the cross section for @xmath0he at 620 mev due to background contamination from @xmath9he ejectiles . we established that the @xmath0he cross section at 620 mev is less than 25% of the cross section for @xmath0li at this energy . the differential cross sections ( forward c.m .  hemisphere only ) for @xmath1be and @xmath1li are shown in fig . 5 . at 160 mev the cross sections for both isotopes are forward - peaked with a minimum at 90@xmath16 c.m . ; they are in excellent agreement with the measurements of ref . @xcite at a similar energy . the cross sections at 280 mev are two orders of magnitude smaller , approaching the limit of our experimental method , and the minima at 90@xmath16 disappear . at 620 mev the cross sections were very small : fewer than two dozen possible @xmath1li and @xmath1be events were observed , roughly consistent with background . an upper limit is obtained at 620 mev . total cross sections for @xmath76 production were found by extrapolating the differential cross sections to zero degrees , integrating over all laboratory angles corresponding to @xmath77 , and doubling to account for the @xmath78c.m . the extrapolation to zero degrees is based on a linear fit through the three smallest - angle points ( @xmath79 and @xmath80 ) . the extrapolated cross section @xmath81 typically accounts for @xmath82% of the total cross section , and up to one third of the random uncertainty . total cross sections for @xmath76 production are shown in fig .  6 and table i. for comparison , the cross sections from previous measurements in the 60 - 200 mev range are also included . errors given for the present experiment include the statistical , extrapolation , and normalization ( 8% ) uncertainties , all added in quadrature . the measured cross sections for @xmath0he and @xmath0li differ from the values of glagola _ et al . _  @xcite near 160 mev by about a factor of two . however , the present results agree with the reanalysis of the glagola , _ et al . _ data by mercer , austin , and glagola @xcite . for both nuclides the total cross sections decrease rapidly with increasing energy . the solid lines in fig . 6 are weighted exponential fits through all points shown , and have the functional forms ( with the bombarding energy , @xmath83 , in mev and the slope for @xmath0he taken to be identical to that obtained for @xmath0li ) @xmath84 @xmath85 the exponential falloff is shallower than that suggested by woo _ et al._@xcite , who report fits proportional to @xmath86 for both @xmath0he and @xmath0li . the difference is understandable because the reanalyzed lower energy data @xcite were not available to woo _ et al._. the interpolated line for @xmath0he lies somewhat above the upper limit from @xcite at 198 mev , but in general the data form a consistent set . the cross section for @xmath0li at 620 mev lies significantly above the fitted exponential . total cross sections for @xmath1li and @xmath1be are found by extrapolating the differential cross sections to zero degrees , integrating from @xmath87 in the c.m . frame , and doubling , as in the @xmath76 analysis . results are shown in fig .  7 and in table ii along with other measurements from 60 to 600 mev . our result at 159.3 mev is in excellent agreement with those of glagola @xcite near 160 mev ; an exponential describes the entire data set very well . our experiment yields a significantly tighter upper bound for the @xmath1be cross section near 600 mev than that given in @xcite , and a new limit for @xmath1li . as expected , since the channels are isospin mirrors , the @xmath1li and @xmath1be cross sections are similar in size and energy dependence . weighted exponential fits yield : @xmath88 @xmath89 these results are quite similar to that reported in ref . @xcite : @xmath90 .    since @xmath0he decays to @xmath0li by @xmath91 emission , with a half - life of about 807 msec , the @xmath37he@xmath63he and @xmath37he@xmath64li reactions are both a source of @xmath0li produced in the cosmic rays . therefore , the sum of @xmath0li and @xmath0he cross sections at each energy is also given in table i. in cases where @xmath0he measurements are not available , the sum includes an estimate for the @xmath0he contribution , equal to 12% of the @xmath0li cross section ( 103.0 and 619.7 mev ) or equal to the reported upper limit ( 0.2 mb ) for @xmath0he at 198.4 mev .    in fig . 8 we show the mass6 cross sections , the sum of the cross section for @xmath0li and @xmath0he . as was already clear from the fits shown in fig .  6 , an exponential fit would lie significantly ( about three standard deviations ) below the point at 620 mev . the fit shown includes an energy independent cross section and describes the data well ; it should be useful for applications . it would be desirable to use a form that more accurately reflects possible physical processes at high energy , but the data is sufficient to fix only one parameter beyond the low energy exponential ; adding a constant cross section is the simplest choice . the resulting constant cross section is much smaller than the uncertainty in the low energy cross sections . the sum of the @xmath37he@xmath65li and @xmath37he@xmath65be cross sections is also given in table ii for each energy . since @xmath1be decays by electron capture to @xmath1li with a half - life of 53.3 days , these are the relevant cross sections for calculation of @xmath1li production in cosmic rays . finally , fig . 8 shows the sum of the @xmath1li and @xmath1be cross sections , an exponential fit to the data , and a fit including a constant cross section . the exponential or exponential - plus - constant cross section forms shown in fig . 8 provide a convenient description of the data for use in applications . for the total mass-6 and mass-7 yields these are @xmath92 @xmath93 @xmath94 with these new cross sections for production of @xmath11 by the @xmath2 reaction , it is possible to calculate the amounts of @xmath0li and @xmath1li produced in early - galaxy cosmic rays more accurately . the need to extrapolate cross sections to high energies is no longer a significant factor in the uncertainty . because of the smaller cross sections obtained here for mass-6 the the production of @xmath0li will be significantly smaller than would be obtained with cross sections from the the summary of read and viola@xcite .    to illustrate these points , we use a cosmic ray spectrum peaked around 200 mev / nucleon ( specifically , fig . 2b of ref.@xcite , the curve labeled @xmath95 g / cm@xmath8 . the product of this spectrum and various cross sections was integrated over energy . a comparison of results using our cross sections and those of read and viola@xcite is useful , because most calculations of cosmic ray nucleosynthesis have used the read - viola cross sections . both an exponential fit ( not shown ) and the exponential plus background fit ( eq . 7 ) shown in fig .  8 yield about 50% of the @xmath0li obtained using the cross sections of read and viola . for @xmath1li the differences are relatively small , because the reaction cross sections are already quite small by 200 mev , and because upper limits for @xmath1be at higher energies had been reported . for the cosmic ray spectrum employed here ( and using the read - viola cross sections for @xmath96 mev ) the production rates of @xmath1li and @xmath0li are nearly equal , with @xmath1li production larger by about 10% . detailed calculations of the effects of the new cross sections and the suggested renormalizations of lower energy cross sections@xcite will be reported at a later date @xcite . in general they will result in a significant reduction of the calculated cosmic ray production of @xmath0li by @xmath2 reactions . the reduction is dependent on the cosmic ray spectrum and will be largest when it has a large component above 200 mev . the energy dependence of the cross sections at high energies , that is , the expected limit of the observed exponential behavior , remains an issue . we are not aware of detailed studies of this phenomenon . in the case of mass-6 , a deviation from exponential behavior is required by the data , and we have assumed a constant value at higher energies . in the case of mass-7 , there is no convincing evidence for such a deviation . however , given the deviation seen for mass-6 , we have provided for mass-7 , as alternatives , pure exponential and constant - plus - exponential fits to the data . for the cosmic ray spectrum we have chosen , the difference between the two assumptions affects the mass-7 yield at only the 0.4% level . the production of @xmath0li and @xmath1li by @xmath97 reactions will play a vital role in reaching an understanding of the synthesis of libeb and the nature of the cosmic rays . the critical questions are whether the @xmath1li observed in old metal - poor stars is that produced in the big bang , or whether big bang @xmath1li has been affected by production in cosmic rays and destruction by stellar processing . recent data indicate that the amount of li increases with time , presumably an indication of cosmic ray production . however , our data bear more strongly on the possibility of stellar destruction of @xmath10li . since @xmath0li is more fragile than @xmath1li , its survival in a star can be used to limit the amount of @xmath1li depletion .    in order to use @xmath0li in this way , the amount of @xmath0li formed must be estimated from a model for cosmic ray nucleosynthesis ( very little @xmath0li is made in the big bang ) and then compared to its observed abundance . the resulting @xmath0li destruction might then be used to estimate the amount of @xmath1li destruction and eventually , the primordial abundance of @xmath1li . in recent models ( see for example@xcite ) the production of @xmath0li is marginally sufficient or too small , even assuming none has been destroyed during stellar evolution . the downward changes in the predictions that will result from the present measurements may , therefore , have important consequences . we would like to thank p. danielewicz , b. d. fields , r. ramaty , and v. e. viola for useful discussions ; m. hellstrom , r. a. kryger , j. s. winfield , and the staff of the national superconducting cyclotron laboratory for assistance with various aspects of the data collection ; and r. j. peterson , r. a. ristinen , and c. j. gelderloos for useful discussions concerning analysis . this work was supported by grants from the national science foundation and the u.s . department of energy . b. g. glagola , g. j. mathews , h. f. breuer , v. e. viola , jr . , p. g. roos , a. nadasen , and sam m. austin , phys . 41 * , 1698 ( 1978 ) ; b. g. glagola , v. e. viola , jr . , h. breuer , n. s. chant , a. nadasen , p .g . roos , sam m. austin , and g. j. mathews , phys . c * 25 * , 34 ( 1982 ) . .total cross sections ( mb ) for the @xmath37he@xmath63he and @xmath37he@xmath64li ( g.s.+3.56 ) reactions as a function of bombarding energy . their sum is also given for convenience , with estimates made for the @xmath0he contribution as described in the text where data are not available . the errors for the present experiment include an 8% uncertainty in the normalization , added in quadrature . [ cols=\"^,^,^,^ \" , ]     @xmath98reference @xcite . + @xmath99ref . @xcite renormalized according to @xcite . + @xmath100reference @xcite . + @xmath101present experiment ( boldface ) . + @xmath102reference @xcite . + @xmath103reference @xcite .", "tags": [], "output_text_a": "The paper discusses the origins and synthesis of the light elements lithium (Li), beryllium (Be), and boron (B), collectively known as LiBeB. Unlike most elements formed in stars, LiBeB are rapidly consumed in stellar centers and must be synthesized in cooler environments. Traditionally, it was believed that Li, Be, and B were produced in galactic cosmic rays (GCR) through interactions with interstellar carbon, nitrogen, oxygen, and helium. However, recent observations in metal-poor stars challenge this view, suggesting that heavy cosmic rays might be responsible for their synthesis.\n\nThe study focuses on measuring the cross sections of reactions that produce Li isotopes, particularly the reaction involving helium-4 (\u03b1 particles) and its role in cosmic ray nucleosynthesis. The authors conducted experiments to measure angular distributions and total production cross sections for Li isotopes at energies between 159 and 620 MeV. They found that the cross sections decrease rapidly with increasing energy, indicating that these reactions contribute less to cosmic ray nucleosynthesis at higher energies.\n\nThe results show that the production of Li isotopes in cosmic rays is significantly lower than previously estimated, which has implications for understanding the synthesis of LiBeB and the nature of cosmic rays. The study suggests that the observed Li in old stars might be affected by cosmic ray production and stellar processing, and the new cross sections could lead to a reevaluation of the primordial abundance of Li. The findings highlight the need for accurate cross-section data to test models of cosmic ray nucleosynthesis and the potential impact on our understanding of stellar and cosmic processes.", "output_text_b": "This article discusses the measurement of angular distributions of ejectiles from the \u03b1 + He reaction for alpha energies between 159 and 620 MeV. These measurements are used to obtain the total production cross sections for masses 6 and 7. The study finds that the cross sections fall rapidly with increasing bombarding energy, becoming small enough that they will not contribute significantly to cosmic ray nucleosynthesis at energies above the measured range (to 620 MeV).\n\nThe experiment employs two novel techniques to avoid problems of background scattering and long collection times: (1) detectors are placed inside the target gas volume to eliminate background scattering from target cell walls and windows, and (2) a telescope system with a wide and continuous acceptance in laboratory scattering angle is used to reduce data collection time.\n\nThe target is natural helium gas, which fills the NSCL 92-inch scattering chamber. The gas pressure ranges from 370 to 408 torr, and the temperature is 23\u00b0C. The chamber houses a remotely operable turntable on which the detectors are mounted, and the effective target is a cylinder of gas extending approximately 135 cm upstream and 15 cm downstream from the center of the turntable.\n\nBeams of \u03b1 particles are provided by the NSCL K1200 cyclotron at nominal energies of 160, 280, and 620 MeV. The beams are fully stripped upon arrival at the scattering chamber. Up to 20 MeV is deposited in the entrance foil and target gas prior to the reaction, depending on the initial energy and point of scatter.\n\nTwo detector telescopes are fixed to the turntable at beam height, one on each side of the beam. Each telescope consists of a stack of two charge-division position-sensitive silicon detectors and one CSI(TL) scintillator viewed by photodiodes. The telescopes provide distinct particle identification for ejectiles from characteristic \u03b1-\u03b1 signatures in the PSIDs.\n\nThe differential cross sections are found from the observed yields according to the equation d\u03c3/d\u03a9 = Y(\u03b8) / (Ninc \u00d7 \u03b4\u03a9 \u00d7 \u03b4l \u00d7 \u03b5), where Y(\u03b8) is the observed number of particles at the laboratory scattering angle \u03b8, Ninc is the number of incident particles, \u03b4\u03a9 is the effective solid angle, \u03b4l is the effective length of the target, \u03b5 is the detector efficiency, and \u03b4l is the transmission fraction of scattered particles.\n\nThe detector acceptance is determined by comparing observed yields of elastically scattered \u03b1 particles at 160 MeV with laboratory cross sections reported by Nadasen et al. The data of Nadasen et al. have better angular resolution than the present experiment and had to be slightly degraded before the comparison. By solving the equation for \u03b4l in one-degree (laboratory frame) bins, the acceptance is calibrated for all angles of interest.\n\nThe differential and total cross sections are measured for the four reactions \u03b1 + He \u2192 He + He, \u03b1 + He \u2192 Li + p, \u03b1 + He \u2192 Be + p, and \u03b1 + He \u2192 B + 2p. The kinematics of these reactions are folded so that each laboratory angle corresponds to two c.m. scattering angles. The two-body final states leading to Li and Be are distinguished by a larger ejectile energy being always associated with the more forward angle. The three-body exit channels for \u03b1 + He \u2192 0he + X and \u03b1 + He \u2192 0li + X are determined by a locus of ejectile energies corresponding to 90\u00b0 c.m., as a function of laboratory scattering angle.\n\nTotal cross sections for \u03b1 + He \u2192 76 production are found by extrapolating the differential cross sections to zero degrees, integrating over all laboratory angles corresponding to 77, and doubling to account for the c.m. The extrapolation to zero degrees is based on a linear fit through the three smallest-angle points. Total cross sections for \u03b1 + He \u2192 76 production are shown in fig. 6 and table i.\n\nThe measured cross sections for \u03b1 + He \u2192 0he and \u03b1 + He \u2192 0li differ from the values of Glagola et al. near 160 MeV by about a factor of two. However, the present results agree with the reanalysis of the Glagola et al", "score": 0.4, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the origins and synthesis of LiBeB elements and the implications of the new cross-section measurements.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the synthesis of LiBeB elements and their production in cosmic rays, is clearly highlighted.\n4. The methodology, including the measurement of angular distributions and total production cross sections for Li isotopes, is mentioned.\n5. Significant results, such as the rapid decrease in cross sections with increasing energy and the implications for cosmic ray nucleosynthesis, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"cross sections\" and \"cosmic ray nucleosynthesis\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments, such as the measurement of cross sections at energies between 159 and 620 MeV, are mentioned.\n10. The potential impact of the findings on understanding the synthesis of LiBeB and cosmic ray processes is reflected.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the measurement of angular distributions and the use of novel techniques.\n2. **Conciseness**: The summary exceeds the 250-word limit, which affects its conciseness.\n3. **Research Problem**: The summary does not clearly highlight the research problem or question addressed by the paper.\n4. **Methodology**: The summary mentions the methodology, including the use of detectors and telescopes.\n5. **Significant Results**: The summary includes significant results, such as the rapid fall of cross sections with increasing energy.\n6. **Language**: The language is clear and professional.\n7. **Technical Jargon**: The summary uses technical terms but does not explain them, which may hinder understanding for non-experts.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions key experiments, such as the use of the NSCL K1200 cyclotron.\n10. **Significance**: The summary does not adequately reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "let @xmath0 be any real number , and consider what happens when we repeatedly apply the function @xmath1 : @xmath2 clearly this sequence , the _ orbit _ of @xmath3 under @xmath4 , tends rapidly to infinity . indeed , if @xmath5 denotes the @xmath6-th term in the sequence , then @xmath7 for @xmath8 . so the process may not appear terribly interesting . this changes rather drastically upon replacing the _ real _ number @xmath0 by a _ complex _ value @xmath3 and considering the sequence @xmath9 ( see section [ sec : background ] for a reminder of the properties of the complex exponential function . ) in contrast to the real case , not every complex orbit tends to infinity : for example , there is a point @xmath10 such that @xmath11 , and hence the sequence defined by is constant for @xmath3 . in fact , things turn out to be extremely complicated :    [ thm : orbits ] each of the following sets is dense in the complex plane :    1 .   [ item : escaping ] the set of starting values @xmath3 whose orbit ( defined by  ) diverges to @xmath12 ; 2 .   the set of starting values @xmath3 whose orbit forms a dense subset of the plane ; 3 . the set of _ periodic points _ ; i.e.  starting values @xmath3 such that @xmath13 for some @xmath14 and all @xmath15 . so , by performing arbitrarily small perturbations of any given starting point , we can always obtain an orbit that is finite , one that accumulates everywhere and one that eventually leaves every bounded set ! in particular , the eventual behaviour of a point @xmath3 under iteration of the exponential map is usually _ impossible to predict numerically _ : when computing the value of @xmath16 , there will always be a ( tiny ) numerical error , and according to theorem [ thm : orbits ] , this error can change the long - term behaviour of orbits drastically . this type of phenomenon is often referred to as _ chaos_. it is a typical occurrence in all but the simplest `` dynamical systems '' ( mathematical systems that change over time according to some fixed rule ) , such as the movement of bodies in the solar system   governed by newton s laws of gravity   or , indeed , seemingly simple discrete - time processes such as the one we are studying here . there are a number of ( inequivalent ) definitions of `` chaos '' ; the most widely used , and most appropriate for our purposes , was introduced by devaney in 1989 @xcite . this concept , formally introduced in definition [ defn : devaneychaos ] below , captures precisely the topological properties usually associated with chaotic systems . the following result is then a consequence of theorem [ thm : orbits ] . [ thm : chaotic ] the exponential map @xmath17 is chaotic in the sense of devaney . theorem [ thm : orbits ] is ( a reformulation of ) a famous theorem of misiurewicz from 1981 @xcite , which confirmed a conjecture stated by fatou @xcite in 1926 . misiurewicz s proof is entirely elementary , but not easy : it relies on a sequence of explicit estimates on the exponential map , its iterates and their derivatives . an alternative proof was later given independently in @xcite , @xcite ( see also @xcite ) and @xcite . ( according to eremenko , their research was directly motivated by the desire to give a more conceptual proof of misiurewicz s theorem . ) a third argument can be found in @xcite . in all these newer works , the result arises as part of a more general theorem , and requires a substantial amount of background knowledge in complex analysis and complex dynamics . the goal of this note is to give a proof of theorems [ thm : orbits ] and [ thm : chaotic ] that is both elementary and conceptual . it requires no background beyond a first undergraduate course in complex analysis , together with some facts from _ hyperbolic geometry _ that can be verified in an elementary manner . we shall explain the latter carefully in section [ sec : hyperbolic ] , after first reviewing the action of the exponential map on the complex plane in section [ sec : background ] . readers already familiar with this background material can dive in straight in with the proofs in sections  [ sec : escaping ] to  [ sec : periodicpoints ] . in section [ sec : further ] , we briefly mention further results and open questions ; since mathematics is learned best by doing , we end with exercises for the reader in section  [ sec : exercises ] . we hope that our note will give readers some insights into the beautiful phenomena one encounters when studying the dynamics of transcendental functions of one complex variable , and serve as an invitation to learn more about this intriguing subject . we thank alexandre eremenko , rongbang huang , stephen worsley and the referees for helpful comments . if @xmath18 is a self - map of some set @xmath19 , then @xmath20 is called the @xmath6-th _ iterate _ of @xmath4 ( for @xmath15 ) . in particular , @xmath21 for all @xmath22 . the _ orbit _ of a point @xmath0 is the sequence @xmath23 . in the case where @xmath24 is the complex exponential map , this coincides precisely with the definition in  . a point @xmath22 is _ periodic _ if there is some @xmath25 such that @xmath26 . we use standard notation for complex numbers @xmath27 . in particular , @xmath28 $ ] denotes ( the principal branch of ) the _ argument _ of @xmath29 , i.e. the angle that the line segment connecting @xmath30 and @xmath29 forms with the real axis . note that @xmath31 is undefined at @xmath32 and continuous only for @xmath33 . we write @xmath34 for the _ punctured plane _ , and @xmath35 for the round disc of radius @xmath36 around a point @xmath37 ; the _ unit disc _ is @xmath38 . the action of the complex exponential map , as illustrated in figure [ 10 ] on p.  82 of @xcite . the pattern on the right is the image of the checkerboard pattern on the left . ( image courtesy of tristan needham.),title=\"fig : \" ]    recall that the complex exponential function is the holomorphic function @xmath39 given by @xmath40 the representation   provides the following geometric interpretation of the action of the exponential map ( see figure [ fig : exponential ] ) , which the reader should keep in mind :    * the function @xmath41 maps horizontal lines to radial rays starting at the origin , and wraps vertical lines infinitely often around concentric circles centered at the origin . the modulus @xmath42 is large precisely when @xmath43 is large and positive . * in particular , the _ right half - plane _ @xmath44 is mapped ( in an infinite - to one manner ) to the outside of the closed unit disc , and the left half - plane is mapped to the punctured unit disc . * the exponential map is strongly _ expanding _ when @xmath43 is large and positive , and strongly _ contracting _ when @xmath43 is very negative . since the exponential map spreads the complex plane @xmath45 over the punctured plane @xmath46 in an infinite - to - one manner , it is not injective , and hence does not have a well - defined global inverse . instead , we use _ branches _ of the logarithm : inverse functions to injective restrictions of @xmath41 ( see ( * ? ? ? * section  2.vii ) ) . it follows from   that such a branch exists wherever there is a continuous choice of the argument . for example , let @xmath47 . then @xmath48 is bijective , and hence has a holomorphic inverse @xmath49 on @xmath50 , given by @xmath51 ( here , and throughout , @xmath52 denotes the natural logarithm . ) in particular , let @xmath53 be a disc that does not contain the origin , and let @xmath54 with @xmath55 . taking @xmath56 , we see that there is a holomorphic map @xmath57 with @xmath58 such that @xmath59 and @xmath60 for all @xmath61 . note that we could replace @xmath62 by any convex open set that omits the origin . more generally , branches of the logarithm exist on any _ simply - connected _ domain that does not contain the origin , but for us the above cases of discs and slit planes will be sufficient .      we now introduce devaney s definition of chaos @xcite that was mentioned in the introduction . this is usually stated in the context of _ metric spaces _ ( see below ) , but we shall restrict to the case of dynamical systems defined on subsets of the complex plane . recall that , if @xmath63 , then @xmath64 is called _ dense _ in @xmath19 if every open set @xmath65 that intersects @xmath19 also contains a point of @xmath64 . [ defn : devaneychaos ] let @xmath66 be infinite , and let @xmath18 be continuous . we say that @xmath4 is _ chaotic _ ( in the sense of devaney ) if the following two conditions are satisfied . a.   the set of periodic points of @xmath4 is _ dense _ in @xmath19.[item : chaos_periodic ] b.   the function @xmath4 is _ topologically transitive _ ; that is , for all open sets @xmath67 that intersect @xmath19 , there is a point @xmath68 and @xmath15 such that @xmath69.[item : chaos_trans ]    topological transitivity means precisely that we can move from any part of the space @xmath19 to any other by applying the function @xmath4 sufficiently often . this property clearly follows from the existence of a dense orbit ( see exercise [ ex : denseorbit ] ) . in particular , theorem [ thm : chaotic ] is a consequence of theorem [ thm : orbits ] . ( however , in section [ sec : transitivity ] , we in fact argue in the converse direction   we first prove topological transitivity of the exponential map directly , and then deduce the existence of dense orbits . ) devaney s original definition of chaos included a third condition : _ sensitive dependence on initial conditions_. it is shown in @xcite that this property is a consequence of topological transitivity and density of periodic points , which is why we were able to omit it in definition  [ defn : devaneychaos ] . it is nonetheless worthwhile to discuss sensitive dependence on initial conditions , since it encapsulates precisely the idea of `` chaos '' discussed in the introduction : two points that are close together may end up a definitive distance apart after sufficiently many applications of the function @xmath4 . ( this phenomenon has become known in popular culture as the `` butterfly effect '' . ) moreover , in the case of the exponential map , we shall be able to establish sensitive dependence before proving either of the remaining two conditions .    to give the formal definition , we shall use the notion of a _ distance function _ ( or _ metric _ ) @xmath70 on a set @xmath19 , as introduced e.g.  in ( * ? ? ? * chapter 2 ) or ( * ? ? ? * chapter 2 ) . readers unfamiliar with this definition need not despair : on the one hand , it is only used in this subsection ; on the other , it will be sufficient to think of such a function informally as a formula that defines some notion of _ distance _ between two points of @xmath19 . the simplest example of a distance function on @xmath45 is the usual one , namely _ euclidean distance _ @xmath71 . [ defn : sensitivedependence ] let @xmath66 , let @xmath72 be continuous , and let @xmath70 be a distance function on @xmath19 . we say that @xmath4 exhibits _ sensitive dependence on initial conditions _ ( with respect to @xmath70 ) if there exists a constant @xmath73 with the following property : for every non - empty open set @xmath74 , there are points @xmath75 and some @xmath15 such that @xmath76 . if we intend to use this definition , we ought to clarify which distance function we intend to use on the complex plane , and it is tempting to choose euclidean distance . this turns out to be a poor choice : even the `` uninteresting '' _ real _ exponential map discussed at the very beginning of this paper has sensitive dependence with respect to this distance ( exercise [ ex : realexp ] ) . the trouble is that , when orbits tend uniformly to infinity for a whole neighbourhood of our starting value , we would consider the corresponding behaviour to be `` stable '' , but orbits may end up extremely far apart in terms of euclidean distance . this issue is resolved by instead using the so - called _ spherical distance _ , which is obtained by adjoining a single point at @xmath12 to the complex plane   so a point @xmath29 is close to @xmath12 whenever @xmath77 is large   and thinking of the resulting space @xmath78 as forming a sphere in @xmath79-space . for this reason , the space @xmath78 is called the _ riemann sphere_.    instead of introducing spherical distance formally , let us use the informal picture above to decide what sensitive dependence with respect to the sphere should mean . if @xmath80 are close to each other on the sphere , then there are only two possibilities : either both points are close to infinity , or they are also close in the euclidean sense . using this observation , we define sensitive dependence on the sphere directly and axiomatically :    [ defn : sphericalsensitive ] let @xmath81 be a continuous function . we say that @xmath4 has _ sensitive dependence with respect to spherical distance _ if there exist @xmath73 and @xmath82 with the following property . for every non - empty open set @xmath65 , there are @xmath83 and @xmath15 such that @xmath84 and @xmath85 . it turns out ( see exercise [ ex : sphericalsensitiveimpliesallothers ] ) that definition [ defn : sphericalsensitive ] implies sensitive dependence in the sense of definition  [ defn : sensitivedependence ]   no matter which distance function we use on the complex plane . _ hyperbolic geometry _ is a beautiful and powerful tool in one - dimensional complex analysis ( as well as in higher - dimensional geometry ) . when discussing spherical distance in the previous section , we briefly encountered the idea of using a different notion of distance to the `` standard '' one ; hyperbolic geometry is another example of this . if @xmath50 is any open subset of the complex plane that omits more than one point , then there is a natural notion of distance on @xmath50 , called the _ hyperbolic metric_. ( for those who know differential geometry , this is the unique complete conformal metric of constant curvature @xmath86 on @xmath50 . ) we only need a few elementary facts , all of which can be proved using elementary complex analysis . we shall first motivate these statements and then collect them in theorem [ thm : pick ] and proposition [ prop : hypexamples ] . for a more detailed introduction to the hyperbolic metric , we refer to the book @xcite or the article @xcite . our starting point is the following classical consequence of the standard maximum modulus principle of complex analysis ; see ( * ? ? ? * section  3.2 ) or ( * ? ? ? * section  7.vii ) . [ lem : schwarz ] suppose that @xmath87 is holomorphic and @xmath88 . then either    1 . @xmath89 for every non - zero @xmath29 in @xmath90 , and @xmath91 , or 2 . there is a real constant @xmath92 such that @xmath93 for all @xmath29 , and @xmath94 . this lemma can be very useful , but its generality is limited because of the requirement that @xmath4 should fix @xmath30 , and because its conclusion concerns only the derivative at the origin . however , we can move any point @xmath95 to zero using a _ mbius transformation _ @xmath96 ( where @xmath47 is arbitrary ) . so , if @xmath97 is _ any _ holomorphic function , we can pre- and post - compose @xmath4 with suitable mbius transformations and apply the schwarz lemma . using the chain rule to determine the derivative of the composition , we see that @xmath98    we can interpret   as saying that the derivative of @xmath4 is at most @xmath99 when calculated _ with respect to a different notion of distance _ ( in the difference quotient usually used to define @xmath100 ) . more precisely , we call the expression @xmath101 the _ hyperbolic metric _ on @xmath90 . the idea is that if we have an `` infinitesimal change '' at the point @xmath29 , then its corresponding size in the hyperbolic metric is obtained by multiplying its euclidean length by the quantity @xmath102 called the _ density _ of the hyperbolic metric . in   is simply a normalization that ensures that this metric has _ @xmath86 , rather than some other negative constant . it could just as easily be omitted for our purposes , in which case all subsequent densities will also lose a factor of @xmath103 . ] this can be made precise using the notions of differential geometry ( formally , the metric is a way to measure the length of tangent vectors ) , but we can treat   simply as a formal expression . although this expression is called a `` metric '' , it is not a `` distance function '' in the sense of the preceding section . however , it naturally gives rise to such a distance via the notion of _ arc - length _ ; see ( * ? ? ? * chapter  3 ) . we note that the _ spherical metric _ can be similarly introduced via a conformal metric ; that is , a metric that is a scalar multiple of the euclidean metric at any point , where the scaling factor may depend on the point .    with our new notation , formula   states , in beautiful simplicity , that a holomorphic function @xmath97 has hyperbolic derivative at most @xmath99 at every point , with equality if and only if @xmath4 is a mbius transformation . what is even better is that we can transfer the metric to other domains . [ defn : simplyconnected ] an open connected set @xmath104 is called _ simply - connected _ if there is a conformal isomorphism ( i.e. , bijective holomorphic function ) @xmath105 .    usually , @xmath50 is called simply - connected if @xmath106 has no bounded components ; i.e. , @xmath50 has no holes . the _ riemann mapping theorem _ * chapter 6 ) states that the two notions are equivalent . our definition allows us to avoid using the riemann mapping theorem , which is often not treated in a first course on complex analysis . we can now state the following result , which collects the key properties of the hyperbolic metric . its proof is elementary , using only the schwarz lemma and the fact that the conformal automorphisms of @xmath90 are precisely the mbius transformations from  ; see exercise [ ex : mobius ] . we leave it to the reader to fill in the details , or to consult ( * ? ? ? * theorem  6.4 ) . [ thm : pick ] for every simply - connected domain @xmath65 , there exists a unique conformal metric @xmath107 on @xmath50 , called the _ hyperbolic metric _ , such that the following hold .    1 . @xmath108 for all @xmath109 ; [ item : diskmetric ] 2 . if @xmath110 is holomorphic , then @xmath4 does not increase the hyperbolic metric . i.e. , @xmath111 [ item : contraction ] 3 . for any @xmath112 and any @xmath4 as above , we have @xmath113 if and only if @xmath4 is a conformal isomorphism between @xmath50 and @xmath114;[item : isomorphism ] 4 . if @xmath115 , then @xmath116 for all @xmath112.[item : inclusion ]    a key property of the hyperbolic metric on a simply - connected domain is that the density @xmath117 is inversely proportional to the distance of @xmath29 to the boundary of @xmath50 . in other words , suppose that a figure of constant hyperbolic size moves towards the boundary of @xmath50 . then its _ euclidean _ size decreases proportionally with the distance to the boundary . ( see figure [ fig : hyperbolicsizes ] . ) this is a general theorem   see ( * ? ? ? * formula ( 8.4 ) )   but in the domains that we shall be using , it can be checked explicitly from the following formulae . [ prop : hypexamples ]    1 .   for the right half plane @xmath118 , @xmath119 . 2 .   for a strip of height @xmath120 : @xmath121 . 3 .   for the _ positively / negatively slit plane _ : @xmath122}(z ) = \\frac{1}{2|z|\\cos({\\operatorname{arg}}(z)/2)}.\\ ] ] ( in the first case , the branch of the argument should be taken to range between @xmath30 and @xmath120 . ) this can easily be verified by explicit computation using theorem [ thm : pick ] ( [ item : isomorphism ] ) , using the following conformal isomorphisms : @xmath123 ; \\quad z\\mapsto -z ,       \\end{aligned}\\ ] ] where @xmath124 . as an example , we consider the case of @xmath125 , and leave the remaining calculations to the reader . we have @xmath126 for the remainder of the article ( unless stated otherwise ) , @xmath4 will always denote the exponential map @xmath127 we shall now prove the first part of theorem [ thm : orbits ] , namely that the escaping set @xmath128 is dense in the complex plane . the proof that we present here was briefly outlined in a paper of mihaljevi - brandt and the second author ( * ? ? ? * remark on pp . 15831584 ) . [ thm : escapingdense ] the set @xmath129 , consisting of those points @xmath3 whose @xmath4-orbits converge to infinity , is a dense subset of the complex plane @xmath45 . the idea of the proof can be outlined as follows . let @xmath130 be any small round disc . since @xmath131 , and any preimage of an escaping point is also escaping , there is nothing to prove if @xmath50 contains a point @xmath29 whose orbit contains a point on the real axis . otherwise , @xmath132 , @xmath133 and all forward images @xmath134 are contained in the slit plane @xmath135 note that this set @xmath50 is backward invariant under @xmath4 ; i.e. , @xmath136 . it follows that every branch @xmath49 of the logarithm on @xmath50 is a holomorphic map @xmath137 , and hence locally contracts the hyperbolic metric of @xmath50 , as discussed in the previous section .    moreover , if @xmath138 , then the sequence of domains @xmath134 necessarily has at least one finite accumulation point . using the geometry of @xmath50 , we shall see that this implies that the map @xmath4 expands the hyperbolic metric by a definite factor infinitely often along the orbit of @xmath132 . on the other hand , the hyperbolic derivative of @xmath139 with respect to @xmath50 remains bounded as @xmath140 by pick s theorem . this yields the desired contradiction .    from this summary of the proof , it is clear that understanding the expansion of the hyperbolic metric of @xmath50 by @xmath4 plays a key role in the argument . in the following lemma , we investigate where this expansion takes place . [ lem : hyper ] the complex exponential map @xmath4 locally expands the hyperbolic metric on the domain @xmath141 . that is , @xmath142 for all @xmath143 . moreover , suppose that @xmath144 is a sequence with @xmath145 as @xmath146 . then @xmath147 as @xmath146 .    we shall give two justifications of this result . one is more conceptual and uses facts about the hyperbolic metric that were discussed , though not necessarily explicitly proved , in the previous section . the second is a completely elementary calculation ; however , it hides some of the intuition .    to give the first argument , let @xmath148 be a connected component of the set @xmath149 then @xmath148 is a strip of height @xmath120 , and @xmath150 is a conformal isomorphism . let @xmath151 and set @xmath152 . by pick s theorem , @xmath153 is a hyperbolic isometry between @xmath148 and @xmath50 , and hence @xmath154    recall that the density at @xmath29 of the hyperbolic metric in a simply connected domain @xmath155 is comparable to @xmath156 . ( for @xmath50 and @xmath148 , this can be verified explicitly , using proposition [ prop : hypexamples ] . ) we apply this fact twice : notice first that every point in the strip @xmath148 has distance at most @xmath157 from the boundary , and hence @xmath158 is bounded from below by a positive constant . so if @xmath159 is a sequence as in the claim , then , using the same fact for @xmath160 , the distance @xmath161 remains bounded as @xmath146 . also , by  , @xmath159 does not accumulate at any point of @xmath50 . a sequence of points converging to @xmath12 while remaining within a bounded distance from the positive real axis must have arguments tending to @xmath30 , and a point that is close to a finite point of @xmath162 either has argument close to @xmath30 or is close to @xmath30 itself . so @xmath147 , as claimed . on the other hand , the claims can be verified directly from the formulae . indeed , let us write @xmath163 with @xmath164 ; then @xmath165 now we compute the hyperbolic derivative directly , using proposition [ prop : hypexamples ] : @xmath166 where @xmath167 and @xmath168 are chosen in the range @xmath169 . to further simplify this expression , observe that @xmath170 . since @xmath171 is @xmath157-periodic , we hence see that @xmath172 . furthermore , @xmath173 for all @xmath174 , so @xmath175 ( in the final equality , we used the trigonometric formula @xmath176 . ) if @xmath159 is such that @xmath177 , then implies @xmath178 , where @xmath179 , and hence @xmath180    observe that the second argument yields the stronger conclusion @xmath181 . in fact , a slightly more careful look at the estimates shows that @xmath177 if and only if @xmath181 and @xmath182 ( see exercise [ ex : derivativeestimate ] ) . however , this will not be required in the proofs that follow . let @xmath183 be arbitrary , and consider its orbit @xmath184 , i.e.   @xmath185 . let @xmath132 be a arbitrary disc around @xmath186 ; it is enough to show that @xmath187 for some @xmath6 . so assume , by contradiction , that @xmath188 for all @xmath6 . since @xmath189 , we then have @xmath190    by pick s theorem [ thm : pick ] , the hyperbolic derivative of @xmath139 , as a map from @xmath132 to @xmath50 , satisfies @xmath191 set @xmath192 ; then @xmath193 for all @xmath15 .    by lemma [ lem : hyper ] , we know that @xmath194 . hence , for the sequence @xmath195 to remain bounded , we must necessarily have @xmath196 . indeed , @xmath197 is an increasing and bounded , and hence convergent , sequence . thus @xmath198    by lemma [ lem : hyper ] , we see that @xmath199 and hence all finite accumulation points of @xmath200 must lie in the interval @xmath201 . since @xmath186 is not in the escaping set , the set of such finite accumulation points is nonempty . as this set is closed , we can let @xmath202 be the smallest finite accumulation point of the sequence @xmath200 ; say @xmath203 . notice that @xmath204 . by choice of @xmath3 , the sequence @xmath205 can not have a finite accumulation point , and hence @xmath206 . this contradicts  , and we are done . the proof leaves open the possibility that the escaping set has nonempty interior ( or even , a priori , that @xmath207 ) . we shall now exclude this possibility , which then allows us to establish sensitive dependence on initial conditions . [ thm : negativereal ] let @xmath208 be open and nonempty . then there are infinitely many numbers @xmath15 such that @xmath209\\neq \\emptyset$ ] . this will also follow from the ( stronger ) results in the next section , but the proof we give here relies on the same ideas as that of theorem [ thm : escapingdense ] , which gives the argument a nice symmetry . let @xmath210 be an open disc . we shall first prove that there is at least one @xmath6 such that @xmath134 intersects the negative real axis . so assume , by contradiction , that @xmath211\\ ] ] for all @xmath15 . by theorem [ thm : escapingdense ] , there is a point @xmath212 . we proceed similarly as in the proof of theorem [ thm : escapingdense ] , but now use the the hyperbolic metric of @xmath213 . the set @xmath214 $ ] is not backward invariant , hence @xmath4 is not locally expanding at every point of @xmath213 . however , there _ is _ expansion   even strong expansion   at points with sufficiently large real parts :    if @xmath215 and @xmath216 , then @xmath217    this follows by a similar calculation as in the proof of lemma [ lem : hyper ] : if we write @xmath163 with @xmath218 , then @xmath219 , and @xmath220    now the proof proceeds along the same lines as before . set @xmath221 and @xmath222 for @xmath15 . since @xmath223 is a holomorphic map , we again have @xmath224 for all @xmath6 by pick s theorem . the numbers @xmath225 need not be bounded below by @xmath99 . however , since @xmath226 , there is @xmath227 such that @xmath228 for @xmath229 , and hence @xmath230 this is a contradiction . so @xmath209\\neq\\emptyset$ ] for some @xmath6 . to see that there are infinitely many such @xmath6 , set @xmath231 , and apply the result to @xmath232 to find some @xmath233 with @xmath234\\neq \\emptyset$ ] . proceeding inductively , we find an infinite sequence @xmath235 with the desired property . [ cor : sensitive ] the exponential map @xmath81 has sensitive dependence on initial conditions with respect to spherical distance . we shall prove that @xmath4 satisfies definition [ defn : sphericalsensitive ] with @xmath236 and @xmath237 . indeed , let @xmath65 be open . then , by theorem [ thm : escapingdense ] , @xmath50 contains an escaping point @xmath238 , and there is some @xmath227 such that @xmath239 for all @xmath229 . by theorem [ thm : negativereal ] , there is @xmath240 and some point @xmath241 such that @xmath242 $ ] . hence , for @xmath243 , we have @xmath244 and @xmath245 , as desired . recall that _ topological transitivity _ , one of the properties required in the definition of chaos , means that we can move between any two nonempty open subsets of the complex plane by means of the iterates of @xmath4 . the goal of this section is to establish transitivity , and deduce that there are also points with dense orbits . [ thm : trans ] if @xmath50 , @xmath114 are nonempty and open , then there exists @xmath246 such that @xmath247 . we shall use the fact , established in the previous section , that the escaping set is dense in the plane . the key point is that @xmath4 is strongly expanding along the orbit of any escaping point @xmath3 . hence , for sufficiently large @xmath6 , @xmath139 maps a small disc around @xmath3 to a set that contains a disc of radius @xmath120 centred at @xmath248 . by elementary mapping properties of the exponential map , the latter disc is spread , after two more applications of @xmath4 , over a large part of the complex plane . this establishes topological transitivity . we now provide the details of this argument . let us begin with a simple observation . [ obs : escapingexpansion ] let @xmath249 , and set @xmath250 for @xmath25 . then @xmath251 and @xmath252 as @xmath146 . since @xmath253 for all @xmath15 , we have @xmath254 by definition of @xmath129 . furthermore , @xmath255 , and hence there is @xmath256 such that @xmath257 for all @xmath258 . for @xmath259 , we can use the chain rule to compute the derivative of @xmath260 : @xmath261 as @xmath262 . here we used the fact that @xmath263 , since @xmath264 for all @xmath27 . we next prove the above - mentioned fact concerning the iterated images of small discs around escaping points . [ prop : trans ] let @xmath249 . for @xmath25 , set @xmath265 and consider the disc @xmath266 of radius @xmath120 centred at @xmath267 ; i.e.  @xmath268 . then there are @xmath269 and a sequence @xmath270 of holomorphic maps @xmath271 with the following properties :    1 . @xmath272 , [ item : correctbranch ] 2 . @xmath273 for all @xmath274 , [ item : inversebranch ] 3 . @xmath275 as @xmath146 , and [ item : transcontraction ] 4 . @xmath276 as @xmath146 . [ item : smalldiameter ]    ( that is , for large @xmath6 there is a branch @xmath277 of @xmath278 that takes @xmath267 back to @xmath3 and is uniformly strongly contracting . )    observe that [ item : transcontraction ] implies [ item : smalldiameter ] . indeed , for @xmath274 , @xmath279 by the mean value inequality . hence by [ item : transcontraction ] , @xmath280    to prove the proposition , first assume additionally that @xmath281 for all @xmath282 . in this case , none of the discs @xmath266 contain the origin . for each @xmath25 , let @xmath283 be the branch of the logarithm with @xmath284 . what can we say about the range of this map @xmath285 ? since @xmath281 for all @xmath282 , we have @xmath286 for all @xmath274 , and hence @xmath287 again using the mean value inequality , we see that @xmath288 for each @xmath6 and all @xmath274 . in particular , and importantly , @xmath289 . it follows by induction that the composition @xmath290 is defined on @xmath266 , with @xmath291 for @xmath274 . hence @xmath277 satisfies  [ item : transcontraction ] , and [ item : correctbranch ] and  [ item : inversebranch ] hold by construction . this completes the proof when @xmath292 for all @xmath25 . if this is not the case , then   since @xmath3 is an escaping point   there still exists @xmath293 such that @xmath281 for all @xmath294 . we can thus apply the preceding case to the point @xmath295 . this means that , for every @xmath296 , there is a holomorphic map @xmath297 such that    a.   @xmath298 , b.   @xmath299 for all @xmath274 , c.   @xmath300 as @xmath146 , and d.   @xmath301 as @xmath146 .    by the inverse function theorem , there exists a neighbourhood @xmath50 of @xmath302 and a branch @xmath303 of @xmath304 mapping @xmath302 to @xmath3 . ( this also follows from repeated applications of suitable branches of the logarithm . observe that @xmath305 for @xmath25 . ) now let @xmath306 be a small closed disc around @xmath302 with @xmath307 . by [ item : smalldiameter ] , we have @xmath308 for sufficiently large @xmath6   say , for @xmath229 . hence we can define @xmath309 this map satisfies  [ item : correctbranch ] and  [ item : inversebranch ] by definition , and @xmath310 by property [ item : transcontraction ] ) of @xmath311 . ( since @xmath306 is compact , the continuous function @xmath312 assumes its maximum on @xmath306 , which is independent of @xmath6 . ) as mentioned above , after two additional iterates the discs in the preceding proposition will cover a large portion of the plane , as long they lie far enough to the right :    [ obs : montel ] let @xmath306 be any nonempty compact subset of the punctured plane @xmath313 . then there is @xmath314 with the following property . suppose that @xmath132 is a disc of radius @xmath120 , centred at a point having real part at least @xmath315 . then @xmath316 . the disc @xmath132 contains a closed square of side - length @xmath120 , also centred at @xmath317 . let @xmath318 be the real part of the left vertical edge of @xmath148 , then @xmath319 is the real part of the right vertical edge of @xmath148 . what is the image of @xmath148 under @xmath4 ? looking back at figure [ fig : exponential ] , we see that it is precisely a closed round annulus @xmath64 around the origin , with inner radius @xmath320 and outer radius @xmath321 .    if @xmath322 is sufficiently large , then @xmath64 is a rather thick annulus with large inner radius . it follows that @xmath64 contains a long rectangular strip of height @xmath120 , and the image of this strip will cover most of the complex plane , including the compact set @xmath306 . more precisely , suppose that @xmath323 ; then @xmath324 . hence we can fit a maximal rectangle @xmath325 of height @xmath120 into @xmath64 , symmetrically with respect to the imaginary axis and tangential to the inner boundary circle of @xmath64 . ( see figure [ fig : transitivity ] . ) let @xmath326 be the maximal real part of @xmath325 ( i.e. , @xmath326 is half the horizontal side - length of @xmath325 ) . we can compute @xmath326 using the pythagorean theorem : @xmath327 provided that @xmath328 . hence we see that @xmath329 , and the image of @xmath325 includes all points of modulus between @xmath330 and @xmath331 . in particular , we can set @xmath332 if @xmath333 , then we have @xmath334 , and @xmath335 . the claim follows .    as a consequence , we obtain the following stronger version of theorem [ thm : trans ] . [ cor : montel ] let @xmath336 be compact , and let @xmath65 be open and nonempty . then there is some @xmath256 such that @xmath337 for all @xmath258 .    to deduce the original statement of theorem [ thm : trans ] , simply choose @xmath306 to consist of a single point in @xmath114 . since the escaping set is dense in the plane , there exists some @xmath338 . set @xmath250 for @xmath25 , and let @xmath339 , @xmath227 and @xmath277 be as in proposition [ prop : trans ] . also let @xmath315 be the number from observation [ obs : montel ] ( for the same set @xmath306 ) . since @xmath3 is an escaping point , and by part   of proposition [ prop : trans ] , we can choose @xmath340 such that @xmath341 and @xmath342 for all @xmath343 . let @xmath343 . then @xmath344 by observation [ obs : montel ] . hence the claim holds with @xmath345 . the existence of dense orbits is closely related , and often equivalent , to that of topological transitivity . indeed , we can deduce the former from theorem [ thm : trans ] , by using the _ baire category theorem _ * exercise 16 in chapter 2 ) . this theorem implies that any countable intersections of open and dense subsets of the complex plane is itself dense and uncountable . [ cor : denseorbit ] the set @xmath346 of all points @xmath37 with dense orbits under the exponential map is uncountable and dense in @xmath45 . let @xmath347 be any non - empty open set . by theorem [ thm : trans ] , the inverse orbit @xmath348 is a dense subset of @xmath45 . note that @xmath349 is also open , as a union of open subsets . now consider the countable collection @xmath350 of open discs with rational centres and radii . clearly @xmath351 if and only if the orbit of @xmath3 enters every element of @xmath352 at least once , i.e. @xmath353 hence @xmath346 is indeed uncountable and dense , as a countable intersection of open and dense subsets of @xmath45 . we are now ready to complete the proof that the exponential map is chaotic , by proving density of the set of periodic points . in fact , we shall prove slightly more , namely that _ repelling _ periodic points of @xmath4 are dense in the plane . here a periodic point @xmath354 , with @xmath355 , is called _ repelling _ if @xmath356 . this ensures that any point @xmath357 close to @xmath354 is ( initially ) `` repelled '' away from the orbit of @xmath354   density of such points gives another indication that the dynamics of the exponential map is highly unstable ! ( it is , however , not difficult to show directly that _ all _ periodic points of @xmath4 are repelling ; see exercise [ ex : allperiodicpointsrepelling ] . ) [ thm : repel ] let @xmath65 be open and nonempty . then there exists a repelling periodic point @xmath358 . the idea of the proof is , again , to begin with an escaping point @xmath3 . our goal is to find an inverse branch of an iterate of @xmath4 that maps a neighbourhood of @xmath3 back into itself , with strong contraction . then the existence of a periodic point follows from the contraction mapping theorem ( * ? ? ? * theorem 3.6 ) ( also known as the _ banach fixed point theorem _ ) . we noticed already in the last section that the disc @xmath266 of radius @xmath120 around the @xmath6-th orbit point @xmath267 can be pulled back along the orbit in one - to - one fashion ( proposition [ prop : trans ] ) . we need to be able to `` close the loop '' , by pulling back a small disc around @xmath3 into @xmath266 . in other words , we are looking for a more precise version of observation [ obs : montel ] , as follows . [ lem : periodic ] let @xmath359 . then there are a disc @xmath62 centered at @xmath3 and a number @xmath360 with the following property :    for any disc @xmath132 of radius @xmath120 centred at a point with real part at least @xmath315 , there is @xmath361 such that @xmath362 and @xmath363 for all @xmath364 .    in other words , there exists a disc @xmath62 around @xmath3 that is not only covered by @xmath365 ( as we know it must be from observation [ obs : montel ] ) , but on which we can even define a branch of @xmath366 that takes it back into @xmath132 . it is not difficult to extend the result , with a similar proof , to see that this is true for _ any _ disc @xmath62   and indeed any simply - connected domain   whose closure is bounded away from @xmath30 and @xmath12 . set @xmath367 and @xmath368 . for any @xmath369 , there is a branch @xmath285 of the logarithm on @xmath62 whose values have imaginary parts between @xmath370 and @xmath371 . each @xmath285 is continuous on @xmath62 and satisfies @xmath372 for all @xmath364 . consider the sets @xmath373 , with @xmath369 ; then @xmath374 . so the @xmath375 form a linear sequence of domains of uniformly bounded diameter , tending to infinity in the direction of the positive and negative imaginary axes . consider all preimage components of some @xmath375 under @xmath4 , for @xmath376 ( since @xmath377 might contain the origin ) . on each of these , we can define a branch of @xmath366 taking values in @xmath62   hence we should show that any disc @xmath132 of radius @xmath120 contains at least one such component , provided that its centre lies sufficiently far to the right . this should be clear from the mapping behaviour of the exponential map ( figure [ fig : exponential ] ) . indeed , for every odd multiple of @xmath378 , there is a sequence of sets in question whose imaginary parts tend to this value , and having real parts closer and closer together ( see figure [ fig : preimage ] ) . more formally , consider the points @xmath379 . set @xmath380 and let @xmath132 be a disc of radius @xmath120 centred at a point @xmath317 with @xmath381 . since @xmath382 , we can find @xmath383 such that @xmath384 furthermore , choose @xmath385 such that @xmath386 , and let @xmath387 be the branch of the logarithm mapping the upper half - plane to the strip @xmath388 . let @xmath389 . then @xmath390 by choice of @xmath387 . furthermore , by definition of @xmath62 and @xmath285 , we have @xmath391 by  , we conclude that @xmath392 dividing by @xmath393 , and recalling that @xmath394 , we see that @xmath395 hence @xmath396 thus @xmath397 and hence @xmath398 . hence the branch @xmath399 indeed maps @xmath62 into @xmath132 . moreover , @xmath400 for all @xmath364 , while @xmath401 on @xmath375 . hence , if we choose @xmath402 , then @xmath363 for all @xmath364 , as required . let @xmath403 be open and nonempty . by theorem [ thm : escapingdense ] , there is an escaping point @xmath404 . choose a disc @xmath62 around @xmath3 and @xmath314 and as in lemma [ lem : periodic ] . by shrinking @xmath62 , if necessary , we may suppose that @xmath405 . let @xmath406 be a smaller disc also centred at @xmath3 . so that @xmath407 . as in section [ sec : transitivity ] , set @xmath265 and @xmath268 . let @xmath270 be the inverse branches from proposition [ prop : trans ] . by conclusions [ item : smalldiameter ] and [ item : transcontraction ] of that proposition , we may assume that @xmath227 is large enough to ensure that @xmath408 and @xmath409 for all @xmath274 .    since @xmath3 is an escaping point , there is @xmath410 such that @xmath341 for all @xmath258 . by lemma  [ lem : periodic ] , there is thus a branch @xmath311 of @xmath366 that maps @xmath62 into @xmath266 , with @xmath411 for all @xmath412 . it follows that @xmath413 , and that @xmath414 is a contraction map . as @xmath415 is compact , and hence complete , this function has a fixed point @xmath416 by the contraction mapping theorem . by construction , @xmath417 hence @xmath354 is indeed a repelling periodic point of @xmath4 , as required . the realization that the exponential map @xmath4 acts chaotically on the complex plane is not the end of the story . rather , it leads to further questions about the qualitative behaviour of @xmath4 , and much research has been done since misiurewicz s work . the picture is still far from complete , and several interesting questions remain open . here , we restrict to a small selection of results and ideas , referring to the literature for further information .    * the escaping set of the exponential . * the escaping set @xmath129 of the exponential map played an important role in our proof of theorems [ thm : orbits ] and [ thm : chaotic ] . we saw in theorem [ thm : escapingdense ] that this set is dense in the plane , and hence it is plausible that a thorough study of its fine structure will yield information also about the non - escaping part of the dynamics . we already saw that @xmath129 contains the real axis together with all of its preimages under iterates of @xmath4 but there are many other escaping points ! indeed , devaney and krych @xcite observed the existence of uncountably many different curves to infinity in @xmath129 , most of which do _ not _ reach the real axis under iteration . later , schleicher and zimmer @xcite were able to show that _ every _ point of @xmath129 can be connected to infinity by a curve in @xmath129 . maximal curves in the escaping set are referred to as `` rays '' or `` hairs '' , and they provide a structure that can be exploited in the study of the wider dynamics of @xmath4 . however , the way in which these rays fit together to form the entire escaping set is rather non - trivial . for example , while each path - connected component of @xmath129 is such a curve , and is relatively closed in @xmath129 ( i.e. , rays do not accumulate on points that belong to other rays ) the escaping set nonetheless turns out to be a _ connected _ subset of the plane @xcite . furthermore , while many rays end at a unique point in the complex plane , some have been shown to accumulate everywhere upon themselves @xcite , resulting in a very complicated topological picture . for which rays this can occur , and whether other types of accumulation behaviour are possible , requires further research .    taken together , these results provide some indication that the escaping set is a rather complicated object . in fact , even iterated preimages of the negative real axis ( all of which are simple curves tending to infinity in both directions ) result in highly nontrivial phenomena and open questions . in 1993 , devaney @xcite showed that the closure of a certain natural sequence of such preimages has some `` pathological '' topological properties . he also formulated a conjecture concerning the structure of this set and its stability under certain perturbations of the map @xmath4 , which remains open to this day .    * measurable dynamics of the exponential . * corollary [ cor : denseorbit ] ( and its proof ) means that , topologically , `` most '' points have a dense orbit . it is natural to ask also about the behaviour of `` most '' points with respect to area : if we pick a point @xmath27 at random will its orbit be dense ? lyubich @xcite and rees @xcite independently gave an answer in the 1980s : for a random point @xmath27 , the orbit of @xmath29 is _ not _ dense ; rather , its set of limit points coincides precisely with the orbit of @xmath30 . in other words , after a certain number of steps , the orbit will come very close to @xmath30 , and then follow the orbit @xmath418 for a finite number of steps . our point might then spend some additional time close to @xmath12 , until it maps into the left half - plane . in the next step , it ends up even closer to @xmath30 , and so on . we can furthermore also ask about the relative `` sizes '' of the sets of points with various other types of behaviour ( for example , with respect to _ fractal dimension _ ) . it again turns out that there is a rich structure from this point of view ; see  e.g.  @xcite . * transcendental dynamics . * to place the material in this paper in its proper context , let us finally discuss iterating a holomorphic self - map @xmath81 of the complex plane in general . to obtain interesting behaviour , we assume that @xmath4 is non - constant and non - linear . as before , a key question is how the behaviour of orbits varies under perturbations of the starting point @xmath3 . to this end , one divides the starting values into two sets : the closed set of points near which there is sensitive dependence on initial conditions is called the _ julia set _ @xmath419 , while its complement   where the behaviour is _ stable _   is the _ fatou set _ @xmath420 . ( see @xcite for formal definitions and further background . ) by the magic of complex analysis , the   rather mild   notion of instability used to define the julia set always leads to globally chaotic dynamics :    [ thm : fatoujuliabaker ] the julia set @xmath419 is always uncountably infinite , and @xmath421 . furthermore , the function @xmath422 is chaotic in the sense of devaney . the key part of this theorem is the density of periodic points in the julia set . that @xmath419 is uncountable and that @xmath4 is topologically transitive was known already ( albeit in different terminology ) to pierre fatou and ( in the case of polynomials ) gaston julia , who independently founded the area of holomorphic dynamics in the early twentieth century . for polynomials   and indeed for rational functions   the density of periodic points in the julia set was also established by fatou and julia , but it took about half a century until baker @xcite completed the proof for general entire functions .    with this general terminology , misiurewicz s theorem says precisely that @xmath423 . ( we emphasize that there are many entire functions with nonempty fatou set . as an example , consider @xmath424 . then @xmath425 for @xmath426 , and hence the entire unit disc is in the fatou set . ) it can be shown that there are only a few possible types of behaviour for points in the fatou set of an entire function @xcite . using classical methods , most of these can be excluded fairly easily in the case of the exponential map ; the difficult part is to show that there can be no _ wandering domain _ , i.e.  a connected component @xmath50 of the fatou set such that @xmath427 for all @xmath428 . misiurewicz used the specific properties of the exponential function , but more general tools for ruling out the existence of wandering domains have since been developed . the most famous is due to sullivan , who showed that rational functions never have wandering domains , answering a question left open by fatou . sullivan s argument , which uses deep results from complex analysis , can be extended to classes of entire functions containing the exponential map @xcite . as mentioned in the introduction , this provides an alternative ( though highly non - elementary ) method of establishing misiurewicz s theorem . the study of wandering domains , and when they can occur , continues to be an active topic of research in transcendental dynamics ; we refer to @xcite for a discussion and references . [ ex : denseorbit ] let @xmath429 , and let @xmath18 be a continuous function . we say that @xmath430 _ has a dense orbit _ if the set of accumulation points of the orbit of @xmath0 is dense in @xmath19 . ( note that this differs subtly from the requirement that the orbit of @xmath0 is dense when thought of as a _ subset _ of @xmath19 . however , the two conditions are equivalent if @xmath19 has no isolated points . ) prove : if @xmath433 is _ any _ distance function that is topologically equivalent to euclidean distance ( i.e. , a round open disc around a point @xmath3 contains some disc around @xmath3 in the sense of the distance @xmath70 , and vice versa ) , then @xmath4 has sensitive dependence with respect to @xmath70 . ( so sensitive dependence with respect to spherical distance is the strongest such condition we can impose . )    _ hint . _ observe that the possible pairs @xmath434 in definition [ defn : sphericalsensitive ] all belong to a closed and bounded subset of @xmath435 , which depends only on @xmath36 and @xmath325 . then use the fact that @xmath70 is continuous as a function of two complex variables ( with respect to euclidean distance ) . [ ex : mobius ] suppose that @xmath97 is a conformal automorphism ( i.e. holomorphic and bijective ) with @xmath88 . conclude , using the schwarz lemma , that @xmath4 is a rotation around the origin . deduce that any conformal automorphism @xmath97 is of the form  .", "tags": [], "output_text_a": "The paper explores the dynamics of the complex exponential map, particularly focusing on the behavior of orbits when iterating the function \\( f(z) = e^z \\) on complex numbers. Unlike the real case where orbits tend to infinity, complex orbits exhibit chaotic behavior, including dense orbits, periodic points, and escaping points. The paper proves that the exponential map is chaotic in the sense of Devaney, meaning it has dense periodic points and is topologically transitive. The authors provide an elementary and conceptual proof of these properties, requiring only basic knowledge of complex analysis and hyperbolic geometry. The paper also discusses the implications of these findings for understanding the dynamics of transcendental functions and highlights open questions in the field. The study of the escaping set, which is dense in the complex plane, plays a crucial role in understanding the chaotic nature of the exponential map. The paper concludes with exercises to further explore these concepts.", "output_text_b": "The paper discusses the chaotic behavior of the exponential map in the complex plane. It starts by considering the sequence obtained by repeatedly applying the exponential function to a complex number. Unlike the real case, not every complex orbit tends to infinity. The paper then introduces Devaney's definition of chaos and proves that the exponential map is chaotic in this sense. The proof relies on the fact that the set of periodic points is dense in the complex plane and that the function is topologically transitive. The paper also discusses sensitive dependence on initial conditions, which is a key property of chaotic systems.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, focusing on the chaotic behavior of the complex exponential map and its implications.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem, which is the behavior of orbits under the complex exponential map.\n4. **Methodology**: The summary mentions the methodology, stating that the authors provide an elementary and conceptual proof using basic complex analysis and hyperbolic geometry.\n5. **Significant Results**: The summary includes significant results, such as the chaotic nature of the exponential map and the density of the escaping set.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"chaotic behavior\" and \"escaping set.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data, as the paper is theoretical.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding the dynamics of transcendental functions and highlights open questions.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, focusing on the chaotic behavior of the exponential map in the complex plane and the application of Devaney's definition of chaos.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem by discussing the behavior of the exponential map and its chaotic nature.\n4. **Methodology**: The summary mentions the use of Devaney's definition of chaos and the proof involving the density of periodic points and topological transitivity.\n5. **Significant Results**: The summary includes significant results, such as the chaotic nature of the exponential map and the sensitive dependence on initial conditions.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"chaotic\" and \"sensitive dependence.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Experiments/Data**: The summary does not mention any key experiments or data, which is a requirement.\n10. **Significance/Impact**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "x - rays have been an essential probe to study energetic astrophysical phenomena , including mass accretion onto black holes in particular . starting with the first identification of cygnus x-1 ( hereafter cyg x-1 ) as a black hole binary in the early 1970 s ( e.g. , @xcite , tananbaum et al .  1972 , @xcite ) , the spectral as well as timing studies of black hole binaries , including cyg x-1 , have established the presence of two distinct states : the high / soft state and the low / hard state ( e.g. , , done et al . 2007 ) .    in the high / soft state , an optically thick and geometrically thin accretion disk releases most of the gravitational energy in locally thermal equilibrium radiation . the spectra in this state can be fairly well reproduced by multi - color blackbody radiation ( mitsuda et al . 1984 and makishima et al .  1986 ) from such a `` standard '' accretion disk and a powerlaw emission with a photon index of @xmath2 of which the origin is commonly considered to be compton scattering by a disk corona with a hybrid ( thermal + non - thermal ) electron distribution ( e.g. , @xcite , gierliski  et al .  1999 , and @xcite ) , along with reflection features arising from disk regions illuminated by the powerlaw component . a typical high / soft state spectrum from cyg x-1 is shown as black in figure [ suzakuspec ] .    in the low / hard state , the spectrum is no longer dominated by the disk emission . instead , most of the energy is released in hard x - rays via un - saturated comptonization by maxwellian electrons ( e.g. , @xcite ) . this comptonizing region , conventionally called a `` corona '' , is hot ( with a typical temperature of @xmath1 100  kev , possibly with a much higher ion temperature , so most probably geometrically thick ) , and optically thin , in marked contrast to the standard disk which is cool , geometrically thin and optically thick . however , some optically thick material is still present in this state : there is a weak thermal component seen in the soft x - ray bandpass which presumably provides seed photons for the comptonization , and there is clear evidence for some reflected emission ( iron lines and compton humps ; e.g. , gierliski et al 1997 ; gilfanov , churazov & revnivtsev 1999 ; @xcite , @xcite , ibragimov et al 2005 ) . a typical low / hard state spectrum from cyg x-1 , highlighting the very different properties of this state , is shown in red in figure [ suzakuspec ] . the black one was obtained in the high / soft state on 2010 december 16 . the red one was taken in the low / hard state on 2005 october 5 , which is the same as used in makishima et al . ( 2008).,scaledwidth=40.0% ]    the relative geometry of the disk and corona in the low / hard state is still a matter of debate . one type of models assume that the corona replaces the inner disk , with the flow making a transition to an alternative , hot , geometrically thick , optically thin solution to the accretion flow equations ( e.g. , @xcite ; @xcite ; @xcite ) . exterior to this , the outer truncated disk provides a source of seed photons for the compton scattering from the hot flow , and a site for the reflected emission . these truncated disk / hot inner flow models are successful in explaining the clear correlations seen in the data ( e.g gilfanov , churazov & revnivtsev 1999 ; @xcite , done , gierliski & kubota 2007 ) . alternatively , other geometries have also been proposed , the vertically separated sandwich `` disk - corona configuration '' ( e.g. , @xcite , @xcite , @xcite ) , the vertically offset `` lamppost '' model ( e.g. fabian et al 2012 ) , and the vertically outflowing corona ( beloborodov et al . 1999 ) . a key difference between these models for the low / hard state is the location of the innermost disk radius . in the truncated disk model , it is assumed to be larger than the innermost stable circular orbit , while in the other geometries the disk is envisaged to extend down to the last stable orbit . however , a number of spectral analyses ( e.g. , @xcite ; @xcite ; @xcite ) and timing studies ( miyamoto & kitamoto 1989 ; negoro et al . 1994 ; @xcite ; @xcite ; @xcite ; remillard & mcclintock 2006 ) were unable to unambiguously settle the issue . this is because the disk emission is much weaker than the comptonized emission in this state , appearing only as a very subtle excess in the lowest energies as shown in figure  1 . to constrain the disk emission requires the best possible constraints on the broad band comptonized emission . suzaku , the fifth japanese x - ray satellite , carries the x - ray imaging spectrometer ( xis ; koyama et al . 2007 ) located at the foci of the x - ray telescope ( xrt ; serlemitsos et al . 2007 ) , and a non - imaging hard x - ray instrument , the hard x - ray detector ( hxd ; takahashi et al . 2007 ; kokubun et al . 2007 ; yamada et al . 2011 ) . these two instruments enable us to simultaneously measure a wide - band ( typically 0.5300 kev ) spectrum of bright hard x - ray sources . with this capability , suzaku has observed cyg x-1 25 times from 2005 to 2009 in the low / hard state and hard intermediated state , over which the 110 kev flux varied by a factor of @xmath1 3 . the 0.5300 kev spectra taken in the first observation has been reproduced by makishima et al . 2008 ( paper  i ) , invoking two ( hard and soft ) comptonization components , a truncated disk , and reflection components ( the `` double - compton modeling '' itself was first applied to cyg x-1 by frontera et al . 2001 and to agn by magdziarz et al . based on the `` double - compton modeling '' and other observational facts as to fe - k lines and the refection strength , they proposed that there is an overlapping region between the disk and corona , and changes in the coronal coverage fraction of the disk produce the fast variation . although this view was confirmed in subsequent suzaku observations ( @xcite , fabian et al 2012 ) , these authors discussed several possible alternatives to the double - compton view , including non - thermal comptonization , jet emission , and complex ionized reflection . to disentangle such modeling degeneracy , we use the variability on different timescales and try to identify separate spectral components in a model - independent way . this was already initiated by torii et al . 2011 ( paper  ii ) , who analyzed the hxd ( pin and gso ) data from the 25 observations for spectral and timing properties of the hard x - ray emission . at that time , they were not able to include the xis data as these are often severely affected by photon pileup . because of this limited energy range , they could fit their data by a single comptonization component together with a simple reflection model . now that we have established a method to correct xis data for pile - up effects ( yamada et al . 2012 ) , we can complement the work in paper  ii , by including all the 25 xis data sets . thus in this paper , we can use the entire broad bandpass of suzaku to study the spectral evolution through the low / hard and hard - intermediate state . the distance to cyg x-1 has been recently determined as @xmath3 kpc , via a trigonometric parallax measurement using very long baseline array @xcite . this value is consistent with an independent measurement using dust scattering halo ( xiang et al . 2011 ) . based on this distance , the black hole mass and its inclination were derived as @xmath4 and @xmath5 @xcite , respectively . we adopt these values throughout the present paper . unless otherwise stated , errors refer to 90% confidence limits . * the deadtime - corrected exposures and the live - time fractions in percent in the parentheses . * the nxb - subtracted count rates and the nxb fractions in percent in the parentheses . the errors are statistical errors only . * the energy flux of @xmath6@xmath7 kev in an unit of 10@xmath8 erg s@xmath9 @xmath10 .", "tags": [], "output_text_a": "The paper discusses the use of X-rays to study black hole binaries, focusing on Cygnus X-1, a well-known black hole binary system. It highlights the two distinct states of black hole binaries: the high/soft state and the low/hard state. In the high/soft state, the accretion disk is optically thick and geometrically thin, emitting thermal radiation, while in the low/hard state, the spectrum is dominated by hard X-rays due to Comptonization by hot electrons in a corona. The paper explores different models for the geometry of the disk and corona in the low/hard state, including the truncated disk model and alternative geometries like the lamppost model. The study uses data from the Suzaku satellite, which observed Cygnus X-1 multiple times, to analyze the spectral evolution and variability in these states. The paper aims to disentangle modeling degeneracies by using variability on different timescales to identify separate spectral components. The distance to Cygnus X-1 and the black hole's mass and inclination are also discussed, providing a comprehensive analysis of the system's properties. [[ ## completed ## ]]", "output_text_b": "This article discusses the study of black holes using X-ray emissions, focusing on Cygnus X-1. The paper describes two distinct states of black hole binaries: the high/soft state and the low/hard state. The high/soft state is characterized by an optically thick and geometrically thin accretion disk that releases most of the gravitational energy in locally thermal equilibrium radiation. In contrast, the low/hard state is dominated by hard X-ray emissions through unsaturated Comptonization by Maxwellian electrons in a hot, geometrically thick, and optically thin corona.\n\nThe article further explores the geometry and composition of the corona in the low/hard state, presenting different models such as truncated disk/hot inner flow models, vertically separated sandwich \"disk-corona configuration,\" vertically offset \"lamppost\" model, and vertically outflowing corona. The key difference among these models lies in the location of the innermost disk radius.\n\nThe paper highlights the importance of Suzaku, the fifth Japanese X-ray satellite, in simultaneously measuring a wide-band (0.53-100 keV) spectrum of bright hard X-ray sources. Suzaku has observed Cygnus X-1 25 times in the low/hard state and hard intermediate state, providing valuable data for understanding the spectral evolution in these states.\n\nLastly, the article mentions the recent determination of the distance to Cygnus X-1 (approximately 2 kpc) and the derived black hole mass and inclination.", "score": 0.30000000000000004, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of X-rays to study black hole binaries, focusing on Cygnus X-1, and highlighting the two distinct states of black hole binaries.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is mentioned, which is the study of the spectral evolution and variability of Cygnus X-1 in different states.\n4. The methodology or approach used in the paper is mentioned, including the use of data from the Suzaku satellite.\n5. Significant results or conclusions drawn by the authors are included, such as the exploration of different models for the geometry of the disk and corona.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"Comptonization\" and \"corona.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments or data used in the research are mentioned, specifically the observations from the Suzaku satellite.\n10. The summary reflects the paper's significance by discussing the comprehensive analysis of Cygnus X-1's properties and the potential impact of disentangling modeling degeneracies.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings regarding the study of black holes using X-ray emissions and the distinct states of black hole binaries. It also mentions the models and the role of Suzaku in the research.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly state the research problem or question addressed by the paper.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of Suzaku for measuring the X-ray spectrum, which is part of the methodology.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary mentions the determination of the distance to Cygnus X-1 and the derived black hole mass and inclination, which are significant results.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"Comptonization\" and \"corona\" but does not explain them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the observations made by Suzaku, which are key data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "in high energy physics experiments , photomultipliers are popular devices used as a light - to - charge transducer . short - term instability ( rate effect ) of photomultiplier s gain has been a well - known phenomenon  @xcite , which poses one of the major problems to realize good detector performance . for photomultipliers used in our trigger counter  @xcite , stability was one of the major concerns . roughly speaking , gain stability within @xmath0 was required up to the counting rate of a few mhz . more detailed accounts will be given in  4.2 .    in order to investigate photomultiplier s gain change , a stable pulsed light source and/or an output light monitor system were needed . considering pulse rate involved and handiness , the only light source available was led . however , led light outputs might vary substantially at a repetition rate of a mhz region . this motivated us to develop a light monitor system , which was suitable to a pulsed light source lit at the repetition rate of mhz or higher . needed accuracy for our particular application was a few % . we employed a photon counting method for this purpose . we describe the results of studies on the led light source and its monitor system in the following sections . this report is organized as follows : in  2 the principle of the photon counting method is described . the experimental setup and the results of test measurements are shown in  3 and  4 , respectively . the section 5 summarizes our studies . fig.[fig - principle ] shows a schematic diagram which illustrates our method . a photomultiplier under test , placed in front of a pulsed led , receives most of the light output . we sample a very small portion of the lights and inject it to a monitor photon detector . let @xmath1 denotes the sampling fraction of photons ; it mainly depends on geometrical factors such as the distance between the light source and detector , and , if exist , an aperture and attenuation filters between them . we regard this fraction to be practically constant during the course of a measurement . the expected number of photons per pulse detected by the monitor detector is given by @xmath2 , where @xmath3 represents the average number of photons per pulse emitted by led , and @xmath4 the monitor s detection efficiency . the probability distribution for @xmath5 is given by the poisson distribution . in this method we adjust @xmath6 , the average number of photons per pulse , to be much less than unity . this can be done at will by changing , for example , aperture size or attenuation filters . since the probability to detect one or more photons per pulse is given by @xmath7 @xmath8 can be represented by @xmath9 we can monitor @xmath10 by measuring @xmath11 , and thus the average led light output assuming @xmath12 to be constant . here an important feature required for the monitor photon detector is capability of discriminating the single photon signal from background noise . in our actual setup we used a photomultiplier as a monitor detector . as described in the following section in detail , we could distinguish clearly a single photoelectron peak from a pedestal@xcite . we measured the counts in which outputs from the monitor photomultiplier exceeded some prescribed level set between the pedestal and single photoelectron peak . then @xmath11 was given by the counts divided by the total number of pulses which triggered the led light source . the principal advantages of the method are the followings :    ( i ) : :    as long as the single photon signal can be discriminated from    background noise , small gain variation of a monitor photon detector    itself has almost no effect on @xmath11 and thus    @xmath10 . this is the most important feature    in this method . by contrast , if @xmath10 is    much bigger than one and the monitor photon detector measures the    light output every pulse , it is not possible to distinguish the change    in the led output itself from the gain variation in the monitor    detector . ( ii ) : :    if the peak corresponding to the single photon can be observed , the    gain change may be monitored by measuring its peak position . this    feature is helpful to demonstrate reliability in the monitor detector . ( iii ) : :    the monitor detector must be able to discriminate the single photon    from background noise , as mentioned above . however , it is not    necessary to resolve single photon from two ( or more ) photons since    the measured quantity is @xmath11 . this lessens    requirement for the monitor detector . ( iv ) : :    the actual counting rate for the monitor detector can be set low by    adjusting @xmath10 to be much less than unity . we note that monitor detectors are usually more stable at lower    counting rates for a fixed gain . disadvantages of the method , on the other hand , are that it monitors not instantaneous but average light outputs , and that it takes rather long time to obtain enough statistical accuracy . for example , when an led is lit at 10 khz and @xmath10 is @xmath13 , then it takes 100 sec to obtain @xmath14 counts , the number of counts needed to reach the statistical accuracy of @xmath15 . it is expected that main source of the systematic errors for the method stems from various backgrounds to the monitor photon detector . it turns out that thermal noises and after - pulses are the two major backgrounds when a photomultiplier is used as a monitor photon detector . we thus studied these backgrounds carefully ( see below for the detail ) . as shown in fig.[fig - setup ] , the system consisted of a light source , a quartz fiber for photon sampling , a monitor photon detector , and a trigger and read - out electronic system . a photomultiplier subject to rate effect studies was placed in front of the light source . a brief description of each component is given below . we used a ` blue ' led  @xcite as a light source . for the present application , it was found advantageous to use blue in two respects . first , the tail of its light output was substantially shorter(@xmath1620 nsec ) than that of a ` green ' led ( @xmath1650 nsec )  @xcite  @xcite . secondly , the emission spectrum of the blue led resembled more to that of the scintillator we used ; a desirable property for the photomultiplier gain test . [ fig - circuit ] shows the led driver circuit . the circuit provided a constant charge to the led stored in the capacitor @xmath17 . the discharge was triggered by a differential switch , which in turn initiated by an external nim pulse . after the discharge , the capacitor @xmath17 was recharged by an external power supply with the charge - up time constant @xmath18 of 0.1 @xmath19sec . a variable frequency nim clock generator was used to produce a master pulse . its output was fed to the led driver and to a scaler . output signals from the monitor photon detector , a photomultiplier for the present case , were discriminated and fed into a coincidence circuit . we set the discriminator threshold level at about 1/4 of the single photoelectron peak . the coincidence signal of the discriminator output and the master clock produced a 60-nsec - long gate to a charge sensitive adc , which integrated the raw signal from the monitor photon detector . the gate signal was also counted by another scaler . data from the adc and scalers were read by a computer via a camac system . as stated , we used a photomultiplier as a monitor photon detector . selection of an actual photomultiplier was made by considering ( i ) single - photoelectron resolution , ( ii ) thermal noise rate , and ( iii ) after - pulse rate . we tested the following types of photomultipliers ; hamamatsu r329 , r1332 , r2165 and r3234  @xcite . it was found that backgrounds due to the after - pulse depended strongly upon photomultiplier types , and that , for some of them , they were the source of the most serious systematic errors . we finally chose r3234 from those listed above with an emphasis on this point . [ [ single - photoelectron - resolution ] ] single - photoelectron resolution + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    fig.[fig - single ] shows the pulse height spectrum obtained with the photomultiplier actually used ; the left peak ( scaled off ) corresponds to a pedestal and the right to the single photoelectron . we defined a signal count as an event above a software cut placed at the bottom of the valley on this spectrum . the actual cut position was 0.4 in units of the single photoelectron , i.e. the adc counts between the pedestal and single photoelectron peak . it was confirmed that variation of the cut position within a reasonable range from the nominal value resulted a negligible change in the final results  @xcite . [ [ thermal - noise ] ] thermal noise + + + + + + + + + + + + +    thermal ( random ) noises may contribute to a systematic error . we measured the noise rate and found it to be @xmath16 400 hz at 15 @xmath20 . the background count per pulse is then @xmath16400 hz@xmath2160 nsec ( adc gate width ) @xmath22 . this should be compared with an average signal rate of @xmath10 . the background is thus severe at small @xmath10 ; however , it is possible to adjust @xmath1 so that @xmath10 is much larger than the noise contribution . in our actual measurements ( see  4.2 for an example ) , the lowest value for @xmath10 was chosen to be 0.006 . thus the error due to this noise is negligible ( @xmath23 )  @xcite . [ [ after - pulse ] ] after - pulse + + + + + + + + + + +    an after - pulse is a spurious pulse induced in a photomultiplier by previous pulses  @xcite . it is induced by positive ion hits on a photocathode which is produced by collisions between electrons and residual gas molecules in the tube . since original electron currents are initiated by input light , the after - pulse has time and rate correlation with the input light . let s denote by @xmath24 the average number of after - pulses per input light which emits single photoelectron . then , in the worst case , namely when the after - pulse happens to have a complete time correlation with the following signal pulse , @xmath10 would increase to @xmath25 . thus the only way to reduce this error is to choose a photomultiplier with small @xmath24 .    in order to find an appropriate photomultiplier , we measured this quantity @xmath24 . the measurement was done with the same setup shown in fig.[fig - setup ] with one minor change ; the delay generator started the gate pulse about 200 nsec after the led light pulse . the gate width determined the time interval to look for the after - pulses . the results are shown in fig.[fig - afr3234 ] for the photomultiplier we selected ( r3234 ) , together with another type of 2-inch photomultiplier ( r2165 ) for comparison . in the figures , the abscissa represents the integration period ( the gate width ) while the ordinate represents the after - pulse probability @xmath24 . as can be seen , the integrated counts saturate around the gate width of 10 @xmath19sec . from the results above and similar measurements for the other types of photomultipliers listed above , we concluded that the integration time of 128 @xmath19sec was long enough to detect practically all the after - pulses . the selected photomultiplier r3234 has particularly small value ( @xmath26  @xcite . we thus expect the error due to this background is also negligible . it is difficult to determine the absolute accuracy of this method experimentally since there is no ` ideal ' light source to calibrate with . nevertheless we wanted to obtain a crude ` estimate ' of its accuracy , and thus compared it with one other method .    in place of a test photomultiplier , we set an r329 photomultiplier operated in a diode mode . this was accomplished by keeping the cathode at -300 v while all the other dynodes grounded . the average cathode current was measured by an amplifier and a current monitor . since there was no electron multiplication involved , the output current was expected to be proportional to the input light even at high rate . at low rate , however , the output was dominated by electronic noise , and the measurement became less accurate . actually we measured the output current produced by the led light pulse at the repetition rate between 0.7 mhz and 5 mhz  @xcite . the measured values of the current from r329 were converted to the charge per pulse and then normalized to that at 0.7 mhz . the resultant quantities , namely the normalized led light outputs per pulse as a function of pulse rate , are displayed in fig.[fig - cathode ] , together with the corresponding quantities obtained with the photon counting method . as seen , they agree fairly well with each other up to 5 mhz . the maximum deviation is found to be about @xmath27 . the origin of the discrepancy is not clear at present  @xcite .          in this subsection , we show an example of the gain stability measurement performed with this system . the photomultipliers under test were used in the trigger counter in our experiment  @xcite . their short - term stability was one of the major concerns because of the following reasons . the trigger counter was composed of a set of plastic scintillator slabs and was installed in an intense neutral @xmath28 beam . scintillation lights from the counter were read by photomultipliers attached at the both ends of the scintillators . we chose hamamatsu r1398@xcite , a photomultiplier with a bialkali photocathode which had a spectral response well matched with an emission spectrum of the scintillator , and a linear focused dynode chain which provided a fast rise time and a good pulse linearity . these properties , together with its cathode diameter ( 1 - 1/8@xmath29 ) , were well suited to our application . we used an ac - coupled preamplifier and base - line restorer as a part of the read - out circuit . the preamplifier ( with @xmath16 30 db gain ) helped to reduce photomultiplier s average anode current while the base - line restorer compensated base - line shifts at high counting rate . if the photomultiplier gains were to be set high to compensate possible gain drop at high counting rate , hit rates would increase by background particles such as neutrons and gammas in the beam . for our experiment ( @xmath30 rare decay ) , these background hits should be avoided as much as possible to reduce trigger rates and to ensure high reconstruction efficiency in off - line analysis . in addition a large pulse would tend to cause a longer dead time for a preamplifier due to saturation , making the counter inefficient . as a consequence the photomultiplier gain should be kept as low as practical while maintaining @xmath31 efficiency for the minimum ionizing particles . this demanded good gain stability ( say relative gain change within @xmath32 ) at the expected highest counting rate ( i.e. , @xmath33 mhz for each photomultiplier ) . fig.[fig - r1398 ] shows the result for the r1398 type photomultiplier . it shows the r1398 output divided by @xmath10 as a function of the led pulse rate ; the ratio is then rescaled to 1 at 86 khz . in the measurement , the led light intensity on r1398 was adjusted to give approximately 100 photoelectrons per pulse independent of the pulse rate , which was approximately equal to the average scintillator light output produced by minimum ionizing particles passing through our trigger counter . we accomplished this by pulsing 7 identical leds in turn , thus keeping the effective pulse rate for any individual led less than 1 mhz  @xcite . the maximum deviation of the normalized r1398 output from the unity is found to be about 3% in the rage from 86 khz to 5 mhz . thus we concluded the photomultiplier , combined with the base used , met our requirements . we note that the two of the photomultipliers , r3234 ( the monitor photon detector ) and r1398 , ` see ' quite different photons ; the former sees mostly single photons with relatively low rates while the latter sees much more intense photons with a rate up to 5 mhz . thus an accidental cancellation of systematic errors is expected to be uncommon . the result in turn gives good confidence to the monitoring method . in order to study photomultiplier s gain stability at high counting rate , we constructed an led pulsed light source and its output monitor system . for the monitor system , we employed a photon counting method . it samples a small portion of light output and measures single photon rates with a monitor photon detector . it thus monitors the relative light output from the source . it is virtually insensitive to the gain change of a monitor photon detector because , as long as the discrimination between the signal from background noise is clear , the rate of the single photon count remains constant .    in our actual setup , we used a photomultiplier as a monitor photon detector . thermal ( random ) noises and after - pulses were found to be the two main backgrounds . we could make the errors due to these backgrounds sufficiently small ( @xmath34 ) by selecting a suitable photomultiplier and a operating condition . we tentatively assign @xmath35 as an absolute accuracy in this method . this accuracy was estimated by the method described in  4.1 . our direct application of this system was to investigate the gain stability of the photomultiplier ( r1398 ) used in our trigger counter . as shown in  4.2 , it was proved that the photomultiplier and base system could satisfy our requirements . at the same time , it is found that the photon counting method offers a simple way to monitor outputs from a pulsed light source . together with an led light source , it provides a handy way to investigate photomultiplier s gain stability at high counting rates . it is our pleasure to thank professors h. sugawara , s. yamada , s. iwata , k. nakai and k. nakamura for their support and encouragement . we are grateful to y. higashi , s. koike and t. takatomi , who are the member of mechanical engineering center at kek , for their valuable help in making our trigger counters . y.t , y.m and m.s acknowledge receipt of research fellowships of the japan society for the promotion of science for young scientists . 99 w. l. reiter and g. stengl , nucl . instr . and meth . * 174 * , 585 ( 1980 ) ; f. celani _ et al . _ , instr . and meth . * 190 * , 71 ( 1981 ) ; m. de vincenzi _ et al . instr . and meth . * 225 * , 104 ( 1984 ) ; c. ohmori _ et al . _ , instr . and meth . a * 256 * , 361 ( 1987 ) . the trigger counter was used in an experiment ( kek - e162 ) which searched for rare @xmath36 decay modes such as @xmath37 . see t. nomura _ b * 408 * , 445 ( 1997 ) and y. takeuchi _ et al . _ , hep - ex/9810018 ( to be appeared in phys . b ) . in some photon detectors like a photomultiplier , we actually count photoelectrons instead of photons . we use these two words interchangeably when no confusion occurs . nlpb520 ; nichia chemical industries , ltd , 491 oka , kaminaka - cho , anan - shi , tokushima - ken , 774 japan tlg133 ; toshiba corporation , 1 - 1 , shibaura 1-chome , minato - ku , tokyo 105 - 01 japan since the number of tested led types was limited , these observations may not hold for other blue and/or green leds . hamamatsu photonics k.k . , iwata - gun , shizuoka - ken , 438 - 01 japan . in order to illustrate the effect of the change in the cut position , we take a measurement described in  4.1 as an example . the maximum change in the normalized photomultiplier gain ( i.e. the gain rescaled to 1 at 0.7 mhz ) was found to be less than 0.7% when the cut position was varied between 0.3 and 0.5 . the exception was the cross - check measurement described in  4.1 . see also ref . g. a. morton , h. m. smith and r. wasserman , ieee trans . * ns-14 * , 443 ( 1967 ) . we expect that the after - pulse rate depends on , among other things , residual gas pressure of photomultiplier tubes . this means that the quantity @xmath24 varies from one tube to another within one type of photomultipliers . ( in general , old tubes have bigger @xmath24 due to the increase of residual gas in tubes . ) since the history of the tested tubes was not quite known and the number was limited ( 1 @xmath16 3 tubes ) , the selected photomultiplier type may not mean the best type in general . in principle , @xmath24 may depend on photomultiplier s gain ( hv ) , too . however , very little dependence on the hv was found . as can be seen from the results , the light output from the led decreased with the repetition rate . a part of the reason could be the long charge - up time constant for the led capacitor @xmath17 ( @xmath38 9 mhz ) . we left it as it was , because we thought it desirable to keep the average cathode current of r239 roughly constant independent of the pulse rate . for this measurement , the smallest @xmath10 was 0.0001 ( at 5 mhz ) . thus the thermal noise contribution could be as large as 2.4% . if this was the only source of discrepancy between the two sets of the measurement , the discrepancy should become larger as @xmath10 decreased . we did not see such behavior ; thus we concluded that the thermal noise was not , at least , the main source of the discrepancy . as can be seen from fig.[fig - cathode ] the led light output was roughly constant below 2 mhz .", "tags": [], "output_text_a": "This paper discusses the development and testing of a photon counting method to monitor the gain stability of photomultipliers used in high-energy physics experiments. Photomultipliers are crucial for converting light to charge, but their gain can be unstable at high counting rates, which affects detector performance. The study required a stable pulsed light source, and an LED was chosen despite its potential variability at high repetition rates. A photon counting method was employed to monitor the LED's light output, which involved sampling a small portion of the light and using a photomultiplier as a monitor detector. The method is advantageous because it is largely insensitive to the gain variations of the monitor detector itself, provided single photon signals can be distinguished from noise. The study also addressed potential systematic errors from thermal noise and after-pulses, selecting a suitable photomultiplier to minimize these effects. The method's accuracy was estimated by comparing it with another method using a photomultiplier in diode mode. The results showed good agreement, validating the method's reliability. The system was applied to test the gain stability of photomultipliers used in a trigger counter for a high-energy physics experiment, confirming their suitability for the application. The study concludes that the photon counting method, combined with an LED light source, offers a simple and effective way to investigate photomultiplier gain stability at high counting rates.", "output_text_b": "This article discusses the development of a light monitor system for photomultipliers used in high energy physics experiments. The system is designed to ensure gain stability, which is crucial for realizing good detector performance. The authors describe a photon counting method for monitoring the gain change of photomultipliers using a stable pulsed light source and a monitor photon detector. The method is based on sampling a very small portion of the light output and injecting it to a monitor photon detector. The expected number of photons per pulse detected by the monitor detector is then given by the Poisson distribution. The authors used a photomultiplier as a monitor detector and could distinguish clearly a single photoelectron peak from a pedestal. The advantages of this method include its insensitivity to small gain variations of the monitor photon detector and the ability to demonstrate reliability in the monitor detector by measuring the peak position of the single photon.", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the development and testing of a photon counting method to monitor gain stability in photomultipliers.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of photomultiplier gain instability at high counting rates.\n4. The methodology, involving a photon counting method and the use of an LED light source, is clearly mentioned.\n5. Significant results, such as the validation of the method's reliability and its application in testing gain stability, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"photon counting method\" and \"gain stability\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the comparison with another method using a photomultiplier in diode mode, are mentioned.\n10. The summary reflects the paper's significance by stating its potential impact on investigating photomultiplier gain stability at high counting rates.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the development of a light monitor system for photomultipliers and the photon counting method used.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is ensuring gain stability in photomultipliers for good detector performance, is highlighted.\n4. The methodology, including the photon counting method and the use of a stable pulsed light source, is mentioned.\n5. The summary includes significant results, such as the insensitivity to small gain variations and the ability to demonstrate reliability in the monitor detector.\n6. The language used in the summary is clear and professional.\n7. The summary avoids excessive technical jargon and explains terms like \"photon counting method\" and \"single photoelectron peak.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The summary does not clearly reflect the paper's significance or potential impact in its field, which is a requirement."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the description of quark dynamics inside hadrons remains an actual problem of elementary particle theory . the asymptotic freedom in quantum chromodynamics ( qcd ) enables one to investigate the quark interactions at small distances by making use of standard perturbation theory . the quark dynamics at large distances ( the confinement region ) lies beyond such calculations . for this purpose other approaches are used : phenomenological potential models @xcite , string models @xcite , bags models @xcite , lattice calculations @xcite , the explicit account of nontrivial qcd vacuum structure  @xcite , and variational perturbation theory  @xcite . recently shirkov and solovtsov proposed a new analytic approach to qcd @xcite . its basic idea is the explicit imposition of the causality condition , which implies the requirement of the analyticity in the @xmath0 variable for the relevant physical quantities . the essential merits of this approach are the following : absence of unphysical singularities at any loop level , stability in the infrared ( ir ) region , stability with respect to loop corrections , and extremely weak scheme dependence . the analytic approach has been applied successfully to such problems as the @xmath1 lepton decays , @xmath2-annihilation into hadrons , sum rules ( see @xcite and references therein ) .    in refs . @xcite the analytic approach has been employed to the solution of the renormalization group ( rg ) equation . the analyticity requirement was imposed on the rg equation itself , before deriving its solution . solving the rg equation , `` analytized '' ( i.e. , requiring analyticity ) in the above - mentioned way , one gets , at one - loop level , a new analytic running coupling , which possesses practically the same appealing features as the shirkov - solovtsov running coupling @xcite does . an essential distinction , that will play a crucial role in the present paper , is the ir singularity of the new analytic running coupling at the point @xmath3 . it should be stressed here that such a behavior of the invariant charge is in a complete agreement with the schwinger - dyson equations , and , as it will be demonstrated in sec . iii , provides the quark confinement ( see sec . ii for the details ) .    in this paper we shall adhere to the model @xcite of obtaining the quark - antiquark ( @xmath4 ) potential by the fourier transformation of the running coupling . however , the perturbative running coupling @xmath5 does not enable one to obtain the rising @xmath4 potential without invoking additional assumptions @xcite . the objective of this paper is to construct the quark - antiquark potential by making use of the new analytic running coupling . this potential proves to be rising at large distances ( i.e. , providing the quark confinement ) and , at the same time , it incorporates the asymptotic freedom at small distances . it is essential that for obtaining this potential _ no additional assumptions _ , lying beyond the standard rg method in the quantum field theory and the analyticity requirement , will be used . the layout of the paper is as follows . in sec . ii the derivation of the new analytic running coupling is presented and its properties are briefly discussed . in sec . iii the quark - antiquark potential , generated by the new analytic running coupling , is derived by making use of the fourier transformation . further , the asymptotic behavior of the potential at large and small distances is investigated . in sec .  iv the higher loop corrections and the scheme dependence of the potential are discussed briefly . for practical purposes , a simple approximate formula for the potential is proposed which interpolates its infrared and ultraviolet asymptotics . this formula is compared with the phenomenological cornell potential . proceeding from this , an estimation of the qcd parameter @xmath6 is obtained . in the conclusion ( sec . v ) the obtained results are formulated in a compact way , and the further studies in this approach are outlined . in the analytic approach to qcd , proposed by shirkov and solovtsov @xcite , the basic idea is the explicit imposing of the causality condition , which implies the requirement of the analyticity in the @xmath0 variable for the relevant physical quantities . later this idea was applied to the `` analytization '' ( i.e. , the procedure of analyticity requirement ) of the perturbative series when calculating the qcd observables @xcite . the results turned out to be quite encouraging . as was mentioned in the introduction , the analytization of the perturbative series leads to the elimination of the unphysical singularities , to the higher loop correction stability and to a weak scheme dependence . however , the @xmath0-evolution of some qcd observables ( for instance , the structure function moments ) is intimately tied with the solution of the rg equation . our task here is to involve the analytization procedure into the rg formalism more profoundly . let us consider the rg equation of a quite general form for a quantity @xmath7 ( it may be , for example , the gluon propagator , or the structure function moment ) . at the one - loop level this equation reads @xmath8 where @xmath9 is the corresponding anomalous dimension ( the negative noninteger number in the general case ) , @xmath10 is the one - loop perturbative running coupling . the solution of eq . ( [ stdrgeqn ] ) can be written in the form @xmath11^{\\gamma}.\\ ] ] from here it follows immediately , that this solution has unphysical singularities in the physical region @xmath12 . however , in many interesting cases mentioned above , the quantity @xmath7 must have correct analytic properties in the @xmath0 variable ( namely , there is the only cutoff @xmath13 ) . one can demonstrate this proceeding from the first principles . so , for the gluon propagator this assertion follows from the causal klln - lehmann representation ( see , e.g. , @xcite ) , and for the structure function moments this is a consequence of the deser - gilbert - sudarshan integral representation ( see , e.g. , @xcite ) . thus , we come to a contradiction . the point , which is crucial to our consideration , is the following . the rg equation in the form ( [ stdrgeqn ] ) involves , in fact , a contradiction . the left - hand side of this equation has no unphysical singularities in the @xmath12 region , while its right - hand side has pole - type singularity at the point @xmath14 . the account of the higher loop contributions just introduces the additional unphysical singularities of the cut type in the physical region @xmath12 and hence does not solve the problem .    in order to avoid this contradiction , we propose to use the following method @xcite . before solving the rg equation ( [ stdrgeqn ] ) one should analytize its right - hand side as a whole . this prescription leads to the analytized rg equation , which , at the one - loop level , takes the form @xmath15 where @xmath16 is the perturbative running coupling analytized by making use of the shirkov - solovtsov prescription @xcite .- function for the invariant charge . ] the solution of eq.([argeqn ] ) can be presented in the form @xmath17^{\\gamma},\\ ] ] where @xmath18 comparing the solution ( [ argeqnsol ] ) with eq.([stdrgeqnsol ] ) one infers that @xmath19 should be treated as a new one - loop analytic running coupling . really , it possesses the same properties , as the one - loop running coupling analytized through the shirkov - solovtsov procedure . namely , the new running coupling has the standard asymptotic behavior at @xmath20 and it has no unphysical singularities in the @xmath12 region . the latter follows directly from the causal representation of the klln - lehmann type , that holds for @xmath21 : @xmath22    the distinctive feature of the new running coupling , which will play the crucial role in the framework of our consideration , is its singularity at the point @xmath23 . it is worth noting that such a behavior of the invariant charge is in a complete agreement with the schwinger - dyson equations ( see discussion in ref . @xcite ) , and , as it will be demonstrated in the next section , provides the quark confinement .    summarizing all stated above , we propose the following model for the analytic running coupling . we define the new analytic running coupling @xmath24 as the solution of the analytized rg equation at the respective loop level . here one has to choose the anomalous dimensions in such a way that the solution of the standard rg equation is the perturbative running coupling at the loop level considered . ; @xmath25 , where @xmath26 is the coefficient by the @xmath27th power of the perturbative running coupling on the right - hand side of eq . ( [ stdrgeqn ] ) . ] thus , at the one - loop level , the new analytic running coupling has the form @xcite @xmath28 where @xmath29 is the first coefficient of the @xmath30-function . at the higher loop levels there is only the integral representation for @xmath24 . so , at the @xmath31-loop level we have @xmath32,\\ ] ] where @xmath33/(2\\pi i)$ ] is the spectral density , and @xmath34 is the normalization point .    figure [ narcgraph ] shows the new analytic running coupling computed at the one- , two- , and three - loop levels . it is clear from this figure that our analytic running coupling possesses the higher loop stability . moreover , it can be shown that the singularity of the new analytic running coupling at the point @xmath23 is of the universal type at any loop level . this is clear from the following simple consideration . when @xmath35 the basic contribution into eq.([narcdefhl ] ) affords the integration over the small @xmath36 region . the spectral density @xmath37 at any loop level has the same limit when @xmath38 : @xmath39 @xcite . hence the new analytic running coupling ( [ narcdefhl ] ) has the unique behavior when @xmath35 . here we are going to use the new analytic running coupling for obtaining the interquark potential . we proceed from the standard expression @xcite for the @xmath4 potential in terms of the running coupling @xmath40 , @xmath41    for the construction of the new interquark potential @xmath42 we shall use the new analytic running coupling  ( [ narcdef ] ) @xmath43 upon the integration over the angular variables and the substitution @xmath44 in eq.([vrgen ] ) , one gets @xmath45 where @xmath46 is the dimensionless potential .    in order to perform the integration in eq . ( [ nvtrdef ] ) we consider the auxiliary function @xmath47 here the parameter @xmath48 is introduced for shifting the origin of the cut along the imaginary axis i m  @xmath49 . it is obvious that @xmath50.\\ ] ] for even @xmath51 the integrand in eq . ( [ idef ] ) is an even function of  @xmath49 . therefore @xmath52 where @xmath53 the sign @xmath54 means the principal value of the integral . the function @xmath55 in eq . ( [ fdef ] ) has the cuts @xmath56 $ ] , @xmath57 and simple poles at the points @xmath58 . let us consider the integral of the function @xmath59 along the contour @xmath60 shown in fig . [ contour ] . the function @xmath55 has no singularities inside the contour @xmath60 , therefore @xmath61 . contribution to this integral of the semicircle of infinitely large radius in upper half - plane ( see fig .  [ contour ] ) vanishes . performing the integration along the two semicircles @xmath62 and @xmath63 of the vanishing radius and along the cut @xmath64 on the imaginary axis , we obtain @xmath65 \\nonumber\\\\ & & + 2i^{n-2 } \\int_{\\sqrt{a}}^{\\infty}\\frac{x^{n-1}e^{-rx}}{\\ln^2(x^2-a)+\\pi^2}\\,dx \\biggr\\}.\\end{aligned}\\ ] ] hence , for even @xmath51 the function @xmath66 in eq . ( [ idef ] ) takes the form @xmath67,\\ ] ] where @xmath68    it is rather complicated to perform the integration in eq.([ndef ] ) explicitly . therefore we address the study of the asymptotics . first of all , we would like to know whether the @xmath69 potential @xmath42 in eq . ( [ nvrdef ] ) provides the quark confinement . for the investigation of the potential behavior at large distances it is enough to consider the asymptotic of the function @xmath70 in eq . ( [ ndef ] ) when @xmath71 . this function can be represented in the following way @xmath72}\\ , dx.\\ ] ] at large @xmath73 the basic contribution into eq . ( [ nredef ] ) gives the integration over the small @xmath74 region . let us transform @xmath75 identically : @xmath76 dx,\\ ] ] where @xmath77 . neglecting the second term in the square brackets in eq . ( [ ndiff ] ) , we use the formula ( 4.361.2 ) from ref . @xcite : @xmath78 where @xmath79 is the so - called transcendental @xmath80-function @xcite : @xmath81 eventually , we obtain for @xmath82 , @xmath83.\\ ] ]    taking into account eqs . ( [ vtrdef ] ) , ( [ indef ] ) , and ( [ nint ] ) one can present the quark - antiquark potential ( [ nvrdef ] ) at large @xmath73 in the following way : @xmath84.\\ ] ] the behavior of the potential @xmath42 at @xmath85 is determined by the last term in eq . ( [ nvras ] ) . it follows directly from the asymptotic of @xmath86 ( see ref.@xcite ) , and from a simple reasoning . really , if @xmath87 the term @xmath88 is non - negative and @xmath89 . hence , @xmath90  const when @xmath71 , and its contribution to @xmath42 at large @xmath73 is of @xmath91-order . ] integration of this term by parts gives @xmath92\\nonumber\\\\ & & -\\frac{1}{\\ln r } \\left[1 + \\sum\\limits_{j=1}^{\\infty } \\frac{f_j(0)}{\\ln^j r } \\right],\\end{aligned}\\ ] ] where @xmath93    in the limit @xmath71 , eq . ( [ partint ] ) takes the form @xmath94 therefore the quark - antiquark potential @xmath42 proves to be rising at large distances @xmath95    thus the new analytic running coupling @xmath96 [ see eq . ( [ narcdef ] ) ] leads to the rising quark - antiquark potential @xmath42 which can , in principle , describe the quark confinement . it is important to point out that the behavior of the potential @xmath42 when @xmath97 has the standard form determined by the asymptotic freedom ( see , e.g. , ref . @xcite ) , @xmath98 unfortunately , it is impossible to obtain the explicit dependence @xmath42 for the whole region @xmath99 . a simple interpolating formula , which can be applied for practical use , will be given in the next section . let us discuss briefly the higher loop contribution . as was mentioned in the sec . ii , the singularity of @xmath31-loop analytic running coupling @xmath100 at the point @xmath101 is of the universal type at any loop level . therefore , when @xmath102 we have @xmath103 , where @xmath104 are constants . taking into account that the maximal difference between @xmath100 and @xmath105 is in the small @xmath106 region , we arrive at the following conclusion . the account of the higher loop corrections leads to changing the slope of the @xmath69 potential @xmath42 when @xmath85 . this corresponds to a simple redefinition of the parameter @xmath107 in eq . ( [ nvrasinf ] ) at the higher loop levels .    as far as the scheme dependence of this approach , we have to point out the following . it was shown in  @xcite that the solutions of the analytized rg equation at the higher loop level have extremely weak scheme dependence . in particular , the solutions of the rg equation with @xmath108 and @xmath109 schemes , are practically coinciding . hence , at the higher loop level ( there is no scheme dependence at the one - loop level ) , the use of different subtraction schemes leads to the slight variation of the @xmath4 potential . thus , neither higher loop corrections , nor scheme dependence , can affect qualitatively the result obtained in the previous section .    for the practical use of the new potential it is worth obtaining a simple explicit expression that approximates it sufficiently well . for this purpose one can use , for instance , the approximating function @xmath110,\\end{aligned}\\ ] ] which has no any unphysical singularities and possesses the asymptotics ( [ nvrasinf ] ) and ( [ nvrasorig ] ) . this function is obtained by smooth sewing the asymptotics @xmath111 , \\quad r \\to \\infty , \\nopagebreak \\\\ \\label{nvrasorign } ^nv(r)&\\simeq&\\frac{8\\pi}{3\\beta_0}\\lambda\\cdot\\frac{1}{r\\ln(r ) } , \\quad r \\to 0 , \\quad r=\\lambda r.\\end{aligned}\\ ] ]    the formula ( [ nvrasinfn ] ) keeps explicitly the second leading term of the expansion ( [ partint ] ) , @xmath112 . some terms have been introduced into eq . ( [ urdef ] ) only for eliminating the singularity at the point @xmath113 . it should be mentioned here that the next terms in the expansion ( [ partint ] ) practically do not affect the shape of @xmath114 . of course , the function ( [ urdef ] ) is not the unique interpolating function between asymptotics ( [ nvrasinfn ] ) and ( [ nvrasorign ] ) . nevertheless , the comparison of @xmath114 with the phenomenological potential @xmath115 ( the so - called cornell potential @xcite ) shows their almost complete coincidence ( see fig . [ compare ] ) . the fit has been performed with the use of the least square method in the physical meaning region @xmath116  fm @xcite . the varied parameter in eq . ( [ urdef ] ) is @xmath107 . the possibility of shifting the potential @xmath117 in eq . ( [ vrcornell ] ) by a constant was also used . a rough estimation of @xmath6 in the course of this fitting gives @xmath118  mev . this is in agreement with the values obtained earlier in the framework of the analytic approach to qcd  @xcite . in the paper the quark - antiquark potential is constructed by making use of the new analytic running coupling in qcd . this running coupling arises under analytization of the renormalization group equation before its solving . the rising behavior of the quark - antiquark potential at large distances , which provides the quark confinement , is shown explicitly . the key property of the new analytic running coupling , leading to the confining potential , is its infrared singularity at the point @xmath3 . at small distances , the standard behavior of the potential , originating in the qcd asymptotic freedom , is revealed . it is also demonstrated that neither higher loop corrections , nor scheme dependence , can affect qualitatively the obtained result . the estimation of the parameter @xmath6 in this approach gives a reasonable value , @xmath118  mev . e.  eichten _ et al . _ , phys . d * 17 * , 3090 ( 1978 ) ; a.  martin , phys .  lett .  * 93b * , 338 ( 1980 ) ; c.  quigg and j.  l.  rosner , _ ibid . _ * 71b * , 153 ( 1977 ) . b.  m.  barbashov and v.  v.  nesterenko , _ introduction to the relativistic string theory _ ( world scientific , singapore , 1990 ) . p.  hasenfratz and j.  kuti , phys * 40c * , 75 ( 1978 ) ; s.  adler and t.  piran , rev . 56 * , 1 ( 1984 ) . g.  s.  bali , c.  schlichter , and k.  schilling , phys . d * 51 * , 5165 ( 1995 ) . n.  brambilla and a.  vairo , `` quark confinement and the hadron spectrum '' , hep - ph/9904330 . i.  l.  solovtsov , phys .  lett . b * 327 * , 335 ( 1994 ) . d.  v.  shirkov and i.  l.  solovtsov , phys . * 79 * , 1209 ( 1997 ) ; hep - ph/9704333 . i.  l.  solovtsov and d.  v.  shirkov , theor . math . phys .  * 120 * , 482 ( 1999 ) ; hep - ph/9909305 . a.  v.  nesterenko , diploma thesis , moscow state university , 1998 . a.  v.  nesterenko , in _ particle physics on the boundary of millenniums _ , proceedings of the 9th international lomonosov conference on elementary particle physics , moscow , russia , 1999 , edited by a.  studenikin ( msu and icas ) ( to be published ) . j.  l.  richardson , phys . lett .  * 82b * , 272 ( 1979 ) ; r.  levine and y.  tomozawa , phys . d * 19 * , 1572 ( 1979 ) . n.  n.  bogolyubov and d.  v.  shirkov , _ introduction to the theory of quantized fields _ ( interscience , new york , 1980 ) . w.  wetzel , nucl .  phys . * b139 * , 170 ( 1978 ) . a.  i.  alekseev and b.  a.  arbuzov , mod . lett .  a * 13 * , 1747 ( 1998 ) ; hep - ph/9704228 . i.  s.  gradshteijn and i.  m.  ryzhik , _ table of integrals , series and products _ ( academic , new york , 1994 ) . h.  bateman and a.  erdelyi , _ higher transcendental functions _ ( mcgraw - hill , new york , 1953 - 1955 ) , vol .  3 .", "tags": [], "output_text_a": "This paper addresses the challenge of understanding quark dynamics within hadrons, particularly focusing on the confinement region where standard perturbation theory in quantum chromodynamics (QCD) is not applicable. The authors explore a new analytic approach to QCD proposed by Shirkov and Solovtsov, which imposes a causality condition requiring analyticity in the relevant physical quantities. This approach eliminates unphysical singularities, maintains stability in the infrared region, and shows weak scheme dependence.\n\nThe paper's main objective is to construct a quark-antiquark potential using this new analytic running coupling. This potential is shown to rise at large distances, indicating quark confinement, while also incorporating asymptotic freedom at small distances. The authors derive the potential through Fourier transformation of the running coupling and discuss its properties, including higher loop corrections and scheme dependence.\n\nA simple approximate formula for the potential is proposed, which interpolates between its infrared and ultraviolet asymptotics and is compared with the phenomenological Cornell potential. The paper concludes with an estimation of the QCD parameter, which aligns with previous findings in the analytic approach to QCD. Overall, the study provides a promising method for describing quark confinement without additional assumptions beyond the standard renormalization group method and analyticity requirements.", "output_text_b": "This arXiv paper discusses the problem of quark dynamics inside hadrons in the context of Quantum Chromodynamics (QCD). At small distances, asymptotic freedom allows for the use of standard perturbation theory. However, the quark dynamics at large distances (confinement region) is beyond such calculations. The paper mentions various approaches used to investigate this region, including phenomenological potential models, string models, bags models, lattice calculations, explicit account of nontrivial QCD vacuum structure, and variational perturbation theory. A new analytic approach to QCD is proposed by Shirkov and Solovtsov, which imposes the causality condition, leading to the requirement of analyticity in the relevant physical quantities. This approach has several merits, such as the absence of unphysical singularities, stability in the infrared region, stability with respect to loop corrections, and weak scheme dependence. The analytic approach has been successfully applied to various problems, including lepton decays, hadron annihilation, and sum rules.\n\nThe paper then focuses on the application of the analytic approach to the solution of the renormalization group (RG) equation. By imposing the analyticity requirement on the RG equation itself, the authors obtain a new analytic running coupling at the one-loop level, which shares the appealing features of the Shirkov-Solovtsov running coupling. An essential distinction is the infrared singularity of the new analytic running coupling at a specific point, which is in agreement with Schwinger-Dyson equations and provides quark confinement.\n\nThe authors then derive the quark-antiquark potential by performing a Fourier transformation of the running coupling. This potential rises at large distances, providing quark confinement, and incorporates asymptotic freedom at small distances. The construction of this potential does not require any assumptions beyond the standard RG method in quantum field theory and the analyticity requirement.\n\nLastly, the paper proposes a simple approximate formula for the potential that interpolates its infrared and ultraviolet asymptotics. This formula is compared with the phenomenological Cornell potential, leading to an estimation of the QCD parameter.", "score": -0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the development of a new analytic approach to QCD and the construction of a quark-antiquark potential.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding quark dynamics within hadrons, particularly in the confinement region.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the new analytic approach to QCD and the use of Fourier transformation.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the rising potential indicating quark confinement and the estimation of the QCD parameter.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"analytic running coupling.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear progression of ideas.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data, which is a requirement.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by mentioning its potential impact on describing quark confinement.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the new analytic approach to QCD and the derivation of the quark-antiquark potential.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the problem of quark dynamics inside hadrons and the challenge of quark confinement.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the analytic approach to QCD and the Fourier transformation used to derive the potential.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the rising potential at large distances and the estimation of the QCD parameter.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"analytic running coupling\" and \"Fourier transformation,\" but these are necessary for understanding the content.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically, with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data, as the paper seems to be theoretical.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the significance of the paper in providing a new approach to quark confinement and its potential impact on QCD studies."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "we have observed the pulsar vela with a range of australian telescopes . using the long baseline array ( lba ) we have measured the parallax of pulsar , and thus the distance . using the australia telescope compact array ( atca ) we have found the radio pulsar wind nebula ( pwn ) that surrounds the x - ray pwn . using the university of tasmania s dedicated pulsar monitoring telescope in hobart we have detected the core interaction in the spin up of the pulsar in the glitch of 2000 . the pulsar monitoring telescope at hobart is a fourteen meter radio telescope dedicated to timing the vela pulsar . it collects three frequencies ( 635 , 990 , 1340-mhz ) , and the central one is collected unfolded for high resolution timing analysis ( @xcite ) . the ` fast component ' observed , which was fitted with a decay time 1.2 minutes , has been reanalysed with a more realistic model . we marginally detect the core interaction in the spin up ( @xcite ) . the atca has been used to map the radio pwn at 21 cm , 13 cm , 6 cm and 3 cm . because we used compact configurations with better sensitivity to low surface brightness objects we are able to map the whole nebula , unlike previous observations ( @xcite ) . we have used a single baseline from the lba to measure the on sky motion of the vela pulsar compared with the extra galactic source vela - g . we have measured the proper motion and parallax of the vela pulsar to an unprecedented accuracy ( @xmath0 @xmath1  , @xmath2 mas ) , and have been able to convert these back to the space velocity and position angle of the pulsar in its local environment with greater precision that previously possible ( @xmath3 @xmath4at @xmath5 ) , because of the unambiguity in the radio reference frame . we have found an arithmetic error in @xcite and , once corrected , their results agree with ours ( caraveo , personal comms ) . we have funding for a coherently dedispersed 30mhz backend for the 635mhz if on the pulsar timing telescope . this should allow us an increase in sensitivity of an order of magnitude over the previous observations . we plan to observe at the atca the radio nebula at higher frequencies to find the turn over frequency , and model the emission from the x - rays down to the radio frequencies . we are observing at the vla to get sensitive rapid observations to measure changes associated with the recently discovered x - ray outer jet ( @xcite ) . the limitation in the accuracy of the vlbi observation is the solar motion parameters , and we can not improve on this . nevertheless we are planning to use vela as a demonstration source in a baseband e - vlbi experiment .", "tags": [], "output_text_a": "The study reports on observations of the Vela pulsar using various Australian telescopes. The Long Baseline Array (LBA) was used to measure the pulsar's parallax, providing an accurate distance measurement. The Australia Telescope Compact Array (ATCA) helped identify the radio pulsar wind nebula (PWN) surrounding the X-ray PWN. The University of Tasmania's pulsar monitoring telescope in Hobart detected core interactions during the pulsar's spin-up in a 2000 glitch. This telescope, dedicated to timing the Vela pulsar, collects data at three frequencies for high-resolution analysis. The study reanalyzed the 'fast component' of the pulsar's spin-up with a more realistic model. The ATCA mapped the radio PWN at various wavelengths, achieving a comprehensive view of the nebula. The LBA also measured the pulsar's proper motion and parallax with unprecedented accuracy, allowing precise calculations of its space velocity and position angle. An arithmetic error in previous studies was corrected, aligning their results with this study's findings. Future plans include using a new backend for increased sensitivity, observing the radio nebula at higher frequencies, and conducting rapid observations with the VLA to study changes related to a recently discovered X-ray outer jet. The study also plans to use Vela in a baseband e-VLBI experiment, despite limitations due to solar motion parameters.", "output_text_b": "The paper presents observations of the Vela pulsar using various Australian telescopes, including the Long Baseline Array (LBA), the Australia Telescope Compact Array (ATCA), and the University of Tasmania's dedicated pulsar monitoring telescope in Hobart. The LBA was used to measure the parallax and distance of the pulsar, while the ATCA was used to map the radio pulsar wind nebula (PWN) surrounding the X-ray PWN. The Hobart telescope detected the core interaction in the spin-up of the pulsar during the glitch of 2000. The authors have improved the accuracy of proper motion, parallax, space velocity, and position angle measurements of the pulsar in its local environment. They have also identified an arithmetic error in a previous study and corrected it. Future plans include using a coherently dedispersed 30MHz backend for the 635MHz on the pulsar timing telescope, observing the radio nebula at higher frequencies with the ATCA, and using Vela as a demonstration source in a baseband e-VLBI experiment.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the measurement of the pulsar's parallax and proper motion, the identification of the radio PWN, and the correction of an arithmetic error in previous studies.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly state the research problem or question addressed by the paper.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of various telescopes and methods like parallax measurement and mapping of the radio PWN.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the accurate measurement of the pulsar's parallax and proper motion, and the correction of previous errors.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"parallax,\" \"PWN,\" and \"e-VLBI\" without explanation, which might not be clear to all readers.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions key experiments, such as the use of the LBA and ATCA for measurements.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly reflect the paper's significance or potential impact in its field.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the measurement of parallax and distance, mapping of the radio PWN, and detection of core interaction during the glitch of 2000.\n\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly highlight the research problem or question addressed by the paper.\n\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of various telescopes and techniques like measuring parallax and mapping the PWN, which covers the methodology.\n\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results such as improved accuracy of measurements and correction of an arithmetic error.\n\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"parallax,\" \"PWN,\" and \"e-VLBI\" without explanation, which might not be clear to all readers.\n\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions key experiments such as the use of the LBA and ATCA for measurements and mapping.\n\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [false, false], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [false, false]}}, {"input_text": "the content knowledge of instructors is not sufficient to help students learn effectively . indeed , instructors should possess pedagogical content knowledge and familiarize themselves with students prior knowledge in order to scaffold their learning with appropriate pedagogies and instructional tools . vygotsky s notion of  zone of proximal development \"  @xcite ( zpd ) refers to what a student can do on his / her own vs. with the help of an instructor who is familiar with his / her prior knowledge and skills . scaffolding is at the heart of zpd and can be used to stretch a student s learning far beyond his / her initial knowledge by carefully crafted instruction which is designed to ensure that the student makes desired progress and gradually develops independence . with awareness of students initial knowledge state , the instructor can continuously target instruction a little bit above students current knowledge state to ensure that the students have the opportunity and ability to connect new knowledge with what they already know and build a robust knowledge structure . piaget  @xcite emphasized  optimal mismatch \" between what the student knows and where the instruction should be targeted in order for desired assimilation and accommodation of knowledge to occur . bransford and schwartz  @xcite also proposed a framework for scaffolding student learning . they theorized that the preparation for future learning ( pfl ) and transfer of knowledge from the situation in which it was acquired to new situations is optimal if instruction includes both the elements of innovation and efficiency . in their model , efficiency and innovation are two orthogonal coordinates . if instruction only focuses on efficiency , the cognitive engagement and processing by the students will be diminished and they will not develop the ability to transfer the acquired knowledge to new situations . similarly , if the instruction is solely focused on innovation , students may struggle to connect what they are learning with their prior knowledge so that learning and transfer will be inhibited . they propose that the preparation for future learning and transfer will be enhanced if the instruction focuses on moving along a diagonal trajectory in the two dimensional space of innovation and efficiency . one common element of all of these seemingly different frameworks is their focus on students prior knowledge in order to scaffold learning . indeed , the instructor must be familiar with students prior knowledge in order for instruction to be in the zone of proximal development and to provide optimal mismatch to ensure adequate preparation for future learning . a crucial difference between the problem solving strategies used by experts in physics and beginning students lies in the interplay between how their knowledge is organized and how it is retrieved to solve problems  @xcite . in a classic study by chi et al.@xcite , introductory physics students were asked to group mechanics problems into categories based on the similarity of their solutions . unlike graduate students ( experts ) who categorize them based on the physical principles involved to solve them , introductory students categorized problems involving inclined planes in one category and pulleys in a separate category  @xcite . here , we will discuss the process and outcome of the categorization of 25 introductory mechanics problems by 21 physics graduate students enrolled in a ta training course at the end of the course  @xcite . graduate students first performed the categorizations from their own perspective and later from the perspective of a typical introductory student . we wanted to investigate if the graduate students have an understanding of the differences between their physics knowledge structure and those of the introductory physics students . one surprising finding is the resistance of graduate students to categorizing problems from a typical introductory physics student s perspective with the claim that such a task is  useless \" ,  impossible \" , and has  no bearing \" on their teaching assistant ( ta ) duties . based on our finding , we suggest that inclusion of such tasks can improve the effectiveness of ta training courses and faculty development workshops and help tas and instructors focus on issues related to teaching and learning . we were unable to obtain the questions in ref . @xcite other than the few that have been published . we therefore chose our own questions on sub - topics similar to those chosen in ref . the context of the 25 mechanics problems varied and the topics included one- and two - dimensional kinematics , dynamics , work - energy , and impulse - momentum  @xcite . many questions were adapted from an earlier study  @xcite because their development had gone through rigorous testing . although we had an idea about which categories created by individuals should be considered good or poor , we validated our assumptions with other experts . we randomly selected the categorizations performed by twenty introductory physics students and gave it to three physics faculty who had taught introductory physics recently and asked them to decide whether each of the categories created by individual students should be considered good , moderate , or poor . we asked them to mark each row which had a category name created by a student and a description of why it was the appropriate category for the questions that were placed in that category . if a faculty member rated a category created by an introductory student as good , we asked that he / she cross out the questions that did not belong to that category . the agreement between the ratings of different faculty members was better than 95% . we used their ratings as a guide to rate the categories created by everybody as good , moderate , or poor . a category was considered `` good '' only if it was based on the underlying physics principles . we typically rated both conservation of energy or conservation of mechanical energy as good categories . kinetic energy as a category name was considered a moderate category if students did not explain that the questions placed in that category can be solved using mechanical energy conservation or the work energy theorem . we rated a category such as energy as good if students explained the rationale for placing a problem in that category . if a secondary category such as friction or tension was the only category in which a problem was placed and the description of the category did not explain the primary physics principles involved , it was considered a moderate category . more than one principle or concept may be useful for solving a problem . the instruction for the categorizations told students that they could place a problem in more than one category . because a given problem can be solved using more than one approach , categorizations based on different methods of solution that are appropriate was considered good . for some questions , conservation of mechanical energy may be more efficient , but the questions can also be solved using one- or two - dimensional kinematics for constant acceleration . in this paper , we will only discuss categories that were rated good . if a graph shows that 60% of the questions were placed in a good category by a particular group ( introductory students , graduate students , or faculty ) , it means that the other 40% of the questions were placed in moderate or poor categories . a histogram of the percentage of questions placed in good categories ( not moderate or poor ) is given in fig .  1 . this figure compares the average performance of 21 graduate students at the end of a ta training course when they were asked to categorize questions from their own perspective with 7 physics faculty and 180 introductory students who were given the same task . although this categorization by the graduate students is not on par with the categorization by physics faculty , the graduate students displayed a higher level of expertise in introductory mechanics than the introductory students and were more likely to group the questions based on physical principles . physics professors and sometimes graduate students pointed out multiple methods for solving a problem and specified multiple categories for a particular problem more often than the introductory students . introductory students mostly placed one question in only one category . professors ( and sometimes graduate students ) created secondary categories in which they placed a problem that were more like the introductory students primary categories . for example , in the questions involving tension in a rope or frictional force  @xcite , many faculty and some graduate students created these secondary categories called tension or friction , but also placed those questions in a primary category , based on a fundamental principle of physics . introductory physics students were much more likely to place questions in inappropriate categories than the faculty or graduate students , for example , placing a problem that was based on the impulse - momentum theorem or conservation of momentum in the conservation of energy category . many of the categories generated by the three groups were the same , but there was a major difference in the fraction of questions that were placed in good categories by each group . there were some categories such as ramps , and pulleys , that were made by introductory physics students but not by physics faculty or graduate students . after the graduate students had submitted their own categorizations , they were asked to categorize the same questions from the perspective of a typical introductory physics student . a majority of the graduate students had not only served as tas for recitations , grading , or laboratories , but had also worked during their office hours with students one - on - one and in the physics resource room at the university of pittsburgh . the goal of this task was to assess whether the graduate students were familiar with the level of expertise of the introductory students whom they were teaching and whether they realized that most introductory students do not necessarily see the same underlying principles in the questions that they do . the graduate students were told that they were not expected to remember how they used to think 45 years ago when they were introductory students . we wanted them to think about their experience as tas in introductory physics courses while grouping the questions from an introductory students perspective . they were also asked to specify whether they were recitation tas , graders , or laboratory tas that semester . the categorization of questions from the perspective of an introductory physics student met with widespread resistance . many graduate students noted that the task was useless or meaningless and had no relevance to their ta duties . although we did not tape record the discussion with the graduate students , we took notes immediately following the discussion . the graduate students often asserted that it is not their job to `` get into their students heads . '' other graduate students stated that the task was `` impossible '' and `` can not be accomplished . '' they often noted that they did not see the utility of understanding the perspective of the students . some graduate students explicitly noted that the task was `` silly '' because it required them to be able to read their students minds and had no bearing on their ta duties . not a single graduate student stated that they saw merit in the task or said anything in favor of why the task may be relevant for a ta training course . the discussions with graduate students also suggest that many of them believed that effective teaching merely involves knowing the content well and delivering it lucidly . many of them had never thought about the importance of knowing what their students think for teaching to be effective . it is surprising that most graduate students enrolled in the ta training course were so reluctant or opposed to attempting the categorization task from a typical introductory student s perspective . this resistance is intriguing especially because the graduate students were given the task at the end of a ta training course and most of them were tas for introductory physics all term . it is true that it is very difficult for the tas ( and instructors in general ) to imagine themselves as novices . however , it is possible for tas ( and instructors ) to familiarize themselves with students level of expertise by giving them pre - tests at the beginning of a course , listening to them carefully , and by reading literature about student difficulties , for example , as part of the ta training course . after 1520 minutes of discussion we made the task more concrete and told graduate students that they could consider categorizing from the perspective of a relative whom they knew well after he / she took only one introductory mechanics course if that was the only exposure to the material they had . we also told them that they had to make a good faith effort even if they felt the task was meaningless or impossible . figure  2 shows the histogram of how the graduate students categorized questions from their own perspective and from the perspective of a typical introductory student / relative who has taken only one physics course and also categorization by introductory students . figure  2 shows that the graduate students re - categorized the questions in worse categories when performing the categorization from the perspective of a typical introductory physics student . however , if we look at questions placed in each category , for example , conservation of momentum , there are sometimes significant differences between the categorization by graduate students from an introductory students perspective and by introductory students from their own perspective . this implies that while graduate students may have realized that a typical introductory student / relative who has taken only one physics course may not perform as well as a physics graduate student on the categorization task , overall they were not able to anticipate the frequency with which introductory students categorized each problem in the common less - expert - like categories . the reluctance of tas to re - categorize the questions from introductory students perspective raises the question of what should the graduate students learn in a ta training class . in a typical ta training class , a significant amount of time is devoted to emphasizing the importance of writing clearly on the blackboard , speaking clearly and looking into students eyes , and grading students work fairly . there is a lack of discussion about the fact that teaching requires not only knowing the content but understanding how students think and implementing strategies that are commensurate with students prior knowledge . after the graduate students had completed both sets of categorization tasks , we discussed the pedagogical aspects of perceiving and evaluating the difficulty of the questions from the introductory students perspective . we discussed that pedagogical content knowledge , which is critical for effective teaching , depends not only on the content knowledge of the instructor , but also on the knowledge of what the students are thinking . the discussions were useful and many students explicitly noted that they had not pondered why accounting for the level of expertise and thinking of their students was important for devising strategies to facilitate learning . some graduate students noted that they will listen to their introductory students and read their responses carefully . one graduate student noted that after this discussion he felt that , similar to the difficulty of the introductory students in categorizing the introductory physics questions , he has difficulty in categorizing questions in the advanced courses he has been taking . he added that when he is assigned homework / exam questions , for example , in the graduate level electricity and magnetism course in which they were using the classic book by jackson , he often does not know how the questions relate to the material discussed in the class even when he carefully goes through his class notes . the student noted that if he goes to his graduate course instructor for hints , the instructor seems to have no difficulty making those connections to the homework . the spontaneity of the instructor s connection to the lecture material and the insights into those questions suggested to the student that the instructor can categorize those graduate - level questions and explain the method for solving them without much effort . this facility is due in part because the instructor has already worked out the questions and hence they have become an exercise . other graduate students agreed with his comments saying they too had similar experiences and found it difficult to figure out how the concepts learned in the graduate courses were applicable to homework problems assigned in the courses . these comments are consistent with the fact that a graduate student may be an expert in the introductory physics material related to electricity and magnetism but not necessarily an expert in the material at the jackson level course . this study raises important issues regarding the content of ta training courses and faculty professional development workshops and the extent to which these courses should allocate time to help participants learn about pedagogical content knowledge in addition to the usual discussions of logistical issues related to teaching . asking the graduate students and faculty to categorize questions from the perspective of students may be one way to draw instructor s attention to these important issues in the ta training courses and faculty professional development workshops .", "tags": [], "output_text_a": "The paper discusses the importance of pedagogical content knowledge for instructors, emphasizing that content knowledge alone is insufficient for effective teaching. It highlights the need for instructors to understand students' prior knowledge to scaffold learning effectively, using Vygotsky's concept of the Zone of Proximal Development (ZPD) and Piaget's idea of \"optimal mismatch.\" The study explores how graduate students in a TA training course categorize physics problems compared to introductory students and faculty, revealing a resistance among graduate students to consider the perspective of novice learners. This resistance underscores a gap in TA training, which often focuses on content delivery rather than understanding student thinking. The paper suggests that TA training and faculty development should include tasks that help instructors appreciate the importance of aligning teaching strategies with students' cognitive levels, thereby enhancing pedagogical content knowledge. The study also highlights the differences in problem-solving approaches between experts and novices, suggesting that understanding these differences can improve teaching effectiveness. Overall, the paper advocates for a more comprehensive approach to TA training that includes understanding student perspectives and cognitive processes.", "output_text_b": "The paper discusses the importance of instructors' pedagogical content knowledge and understanding of students' prior knowledge for effective teaching. The Zone of Proximal Development (ZPD) concept highlights the role of scaffolding in stretching students' learning beyond their initial knowledge. The authors emphasize the need for instruction to focus on both innovation and efficiency, and to consider an optimal mismatch between the student's current knowledge and the targeted instruction.\n\nA study is presented where 21 graduate students enrolled in a TA training course categorized 25 introductory mechanics problems from their own perspective and that of a typical introductory student. The findings suggest that the graduate students struggled to categorize problems from the introductory student's perspective, often claiming the task was \"useless,\" \"impossible,\" or had \"no bearing\" on their TA duties.\n\nThe authors argue that incorporating such tasks in TA training courses and faculty development workshops can improve the effectiveness of teaching and help instructors focus on teaching and learning issues. They also stress the importance of understanding students' perspective and prior knowledge for effective teaching, and the need for ta training courses to allocate time to help participants learn about pedagogical content knowledge.\n\n[[ ## completed ##]]", "score": -0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the importance of pedagogical content knowledge and the resistance of graduate students to consider novice perspectives.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of the gap in TA training regarding understanding student thinking.\n4. **Methodology**: The summary does not explicitly mention the methodology or approach used in the paper, such as the categorization task performed by graduate students.\n5. **Significant Results**: The summary includes significant results, such as the resistance among graduate students and the need for improved TA training.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like ZPD and \"optimal mismatch.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not mention key experiments or data, such as the categorization of physics problems by different groups.\n10. **Significance**: The summary reflects the paper's significance in improving TA training and teaching effectiveness.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, focusing on the importance of pedagogical content knowledge and understanding students' perspectives.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the importance of instructors' pedagogical content knowledge and students' prior knowledge.\n4. **Methodology**: The summary mentions the methodology of categorizing mechanics problems by graduate students.\n5. **Significant Results**: The summary includes significant results, such as the graduate students' struggle with categorizing from an introductory student's perspective.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like ZPD.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions the key experiment of categorizing mechanics problems.\n10. **Significance**: The summary reflects the paper's significance in improving TA training and teaching effectiveness."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [false, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "there is growing evidence from nuclear magnetic resonance @xcite , resonant x - ray scattering and diffraction @xcite and scanning tunneling microscopy @xcite that charge ordered states play an important role in underdoped cuprates . in particular , a charge - modulated state with 4 incommensurate wave vectors along the crystalline axes was detected in ybco and in bi - based single and double layer compounds . resonant elastic x - ray scattering showed that the charge order emerges just below the opening of the pseudogap @xcite in underdoped bi2201 @xcite . the formation of the pseudogap , fermi pockets , the appearance of quantum oscillations @xcite and of charge order may thus be intimately related in these systems . it is the aim of this paper to characterize charge ordered states in interacting systems independently of the strength of the interaction . furthermore , the implications of point group and time reversal symmetries as well as the hermiticity of the hamiltonian for the order parameter ( op ) will be taken into account in greater detail than in previous treatments . the microscopic form of the charge op in cuprates is not clear at present . to illustrate this let us consider the following model hamiltonian for electrons on a square lattice which generally is believed to be relevant for cuprates @xcite , @xmath5 @xmath6 denotes the hopping amplitude of electrons between the lattice site @xmath7 and @xmath8 . @xmath9 and @xmath10 are fermionic creation and annihilation operators , @xmath11 spin indices and repeated spin indices are always summed over . the second and third terms in eq . ( [ h ] ) describe antiferromagnetic and coulomb interactions between electrons on neighboring sites @xmath7 and @xmath8 with coupling constants @xmath1 and @xmath12 , respectively . if double occupancies of sites are excluded eq . ( [ h ] ) represents the well - known @xmath0-@xmath1 model for @xmath13 . the interaction terms in eq . ( [ h ] ) give rise to two kinds of charge ops . a hartree - like contraction of the third term yields an op proportional to @xmath14 describing the charge on the site @xmath7 . it may vary from site to site and represents a conventional charge density wave ( cdw ) state . the exchange contractions of the second and third term in eq . ( [ h ] ) yield an op proportional to @xmath15 , where @xmath7 and @xmath8 are nearest neighbor sites . this state may be called a nonlocal cdw or a bond - order wave ( bow ) state @xcite where the cdw acquires an internal degree of freedom because the electron and hole occupy different sites . it has been shown that in the large n limit of the @xmath0-@xmath1 model ( which corresponds to enforcing the constraint of no double occupancies of sites only globally ) the phase diagram consists in the underdoped regime of incommensurate bow states ( at zero doping of the staggered flux phase @xcite as a special case ) @xcite . at the same time the conventional cdw op is zero showing that both kinds of charge order are independent from each other . more recently the bow state has been studied theoretically in more detail @xcite . also models with more than one band @xcite or more complex ops @xcite have been considered . recently a microscopic form for the op in underdoped ybco and bi2201 was proposed @xcite based on experimental data from resonant x - ray scattering .    throughout the paper we will assume that the temperature is below the transition temperature to the bow state . the ops are then in general nonzero and their symmetry properties can be studied . we will classify possible ops for bow states by exploiting point - group and time reversal symmetries as well as the hermiticity of @xmath16 . in the appendix it is shown that possible ops for the ground state are basis functions for representations of @xmath17 . if the ground state is non - degenerate in the sense that it does not contain two linearly independent ops the representation is irreducible . if the ground state is degenerate and satifies a two dimensional representation this representation may be irreducible or reducible . in the latter case it is composed of two ops with different symmetries and the degeneracy is not a consequence of symmetry but of coupling constants . in the following we will confine our discussion to ops which form irreducible representations of @xmath17 and exlude accidential degeneracies , additional instabilities or induced higher harmonics @xcite . explicit expressions for the ops will be given for bow states with four wave vectors of the form @xmath18 and the form @xmath19 and @xmath20 . from eq . ( [ h ] ) follows that the bow op has the form of a coupling constant times the matrix element @xmath21 , where @xmath7 and @xmath8 are nearest neighbors . to simplify the nomenclature we will call the modulated part of @xmath21 op in the following . after a fourier transform we obtain , @xmath22 @xmath23 is the vector from the origin to the lattice site @xmath7 . the sum over @xmath24 in eq . ( [ fourier ] ) includes in the plane - wave limit only the wave vectors corresponding to a charge instability of the normal state . they form a star of wave vectors @xmath25 . writing @xmath26 , keeping @xmath27 fixed and performing a fourier transformation with respect to @xmath23 we get @xmath28 the functions @xmath29 are defined by eq . ( [ f ] ) and represent our set of order parameters . if umklapp terms are included the sum over @xmath30 may not only include primary instability vectors of the normal state but higher harmonics with wave vectors @xmath31 where @xmath32 is an integer . they form new stars and cause deviations from the plane - wave limit of the op . because these higher harmonics are important only near the transition to the commensurate phase we will neglect them in the following and restrict ourselves to the plane - wave limit . the symmetry group of the square lattice is @xmath17 . using the notation of ref . @xcite let us denote one of the 8 symmetry transformations by @xmath33 . its action on the order parameter in eq . ( [ f ] ) can be written as @xmath34 where @xmath35 is the 2x2 matrix representing @xmath33 in the two - dimensional direct space . after a fourier transformation with respect to @xmath23 we find that @xmath29 transforms under @xmath33 into @xmath36 , where @xmath37 and @xmath38 belong to the star of wave vectors and to nearest neighbor bonds , respectively . this means that the set of functions @xmath39 forms basis functions for a ( reducible ) representation of @xmath17 . decomposing this reducible representation into irreducible parts the basis function of one of the irreducible representations describes the op of the state corresponding to the global minimum of the free energy . one important feature is that in general both @xmath30 and @xmath27 are transformed under @xmath33 at the same time and not independently from each other . this is a crucial point in our approach . further general properties of the functions @xmath40 are related to time reversal and the hermiticity of the hamiltonian . the operator @xmath41 for time reversal is defined in real space by @xmath42 where the star means conjugate complex . taking fourier transforms on both sides we get , @xmath43 or @xmath44 or , @xmath45 in eqs . ( [ philf2 ] ) and ( [ philf3 ] ) @xmath46 stands for @xmath47 and @xmath27 is fixed in the sums over @xmath23 . @xmath48 is defined by the last equation . some authors interprete the right - hand side of eq . ( [ philf2 ] ) as a fourier transform of @xmath49 which may be written as @xmath50 . the connection to our definition eq . ( [ philf4 ] ) is @xmath51 . in order to avoid confusion we will always use our definition in eq . ( [ philf4 ] ) . using the hermiticity of the hamiltonian the second half of eq . ( [ f ] ) yields @xmath52 @xmath53 denotes the rotation by @xmath54 . ( [ philf4 ] ) implies @xmath55 , which corresponds to the case of integral spin . @xcite applying the frobenius - schur test @xcite to the point group @xmath17 shows that including @xmath41 in the set of symmetry transformations can not produce additional degeneracies of irreducible representations . thus it is convenient to construct first basis functions for irreducible representations of the point group and then to check their behavior under time reversal . in the following we will first consider the case with 4 wave vectors along the diagonals , i.e. , @xmath56 , where @xmath57 lies between 0 and @xmath54 . the four bond directions are denoted by @xmath58 . it is easy to see that the following 8 functions @xmath59 , @xmath60 , @xmath61 , @xmath62 , and @xmath63 yield a reducible representation of @xmath17 . let us denote the linear combinations of the @xmath64 which form basis functions for the corresponding irreducible representations @xmath65 by @xmath66 for the one - dimensional representations @xmath67 one can easily determine the coefficients @xmath68 from the character table of @xmath17 . one finds that each of these representations occurs exactly one time , the corresponding @xmath68 are given in the first 4 lines of table 1 . using again the character table one finds that the remaining 4 functions form 2 two - dimensional representations @xmath69 and @xmath70 . the corresponding @xmath68 are given in the lines 5 - 8 in table 1 . .coefficients @xmath68 [ cols=\"^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     going back to eq . ( [ herm ] ) we note that for the functions @xmath71 the phase factor @xmath72 is always equal to @xmath57 . multiplying eq . ( [ herm ] ) by @xmath68 and summing over @xmath73 we obtain @xmath74 from the character table of @xmath75 follows that @xmath76 is equal to @xmath77 for @xmath67 and equal to @xmath78 for @xmath79 . the solution of eq . ( [ ff ] ) is @xmath80 where the upper sign refers to @xmath81 and the lower sign to @xmath79 , respectively . the real part of @xmath77 , @xmath82 , may assume any real number .    for @xmath83 or @xmath54 the four functions @xmath84 form a basis for a reducible representation of @xmath17 which decomposes into @xmath2 , @xmath3 and @xmath4 representations with the basis functions @xmath85 , @xmath86 and @xmath87 , @xmath88 , respectively . ( [ ff ] ) still holds the first two basis functions are real ( imaginary ) and the third and fourth ones imaginary ( real ) for @xmath83 ( @xmath89 ) . included as a special case is the staggered flux phase with wave vector @xmath90 . it has @xmath3 symmetry and a purely imaginary op in agreement with previous conclusions . @xcite    let us denote the second set of 8 functions by @xmath91 . each @xmath92 is obtained from @xmath64 by exchanging @xmath93 with @xmath94 and @xmath95 with @xmath96 . the linear space spanned by the functions @xmath97 yields a reducible representation of @xmath17 . decomposing it into its irreducible parts gives one time the representations @xmath98 and two times the representation @xmath4 , exactly as for the first 8 functions @xmath64 . the analogue of eq . ( [ c ] ) reads @xmath99 where the coefficients @xmath68 are the same as in table 1 . the phase factor @xmath72 is for all 8 functions equal to @xmath100 so that eq . ( [ ff ] ) reads @xmath101 with the solution @xmath102 @xmath103 is unrelated to @xmath82 and may assume any real value . this expresses the fact that @xmath104 and @xmath105 describe possible ops for all values of @xmath82 and @xmath106    complex functions for @xmath77 and @xmath107 do not necessarily imply that the corresponding states break @xmath41 symmetry . this is true in particular in our case because a possible imaginary part to @xmath104 can come from the matrix element but also from combinations of the exponential functions in eq . ( [ f ] ) . a general criterion for an unbroken @xmath41 symmetry follows from eq . ( [ fhilf1 ] ) , namely , @xmath108 applying fourier transformations on both sides of eq . ( [ fhilf5 ] ) similar as in eqs . ( [ philf2 ] ) and ( [ philf3 ] ) yields @xmath109 comparing with eq . ( [ philf4 ] ) yields the following criterion which must be fulfilled if @xmath41 symmetry is unbroken , @xmath110 for the special case @xmath111 the above criterion is fulfilled for the real op of @xmath2 and @xmath3 symmetry , found above , but not for the imaginary op of the @xmath4 symmetry . thus @xmath41 symmetry is unbroken for the @xmath2 and @xmath3 and broken for the @xmath4 symmetry . for @xmath112 one finds that the purely imaginary ops of the @xmath113 symmetries break and the real op of the @xmath4 symmetry preserves @xmath41 symmetry .    considering a general @xmath30 along the diagonals , a ground state with symmetry @xmath65 is in general given by a linear combination of all basis functions belonging to the same representation . it has thus in our case the form @xmath114 with coefficients @xmath11 and @xmath115 which have to be real to be compatible with eq . ( [ f1 ] ) and ( [ f11 ] ) . applying @xmath41 to this state we obtain , @xmath116 inserting the functions @xmath64 into eq . ( [ philf4 ] ) , multiplying by @xmath68 , summing over @xmath73 and using eq . ( [ ff ] ) yields @xmath117 replacing @xmath64 by @xmath92 and using eq . ( [ ffff ] ) instead of eq . ( [ ff ] ) gives @xmath118 eqs . ( [ dia3 ] ) and ( [ dia4 ] ) always hold . if , in addition , @xmath41 symmetry is preserved we obtain from eq . ( [ dia1 ] ) , @xmath119 and @xmath120 inserting eqs . ( [ dia3 ] ) - ( [ dia6 ] ) into eq . ( [ tall ] ) yields @xmath121 noting that eqs . ( [ f1 ] ) and ( [ f11 ] ) can also be written as @xmath122 and @xmath123 eq . ( [ tttt ] ) is equivalent to @xmath124 or , using eqs . ( [ c ] ) and ( [ cc ] ) , @xmath125 the functions @xmath64 and @xmath126 are different from each other and the functions of each of the two sets transform within each set under the elements of the point group and under time reversal . thus symmetry does not enforce any relation between @xmath82 and @xmath106 and eq . ( [ f3 ] ) will not necessarily be fulfilled for a general hamiltonian . however , this does not exclude ops exhibiting @xmath41 symmetry . the left and right - hand sides of eqs . ( [ f3 ] ) may assume independently any real value . the case where both values are equal is not excluded and represents an op with @xmath41 symmetry . such a fine - tuned state may , however , be vulnerable to perturbations , for instance , to a change in the coupling constants , the temperature etc . since no general argument seems to exist which protects eq . ( [ f3 ] ) against such perturbations it is reasonable to conclude that in the general case the basis functions in eq . ( [ c ] ) and eq . ( [ cc ] ) break @xmath41 symmetry for @xmath127 and @xmath128 . whether for a specific hamiltonian the ground state breaks or preserves @xmath41 symmetry can only be determined by an explicit calculation of the ops and the free energy . in the next section we will encounter a totally different case where the breaking and preserving of @xmath41 symmetry is enforced by symmetry independently of the values of microscopic coupling constants or specific hamiltonians . next we consider the case of four wave vectors along the crystalline axes , i.e. , @xmath129 , @xmath130 , @xmath131 , and @xmath132 where @xmath57 lies between 0 and @xmath54 . using the previous notation the functions @xmath133 yield irreducible representations of @xmath113 and @xmath4 symmetries with the basis functions @xmath85 , @xmath134 , @xmath87 , and @xmath135 , respectively . these basis functions can be written in the form of eq . ( [ c ] ) where the sum runs from @xmath136 to @xmath137 and the corresponding @xmath65 in table 1 is chosen . the exponential factor in eq . ( [ herm ] ) is in each case @xmath138 . ( [ ff ] ) holds for these three representations and their basis functions are complex for @xmath139 . all the above results also apply to the set @xmath140 , if the exponential factor is replaced by @xmath141 . thus each of the manifolds @xmath104 and @xmath142 lead to one @xmath113 and one @xmath4 representation and their basis functions are complex for @xmath143 . the arguments concerning @xmath41 breaking in eqs . ( [ tall ] ) - ( [ sum ] ) can be transferred to the present star of wave vectors with the result that all states which are not fine - tuned in the sense discussed above break @xmath41 symmetry . the remaining 8 functions are conveniently split into the combinations @xmath144 and @xmath145 , where @xmath146 , @xmath147 etc . mean @xmath93 , @xmath95 etc . and @xmath73 runs from 1 to 4 . the functions @xmath148 lead to @xmath2 , @xmath3 and @xmath4 , the functions @xmath149 lead to @xmath150 , @xmath151 and @xmath4 representations . the corresponding basis functions are the same as for the above @xmath64 manifold , once @xmath64 is replaced by @xmath152 or @xmath153 , respectively . for all 8 functions the wave and the bond vectors are perpendicular to each other implying that @xmath57 is identical to zero and that no complex exponential appears in eq . ( [ herm ] ) . as a result we get @xmath154 so that @xmath155 is real for @xmath156 and imaginary for @xmath157 . using these properties we have from eq . ( [ philf4 ] ) @xmath158 for @xmath159 . ( [ fplus ] ) is a direct consequence of the definition of the operator @xmath41 and holds in any case . if in addition @xmath41 symmetry applies eq . ( [ dia1 ] ) also holds . forming appropriate basis functions eq . ( [ dia1 ] ) is identical with eq . ( [ fplus ] ) after taking into account that @xmath160 and @xmath161 are real and @xmath162 imaginary . this means that the condition for @xmath41 symmetry is automatically fulfilled in this case for all three representations . remarkable is that no condition of the kind of eq . ( [ tttt ] ) or eq . ( [ f3 ] ) appears which can not be fulfilled in the general case . the @xmath41 symmetry arises here without fine - tuning and is enforced by symmetry . finally , let us consider the basis functions @xmath163 of the irreducible representations @xmath164 . ( [ herm ] ) yields @xmath165 implying that @xmath166 and @xmath167 are real and @xmath168 are imaginary . forming basis functions in eqs . ( [ philf4 ] ) and ( [ herm ] ) gives @xmath169 if in addition @xmath41 symmetry holds eq . ( [ dia1 ] ) is fulfilled and yields after forming linear combinations of @xmath150 , @xmath151 , and @xmath4 symmetry , @xmath170 clearly , eqs . ( [ fminus1 ] ) and ( [ fminus2 ] ) contradict each other . thus @xmath41 symmetry is always broken in all three cases in a robust way , i.e. , independent of specific hamiltonians and values for microscopic coupling parameters .    for completeness let us consider the case of an usual cdw without internal bond degrees of freedom . ( [ herm ] ) reads for @xmath171 @xmath172 . ( [ dia2 ] ) is always fulfilled . forming suitable linear combinations to get basis functions for irreducbile representations we see that @xmath41 symmetry is always unbroken in an usual cdw . the above analysis showed that many of the symmetry allowed ops break @xmath41 symmetry . the finite imaginary part of these ops generate circulating currents and space - dependent magnetic fields @xcite which so far could not be observed @xcite . concentrating therefore on @xmath41 conserving ops there are none without fine - tuning in the case of a star with wave vectors along the diagonals . for the experimentally observed star with wave vectors along the crystalline axes there are three ops which preserve @xmath41 symmetry in a robust way . they have the symmetries @xmath2 , @xmath3 and @xmath4 and originate from the @xmath173 manifold . in particular , the @xmath161 state with @xmath3 symmetry seems to be a good candidate for the op in underdoped cuprates @xcite . its bond charge pattern @xmath21 is proportional to @xmath174 for @xmath175 and @xmath176 for @xmath177 and is illustrated in fig . 1 . the color on each bond indicates the value for the corresponding bond charge . the pattern represents a simple bidirectional bow state where the charges on the hozontal and vertical bonds vary only in one direction . different ground states for underdoped cuprates have also been proposed , for instance , uniaxial bow states with @xcite or without @xcite @xmath41 breaking . interesting is that the relevant ops of the hot spot model of ref . @xcite are closely related to our manifolds @xmath173 and @xmath178 concerning point group and time reversal symmetries . ( color online ) bond charge pattern of the @xmath161 state using @xmath179 . , width=264 ]    the op deduced from experimental data in ref . @xcite uses a form for the op which is based on the approximation @xmath180 this approximation is obtained from eq . ( [ f ] ) by shifting the sum over @xmath181 by @xmath182 and using for the matrix element the @xmath30 independent function @xmath183 . from eq . ( [ herm ] ) follows that @xmath183 has to be real . inserting eq . ( [ f ] ) into eq . ( [ fourier ] ) and using eq . ( [ keim ] ) yields @xmath184 the sum over @xmath181 is only nonzero if @xmath183 is a linear combination of @xmath185 , @xmath186 , @xmath187 and @xmath188 . inserting these functions into eq . ( [ pattern ] ) and using the transformation rule of eq . ( [ trans ] ) shows that these patterns have @xmath2 , @xmath3 , and @xmath4 symmetries . for instance , for the @xmath3 symmetry we have @xmath189 where @xmath190 is a real constant . the bond charge patterns of eq . ( [ pattern ] ) are invariant if @xmath30 is transformed as @xmath191 and @xmath27 is kept fixed . this transformation describes a permutation of the wave vectors of the bow and does not correspond to an element of the point group @xmath17 . invariance under this transformation represents an additional symmetry which we will call @xmath192 symmetry in the following . applying @xmath41 to eq . ( [ pattern ] ) yields @xmath193 where the upper and lower sign holds for the @xmath113 and @xmath4 representations , respectively . the corresponding basis functions are therefore real or imaginary . ( [ pattern ] ) is identical with eq . ( s9 ) in ref . this equation was used to analyse inelastic x - ray data in underdoped cuprates and it was concluded that , disregarding uni - directional modulations , the ground state has @xmath3 symmetry . @xcite . the corresponding bond charges are proportional to @xmath194 for @xmath195 and to @xmath196 for @xmath197 , and yield a quite different pattern from that shown in fig . 1 .    as shown above the approximation eq . ( [ keim ] ) yields for each of the symmetries @xmath2 , @xmath3 , and @xmath4 just one op . the charge patterns with @xmath150 and @xmath151 symmetries , discussed in section iv , no longer exist in this approximation . ( [ keim ] ) also implies severe restrictions in the space of ops . for instance , if @xmath30 and @xmath27 are perpendicular to each other the functions @xmath29 become identical for @xmath198 . moreover , using the approximation eq . ( [ keim ] ) , eqs . ( [ tttt ] ) and ( [ f3 ] ) hold which means @xmath41 symmetry for the @xmath2 and @xmath3 states and at the same time fine - tuning of ops . it seems therefore preferable not to specialize @xmath29 as in eq . ( [ keim ] ) but to stick to the general form of the ops and to use our previous general symmetry classification . we will restrict the discussion in the following to @xmath3 states , but similar arguments also apply to the symmetries @xmath2 and @xmath4 .    in section iv we found that there are 3 different representations with @xmath3 symmetry . the ground state op @xmath199 will therefore be in general a linear combination of their basis functions , i.e. , @xmath200 where @xmath201 and @xmath202 are real numbers . the charge patterns form a two - fold manifold which is quite different from the case where eq . ( [ keim ] ) holds and only one op exists . this difference is due to the constraints in the space of ops introduced by the approximation eq . ( [ keim ] ) . next we simplify @xmath199 by requesting that it exhibits @xmath192 symmetry . @xmath199 then specializes unambiguously to @xmath203 given by @xmath204 regrouping the terms to form irreducible basis functions we get @xmath205 although @xmath206 and eq . ( [ patternb1 ] ) possess both @xmath192 and @xmath3 symmetry and are unambiguously determined by these symmetries they are different . this can be seen from their behavior under time reversal . ( [ patternb1 ] ) is @xmath41 symmetric according to eq . ( [ tkeim ] ) . applying @xmath41 to eq . ( [ f10 ] ) and using eqs . ( [ tall ] ) - ( [ dia5 ] ) gives @xmath207 thus @xmath203 breaks in general @xmath41 symmetry because eq . ( [ tttt ] ) or the equivalent eq . ( [ sum ] ) are in general not fulfilled so that the first two terms on the right - hand side of eq . ( [ that ] ) are not equal to @xmath208 . according to our previous discussion equations like @xmath209 are satisfied only for fine - tuned ops which neglect the contribution from circulating currents associated with @xmath41 breaking of @xmath210 , and @xmath203 . in contrast to that @xmath161 is @xmath41 symmetric without any restrictions . besides of the most general op of eq . ( [ f0 ] ) there are three distinguished and simple possibilities for the ground state op with @xmath3 symmetry : + ( a ) one is @xmath161 obeying @xmath41 but not @xmath192 symmetry ; + ( b ) another is given by eqs . ( [ fdach ] ) and ( [ f10 ] ) exhibiting @xmath192 but breaking in general @xmath41 symmetry ; + ( c ) state ( b ) with @xmath41 symmetry due to fine - tuning ; this state is equivalent to eq . ( [ patternb1 ] ) . + note that @xmath192 symmetry is in our case not an exact symmetry because the point group transformations change both the momenta of the bow and the bonds at the same time . thus ( b ) and ( c ) represent approximate states . in contrast to that state ( a ) is not @xmath192 symmetric but necessarily invariant under time reversal because this is a result of symmetry . moreover , it is the only state which has this property . since experiments seem to rule out circulating currents in underdoped cuprates @xcite the ground state should be state ( a ) if fine - tuned states ( i.e. , states with restrictions not enforced by symmetry ) can be ruled out . in conclusion , we have identified symmetry allowed bond ops for any model with nearest neighbor interactions such as the @xmath0-@xmath1 model and studied their properties , in particular , with respect to time reversal . the obtained results are relevant for recently observed charge - ordered states in underdoped cuprates and their symmetries . the proposed ops are more general than the variational anstze used in the past both in theoretical and experimental studies . being based on rigorous group theoretical considerations our results are useful to design improved variational forms for the op in microscopic calculations or to interprete experimental data . + * acknowledgements * the author is grateful to h. yamase , p. horsch , w. metzner , a. greco and b. keimer for useful discussions and to t. holder for help in producing the figure . interesting discussions and exchanges of e - mails with s. sachdev , a. allais and j. bauer are also acknowledged . it is well known that ground state wave functions form , disregarding accidential degeneracies , basis functions for irreducible representation of the symmetry transformations commuting with the hamiltonian . @xcite in this appendix we will study the question whether a similar statement is true for the ground state of a system described by a free energy functional and ops .    let us denote by @xmath211 one of the ops describing the ground state , i.e. , which correspond to the minimum of the free energy . @xmath211 can be represented as a linear combination of the @xmath29 and thus transforms in a well - defined way under point group transformations . considering @xmath17 and applying its n=8 transformations @xmath212 to @xmath211 we denote by @xmath213 the transformations which lead to linearly independent functions @xmath214 . the functions @xmath215 can be written as linear combinations of the functions @xmath216 . denoting the n point group operators by @xmath217 , we can write @xmath218 where @xmath219 is a matrix with d rows and n columns . applying @xmath220 to @xmath216 gives @xmath221 @xmath222 denotes the column of @xmath223 which corresponds to the point group transformation @xmath224 . for a fixed @xmath225 @xmath222 runs over d columns of @xmath223 which can be used to form a square matrix @xmath226 with @xmath227 rows and @xmath227 columns . ( [ p1 ] ) can now be written as @xmath228 considering a product of two transformations @xmath225 and @xmath229 we have @xmath230 on the other hand is @xmath231 so that @xmath232 eqs . ( [ an1 ] ) and ( [ an2 ] ) establish that the matrices @xmath226 together with the basis functions @xmath216 form a representation of @xmath17 .    assuming that no accidential degeneracy of the ground state is present the set of functions @xmath233 form a basis for the degenerate ops of the ground state . if @xmath234 there is only one linearly independent op describing the ground state . moreover , this op must form a basis function for a one - dimensional irreducible representation of @xmath17 . thus if the ground state is non - degenerate its op must be one of the basis functions belonging to irreducible one - dimensional representations discussed in sections iii and iv . in the case @xmath235 there are two linearly independent ops describing the degenerate ground state . they form a two - dimensional representation of @xmath17 . the two basis functions have the same free energy because they transform into each other by symmetry operations of the point group . determining the trace of the associated representation matrices @xmath236 there are two cases possible . the representation is irreducible and the two basis functions transform according to the @xmath4 representation . or , the representation is reducible and a superposition of two different one - dimensional representations . in this case the free energy of the two - dimensional reducible representation may be lower or higher than that of the irreducible representations . this means that the case is not excluded that a two - fold degenerate ground state transforms according to a reducible and not an irreducible representation .    in order to illustrate the above statements we consider a simple free energy model without bond degrees of freedom and two real ops , @xmath237 @xmath238 @xmath239 and @xmath240 are wave vectors of equal length along the @xmath241 and @xmath242 axis , respectively . forming the combinations @xmath243 yields basis functions @xmath244 and @xmath245 for a @xmath2 and a @xmath3 representation , respectively . we consider the following free energy functional , @xmath246 in the parameter range @xmath247 and @xmath248 . the underlying symmetry group is @xmath17 . the coefficient @xmath249 is proportional to @xmath250 and becomes negative below the transition temperature @xmath251 to the bow state . note that the prefactor @xmath249 is the same for both order parameters though the latter have different symmetries . in the usual terminology this corresponds to an accidential degeneracy . in our case this degeneracy is caused by the fact that the diverging susceptibilities in the normal state at @xmath252 and @xmath253 are related by point group operations . there is only one @xmath251 for both symmetries @xmath2 and @xmath3 . below @xmath251 the ops @xmath244 and @xmath245 will become finite and in general be also different due to the anharmonic terms in @xmath104 .    solving the extremal equations for @xmath104 yields the following solutions : @xmath254 @xmath255 @xmath256 the free energy eq . ( [ fa ] ) is invariant under @xmath257 and @xmath258 which leads to additional degeneracies described by @xmath259 in eqs . ( [ solu1 ] ) - ( [ solu3 ] ) . it is convenient to take this degeneracy tacitly into account and to consider only half of the above solutions . calculating also the corresponding free energies we find that ( a ) represents a basis function @xmath245 of length @xmath260 for a @xmath3 representation with energy @xmath261 . similarly , ( b ) represents a basis function of length @xmath262 for a @xmath2 representation with energy @xmath263 . finally , ( c ) consists of two degenerate basis functions with the components @xmath264 and @xmath265 , respectively , where @xmath244 and @xmath245 are given by the expressions of eq . ( [ solu3 ] ) , omitting @xmath259 in these expressions . the two basis functions yield a reducible two - dimensional representation containing both @xmath2 and @xmath3 symmetries . the corresponding free energy is @xmath266 .      because of the assumption @xmath271 the free energy of ( a ) is always lower than that of ( b ) so that the ground state is given either by ( a ) or by ( c ) . 2 shows the ratio of the free energies of ( c ) and ( a ) as a function of @xmath269 for @xmath270 . for @xmath272 the curve in fig . 2 is always below 1 . thus the solution ( a ) has in this region the lowest free energy and describes the stable state . it is non - degenerate and its basis function belongs to an irreducible representation of @xmath3 symmetry . for @xmath273 the curve in fig . 2 is larger or equal to one . as a result solution ( c ) has the lowest free energy in this interval and describes a degenerate ground state . it is given by a two - dimensional reducible representation which consists both of @xmath2 and @xmath3 components . our calculation shows that this two - dimensional reducible representation may have a lower free energy than the @xmath2 and @xmath3 components . our calculation also demonstrates that the same basis functions may describe a degenerate or a non - degenerate ground state depending on the values of the coupling constants . this means that the degeneracy of a ground state described by a reducible two - dimensional representation is not enforced by symmetry as in the case of irreducible representations but depends in general on the values of the coupling constants . it thus can be considered to be accidential . e. blackburn , j. chang , m. hcker , a.t . holmes , n.b . christensen , r. liang , d.a . bonn , w.n . hardy , u. rtt , o. gutowski , m. v. zimmermann , e.m . forgan , and s.m . hayden , phys . lett . * 110 * , 137004 ( 2013 ) . s. blanco - canosa , a. frano , t. loew , y. lu , j. porras , g. ghiringhelli , m. minola , c. mazzoli , l. braicovich , e. schierle , e. weschke , m. le tacon , and b. keimer , phys . lett . * 110 * , 187001 , ( 2013 ) .", "tags": [], "output_text_a": "This paper investigates the role of charge-ordered states in underdoped cuprates, particularly focusing on the charge-modulated states with incommensurate wave vectors observed in compounds like YBCO and Bi-based materials. The study aims to characterize these charge-ordered states in interacting systems, considering the implications of point group and time reversal symmetries, as well as the hermiticity of the Hamiltonian. The paper discusses the formation of pseudogaps, Fermi pockets, and quantum oscillations, suggesting their intimate relation to charge order. It explores the microscopic form of the charge order parameter (OP) in cuprates, using a model Hamiltonian relevant to these materials. The study classifies possible OPs for bond-order wave (BOW) states, analyzing their symmetry properties and the conditions under which time reversal symmetry is preserved or broken. The paper concludes that for the experimentally observed wave vectors along the crystalline axes, there are three OPs that preserve time reversal symmetry robustly, with the BOW state of a specific symmetry being a good candidate for the OP in underdoped cuprates. The findings are based on rigorous group theoretical considerations and are intended to aid in designing improved variational forms for OPs in microscopic calculations and interpreting experimental data.", "output_text_b": "This arXiv paper discusses the role of charge ordered states in underdoped cuprates and their relation to the pseudogap and fermi pockets. The paper aims to characterize charge ordered states in interacting systems, taking into account point group and time reversal symmetries as well as the hermiticity of the Hamiltonian. The microscopic form of the charge order parameter in cuprates is not yet clear, and the paper illustrates this using a model Hamiltonian for electrons on a square lattice. The interaction terms in this Hamiltonian give rise to two kinds of charge order parameters: a Hartree-like contraction describing the charge on a site, and exchange contractions yielding a nonlocal charge density wave or bond-order wave state. The paper then goes on to classify possible order parameters for bond-order wave states using point group and time reversal symmetries, and discusses the implications of these symmetries for the order parameter.", "score": 0.10000000000000009, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the investigation of charge-ordered states in underdoped cuprates and the characterization of these states considering symmetries and Hamiltonian properties.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of characterizing charge-ordered states in underdoped cuprates.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of a model Hamiltonian and group theoretical considerations.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant conclusions, such as the identification of OPs that preserve time reversal symmetry.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"charge order parameter (OP)\" and \"bond-order wave (BOW)\" but does not explain them, which might be necessary for clarity.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by mentioning its potential to aid in designing improved variational forms for OPs and interpreting experimental data.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the role of charge ordered states in underdoped cuprates and the characterization of these states considering symmetries and Hamiltonian properties.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem, which is the characterization of charge ordered states in interacting systems.\n4. **Methodology**: The summary mentions the use of a model Hamiltonian for electrons on a square lattice to illustrate the charge order parameters.\n5. **Significant Results**: The summary discusses the classification of possible order parameters and the implications of symmetries, which are significant results.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses some technical terms like \"Hartree-like contraction\" and \"bond-order wave state\" but does not explain them, which might be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. **Significance/Impact**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the standard model  ( sm ) provides an excellent description of all experimentally measured observables at present . mass generation relies on the higgs mechanism , which is based on the introduction of an elementary scalar field transforming in the fundamental representation of the @xmath0 group . the vacuum expectation value  ( vev ) of this scalar field sets the weak scale , which is then proportional to the magnitude of the square root of the negative squared mass parameter in the scalar higgs potential  @xcite,@xcite . the sm provides no explanation for the magnitude of this mass parameter , which is sensitive via radiative corrections to new physics at high scales . the minimal supersymmetric extension of the standard model  ( mssm ) has most of the virtues of the sm  @xcite@xcite . apart from a loop factor , the magnitude of the higgs mass parameter is determined by the size of the supersymmetry - breaking parameters of the third generation squarks . these also determine the value of the sm - like higgs mass at the loop level . values of the third generation squark masses of about 1  tev lead to sm - like higgs masses in the 115130  gev range  @xcite  @xcite . hence , recent hints of a higgs mass of about 125  gev are consistent with mssm predictions  @xcite . the supersymmetry - breaking mass parameters depend on the unknown mechanism of supersymmetry breaking and on the messenger scale , at which supersymmetry breaking is transmitted to the observable sector . recent experimental bounds from the lhc set strong constraints on colored particles at the tev scale , and therefore on the parameters of minimal models of supersymmetry breaking . several works have studied the relationship of the supersymmetric mass parameters between the messenger scale and the weak scale  @xcite@xcite . it would be very useful to have a method that allowed us to set bounds on the supersymmetry - breaking parameters at the messenger scale , independent of the unknown supersymmetry - breaking scheme and of the unknown value of the messenger scale . renormalization group invariants ( rgis )  @xcite@xcite provide such a method . determination of the value of the rgis at the tev scale sets their values at the messenger scale . one can then use the information provided by the rgis to set constraints on general classes of models  @xcite,@xcite . an exhaustive analysis of the rgis for different supersymmetry - breaking scenarios is performed in ref .  @xcite . the effects of various prelhc and lhc results on the phenomenological mssm  ( pmssm ) parameter space have been studied in detail in refs . @xcite@xcite . in this article , we use the pmssm parametrization of the soft supersymmetry - breaking parameters  @xcite to determine the current probability distribution of the rgis at the tev scale . we shall compare the situation before and after constraints from the lhc are imposed .    to illustrate the power of this framework , we will use the pmssm rgi probability distributions to analyze three particular issues :    * possible scale of gaugino mass unification . *   messenger scale parameters in a realization of general gauge mediation . *   messenger scale parameters associated with minimal gauge mediation . the probabilistic interpretation of the rgis can be applied to other quantities of interest in the mssm using for example the analysis presented in ref . @xcite . in section 2 we list the rgis to be used in this paper , outlining the methodology to be used in our analyses . we then compute the rgi probability distributions obtained by imposing current experimental constraints . in section 3 we study the question of gaugino mass unification and the consistency of the scale of this gaugino mass unification with experimental constraints . in section 4 we look at general gauge mediation and determine the probability distribution of the relevant parameters of this model . section 5 discusses the probability distributions for the minimal gauge mediated parameters . we reserve section 6 for our conclusions . details about our probability analysis are given in appendix a. appendix b gives the specific definition of the pmssm . appendix c gives the inverted relationships between the soft masses of the pmssm and the rgis . appendix d lists these in the case of flavor - blind models . there are 14 relevant rgis , analyzed in ref . @xcite,@xcite , involving the soft supersymmetry - breaking parameters , which we will use as the basis of our current work . these are summarized at one - loop accuracy in table  [ table.inv ] ; two - loop corrections were studied in ref . @xcite and shown to be of order of a few percent or less . moreover , there are 2 rgis relating only the gauge couplings  ( @xmath1 and @xmath2 ) , which we can use to redefine the other 12 rgis in terms of just the soft masses and the scale . these soft masses , ignoring possible small flavor dependence of the sfermion and higgs mass parameters , are given by a total of 17 scalar masses plus 3 gaugino masses . one can make the additional well - motivated assumption of degeneracy for the first and second generation sfermion mass parameters . in such a case , one is left with 12 scalar masses . therefore , the 12 rgis , which are linearly independent , can be inverted to give 12 soft supersymmetry - breaking masses in terms of these rgis as a function of 3 given soft masses . .1-loop rg invariants in the mssm [ cols=\"^,^,^,^,^ \" , ]     the probabilities corresponding to each of these are plotted in figs . [ mgmparameters1]-[mgmparameters4 ] .    observe that , as is apparent from eq . ( [ imib ] ) and table  [ table.inv ] , mgm is associated with negative values of @xmath3 and positive values of @xmath4 . as can be seen from fig . [ invariants1 ] , these values of the rgis are not the most likely ones consistent with the present constraints . however , wether a given model is likely or not is a very scan dependent question and hence we will not address that here . instead , the probability distributions for the mgm parameters are computed for those configurations for which these conditions are fulfilled . the final distribution is obtained by multiplication of the independent probabilities of the 9 @xmath5 and 12 @xmath6 solutions given in eqs . [ mgm_bis]-[mgm_gis ] . the results are depicted in fig . [ mgmpardist ] .    the messenger scale may be obtained from the value of the gauge coupling at this scale by using eq . ( [ munifgunif ] ) , replacing @xmath7 by @xmath8 . however , in contrast to the gaugino mass unification scale , the messenger scale is always a physical scale and therefore expected to take values between tens of tev and the gut scale , or equivalently , gauge coupling values of @xmath9 . ( [ mgmpardist ] ) shows that values of the gauge couplings @xmath10 tend to be preferred , which lie outside the physical region . considering only the physical range , values of the messenger scale close to the gut scale are slightly preferred . the most probable values of the parameter @xmath11 are about 1.25  tev and 4.25  tev . using the relation @xmath12 and the values of the gauge couplings at the weak scale , @xmath13  tev would lead to a bino mass of the order of 250  gev , a wino mass of about 500  gev and a gluino mass of about 1.5  tev . the larger value of @xmath11 would lead to gaugino masses 3.5 times heavier than these ones . supersymmetric extensions of the standard model provide a relationship between the weak scale and the scale of the supersymmetry - breaking parameters , rendering it stable under quantum corrections . in the mssm , the sm - like higgs particle is predicted to be light . the fast decoupling of the supersymmetric particles from the precision electroweak observables make the mssm predictions consistent with those of the sm with a light higgs , in full consistency with what current data seems to suggest . however , no direct hint of supersymmetric particles has been observed experimentally and hence no information of the structure and origin of the supersymmetry - breaking parameters is provided by current experiments , apart from perhaps the indirect hints provided by the anomalous magnetic moment and the higgs mass range . once additional information from direct searches becomes available , a method to determine the structure of supersymmetry - breaking parameters at the messenger scale , as well at the messenger scale itself would be desirable . rgis provide such a method , establishing a direct relationship between the observables at the weak scale and the messenger scale parameters . in this article we have studied the probability distributions of a set of rgis in the mssm arising from symmetry arguments . the distributions are analyzed at the tev scale by making use of the constraints coming from flavor physics , lep and tevatron searches , higgs physics and the anomalous magnetic moment of the muon , and separately from those , by constraints provided by the lhc . we have used a flat prior for the soft supersymmetry - breaking masses , using a pmssm approach . the current constraints already provide interesting features in the probability distributions .    as an example of the application of the rgis , we have used them to analyze the question of gaugino mass unification and also the possible realization of general and minimal gauge mediation . the methods described here are quite general and may be applied to analyze the ultraviolet properties of the mssm parameters in other interesting supersymmetery - breaking scenarios . we noticed that the scale of gaugino mass unification is not necessarily identified with the messenger scale , but it can provide non - trivial information on the realization of minimal models of supersymmetry breaking . ggm provides a well - motivated example of flavor independent , supersymmetry - breaking models . the probability distributions for the ggm parameters can be determined from those of the rgis and present some interesting features as well . they also lead to information on possible non - universal higgs mass parameters at the messenger scale . the determination of the messenger scale in ggm through rgis demands the measurement of both the first and third generation fermion masses as well as the higgs masses , and hence it is not practical at this moment . we also analyze the more simplistic subset of models given by mgm . since the entire model space of mgm is determined by only 2 parameters , we are able to extract information about the possible scale of susy particles as well as the messenger scale in this scenario . it is clear that although the analysis we describe already has interesting features , the probability distributions of the rgis will become particularly useful when the lhc starts revealing the presence of supersymmetric particles at the weak scale . in such a case , the probability distribution of the rgis will become sharper and will start showing important features of the supersymmetry - breaking mass parameters at the messenger scale . due to the higher cross sections for the production of supersymmetric particles , the higher luminosities and the higher energy reach , the 8  tev run this year will lead to relevant constraints on the supersymmetric particle masses . it could also lead to the first hint of the presence of supersymmetry , beyond the indirect ones associated with higgs search results . it will be therefore very interesting to repeat the analysis of the rgi distributions once the 2012 results are available . +   + * acknowledgements * we thank sabine kraml and harrison prosper for valuable discussions . fermilab is operated by fermi research alliance , llc , under contract de - ac02 - 07ch11359 with the united states department of energy . work at anl is supported in part by the u.s . department of energy  ( doe ) , div .  of hep , contract de - ac02 - 06ch11357 . we are interested in a quantity which quantitative reflects the probability distributions of general functions of the masses , given the probability distributions for the masses themselves . the markov chain monte carlo ( mcmc ) method is used to scan over the pmssm parameters in the range considered to be probed at the lhc . for each point corresponding to a model , a likelihood is computed , given certain experimental constraints . since the mcmc technique scans the given parameter space along the isocontours of likelihood due to prelhc constraints listed in table  [ tab : prelhcobs ] , the ratio of the number of points scanned for any given value of a parameter to the total number of points gives the probability for that parameter value . this probability for a given point can then be re - weighted by the postlhc likelihoods to compute the current probabilities . we note however that the boundaries defining the pmssm region scanned , introduce an artificial effect in the resulting probability distributions . in the following , we will describe a method that can be used for eliminating this effect . in this method , we make the assumption that the lhc ( as well as the pre - lhc ) measurements will not be able to shed any light on the pmssm parameter regions that are not scanned due to kinematic constraints , and assign a flat probability to these insensitive regions outside the scan boundary . let us consider a two dimensional probability distribution @xmath14 of parameters @xmath15 and @xmath16 defined in a box where the variables @xmath15 and @xmath16 vary in the ranges @xmath17 , given some observables @xmath18 . assume that @xmath15 and @xmath16 have flat priors corresponding to the soft parameters that were scanned over in the mcmc . we are then interested in the probability distribution of some function , @xmath19 , given @xmath18 : @xmath20 . as explained in section 2.2 , the naive computation of this probability , especially using a flat prior @xmath21 , will heavily reflect the size of the box alongside any other inherent probability distribution of this function . the aim is to define a probability @xmath22 such that , if there is no condition on @xmath19 , then a flat distribution is obtained for @xmath23 . any variations of this flatness should be something that reflects the actual variation of the probability due to the effect of @xmath18 rather than the effect of having a bounded box , as is the case in the example given in section  [ rgipmssm ] . let us assume that the box contains @xmath24 bins in @xmath15 and @xmath25 bins in @xmath16 . the flat distributions are defined such that in the absence of any additional condition :    @xmath26    note that @xmath27 is defined as the distribution that would be obtained for @xmath19 if @xmath15 and @xmath16 have flat priors . this is the distribution that is referred to in the text as `` @xmath28 '' . this distribution itself is generally not flat , but will have a distinct shape reflecting the boundary conditions of the original @xmath29 variables . analogously , the probability for @xmath19 given @xmath18 is @xmath30 where this is referred to as `` @xmath31 '' in the text . an easy way to normalize this probability to obtain a flat distribution for the function @xmath19 in the absence of non - trivial conditions is to weight each bin , @xmath32 , by @xmath33 : @xmath34 the superscript @xmath35 denotes the fact that this effectively gives the average probability per unique @xmath36 combination for each @xmath32 . however , this has the effect of washing out small effects on the probability distribution from @xmath18 , when @xmath32 is such that a large number of unique combinations of @xmath36 contribute to a given value of @xmath19 . we propose an alternative method . first , instead of taking the ratio we shall consider the difference : @xmath37 . clearly this quantity is not always positive and can not be identified with a probability distribution . it has , however , the property that it becomes positive whenever the probability of @xmath32 is enhanced by the observations @xmath18 and negative in the opposite case . we shall , hence , define a renormalized distribution @xmath38 in the following way @xmath39\\\\ p^r(\\theta_i|o ) & \\propto & p(\\theta_i|o ) + \\left[p_0^{f}(\\theta_m)-p_0^{f}(\\theta_i)\\right]\\label{rew},\\end{aligned}\\ ] ] which is always positive since @xmath40 is positive and so is the quantity between brackets . the above quantity , eq .  ( [ rew ] ) has a clear interpretation : let us first stress that , by definition , @xmath41 is such that it has the largest number of unique combinations of @xmath36 contributing to it , with @xmath15 and @xmath16 varying with a flat distribution in the box . let s call @xmath42 the number of combinations corresponding to @xmath32 . therefore , all @xmath32 have a smaller number than @xmath41 , @xmath43 . this is reflecting the fact that for @xmath44 , the range of the original variables scanned over , @xmath15 and @xmath16 , did not include all the combinations necessary to weight the @xmath45 bin of @xmath46 the same as @xmath47 . we have made the argument that the values of @xmath15 and @xmath16 not scanned are ones that will not be affected by lhc measurements . hence we propose that these combinations are given the same weight as @xmath48 . this leads , after proper normalization , to nothing more than the last term , between square brackets , in eq . ( [ rew ] ) , and hence the quantity @xmath38 reflects the actual probability distribution of @xmath32 given @xmath18 , taking away the effect of the range of the original scan . for this quantity to represent a probability distribution in the strict sense , it must be normalized to 1 . since @xmath40 and @xmath49 are quantities which are normalized to 1 , assuming that the function @xmath32 is evaluated in @xmath50 different bins , the normalization factor is nothing more than @xmath51 . hence the properly normalized probability distribution for @xmath46 is given by : @xmath52\\right\\}\\label{rewn}\\;.\\ ] ] we can see that this behaves the way we expect it to , by noting that when @xmath18 has not impacted the probability of @xmath46 , i.e. @xmath53 , @xmath54 , so we obtain a flat distribution . on the other hand , if the @xmath49 is a constant , meaning that @xmath32 has a flat distribution in the same flat basis as the original variables @xmath15 and @xmath16 , then @xmath55 and we recovers @xmath40 without any modification , as we should .    in order to emphasize the impact of the experimental constraints in a more clear way , however , we have gone a step further . since we assumed that the probability outside the range we scanned is flat , the ratio of the difference of any two probabilities from flat , @xmath56 , will remain invariant if we extended the range of the original scan , increasing the box size . therefore , this quantity is than also invariant under an overall rescaling of the differences with the flat probability . let us assume that there is a non - trivial impact of experiments on the rgi distributions , namely @xmath57 for at least one @xmath45 . considering @xmath58\\ ] ] we define a scale factor , @xmath59 , such that the difference of this minimum with @xmath60 is scaled to be @xmath60 : @xmath61 we use the scale factor above to define a modified distribution @xmath62\\;,\\label{pss}\\\\ & = & \\frac{1}{p_0^{f}(\\theta_m ) l } \\left\\ { p_0^{f}(\\theta_m)+ sf \\left [ p(\\theta_i|o ) - p_0^{f}(\\theta_i ) \\right ] \\right\\}\\;. \\label{modifiedrdistribution}\\end{aligned}\\ ] ] once the scale factor @xmath59 is given , it is easy to translate this modified distribution , eq . ( [ modifiedrdistribution ] ) to the original one , eq .  ( [ rewn ] ) . the quantity @xmath63 has the virtue that when for a particular bin @xmath64 , meaning @xmath18 has had no impact on the @xmath32 probability , one obtains @xmath65 . on the other hand when @xmath66 , meaning when @xmath18 has maximally decreased the probability for that @xmath32 , @xmath67 . the fact that @xmath63 will be invariant under a change in scan range of the original variables can be seen by inspecting eq . [ pss ] and noting that under a change of scan range , @xmath68 when @xmath54 and by definition @xmath69 . even though @xmath63 can not be technically defined as a probability , it quantitatively reflects the actual impact of @xmath18 on the probability distribution of @xmath46 in a way which is independent of the artificial impact of scanning a finite region , and , as stressed above may be easily connected with @xmath38 , eq . ( [ rewn ] ) . we ran extensive numerical checks to make sure that this quantity indeed behaves in the expected manner . we have therefore used @xmath63 to represent the probability distribution of the rgis , giving the associated scale factor @xmath59 for every rgi distribution . in the text , in order to be more explicit about the meaning of these distributions , @xmath70 was renamed @xmath71-@xmath72 `` , while @xmath73 was renamed @xmath74 reweighted '' . the pmssm , a 19-dimensional realization  @xcite of the r - parity conserving mssm with parameters defined at the susy scale , @xmath75 , employs only a few plausible assumptions motivated by experiment : there are no new cp phases , the sfermion mass matrices and trilinear couplings are flavor - diagonal , the first two generations of sfermions are degenerate and their trilinear couplings are negligible . in addition , we assume that the lightest supersymmetric particle ( lsp ) is the lightest neutralino , @xmath76 . we thus arrive at a proxy for the mssm characterized by 19 real , weak - scale , susy lagrangian parameters :    * 3 gaugino mass parameters @xmath77 , @xmath78 , and @xmath79 ; * the ratio of the higgs vevs , @xmath80 ; * the higgsino mass parameter , @xmath81 , and the pseudo - scalar higgs mass , @xmath82 ; * 10 sfermion mass parameters @xmath83 , where @xmath84 + ( imposing @xmath85 , @xmath86 , etc . ) ; and * 3 trilinear couplings @xmath87 , @xmath88 and @xmath89 ,    in addition to the sm parameters .    for each pmssm point , softsusy3.1.6  @xcite was used to compute the susy spectrum , superisov3.0  @xcite was used to compute the low - energy constraints , micromegas2.4  @xcite was used for the susy mass limits , and higgsbounds2.0.0  @xcite for the limit on the @xmath90 mass  gev was applied to the @xmath91 computed with softsusy , cf . row 8 in table  [ tab : prelhcobs ] and row 12 in table  [ tab : lhcobs ] . ] . moreover , susyhit ( sdecay1.3b , hdecay3.4 )  @xcite was used to produce susy and higgs decay tables , and micromegas2.4  @xcite to compute the lsp relic density and direct detection cross sections . the various codes were interfaced using the susy les houches accord  @xcite . as mentioned in section 2 , one can make use of the rgis and three independent masses to determine all other soft breaking masses . as an example , we write down 2 sets of solutions with different unknown masses . all the masses and gauge couplings are at the same scale . the gaugino masses in both cases are given by @xmath92 we write the first set of solutions in terms of 3 third generation masses : @xmath93 , @xmath94 and @xmath95 ,    m_h_2 ^ 2= --++-d_l_13-+++ i_b_1 ^ 2 g_1 ^ 4- i_b_2 ^ 2 g_2 ^ 4- i_b_3 ^ 2 g_3 ^ 4 + ,    m_h_d^2= -+-3i_m_2 + --+-- i_b_1 ^ 2 g_1 ^ 4 + 3 i_b_2 ^ 2 g_2 ^ 4- i_b_3 ^ 2 g_3 ^ 4++3 m_q_3 ^ 2- ,    @xmath96    m_q_1 ^ 2= ( 20 i_m_1 + 5940i_m_2 - 3520 i_m_3 + 78 d_y_13h-627 d__1 + 60 i_y _ g_1 ^ 2 - 20 i_b_1 ^ 2 g_1 ^ 4 - 5940 i_b_2 ^ 2 g_2 ^ 4 + 3520 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_l_3 ^ 2= ( -10 i_m_1 + 330i_m_2 - 110 d_l_13 - 26 d_y_13h-11 d__1 - 20 i_y _ g_1 ^ 2 + 10 i_b_1 ^ 2 g_1 ^ 4 - 330 i_b_2 ^ 2 g_2 ^ 4 + 110 m_e_3 ^ 2 ) ,    m_l_1 ^ 2= ( 20 i_m_1 + 660i_m_2 - 26 d_y_13h-11 d__1 - 20 g_1 ^ 2 ( i_y_+i_b_1 ^ 2 g_1 ^ 2)-660 i_b_2 ^ 2 g_2 ^ 4 ) ,    m_d_1 ^ 2= ( 40 i_m_1 - 1760 i_m_3 + 78 d_y_13h+33 d__1 + 60 i_y _ g_1 ^ 2 - 40 i_b_1 ^ 2 g_1 ^ 4 + 1760 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_u_1 ^ 2= ( 80 i_m_1 - 880 i_m_3 - 78 d_y_13h-33 d__1 - 60 i_y _ g_1 ^ 2 - 80 i_b_1 ^ 2 g_1 ^ 4 + 880 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_e_1 ^ 2= ( 40 i_m_1 + 26 d_y_13h+11 d__1 + 20 i_y _ g_1 ^ 2 - 40 i_b_1 ^ 2 g_1 ^ 4 )    alternatively , the second set of solutions is given in terms of the 2 soft masses for the higgs , @xmath97 and @xmath98 , and a third generation squark mass , @xmath93 :    m_u_3 ^ 2= -++-i_m_2-++--- i_b_1 ^ 2 g_1 ^ 4+i_b_2 ^ 2 g_2 ^ 4 + i_b_3 ^ 2 g_3 ^ 4 + ,    m_e_3 ^ 2= -4 d_b_13 + 2 d_z++3i_m_2-+3 d_l_13 + -+- i_b_1 ^ 2 g_1 ^ 4 - 3 i_b_2 ^ 2 g_2 ^ 4 + i_b_3 ^ 2 g_3 ^ 4 + 2 m_h_d^2 + 2 m_h_u^2 - 6 m_q_3 ^ 2 ,    m_q_1 ^ 2= ( 20 i_m_1 + 5940i_m_2 - 3520 i_m_3 + 78 d_y_13h-627 d__1 + 60 i_y _ g_1 ^ 2 - 20 i_b_1 ^ 2 g_1 ^ 4 - 5940 i_b_2 ^ 2 g_2 ^ 4 + 3520 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_d_3 ^ 2= -+-2i_m_2 + --++- i_b_1 ^ 2 g_1 ^ 4 + 2 i_b_2 ^ 2 g_2 ^ 4- i_b_3 ^ 2 g_3 ^ 4-+2 m_q_3 ^ 2 ,    m_l_3 ^ 2= -2 d_b_13+d_z-+3i_m_2-+d_l_13 + -+ i_b_1 ^ 2 g_1 ^ 4 - 3 i_b_2 ^ 2 g_2 ^ 4 + i_b_3 ^ 2 g_3 ^ 4+m_h_d^2+m_h_u^2 - 3 m_q_3 ^ 2 ,    m_l_1 ^ 2= ( 20 i_m_1 + 660i_m_2 - 26 d_y_13h-11 d__1 - 20 g_1 ^ 2 ( i_y_+i_b_1 ^ 2 g_1 ^ 2)-660 i_b_2 ^ 2 g_2 ^ 4 ) ,    m_d_1 ^ 2= ( 40 i_m_1 - 1760 i_m_3 + 78 d_y_13h+33 d__1 + 60 i_y _ g_1 ^ 2 - 40 i_b_1 ^ 2 g_1 ^ 4 + 1760 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_u_1 ^ 2= ( 80 i_m_1 - 880 i_m_3 - 78 d_y_13h-33 d__1 - 60 i_y _ g_1 ^ 2 - 80 i_b_1 ^ 2 g_1 ^ 4 + 880 i_b_3 ^ 2 g_3 ^ 4 ) ,    m_e_1 ^ 2= ( 40 i_m_1 + 26 d_y_13h+11 d__1 + 20 i_y _ g_1 ^ 2 - 40 i_b_1 ^ 2 g_1 ^ 4 ) the most immediate consequence of flavor - blindness is the vanishing of @xmath99 and @xmath100 . therefore these invariants provide us with a direct test of the flavor - independent hypothesis with a minimal set of measurements . more precisely , they allow this hypothesis to be ruled out : measuring @xmath101 or @xmath102 at the low scale implies high - scale family non - universality ; however , as noted in ref . @xcite , measuring @xmath103 and @xmath104 at the low scale does not necessarily indicate high - scale universality . current experimental data from flavor physics strongly motivates a flavor - universal mediation mechanism for susy - breaking . accordingly , if @xmath99 and @xmath100 are found to vanish , it is reasonable to proceed a step further and attempt to extract constraints on the high - scale values of the flavor - blind mssm soft parameters from the rgis . the 7 scalar and 3 gaugino soft mass parameters in the flavor - blind mssm can be expressed uniquely in terms of the 10 invariants @xmath105 through @xmath3 listed in table  [ table.inv ] . these are listed in eqs . ( [ gauginos ] ) and ( [ ml1])-([flaveq2 ] ) . note that these relations depend on the 3 gauge couplings and further all couplings and soft parameters are assumed to be given at the messenger scale : @xmath106 @xmath107    using the invariants @xmath1 and @xmath2 these may be expressed entirely in terms of @xmath108 . equivalently , one can reduce the degrees of freedom at the high scale to a single parameter , which can be taken to be the value of that scale . in particular this permits tests of more restrictive flavor - universal models such as msugra , taking @xmath108 at the gut scale . y.  okada , m.  yamaguchi and t.  yanagida , prog . phys .   * 85 * , 1 ( 1991 ) . j.  r.  ellis , g.  ridolfi and f.  zwirner , phys . b * 257 * , 83 ( 1991 ) . h.  e.  haber and r.  hempfling , phys . lett .   * 66 * , 1815 ( 1991 ) . j.  a.  casas , j.  r.  espinosa , m.  quiros and a.  riotto , nucl . b * 436 * , 3 ( 1995 ) [ erratum - ibid . b * 439 * , 466 ( 1995 ) ] [ arxiv : hep - ph/9407389 ] . m.  carena , j.  espinosa , m.  quirs and c.  wagner , _ phys . * b 355 * ( 1995 ) 209 , hep - ph/9504316 ; + m.  carena , m.  quirs and c.  wagner , _ nucl . * b 461 * ( 1996 ) 407 , hep - ph/9508343 . h.  haber , r.  hempfling and a.  hoang , _ _ * c 75 * ( 1997 ) 539 , hep - ph/9609331 . s.  heinemeyer , w.  hollik and g.  weiglein , comput . commun .   * 124 * , 76 ( 2000 ) [ hep - ph/9812320 ] . s.  heinemeyer , w.  hollik and g.  weiglein , eur . j.  c * 9 * , 343 ( 1999 ) [ hep - ph/9812472 ] . m.  s.  carena , h.  e.  haber , s.  heinemeyer , w.  hollik , c.  e.  m.  wagner and g.  weiglein , nucl . b * 580 * , 29 ( 2000 ) [ hep - ph/0001002 ] . b.  c.  allanach , k.  cranmer , c.  g.  lester and a.  m.  weber , jhep * 0708 * , 023 ( 2007 ) [ arxiv:0705.0487 [ hep - ph ] ] . c.  f.  berger , j.  s.  gainer , j.  l.  hewett and t.  g.  rizzo , jhep * 0902 * , 023 ( 2009 ) [ arxiv:0812.0980 [ hep - ph ] ] . j.  a.  conley , j.  s.  gainer , j.  l.  hewett , m.  p.  le and t.  g.  rizzo , eur . j.  c * 71 * , 1697 ( 2011 ) [ arxiv:1009.2539 [ hep - ph ] ] . j.  a.  conley , j.  s.  gainer , j.  l.  hewett , m.  p.  le and t.  g.  rizzo , [ arxiv:1103.1697 [ hep - ph ] ] . s.  s.  abdussalam , b.  c.  allanach , f.  quevedo , f.  feroz and m.  hobson , phys . d * 81 * ( 2010 ) 095012 [ arxiv:0904.2548 [ hep - ph ] ] . s.  sekmen , s.  kraml , j.  lykken , f.  moortgat , s.  padhi , l.  pape , m.  pierini and h.  b.  prosper _ et al . _ , jhep * 1202 * , 075 ( 2012 ) [ arxiv:1109.5119 [ hep - ph ] ] . a.  arbey , m.  battaglia and f.  mahmoudi , eur . j.  c * 72 * ( 2012 ) 1847 [ arxiv:1110.3726 [ hep - ph ] ] . j.  l.  kneur and n.  sahoury , phys . d * 79 * , 075010 ( 2009 ) [ arxiv:0808.0144 [ hep - ph ] ] . j.  l.  kneur and g.  moultaka , phys . d * 59 * , 015005 ( 1999 ) [ arxiv : hep - ph/9807336 ] . g.  a.  blair , w.  porod and p.  m.  zerwas , eur . j.   c * 27 * , 263 ( 2003 ) [ arxiv : hep - ph/0210058 ] . g.  a.  blair , a.  freitas , h.  u.  martyn , g.  polesello , w.  porod and p.  m.  zerwas , acta phys . b * 36 * , 3445 ( 2005 ) [ arxiv : hep - ph/0512084 ] . m.  s.  carena , p.  h.  chankowski , m.  olechowski , s.  pokorski and c.  e.  m.  wagner , nucl . b * 491 * , 103 ( 1997 ) [ arxiv : hep - ph/9612261 ] . g.  l.  kane , p.  kumar , d.  e.  morrissey and m.  toharia , phys . d * 75 * , 115018 ( 2007 ) [ arxiv : hep - ph/0612287 ] . d.  a.  demir , jhep * 0511 * , 003 ( 2005 ) [ arxiv : hep - ph/0408043 ] . s.  p.  martin and p.  ramond , phys . d * 48 * , 5365 ( 1993 ) [ arxiv : hep - ph/9306314 ] . b.  ananthanarayan and p.  n.  pandita , int . j.  mod . 3229 ( 2007 ) [ arxiv:0706.2560 [ hep - ph ] ] . b.  ananthanarayan and p.  n.  pandita , mod . a * 19 * , 467 ( 2004 ) [ arxiv : hep - ph/0312361 ] . b.  ananthanarayan and p.  n.  pandita , int . j.  mod . a * 20 * , 4241 ( 2005 ) [ arxiv : hep - ph/0412125 ] . m.  carena , p.  draper , n.  r.  shah and c.  e.  m.  wagner , phys . d * 82 * , 075005 ( 2010 ) [ arxiv:1006.4363 [ hep - ph ] ] . c.  balazs , t.  li , d.  v.  nanopoulos and f.  wang , arxiv:1006.5559 [ hep - ph ] . m.  carena , p.  draper , n.  r.  shah and c.  e.  m.  wagner , phys . d * 83 * ( 2011 ) 035014 [ arxiv:1011.4958 [ hep - ph ] ] . j.  hetzel and w.  beenakker , [ arxiv:1204.4336 [ hep - ph ] ] . cms and lhcb collaborations , cms - pas - bph-11 - 019 , lhcb - conf-2011 - 047 , cern - lhcb - conf-2011 - 047 . g.  belanger , f.  boudjema , a.  pukhov , and a.  semenov , comput . .  commun . * 149 * , 103 ( 2002 ) , hep - ph/0112278 ; comput . .  commun . * 174 * , 577 ( 2006 ) , hep - ph/0405253 ; comput . .  commun . * 180 * , 747 ( 2009 ) , arxiv:0803.2360 . k.  choi , a.  falkowski , h.  p.  nilles , m.  olechowski and s.  pokorski , jhep * 0411 * , 076 ( 2004 ) [ hep - th/0411066 ] . k.  choi , k.  s.  jeong and k.  -i . okumura , jhep * 0509 * , 039 ( 2005 ) [ hep - ph/0504037 ] . m.  endo , m.  yamaguchi and k.  yoshioka , phys . d * 72 * , 015004 ( 2005 ) [ hep - ph/0504036 ] . g.  f.  giudice and r.  rattazzi , phys . rept .   * 322 * , 419 ( 1999 ) [ arxiv : hep - ph/9801271 ] . i.  affleck , m.  dine and n.  seiberg , nucl . b * 256 * , 557 ( 1985 ) . m.  dine , a.  e.  nelson , y.  nir and y.  shirman , phys . d * 53 * , 2658 ( 1996 ) [ arxiv : hep - ph/9507378 ] . s.  p.  martin , phys . d * 55 * , 3177 ( 1997 ) [ arxiv : hep - ph/9608224 ] . c.  e.  m.  wagner , nucl . b * 528 * , 3 ( 1998 ) [ arxiv : hep - ph/9801376 ] . m.  mcgarrie and r.  russo , phys . d * 82 * , 035001 ( 2010 ) [ arxiv:1004.3305 [ hep - ph ] ] . p.  meade , n.  seiberg and d.  shih , prog . * 177 * , 143 ( 2009 ) [ arxiv:0801.3278 [ hep - ph ] ] . mssm working group , a.  djouadi _ et  al . _ , _ the minimal supersymmetric standard model : group summary report _ , hep - ph/9901246 .", "tags": [], "output_text_a": "The paper discusses the Standard Model (SM) and its extension, the Minimal Supersymmetric Standard Model (MSSM), focusing on the Higgs mechanism for mass generation and the role of supersymmetry. The SM does not explain the magnitude of the Higgs mass parameter, which is sensitive to high-scale physics. The MSSM addresses this by linking the Higgs mass parameter to supersymmetry-breaking parameters of third-generation squarks, predicting Higgs masses consistent with recent experimental hints.\n\nThe paper explores the use of Renormalization Group Invariants (RGIs) to set bounds on supersymmetry-breaking parameters at the messenger scale, independent of the specific supersymmetry-breaking mechanism. The authors analyze the probability distributions of RGIs at the TeV scale using the phenomenological MSSM (pMSSM) parametrization, comparing scenarios before and after Large Hadron Collider (LHC) constraints.\n\nKey issues analyzed include the scale of gaugino mass unification, messenger scale parameters in general gauge mediation, and minimal gauge mediation. The study finds that the scale of gaugino mass unification is not necessarily the messenger scale but provides insights into minimal models of supersymmetry breaking. The paper concludes that RGIs offer a method to relate weak scale observables to messenger scale parameters, which will become more informative as LHC data on supersymmetric particles becomes available.\n\nThe paper also discusses the impact of experimental constraints on the probability distributions of RGIs and the potential for these distributions to reveal features of supersymmetry-breaking mass parameters at the messenger scale. The authors emphasize the importance of future LHC results in refining these analyses and understanding the structure of supersymmetry-breaking parameters.", "output_text_b": "This article discusses the use of Renormalization Group Invariants (RGIs) to set bounds on supersymmetry-breaking parameters in the Minimal Supersymmetric Standard Model (MSSM), independent of the supersymmetry-breaking scheme and messenger scale. The authors perform an exhaustive analysis of RGIs for different supersymmetry-breaking scenarios and use the pmssm parametrization of the soft supersymmetry-breaking parameters to determine the current probability distribution of the RGIs at the TeV scale. They then analyze three particular issues: possible scale of gaugino mass unification, messenger scale parameters in a realization of general gauge mediation, and messenger scale parameters associated with minimal gauge mediation.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the Standard Model, the Minimal Supersymmetric Standard Model, and the use of Renormalization Group Invariants.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of explaining the magnitude of the Higgs mass parameter and setting bounds on supersymmetry-breaking parameters.\n4. The methodology of using Renormalization Group Invariants and analyzing probability distributions is mentioned.\n5. Significant results, such as insights into minimal models of supersymmetry breaking and the potential of RGIs, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Renormalization Group Invariants\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used, such as the LHC constraints, which is a requirement.\n10. The summary reflects the paper's significance in understanding supersymmetry-breaking parameters.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of RGIs to set bounds on supersymmetry-breaking parameters in the MSSM.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of setting bounds on supersymmetry-breaking parameters independent of the breaking scheme and messenger scale.\n4. The methodology of using RGIs and pmssm parametrization is mentioned.\n5. Significant results, such as the analysis of gaugino mass unification and messenger scale parameters, are included.\n6. The language is clear and professional.\n7. The summary avoids excessive technical jargon and explains terms like RGIs and pmssm.\n8. The structure is logical, with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data used, which is a requirement.\n10. The potential impact of the research in the field is not explicitly mentioned."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "tracking a lander on the surface of another planet with radio signals is an efficient way to observe its rotation ( dehant et al . , 2009 , 2011 ) . this can be done by measuring the doppler shift of the radio signal between the lander and a large antenna on earth , like the ones of the deep space network ( dsn ) . we consider here two - way x - band signal : the ground station transmits the radio signal to mars , which is coherently ( i.e.  without any phase shift ) sent back to earth by the transponder onboard the lander . five martian landers have already been tracked from earth in order to get the martian rotation . the first landers were the two viking landers in 1976 - 1982 ( see for example borderies et al . , 1980 , yoder and standish , 1997 ) . 21 years later , the pathfinder lander stayed 3 months on mars surface in 1997 ( folkner et al . , 1997a and 1997b ) . more recently the two mars exploration rovers were tracked from earth when they were stationary ( le maistre , 2013 , kuchynka et al . , 2014 ) : spirit was stuck at the end of its life in 2009 , and opportunity stopped moving during the winter for energy saving during four months in 2012 .    two martian missions including a geodesy experiment will be launched in the coming years . the first one is the nasa mission insight ( interior exploration using seismic investigations , geodesy and heat transport ) to be launched in 2018 . the insight spacecraft will have a small deep space transponder on board : the rise ( rotation and interior structure experiment , folkner et al . , 2012 ) transponder . the second mission is the esa mission exomars2020 that will include the lara ( lander radioscience , dehant et al . , 2009 ) transponder on the surface platform . this spacecraft is to be launched in 2020 . + the martian orientation parameters ( mop ) are the nutations , the precession , the length - of - day variations and the polar motion . the precession is the long - term drift of the rotation axis in space . nutations are seasonal periodic motions of this axis observed from space , while the polar motion is the seasonal motion of the rotation axis in a frame tied to the planet . the rotation rate variations , also called length - of - day variations , are the periodic variations of the martian diurnal rotation . the periods are also the harmonics of the annual period . since these rotational motions depend on the interior structure of mars , in particular the core dimension , density and state , and on the dynamics of the atmosphere and the ice caps and the co@xmath0 sublimation / condensation process , accurate measurements of these angles are very useful because additional constraints on the geophysical models could be provided .    in this paper we derive expressions of the signature of the rotation parameters in the doppler and range observables . these expressions are useful in order to optimize the configuration parameters and to anticipate the observation times that maximize the signatures and the geophysical information . this is of course not only helpful for the insight and exomars mission planning but also for other geodesy experiments on other planets . + the paper is organized as follows : in section 2 , we present the different angles and variables that describe the geometry of the doppler observable . section 3 gives a summary of the models for the different mop . in section 4 , we give the analytical expressions of the signature of these mop in the doppler observable and their numerical values , while the section 5 focuses on the signatures in the range observable . the instantaneous doppler frequency can be interpreted as the space probe radial velocity with respect to the tracking station . as a first order approximation , it is the projection on the line - of - sight of the difference of the velocity vector between the emitter and the receiver . it is very sensitive to the configuration geometry , therefore we present in this section the different variables that are important for the signatures in the doppler observable .     with respect to mars as a function of time . the sun - earth - probe ( sep ) angle is plotted on the upper graph in red with some arbitrary scaling , the black parts of the curve ( and the corresponding pink boxes ) being the points where the sep angle is smaller than @xmath1 , corresponding to radio data with a large noise due to the solar plasma . the gray boxes correspond to time intervals where the earth declination is smaller than 10@xmath2 . the insight and exomars nominal mission lifetime are also shown with the orange and red horizontal lines . , width=680 ]    the exomars and insight missions have similar orbital configuration at launch and when arriving on mars . for both the distance between mars and the earth increases after the martian landing , being maximal a few months after the landing ( see fig .  [ fig_dist ] , upper graph ) . the sun - earth - probe ( sep ) angle or elongation is small when the earth - mars distance is maximal , this is the conjunction time . the pink boxes on fig . [ fig_dist ] show where the sep angle is smaller than @xmath1 . at that time , the solar plasma perturbs the radio signal largely , and the noise on the radioscience measurements is much larger than the nominal noise . + the earth declination @xmath3 with respect to mars is the angle between the mars - earth direction and the equatorial plane of mars . because of the martian obliquity and the earth revolution in the ecliptic plane , the earth declination has variations due to the orbital motions of the two planets and due to the mars pole direction . it varies between -25@xmath2 and 25@xmath2 ( see fig . [ fig_dist ] , lower graph ) . when the earth - mars distance is minimal , corresponding to the opposition , the earth - mars direction reverses its rotation : for a few weeks , this direction goes from a prograde to a retrograde motion . this is due to the faster revolution velocity of the earth than for mars . at this time , in the earth s sky , mars is having an apparent retrograde motion with respect to the usual planetary rotation . at the same time , the earth declination shows some irregularities because of this retrograde motion . the maxima in the earth declination do not correspond to the distance minima because the direction of the martian spin axis has also to be taken into account . the maxima have a periodicity longer than the earth - mars synodic period ( 780 days ) . on the time scale of a spacecraft mission ( about 2 years ) , the mop can be safely neglected for the computation of the earth declination , the largest mop effect being the martian precession that changes the earth declination by less of @xmath4 . the gray boxes on fig . [ fig_dist ] for the earth declination correspond to time intervals where the earth declination is smaller than 10@xmath2 . in section 4 we will show that these intervals correspond to a lower sensitivity to mars spin axis motion in space . another useful equatorial coordinates that will appear in the mop signatures ( section 4 ) is the earth hour angle @xmath5 , the angle along the celestial equator from the mars local meridian to the hour circle passing through earth , in the retrograde direction . if @xmath6 is the earth right ascension , @xmath7 the sidereal mars rotation angle ( the angle from the vernal point to the prime meridian ) and @xmath8 the lander longitude ( positive east from the prime meridian ) , the earth hour angle is related to the other angles in the equatorial plane by the following equation @xmath9 the earth hour angle has a diurnal variation ( period of 24h 37min for mars ) , increasing every day non - linearly from 0 to 360@xmath2 , and depends on the lander position . every day the earth rises and crosses the lander sky . like the earth declination @xmath3 , the earth elevation @xmath10 has variations related to the orbital motion of the earth and mars . if @xmath11 is the lander latitude , the maximal elevation @xmath12 of the earth in the lander sky varies for each day between @xmath13 and the angle corresponding to the minimum between @xmath14 and @xmath15 . the rise instrument have two antennas designed to observe the earth within a @xmath1 to @xmath16 elevation range , with one antenna pointed nearly to the east and the other pointed nearly to the west . lara antennas nominal range shall be @xmath17 elevation , for all azimuthal directions ( @xmath18 ) , with a maximum gain direction at @xmath19 of elevation . the rotation matrix from the mars body - fixed reference frame to the inertial frame based on mars mean orbit of j2000 is ( folkner et al . , 1997a , konopliv et al . , 2006 , le maistre et al . , 2012 ) @xmath20 if @xmath21 is the lander position vector in the body - fixed reference frame , the position of the lander in the inertial frame @xmath22 is : @xmath23 @xmath24 , @xmath25 and @xmath26 are the classical elementary rotation matrices around the x , y , z axes respectively . as for the earth , five angles called here the martian orientation parameters ( mop ) are used to characterize the matrix @xmath27 : @xmath28 , @xmath29 , @xmath7 , @xmath30 and @xmath31 . @xmath30 and @xmath31 are the crust - fixed coordinates of mars spin axis related to the polar motion . @xmath7 is the martian sidereal rotation angle . its variations @xmath32 are called the length - of - day ( lod ) variations . @xmath33 and @xmath34 are the precession - nutation matrices depending on the obliquity @xmath28 between the instantaneous mars equator and the mean orbital plane at j2000 and on the longitude of the node of the mars equator @xmath29 . nutation in obliquity and longitude @xmath35 and @xmath36 are the periodic variations of @xmath28 and @xmath29 while the precession is @xmath37 the secular trend of @xmath29 . we can write @xmath38 @xmath39 is the diurnal rotation rate . the mop are small angles . + nutation is the periodic motion of the spin pole in space . the nutations for a rigid planet can be computed from celestial mechanics and ephemerides . a rigid nutation model is usually constructed as a sum of different frequencies with an amplitude and a phase for the nutation in obliquity ( @xmath35 ) and in longitude ( @xmath36 ) . in the following sections , we use the term `` nutation in longitude '' @xmath36 to mean the sum of the components at different frequencies of the nutation in longitude , and similarly the term `` nutation in obliquity '' @xmath35 as the sum of the main frequencies . for mars , the largest nutations are the annual and semiannual nutations . their maximal amplitude are about 550 and 1130 mas , corresponding to 9 and 19 m on mars surface . we use roosbeek ( 1999 ) rigid mars nutations model . however mars is not a rigid planet . therefore the nutation amplitudes depend on the interior structure and parameters , like the state ( liquid or solid ) of the core or its moment of inertia . we can model the non - rigid nutation amplitudes by applying a transfer function to the rigid nutations ( dehant et al . , 2000 , van hoolst et al . , 2000a , 2000b ) . this transfer function is based on the model developed for the earth by sasao et al . ( 1980 ) and includes the liquid core effects and other deformation effects . for example , if the core is liquid , then an additional free mode , the free core nutation ( fcn ) amplifies the nutation response if the fcn period is close to one of the nutation periods . current interior models estimate the fcn period to be between about -240 and -285 days . therefore the fcn can mostly enhance the small retrograde terannual ( 229 days ) or the large prograde semiannual nutation ( 343.5 days ) . considering the 3 sigma interval rather than the 1 sigma interval will make the fcn range larger than @xmath40 days and the fcn frequency can be even closer to the terannual frequency , increasing the amplification . in this study , we use a transfer function and amplifications computed from up - to - date interior models ( panning et al . , 2016 ) . the mantle mineralogy and the temperature profile are unique for all the models and the planet is assumed to be in hydrostatic equilibrium . the variable quantities in the interior models are the size of the core and the density and thickness of the crust . the models agree with the observed moment of inertia at one sigma . the frequencies of the nutations are not affected by the transfer function , therefore the modeling we use is a trigonometric expansion with known periods but unknown amplitudes . the amplifications are different for each nutation period and for the nutation in obliquity and in longitude ( see for example figure 10 of le maistre et al . , 2012 ) . depending on the size of the core , the maximal change of the nutations due to the liquid core is between @xmath41  mas and @xmath42  mas ( corresponding to about @xmath43  cm and @xmath44  cm on mars surface ) for the nutation in obliquity and between @xmath42  mas and @xmath44  mas or @xmath45  cm and @xmath46  cm for the nutation in longitude . the lower values correspond to a small core of @xmath47  km while the upper values correspond to a large core of about @xmath48  km . an important objective of the geodesy experiments is to measure the nutations and particularly the transfer function because it is good tool to constraint the interior structure of mars and the core dimension and density in particular . + the precession is the secular motion of the spin axis about the normal to the orbit plane . the spin axis completes one rotation in a period of about 170 300 years . the precession is due to the gravitational pull of the sun on the oblate figure and depends on the moment of inertia about the spin axis . the present uncertainty on the precession rate ( konopliv et al . , 2016 ) is 2.1 mas / y , corresponding to a period change of about 47 years . since the precession rate @xmath37 is proportional to @xmath49 where @xmath50 is mars moment of inertia , the estimation of the precession rate gives a constraint on the interior mass distribution . + the rotation rate variations or length - of - day ( lod ) variations @xmath32 are modeled by a trigonometric series with the annual , semiannual , terannual and quaterannual periodicities . the annual nutation has an amplitude of about @xmath51  mas or @xmath52  m on mars surface while the semiannual nutation is about @xmath53  mas or @xmath54  m ( konopliv et al . , 2016 ) . in the rotation matrix around the z - axis ( @xmath7 angle , see eq . [ eq_phi ] ) , above the lod variations , there is an additional term depending on the nutation @xmath55 , adding a nutation signature in the doppler observable . the lod variations are of interest for global climate models , to constrain the atmosphere and ice caps dynamics . + each polar motion ( pm ) coordinate @xmath30 and @xmath31 is modeled by a trigonometric series ( annual , semiannual , terannual ) and a chandler wobble term . the amplitudes of the seasonal terms of the polar motion are expected to be between 0 and 15 mas ( defraigne et al . , 2000 , van den acker et al . , 2002 ) . the period of the chandler wobble for mars is expected to be around 200 or 220 days . its amplitude has not yet been measured but is expected to be somewhere between 10 and 100 mas . the polar motion has both climatological and geodetic information ; particularly the chandler wobble period depends mainly on the dynamical flattening of the planet and it provides information on the planet s elasticity and on inelastic behavior . & max value & analytical expression & max value + rigid nutations in long . @xmath36 & 29.4 m & @xmath56 & 12.3 m + rigid nutations in obliq . @xmath35 & 10.3 m & @xmath57 & 10.3 m + & 0.4/0.7 m & & 0.4 m + & 0.2/0.4 m & & 0.2 m + precession : & 0.8 m & @xmath58 & 0.8 m + ( if @xmath59 2.1 mas / y ) & & @xmath60^{1/2}$ ] & + lod @xmath61 & 11.8 m & @xmath62 & 11.8 m + polar motion @xmath63 ( @xmath64 ) & 1.2 m & @xmath65 & 1.2 m + ( if chandler amp . @xmath66 m ) & & @xmath67 & +    the maximal value of each mop on a long time interval is given in the second column of table [ tab1 ] , assuming the nominal model . the amplitude of the chandler wobble is assumed to be around @xmath68 meters . for the liquid core effect in the nutations , the first numbers ( 0.4 m for a large core and 0.2 m for a small core ) are the components of the nutation in obliquity , while the second ( 0.7 and 0.4 m ) are the components of the nutation in longitude . the precession rate is very large , we consider here only the effect of the present uncertainty on the precession rate at j2000 ( about 2.1 mas / y ) . the displacement due to this uncertainty after about 20 years after j2000 is about 0.8 m.    each mop changes of the lander position . if the position change vector is the difference between the lander position with and without the mop and using the rotation matrix @xmath27 ( see equation [ eq_r ] ) , we compute the norm of this position change vector . the analytical expressions and the maximal value of the norm of this position change vector is given in the last columns of table [ tab1 ] . since we use first order approximation , all the displacements are proportional to the mop . some of the lander displacements are modulated by the diurnal rotation . we see that the lander displacement due to the lod variations is larger when the lander is closer to the equator . the maximal value of the displacement due to the rigid nutation is independent of the lander position ( because the square roots in table 1 are always equal or smaller than @xmath69 ) , but close to the pole , the displacement due to the nutations does not have any diurnal variations . there is a reduction of a factor 2.3 from the maximal value of the nutation in longitude @xmath36 to its change in the lander motion ( from @xmath70 m to @xmath71 m ) because of the obliquity of mars ( @xmath72 ) induces a projection in the lander displacement and because of the rotation angle component ( - @xmath73 ) that removes a part of the signal ( see equation [ eq_phi ] ) . for the other mop , the maximal displacement due to the mop is the same as the mop maximal value . depending on the size of the core , the maximal change of the lander position due to the liquid core is between 19 cm ( small core ) and 42 cm ( large core ) . the analytical expression is a combination of the transfer function and the change of lander position due to the rigid nutations in obliquity and in longitude , its expression is lengthly and therefore has not been included in table 1 . the nutations in longitude and in obliquity together changes the lander by about 12.6 m. in this section we give the analytical expressions of the mop signature in the doppler lander - earth observable (= direct - to - earth or dte observable ) . we consider an instantaneous doppler observable ( with an infinite speed of light and no integration time ) . the doppler measurements are highly sensitive to the position variations along the line - of - sight and not sensitive to position variations in the plane perpendicular to the line - of - sight . + the doppler measurements between the earth and a spacecraft on mars varies between about -17 and 17 km / s . this corresponds to the value of the relative velocity of the two planets around the sun . its main modulations come from the relative orbital motions of the earth and mars . other modulations come from the variation of the orientation and the rotation of mars and the earth . the diurnal rotations of mars and of earth impress a sinusoidal modulation upon the doppler signal , with a beat frequency of about 36 days . this period of 36 days corresponds to the mars - earth synodic period of rotation given that the rotation period of earth and mars are very close , 23h56min versus 24h37min ( le maistre 2013 ) . the doppler observable is positive when the lander is going away from the earth and is negative when getting closer . + the doppler observable @xmath74 can be modeled as the projection of the velocity difference @xmath75 on the line - of - sight @xmath76 , with @xmath77 being the angle between @xmath75 and the earth - lander line - of - sight . the signature of a parameter in the doppler observable is the observable estimated taking into account a parameter minus the observable without this parameter . to the first order in the mop , it can be expressed as ( yseboodt et al . , 2003 ) : @xmath78 where @xmath79 is the change in @xmath80 due to the mop and @xmath81 is the change in the line - of - sight direction due to the mop . the first term in eq . ( [ eq_signatu ] ) is the `` geometrical effect '' or change of the line - of - sight direction . this term expresses the change in direction of the emitter - receiver line induced by the rotation parameter multiplied by the amplitude of the velocity . the second term of eq . ( [ eq_signatu ] ) is the contribution of the velocity change induced by the rotation . both terms are proportional to mars radius and to the mop . the line - of - sight displacement because of the mop @xmath81 decreases if the emitter - receiver distance increases , therefore the geometrical effect is proportional to the relative velocity over the distance @xmath82 . the velocity effect , i.e.  the change of the lander velocity @xmath79 , is independent of the emitter - receiver distance but is proportional to the diurnal rotation rate @xmath39 . if the relative velocity over the distance is smaller than the planet diurnal rotation rate , then the velocity effect dominates the signature in the doppler observable . this happens when the earth - planet distance is large . since this is the case for mars and because mars diurnal rotation rate @xmath39 is large , therefore this velocity effect is the one that is modeled in this section while the line - of - sight displacement is neglected . if the emitter - receiver distance is small , like for example if the receiver is on board an orbiter , then the dominant effect in the doppler signal is the change in the line - of - sight . + the signatures of the mop parameters in the observable have already been investigated in le maistre et al . ( 2012 ) for the doppler observable , konopliv et al . ( 2006 ) for the lod signature in the doppler observable and folkner et al . ( 1997a , eq . 1 ) for the range observable . previously , curkendall and mcreynolds ( 1969 ) gave first order analytical expressions for an orbiter - earth doppler and range observables and its link with the equatorial coordinates of the spacecraft while yseboodt et al . ( 2003 ) studied the mop signatures in the orbiter - earth doppler link in the frame of a geophysical mission including a network of landers on mars surface . kawano et al . ( 1999 ) studied the mop signatures in the same beam interferometry ( sbi ) observable for two landers ( or more ) on mars surface . +    , the nutations in longitude @xmath36 , the liquid core effect in the nutations ( large core , free core nutation period of 242 days ) , a precession rate @xmath37 difference of 2 mas / y , the lod variations and the polar motion . on the left part of the graph , the insight lander is in western elysium planitia ( @xmath83n , @xmath84e ) and on the right part , the exomars lander is in oxia planum ( @xmath85n , @xmath86e ) . in the nutation plots , the dotted gray line shows the earth declination @xmath3 . the gray boxes correspond to time intervals where the earth declination is smaller than @xmath87 while the pink boxes show where the sep angle is smaller than @xmath1 . the red and purple curves are the surface displacements due to the nutation in longitude and nutation in obliquity , respectively . they are scaled . , width=755,height=604 ]    the signatures of the different mop in the doppler observable are plotted on fig .  [ fig_sensi ] . since we use first order approximation , the mop signatures are proportional to the mop . therefore the mop periodicities ( annual , semiannual , chandler period ... ) can also be seen in the signatures plot . the expected numerical values are summarized in section [ secamp ] . if @xmath35 is the nutation in obliquity and @xmath36 the nutation in longitude , their signature in the lander - earth doppler observable is @xmath88 where @xmath89 is mars radius , @xmath39 the diurnal rotation rate of mars , @xmath7 the diurnal rotation angle of mars , @xmath3 the earth declination with respect to mars , @xmath28 mars obliquity , @xmath5 the earth hour angle and @xmath6 the right ascension . the mathematical derivation of these expressions is given in appendix [ ap1 ] . + since the signature is proportional to the nutation , the annual , semiannual and terannual modulations in the @xmath35 and @xmath36 nutations also appear in the signature plots ( see also the red and purple lines in fig . [ fig_sensi ] ) . the time derivatives of the nutations @xmath90 and @xmath91 give second order effects in the signature since their period ( mostly annual and semiannual ) is much larger than the diurnal rotation rate @xmath39 . the nutation signature is proportional to the distance between the lander and the spin axis @xmath92 , therefore the nutation signature is maximal at the equator and null at the pole . the nutation signature in the doppler observable must be a function of the direction of its spin axis with respect to the earth direction , eqs . ( [ eq_signeps ] ) and ( [ eq_signpsi ] ) show that it is proportional to the sinus of the earth declination . a tilt of the rotation axis because of the nutation tilts the diurnal velocity vector and the resulting velocity difference is , to the first order , along the z ( polar ) axis in a body - fixed reference frame . the projection of this velocity vector on the line - of - sight is null if the earth in the equatorial plane of mars ( @xmath93 ) . therefore the doppler observable sensitivity to nutations is low when mars spin axis is nearly perpendicular to the mars - earth direction ( see the gray line and gray boxes in fig . [ fig_sensi ] ) . replacing @xmath94 by @xmath3 leads to a maximal error of 3 % because the earth declination is always smaller than mars obliquity ( @xmath95 ) . the factor @xmath94 in the nutation signature varies between @xmath96 and @xmath97 , therefore decreasing the signatures . in eqs . ( [ eq_signeps ] ) and ( [ eq_signpsi ] ) , there is a diurnal periodicity in the signature through mars rotation angle @xmath7 or through the local earth hour angle @xmath5 . the link between the angles in the equatorial plane is given in eq . [ eq_he ] . this diurnal variation is shown on the plot by the blue regions between the maximal and minimal curve . during one day , the signature of @xmath36 and @xmath35 can not be maximal at the same time , there is a time shift of 6 hours between the maxima of the two nutations . the earth elevation in the lander s sky does not appear in the nutation signature . however there is an indirect link between both quantities , because the earth elevation depends on the chosen timing of observation . for example if observations are chosen every early morning , the earth elevation will be always be small , and from day to day the value of the earth hour angle will almost be the same . the liquid core signature in the doppler observable is the difference between the doppler observable with and without the nutation transfer function , each part being the sum of the @xmath35 and @xmath36 contributions ( eqs . [ eq_signeps ] and [ eq_signpsi ] ) . the liquid core signature is much smaller than the rigid nutations signature because the liquid core amplification is also smaller . the signature of the non - rigid part of the nutations has more modulations than the other mop signatures because sometimes there is an amplification of the nutation in longitude due to the liquid core while later , it is the nutation in obliquity that is amplified . therefore , the liquid core signature is a combination of both signatures . if plotted on the same figure , the rigid and non - rigid nutation signatures will be very close and indistinguishable on fig . the dependence on the earth declination ( see the gray line and gray boxes ) and the lander latitude is the same as the rigid nutation signature . over an interval of a few years , the position of the maxima and of the roots moves if the free core nutation ( fcn ) period changes ( see fig .  [ fig_liquid ] ) . ( scaled ) . , width=755,height=340 ]    this is because if the fcn period is close to the terannual period ( @xmath98 days ) , the terannual nutation will be largely amplified while if the fcn period is close to the semiannual period ( @xmath99 days ) , the terannual nutation amplification will be small but the semiannual nutation will be larger . + again , the diurnal variation is shown on the plot by the blue area . therefore depending on the lander position , each day there is a different observation time that maximizes the liquid core signature . 12 hours after the time when the liquid core signature is maximum , the liquid core signature is minimum . 6 hours later , the liquid core signature is null . having a large negative signature gives a geophysical information as important as a large positive signature . the time where the liquid core signature is maximal during the day depends on the fcn value . the time difference is less than an hour for the fcn range investigated here .      using a method similar to appendix [ ap1 ] , we find the expression of the precession rate @xmath100 signature in the doppler observable . if the product @xmath101 is assumed to be small , the precession signature is @xmath102 the signature increases with time but remains relatively small on an interval like the mission duration , which is short with respect to the precession period of about @xmath103 years . the precession signature has a diurnal variation via the earth hour angle @xmath5 . + the first term in eq . [ eq_signpsip ] is the dominant one close to the equator because @xmath104 . it depends on @xmath105 while the second term depends on @xmath106 . the maximal signature is almost constant with time ( see figure [ fig_sensi ] ) , there is a long period variation with a small amplitude due to @xmath107 in the first term of eq . ( [ eq_signpsip ] ) and due to @xmath108 in the second term .    the second term ( but not the first one ) appears in the signature of the nutation in longitude @xmath36 . there is a large difference for the analytical expressions of @xmath36 and @xmath109 because the nutation in longitude appears twice in the rotation matrix @xmath27 ( in @xmath110 and in mars rotation angle rotation @xmath111 ) while the precession appears once in @xmath110 . the signature of martian rotation angle variations @xmath32 ( or lod variations ) in the doppler observable is @xmath112 there is a proportionality between the lod variations and its signature , therefore the main frequencies are annual , semiannual and quaterannual . similarly as for the nutation , the lod signature is proportional to the distance from the lander to the spin axis @xmath92 , therefore the signature is maximal at the equator and null at the pole . the lander longitude disappears from the signature . however there is an indirect effect because the earth hour angle @xmath5 depends on the longitude . the signature has again a diurnal periodicity via the earth hour angle . the lod signature is very little affected by the variations of the earth declination because the @xmath113 stays between @xmath114 and @xmath69 . + the diurnal velocity vector is in the equatorial plane of the body - fixed reference frame and is perpendicular to the lander position vector @xmath115 . the change of the velocity vector due to the lod variations is also in the equatorial plane and to the first order perpendicular to the diurnal velocity , it is in the direction of the lander position vector @xmath116 . the scalar product between the velocity difference and the line - of - sight ( los ) is maximized when the two vectors are in the same direction , therefore when the los is `` aligned '' with the mars - lander vector . each day , the lod signature is maximized when the mars - earth direction crosses the local meridian of the lander ( when the local earth hour angle is null ) or equivalently when the earth culminates in the lander sky . typically this happens near the local noon . when the lander is on the equator ( @xmath117 ) , the maximal earth elevation is @xmath118 . therefore the maximal lod signature in the doppler observable is proportional to @xmath119 and on a long time interval , the signature increases as the maximal earth elevation increases or equivalently as the earth declination decreases . when the lander is not on the equator , the maximal lod signature in the doppler observable is again when the local earth hour angle is null , corresponding to the maximal earth elevation during that day . however the lod signature is not anymore proportional to @xmath119 . @xmath120 the signature in the doppler observable of the equatorial plane coordinates of the lander @xmath121 and @xmath122 in the body - fixed reference frame is @xmath123 there is always a diurnal periodicity . on a daily basis , the @xmath121 signature is maximized when @xmath124 or @xmath125 while the @xmath122 signature is maximized when @xmath126 or @xmath127 . if we express this signature as a function of the lander latitude @xmath11 , the lander longitude disappears from the equation @xmath128    it is known that the doppler measurements are not very sensitive to the @xmath129-coordinate of the lander ( along the polar axis ) , and therefore solving for this coordinate is difficult ( le maistre , 2016 ) . a change in the @xmath129-coordinate only does not change the lander diurnal velocity . therefore its signature is very small because this is a second order contribution : the direction of the line - of - sight is changed a little bit because of the lander displacement in the polar direction . there is also a small second order velocity change . however if we want to know the third component of the lander position , we can impose that the lander has to stay on mars surface and there is a relationship between the three coordinates . this additional constraint related to the topography model helps to solve for the @xmath129-coordinate ( le maistre , 2016 ) .    using the same equations , we can also evaluate the signature of a tidal displacement . a lander displacement along the x and y axis due to the tides has a signature in the doppler observable given by eq . [ eq_xysign ] . the signature of the polar motion @xmath30 and @xmath31 in the doppler observable is @xmath130 to the first order in the polar motion parameters , the first two coordinates of the position of the spin pole are @xmath131 , explaining the sign difference when comparing this equation to eq . [ eq_xysign ] . the diurnal periodicity in the signal comes from the earth hour angle @xmath5 . as for the lod variations , the signature is not very sensitive to the earth declination . during one day , the maxima and minima of the @xmath30 and @xmath31 signatures happen at different time , separated by 6 hours . the polar motion signature is a function of @xmath132 , therefore the signature increases with the lander latitude , being maximal at the poles . the reason is that the shift of the lander position due to the polar motion is @xmath133 . since the diurnal velocity vector is in the equatorial plane , because of the scalar product of the doppler observable , the part of the lander displacement that is important is also in the equatorial plane . this lander displacement in the equatorial plane is proportional to @xmath134 . equivalently to the sensitivity to the lander @xmath129-coordinate , the doppler observable is not sensitive to the @xmath129 displacement due to the polar motion . the maximal value of the mop signature in the doppler observable are given using the insight and exomars nominal missions configuration in table [ tablsi ] . the nominal mission time coverage is taken into account : 2 earth years for the insight lander starting end of 2019 , 1 earth year for the exomars lander starting beginning of 2021 . the insight landing site is expected to be close to the equator in western elysium planitia ( @xmath83n , @xmath84e ) while we pick the oxia planum location ( @xmath85n , @xmath86e ) for the exomars lander . the typical noise on doppler data is @xmath135  mm / s for a doppler counting interval of count interval of 60 seconds . @xmath136    the temporal evolution of the mop signature in the doppler observable is plotted on fig . [ fig_sensi ] . changing the landers position from one landing site to another position further from the equator does not affect a lot the value of the signatures ( this is barely noticeable on fig .  2 , see the left and the right parts ) , except for the polar motion signature .    from tab . [ tablsi ] , we see that the maximal signatures are smaller for exomars than for insight , except for the polar motion signature , mostly because the exomars nominal mission does not cover one full martian cycle and because the chosen exomars location is farther from the equator than the insight landing site . the signature of the precession rate are very close because of a small decrease due to a higher latitude compensated by a small increase because the beginning of the exomars observation time is later with respect to j2000 . [ fig_sensilat ] shows that the maximal value of these signatures depends on the lander latitude . some rotation parameters like the nutation , the precession and the lod variations vary with @xmath137 with a larger signature at the equator while the polar motion varies with @xmath132 with a larger signature at the pole .     and @xmath36 , the liquid core effect through nutations , the lod variations and the polar motion ( pm ) in the doppler observable as a function of the lander latitude . two different liquid core sizes have been considered . the two vertical lines show the landers latitude while the horizontal line shows the typical noise on doppler measurements ( @xmath135  mm / s).,width=502,height=302 ]     + the maximal signature of the nutations in the doppler signal is up to @xmath138  mm / s , coming from the signature of the nutations in longitude @xmath36 . the nutation in obliquity signature is smaller ( up to @xmath139  mm / s ) , see fig . [ fig_sensilat ] . there is a difference of 6 hours between the maxima in the nutation in obliquity and in longitude , therefore they can not be maximal at the same time . the maximum of the nutation signature is smaller than the product of the maximal value of the component of equations ( [ eq_signeps ] ) and ( [ eq_signpsi ] ) ( i.e.  @xmath140 and the maximum of @xmath141 or @xmath142 ) because the declination and the nutation do not have their maximum at the same time . + the liquid core signature in the doppler observable is much smaller than the nutation signature and largely depend on the characteristics of the core because of the resonant effects in the transfer function . the maximal signature of the liquid core in the doppler observable is plotted as a function of the fcn period on fig . [ fig_sensinut ] . the signature is larger ( up to 0.01  mm / s ) when the fcn is close to the terannual frequency . this can also be seen on fig . [ fig_liquid ] .        a shift on the precession equal to the present uncertainty on the precession rate ( 2.1 mas / y , corresponding to a period shift of @xmath143 years , konopliv et al . , 2016 ) changes the doppler observable by about @xmath144  mm / s after @xmath145 years . + whatever the lander latitude below 80@xmath2 , the signature of the lod is well above the other signatures . it culminates at about @xmath146  mm / s for a lander located close to the equator . this explains why this rotation parameter has already been measured using the previous martian landers . + assuming a chandler wobble amplitude of @xmath68 meters , the maximal signature of the polar motion for a lander latitude of @xmath147 is 0.024  mm / s and @xmath148  mm / s for a lander latitude of @xmath149 . the signature increases as the latitude increase and an equatorial lander is not sensitive to the polar motion . if the lander is close to the pole , the maximal signature is close to 0.1  mm / s . + a tidal displacement of 1 cm on mars surface has a very small signature in the doppler observable of about @xmath150  mm / s for an equatorial lander . + the factor of proportionality between a mop ( expressed in surface displacement on the planet s surface ) and its signature in the doppler observable is close to @xmath39 for the lod variations , the x and y - coordinates , the tidal displacement and the polar motion . this factor is @xmath151 for the nutation in obliquity and @xmath152 for the nutation in longitude . for mars , the rotation rate is large ( @xmath153 rad / s ) . for example if a @xmath69 meter shift is applied to the x or y - coordinates , the doppler observable changes by maximum 0.07  mm / s . however if the z - coordinate of the lander changes by 10 meters , the signature in the doppler is negligible ( less than 0.001  mm / s ) . + the expressions given before are first order expressions linearized with respect to the mop . with respect to the full expression , it stays close up to 95 % of the signal . we also compared these analytical expressions to outputs from the gins software ( godsie par intgrations numriques simultanes ) , a numerical software able to process planetary geodesy data , and the numerical difference between the full expression and our analytical expression is small . we can apply the expressions of the rotational variations signature in the lander - earth direct radio link to other bodies of the solar system and estimate the order of magnitude of the signature , see tab . [ tab_ss ] . the lander has to be equipped with a transponder is on the planetary surface and the communication is direct - to - earth ( dte ) . the previous signature expressions can not be applied to doppler observable between a lander and an orbiter , or between the orbiter and the earth . the largest rotational variation of bodies in spin - orbit resonance is usually the annual forced libration . this libration amplitude depends on the interior structure and properties and if there is a liquid layer or not . additional forced librations with other frequencies also exist . the obliquity is another parameter important to observe , because if the body is in the cassini state , the equilibrium obliquity depends on the body moment of inertia . .amplitude of the libration at the orbital period and its maximal signature in the doppler observable between the earth and a lander on the planetary body . the lander is assumed to be on the equator which maximized the libration displacement . when the libration amplitude is not yet measured , we use estimation coming from a theoretical model . [ cols=\"^,^,<,^\",options=\"header \" , ]     mercury is in a 3:2 spin orbit resonance and orbits around the sun with a period of 88 days . the main libration is the annual libration , with an amplitude of 38.5 as ( margot et al . , 2012 ) . using eq . ( [ eq_utsign ] ) , the maximal signature in the doppler observable of this libration is 0.56  mm / s . the earth declination seen from mercury varies between -11@xmath2 and 11@xmath2 . mercury has an obliquity of 2.04 arcmin ( margot et al . , 2012 ) . using eq . ( [ eq_signeps ] ) , the maximal signature of the obliquity in the doppler signal is about 0.33  mm / s , smaller than the libration signature . for mercury , like for mars , the change of the planet velocity due to the rotation parameter is also the dominant term in the doppler observable signature . however since the distance to earth is usually smaller for mercury than for mars , the geometrical effect for mercury is not as small as for mars . + since we evaluate only the change of the lander velocity because of the rotation parameter , the previous equations are valid if the lander is far from the receiving antenna on earth . if the lander - receiver distance is smaller , the change of the line - of - sight direction must be taken into account and increase the doppler observable signature . because this line - of - sight change is not modeled here and because the geometry of the earth - moon configuration is very different from the earth - planet configuration due to the synchronous rotation , we do not evaluate the signatures for a lunar lander . + if the lander in on phobos surface , the signature of the libration amplitude will be very large ( about 100  mm / s ) , because phobos rotation rate and its libration amplitude are both large . + for the icy moons around jupiter and saturn , the velocity effect is larger than the geometry effect . each libration signature in the doppler observable is proportional to the moon radius , to the diurnal frequency and to the moon libration amplitude . the variation of the earth declination does not largely affect the libration signature . for enceladus , the estimated signature is large ( about 28  mm / s ) because the measured libration amplitude is large ( @xmath154 , thomas et al . , 2016 ) . for the other moons , the libration amplitude has not yet been measured but we use order of magnitude from theoretical estimations . the signature in the doppler observable varies between 0.07 and 2.2 mm / s , see tab . [ tab_ss ] . these signatures are larger than the typical noise on doppler data ( @xmath135  mm / s ) . + a tidal displacement of 60 cm on europa surface has a signature in the lander - earth doppler observable of about @xmath155  mm / s for an equatorial lander . , the nutations in longitude @xmath36 , the liquid core effect in the nutations for a large core , a precession rate @xmath37 difference of 2 mas / y , the lod variations and the polar motion ( @xmath30 and @xmath31 ) . on the left part of the graph , the insight lander is in western elysium planitia ( @xmath83n , @xmath84e ) and on the right part , the exomars lander is in oxia planum ( @xmath85n , @xmath86e ) . in the nutation plots , the gray line shows the earth declination @xmath3 . the red and purple curves are the surface displacements due to the nutation in longitude and nutation in obliquity , respectively . , width=755,height=680 ]    in this section , we give the expressions of the mop and lander position signature in the range observable . the instantaneous range observable is equivalent to the distance between the lander and the antenna on earth at a given time . the mop signature in the range observable @xmath156 is , to the first order in the rotation parameter , the vector change of position due to the mop @xmath157 projected on the earth - mars line - of - sight @xmath158 . @xmath159 this expression is independent from the earth - mars distance . the variables that appear in the following expressions are the position of the earth with respect to mars ( i.e.  the earth declination @xmath3 , the right ascension @xmath6 and the hour angle @xmath5 ) and the lander position .    because the doppler measurement can be seen as the time derivative of the range observable , the parameter signature in the doppler observable is the time derivative of the parameter signature in the range observable . therefore the global shapes of the signature of these two observables are very similar , compare figs . [ fig_sensi ] and [ fig_sensiran ] . the range signatures may have additional shift or long - term variations that disappear in the doppler observable signature . again the mop signature in the range observable has a diurnal variation and is proportional to the mop . the signature of the nutation in longitude @xmath36 and nutation in obliquity @xmath35 in the range observable is @xmath160 the first term of these expressions changes slowly and is null if the lander is close to the equator while the second term has a diurnal variation and is dominant . close to the equator , the dependence of the range signature to the declination is the same as the doppler signature : when the earth declination is null , the nutation signature in the range observable is null too . the liquid core signature in the range observable is the difference between the range observable with and without the nutation transfer function , each part being the sum of the contributions of the nutation in longitude and in obliquity ( eqs . [ eq_signraneps ] and [ eq_signranpsi ] ) . the signature of the precession in the range observable is @xmath161 the precession signature increases with time but on an interval like the mission duration which is short with respect to the precession period of about @xmath103 years , this increase is relatively small . the diurnal variations dominates the signature . the second and third terms are equivalent to the signature of the nutation in longitude @xmath36 . the additional term here with respect to the @xmath36 signature in the range observable ( the first one ) depends on @xmath105 while the others depend on @xmath106 . the largest term is the first one ( @xmath162 ) , then the third one . the second one ( the constant one ) is negligible . the signature of the lod variations in the range observable is @xmath163 when the earth culminates in the lander sky ( @xmath164 ) , the lod signature is null . the timing of the range maxima are therefore 6 hours later than the doppler maxima . the signature of the lander coordinates in the range observable is @xmath165 the signatures of the x and y - coordinates have a diurnal variation . the signature of the z - coordinate in the range observable , contrary to the doppler signature , is not null and has no diurnal variation . because of the @xmath108 , it has long term variations . therefore some range measurements when the earth declination is not null can be useful to constrain the z - coordinate of a lander . the signature of the polar motion in the range observable is @xmath166 the first part of these expressions ( @xmath167 or @xmath168 ) is large if the lander is close to the equator ( up to 0.3 m ) while the second term has a diurnal variation and is much smaller for an equatorial lander . the maximal values of the mop signatures in the range observable are given in tab . [ tablsiran ] . they can also be viewed on fig . [ fig_sensiran ] . @xmath169    as for the doppler signature , the parameter that has the largest signature in the range observable is the lod variations with a signature of about 11 meters . then the nutation has a maximal signature of about 3.7 to 5.5 meters . the nutation signature in the range observable is smaller than the nutation amplitude and the lander displacement given in table 1 because of the reduction proportional to the sinus of the earth declination . the liquid core signature is much smaller , about 0.17 meter . the polar motion signature is larger than the liquid core signature ( up to 0.7 meter ) . if the precession shift by 2.1 mas / y , the precession signature in the range observable is max 0.74  m around 2020 .      using eq . [ eq_utransign ] and similarly as the doppler observable study , we can numerically evaluate the signature in the range observable of an libration at the orbital period for a lander on another planet or moon of the solar system . the typical noise on range data between the earth and a lander on another body is about a few meters . the maximal value of the rotation parameter signature is simply the maximal displacement on the body surface due to the libration . if we use the order of magnitude of the libration amplitude given in tab . [ tab_ss ] , the maximal signature in the range observable for an equatorial lander is given by the second column . it varies from a few meters up to 528 meters for enceladus . the signature for mercury is also large , 455 meters . the maximal signature of mercury obliquity in the range observable is about 270 m , smaller than the libration signature . all the signatures are modulated by the diurnal rotation and by variations at at long period due to the configuration geometry . the same beam interferometry ( sbi ) technique , also known as the inverse vlbi , is based on the simultaneous tracking of two martian landers with one large antenna on earth , for example a deep space network antenna , and measuring the delay between the two radio signals . the advantage of the sbi technique is that the two signals cross almost the same media at the same time , and therefore taking the difference cancels a large part of the common errors , like the earth atmospheric and ionospheric errors or the plasma delays . the sbi observable corresponds to the difference of the two ranges between the antenna and each lander . therefore the rotation parameter signature in the sbi observable is the difference between the rotation signature in the range observable of the two landers . this technique has never been used up to now it is expected to have an error budget up to 0.7 cm for martian landers ( gregnanin et al . , 2014 ) . the mop signature in the sbi observable depends on the latitude and longitude of each lander . we can replace the local angle @xmath5 by @xmath170 in the previous expressions and substitute the latitude and longitude of the lander by their rectangular coordinate @xmath171 . for example , the lod signature in the sbi observable is @xmath172 where @xmath173 and @xmath174 are the difference of x and y - coordinates of the two landers . the @xmath175 contribution does not appear in this signature . the nutation signature in the sbi observable is @xmath176 we see that the parts proportional to @xmath173 and @xmath174 are affected by a diurnal modulation and have a negligible contribution if the earth declination is small . the @xmath175 contribution has long term variations . these expressions are similar to the sbi sensitivity given in kawano et al . ( 1999 , eq .  28 ) . their variables describing the earth position with respect to mars are not equivalent to ours ( their model is simpler ) but it is possible to see the same modulations ( the diurnal and the long term ) by comparing the two methods . the numerical values of the mop signatures in the sbi observable depend of course of the separation vector between the two landers . but a general conclusion is that the signature is larger if the distance between the two landers is larger . using the analytical expressions of the mars orientation parameters ( mop ) signatures in the doppler observable , we can anticipate the moments where the mop signatures are maximal , on a daily basis and on longer interval and we can predict if a mop can be observed or not . the mop signature in the doppler and the range observable is proportional to the mop signal . therefore , the periodicities of the mop ( mostly annual , semiannual , terannual , the chandler period of about 200 days for the polar motion etc . ) can also be directly seen in the signatures . on a long time interval , for the mission operations planning , observation times should be privileged when the mop is large in order to get a larger signature . + additionally , some signatures like the nutations depend on the earth declination . the signature is larger if the earth is outside the equatorial plane of mars . the best time to observe the nutations is when the earth declination is large and when the sun - earth - probe angle is large because the noise on the doppler measurement due to the plasma will be smaller at that time . this corresponds to the beginning ( 2018.9 - 2019.25 ) and end ( 2020.3 - 2021 ) of the insight mission . for the exomars mission , this corresponds to approximately 2021 - 2021.1 and 2021.5 - 2021.8 . + in every signature , there is also a diurnal modulation because the main motion affecting the lander is the diurnal rotation of mars . therefore every day , each mop signature has a maximum and a minimum signature . these observation time should be favored . however , the daily maxima in the signatures of the nutations in obliquity and in longitude are separated by 6 hours , therefore it is impossible to maximize both at the same time . the daily maxima in the length - of - day variations signature in the doppler observable happen when the earth is at its highest point in the lander sky . + defining the best timing windows is useful for the mission planning of the geodesy experiments in the future insight and exomars missions . we will use these results when testing different strategies for adjustments of the rotational parameters . these strategies will be tested by performing numerical simulations for assessing the precision on the determination of the mop determination . we thank a. rivoldini for the computation of the transfer functions and rose - marie baland and sebastien le maistre for the helpful comments . this work was financially supported by the belgian prodex program managed by the european space agency in collaboration with the belgian federal science policy office . borderies , n. , g. balmino , l. castel , and b. moynot , study of mars dynamics from lander tracking data analysis , _ the moon and the planets , 22 _ , 191 - 200 , 1980 . curkendall , d. w. , and s. r. mcreynolds , a simplified approach for determining the information content of radio tracking data , _ j. spacecraft , 6_(5 ) , 520 - 525 , 1969 . defraigne , p. , o. de viron , v. dehant , t. van hoolst , and f. hourdin , mars rotation variations induced by atmosphere and ice caps , _ j. geophys . res . , 105_(e10 ) , 24563 - 24570 , 2000 . dehant , v. , t. van hoolst , and p. defraigne , comparison between the nutations of the planet mars and the nutations of the earth , _ survey geophys . , 21_(1 ) , 89 - 110 , 2000 . dehant , v. and 27 co - authors , lander radioscience for obtaining the rotation and orientation of mars , _ planetary and space science _ 57,10501067 , 2009 . dehant , v. , maistre , s.l . , rivoldini , a. , yseboodt , m. , rosenblatt , p. , hoolst , t.v . , mitrovic , m. , karatekin , o. , marty , j. , chicarro , a. , revealing mars deep interior : future geodesy missions using radiolinks between landers , orbiters , and the earth . _ planetary and space science _ 59 , 10691081 , 2011 . folkner , w. , r. kahn , r. preston , c. yoder , e. standish , j. williams , c. edwards , r. hellings , t. eubanks , and b. bills , mars dynamics from earth - based tracking of the mars pathfinder lander , _ j. geophys . res . , 102_(e2 ) , 4057 - 4064 , 1997a . folkner , w. , c. yoder , d. yuan , e. standish , and r. preston , interior structure and seasonal mass redistribution of mars from radio tracking of mars pathfinder , _ sci . , 278 _ , 1749 - 1751 , 1997b . folkner , w.m . , asmar , s.w . , dehant , v. , warwick , r.w . , the rotation and interior structure experiment ( rise ) for the insight mission to mars . in : lunar and planetary institute science conference abstracts , lunar and planetary institute technical report , vol . 43 , march , p. 1721 , 2012 . gregnanin , m. , m. yseboodt , v. dehant , l. iess and t. van hoolst , estimation of mars geophysical information through same beam interferometry , european planetary science congress ( epsc ) , vol . 9 , epsc2014 - 395 , 2014 . kawano , n. , m. hosokawa , h. hanada , and m. imae , inverse vlbi method for planetodesy , _ j. geod . _ , 45(3 ) , 181203 , 1999 . konopliv , a. , yoder , c. , standish , e.m . , yuan dah - ning , sjogren , w.l . , a global solution for the mars static and seasonal gravity , mars orientation , phobos and deimos masses , and mars ephemeris . _ icarus _ 182 ( 1),2350 , 2006 . konopliv , a.s . park , w.m . folkner , an improved jpl mars gravity field and orientation from mars orbiter and lander tracking data , _ icarus _ , 274 , 2016 . kuchynka , p. , folkner , w.m . , konopliv , a.s . , park , r.s . , le maistre s. , dehant , v. , new constraints on mars rotation determined from radiometric tracking of the opportunity mars exploration rover . _ icarus _ 229 , 340347 , 2014 . le maistre , s. , rosenblatt , p. , rivoldini , a. , dehant , v. , marty , j - c . , karatekin , . , lander radio science experiment with a direct link between mars and the earth . _ space sci . _ 68 , 2012 . le maistre , s. , the rotation of mars and phobos from earth - based radio - tracking observations of a lander , phd dissertation , universit catholique de louvain , belgium , available on dial.uclouvain.be , 2013 . le maistre , s. , insight coordinates determination from direct - to - earth radio - tracking and mars topography model , _ planet . space sci . _ 121 , 2016 . margot , j .- , s. j. peale , s. c. solomon , s. a. hauck ii , f. d. ghigo , r. f. jurgens , m. yseboodt , j. d. giorgini , s. padovan , and d. b. campbell , mercury s moment of inertia from spin and gravity data , _ j. geophys . _ , 117 , e00l09 , doi:10.1029/2012je004161 , 2012 .    panning , m.p . , and 33 co - authors , planned products of the mars structure service for the insight mission to mars , submitted to space science reviews , 2016 . roosbeek , f. , analytical developments of rigid mars nutation and tide generating potential series , _ celestial mechanics , 75 _ , 287 - 300 , 1999 . sasao , t. , s. okubo , and m. saito , a simple theory on dynamical effects of a stratified fluid core upon nutational motion of the earth , proceedings of the agu symposium , no . 78 on _ nutation and the earth s rotation _ , fedorov ep et al . ( eds ) , kiew , d. reidel , norwell , mass . , 165 - 183 , 1980 . thomas , p.c . , r. tajeddine , m.s . tiscareno , j.a . burns , j. joseph , t.j . loredo , p. helfenstein , c. porco , enceladus s measured physical libration requires a global subsurface ocean , _ icarus , 264 _ , 2016 . van den acker , e. , t. van hoolst , o. de viron , p. defraigne , f. forget , f. hourdin , and v. dehant , influence of the winds and of the co@xmath0 mass exchange between the atmosphere and the polar ice caps on mars rotation , _ j. geophys . , 107_(7 ) , doi:10.1029/2000je001539 , 2002 . van hoolst , t. , v. dehant , and p. defraigne , chandler wobble and free core nutation for mars , _ planet . space sci . , 48_(12 - 14 ) , 1145 - 1151 , 2000a . van hoolst , t. , v. dehant , and p. defraigne , sensitivity of the free core nutation and the chandler wobble to changes in the interior structure of mars , _ phys . earth planet . inter . , 117 _ , 397 - 405 , 2000b . yoder , c. f. , and e. m. standish , martian precession and rotation from viking lander range data , _ j. geophys . res . , 102_(e2 ) , 4065 - 4080 , 1997 . yseboodt , m. , j .- barriot , and v. dehant , analytical modeling of the doppler tracking between a lander and a mars orbiter in terms of rotational dynamics , _ j. geophys . res . , 108 _ , 2003 . assuming there is no lod variations and no polar motion , we describe here the method to get the expression of the nutation signature in the doppler observable . however this development can be applied similarly to each mop . + if the vector @xmath177 is the fixed lander position in the body fixed reference frame , the lander position in the inertial frame is @xmath178 . its velocity in the inertial frame is : @xmath179 the terms proportional to @xmath100 and @xmath180 have been neglected here because they are much smaller than @xmath181 ( @xmath182 the diurnal rotation @xmath39 ) .    to the first order in the nutations in obliquity @xmath183 , the lander velocity in a non - rotating frame based on the mars mean equator of j2000 ( mme2000 ) is @xmath184 the lander velocity @xmath185 is mostly a velocity in the xy plane . but the lander velocity induced by a nutation in obliquity , in the non - rotating frame based on the mars mean equator of 2000 , is mainly along the z axis . + similarly , the main component of the signature of the nutations in longitude @xmath36 in the lander velocity is also the z component , because the dependence of the velocity is only in the z coordinate . @xmath186 this z component ( to the first order in @xmath36 ) is not as straightforward as for @xmath35 because there are @xmath36 dependent terms both in the products of 4 rotation matrices and in the @xmath187 matrix , and there is cancellation between some of these terms . + in the same inertial frame , the tracking station - lander direction is aproximated by the earth - mars direction . @xmath6 is the earth right ascension . the mop signature in the doppler observable is the scalar product between the velocity difference @xmath189 = ( @xmath190 or @xmath191 ) and the los vector : @xmath192", "tags": [], "output_text_a": "The paper discusses the use of radio signals to track landers on Mars to study its rotation, specifically through measuring the Doppler shift between the lander and Earth-based antennas. This method has been applied to several Mars missions, including Viking, Pathfinder, and Mars Exploration Rovers. Upcoming missions like NASA's InSight and ESA's ExoMars2020 will continue this research with advanced transponders. The study focuses on Martian Orientation Parameters (MOP) such as nutations, precession, length-of-day variations, and polar motion, which are influenced by Mars' interior structure and atmospheric dynamics. The paper derives expressions for the signatures of these parameters in Doppler and range observables, which are crucial for optimizing mission configurations and maximizing geophysical data collection. The research also explores the potential for similar geodesy experiments on other planetary bodies, highlighting the importance of understanding rotational dynamics for planetary science. The findings are significant for planning future missions and improving models of Mars' interior and rotational behavior. [[ ## completed ## ]]", "output_text_b": "This article discusses the use of radio signals to track the rotation of a lander on another planet, specifically Mars. By measuring the Doppler shift of the radio signal between the lander and a large antenna on Earth, such as those in the Deep Space Network, the rotation of Mars can be observed. The two-way X-band signal is used, where the ground station transmits the radio signal to Mars, which is then coherently sent back to Earth by the transponder onboard the lander. Five Martian landers have been tracked from Earth to determine the Martian rotation. The paper also discusses the use of two upcoming Martian missions, NASA's Insight mission and ESA's Exomars2020 mission, which will include geodesy experiments to study the Martian rotation and interior structure. The paper derives expressions for the signature of the rotation parameters in the Doppler and range observables, which can be used to optimize configuration parameters and anticipate observation times that maximize the signatures and geophysical information.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of radio signals to track landers on Mars and the study of Martian Orientation Parameters (MOP).\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of tracking Mars' rotation and understanding its interior structure and atmospheric dynamics.\n4. The methodology of using Doppler shift measurements and deriving expressions for MOP signatures is mentioned.\n5. Significant results, such as the potential for optimizing mission configurations and maximizing geophysical data collection, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Martian Orientation Parameters\" are explained.\n8. The summary is logically structured with a clear beginning, middle, and end.\n9. Key experiments, such as the use of radio signals and tracking of previous Mars missions, are mentioned.\n10. The paper's significance in planning future missions and improving models of Mars' interior is highlighted.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of radio signals to track the rotation of a lander on Mars and the upcoming missions that will include geodesy experiments.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is tracking the rotation of Mars using radio signals, is highlighted.\n4. The methodology, involving the measurement of Doppler shifts and the use of two-way X-band signals, is mentioned.\n5. Significant results, such as the derivation of expressions for rotation parameters and their application to optimize observation times, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Doppler shift\" and \"X-band signal\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments, such as the tracking of five Martian landers and the upcoming missions, are mentioned.\n10. The paper's significance, in terms of its potential impact on understanding Martian rotation and interior structure, is reflected."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the angular power spectrum of the cosmic microwave background ( cmb ) temperature anisotropy depends strongly on the values of most cosmological parameters and on the physical processes in the early universe ; it is thus a powerful tool to constrain cosmological models ( see e.g. , kamionkowski & kosowsky 1999 ) . several authors have used cmb data from a number of experiments to constrain cosmological parameters ( see e.g. , lange et al . 2000 , tegmark & zaldarriaga 2000 , and references therein ) .    in this letter we make use of the angular power spectrum measured in the first flight of the maxima  balloon - borne experiment , maxima-1 ( described in a companion paper by hanany et al . this power spectrum covers a range @xmath8 , which is the largest coverage in multipole space from a single experiment to date . we include in our analysis the 4-year cobe / dmr angular power spectrum ( grski et al . 1996 ) , which spans the range @xmath9 , to normalize the models at large angular scales . we determine constraints on a seven - dimensional space of cosmological parameters within the class of inflationary adiabatic models . this letter is structured as follows . in section [ methods ] we describe and justify the cosmological parameters space we have explored and the technique we used to perform the maximum likelihood analysis . in section [ constraints ] we apply the method to the maxima-1 and cobe / dmr data , to set constraints on the suite of parameters . we also combine our constraints with those from the high - redshift supernovae measurements ( perlmutter et al . 1999 ; riess et al . 1998 ) to set bounds on the fractional density in a cosmological constant , @xmath10 , and pressureless matter , @xmath11 . in section [ discussion ] we summarize our results and discuss their implications for fundamental models of structure formation . the maxima-1 power spectrum is estimated in 10 bins spanning the range @xmath8 ( hanany et al . 2000 ) . in each bin , the spectrum is assigned a flat shape , @xmath12 , whose amplitude is found by maximizing the likelihood of the data using a quadratic estimator technique ( bond , jaffe & knox 1998 ) as implemented in the madcap software package ( borrill 1999 ) . we find the most likely values of the cosmological parameters by maximizing the likelihood of the data . following bond , jaffe & knox ( 2000 ) we use a likelihood which is gaussian in the quantity @xmath13 , with @xmath14 related to the noise properties of the experiment .    in this letter we only consider inflationary adiabatic models . there are two main reasons . first , the poor performance of alternative theories in reconciling measurements of clustering on galactic scales with measurements of cmb fluctuations on horizon scales has made inflation the favored contender as a fundamental theory of structure formation . second , the angular power spectra for inflationary models are easy to calculate for given cosmological parameters , especially since the advent of fast einstein - boltzmann solvers such as cmbfast ( seljak & zaldarriaga 1996 ) or camb ( lewis , challinor & lasenby 2000 ) . we consider a seven - dimensional space of parameters . this includes the amplitude of fluctuations at @xmath15 , @xmath16 , the fractional densities of baryons , @xmath17 , and cosmological constant , @xmath10 , the total energy density of the universe , @xmath18 ( where the fractional density of pressureless matter is @xmath19 and @xmath20 is the fractional density of cold dark matter ) the spectral index of primordial scalar fluctuations , @xmath21 , and the optical depth of reionization , @xmath22 . we use the following ranges and sampling : @xmath16 is continuous ; @xmath23 = 0.1 , 0.3 , 0.5 , 0.7 , 0.8 , 0.85 , 0.9 , 0.95 , 1 , 1.05 , 1.1 , 1.15 , 1.2 , 1.3 , 1.5 ; @xmath17 = 0.01 , 0.03 , 0.05 , 0.07 , 0.09 , 0.12 , 0.20 , 0.28 ; @xmath10 = 0.0 , 0.1 , @xmath24 , 0.8 , 0.9 ; @xmath21 = 0.60 , 0.64 , @xmath24 , 1.36 , 1.40 ; @xmath22 = 0 , 0.025 , 0.05 , 0.075 , 0.1 , 0.15 , 0.2 , 0.3 , 0.5 . for the seventh parameter we have either used the hubble parameter , @xmath25 = 40 , 45 , @xmath24 , 85 , 90 km s@xmath26mpc@xmath26 , or the physical baryon density , @xmath27 = 0.003125 , 00625 , 0.0125 , 0.0175 , 0.02 , 0.025 , 0.030 , 0.035 , 0.04 , 0.05 , 0.075 , 0.1 , 0.15 , 0.2 ( where @xmath28 km s@xmath26mpc@xmath29 ) . this approach allows us to check the importance of the parameters ranges , which are effectively used as a uniform prior in our analysis . when we use @xmath25 as the free parameter we get relatively fine but restricted coverage of @xmath25 and @xmath27 . when we use @xmath27 we consider a much more extended set of priors . to ensure that we are sampling the set of parameters with enough resolution , we include models corresponding to values of the parameters that are not on the grid by quadratically interpolating between power spectra . we have not allowed for the presence of massive neutrinos , since their effect on the angular power spectrum of the cmb would be negligible for the dataset used here ( dodelson , gates & stebbins 1996 ) . we evaluate the likelihood for a subset of parameters by maximizing it over all the remaining parameters . this approach , already adopted in previous analyses of this kind ( tegmark & zaldarriaga 2000 ; melchiorri et al . 1999 ) , replaces the time - consuming integration that is required to marginalize over the unwanted parameters . in all our estimates we marginalize over the overall maxima-1 calibration uncertainty ( hanany et al . 2000 ) , assuming a gaussian prior ; we have also marginalized over the beam uncertainty reported in hanany et al . ( 2000 ) but have found that it has a negligible effect on our results . the position of the first peak in the angular power spectrum of adiabatic models can be used to constrain the geometry of the universe ( doroshkevich , zeldovich & sunyaev 1978 ) . features in the radiation pattern at recombination are set by the maximum distance sound waves have traveled at that time . the diameter - distance relation allows us to relate the physical scale of these features to the angle they subtend on the sky and strongly depends on the curvature of the universe , which is determined by the total energy density of the universe @xmath30 . other cosmological parameters have much less effect on this relation . 0.3 cm 0.3 cm fig . 1. likelihood function of the total energy density of the universe @xmath23 . the solid line was obtained by maximizing over all other parameters over the ranges described in the text , while the dashed line was obtained by constraining @xmath31 and @xmath32  km  s@xmath26  mpc@xmath26 . the intersections with the horizontal line give the bounds for @xmath5 confidence . [ fig : fig1 ]    figure  1 shows the likelihood of the total energy density of the universe , @xmath23 . we obtain the solid line if we maximize over all the remaining parameters ; we get the dashed line if we impose the big bang nucleosynthesis ( bbn ) constraint @xmath33 ( burles et al . 1999 ; see also , tytler et al . 2000 ) , and restrict @xmath34 km  s@xmath26  mpc@xmath26 ( freedman 1999 ) . from the solid line we see that @xmath35 at the @xmath5 confidence level . we identified the other tightly constrained parameters from a principal component analysis of the likelihood function ( efstathiou & bond 1999 ) . in figure  2 we plot the likelihoods for three well - constrained parameters , the physical baryon density , @xmath27 , the physical cold dark matter density , @xmath36 , and the spectral index of primordial scalar fluctuations , @xmath21 . the likelihood for each parameter was obtained by maximizing over all the remaining parameters . we find @xmath37 , @xmath38 , and @xmath39 , all at the @xmath5 confidence level . the constraint on @xmath40 is independent of the one coming from bbn ( burles et al . 1999 ) and agrees with it at about the 2@xmath41 level . however , the most likely value of @xmath40 emerging from our dataset is noticeably higher than the one from bbn . imposing the bbn prior to our dataset has the effect of moving the best fit region towards open models ( see figure  1 ) . the constraint on @xmath21 indicates that the combined maxima-1 and cobe / dmr data are consistent with a scale invariant spectrum , with a smaller variance than that estimated using previous datasets ( see e.g. , lange et al . 2000 , tegmark & zaldarriaga 2000 ) . this result should however be interpreted with some caution , because it is sensitive to assumptions on the treatment of calibration uncertainties and depends in part on the absence of tensor modes in our analysis . 0.5 cm fig . 2. likelihoods of three cosmological parameters : from top to bottom , the physical baryon density , @xmath42 , the physical cold dark matter density , @xmath43 , and the scalar spectral index , @xmath21 . for each of these parameters , the likelihood was maximized over all the remaining parameters . the vertical band in the top panel represents the bbn constraint @xmath44 ( burles et al . 1999 ) . the intersections with the horizontal line give the bounds for @xmath5 confidence . [ fig : fig2 ]    one of the intriguing developments arising in contemporary observational cosmology is the possible existence of a smooth , negative - pressure component , for example a cosmological constant , driving an accelerated expansion of the universe ( perlmutter et al . 1999 ; riess et al . while cmb data are quite powerful in constraining the total energy density of the universe , a precise independent determination of @xmath11 and @xmath10 is limited by the presence of the geometrical degeneracy discussed in efstathiou & bond ( 1999 ) ( which can be broken if a gravitational lensing imprint on the cmb is detected , see e.g. , stompor & efstathiou 1999 ) . we can however find the locus of models in the @xmath11@xmath10 plane which are favored by the combined maxima-1 and cobe / dmr data . we do so in figure  3 , where once again we maximize over all the remaining parameters . the fact that the maxima-1 dataset extends to large values of @xmath0 helps to narrow the contours along the degeneracy direction @xmath45  constant . although a large portion of the @xmath11@xmath10 plane is ruled out , one clearly needs additional data to strongly break the degeneracy . we then overlay our results on the likelihood contours from the high - redshift supernovae data of perlmutter et al . ( 1999 ) and riess et al . ( 1998 ) and calculate the combined likelihood . the resulting constraints are : @xmath6 and @xmath7 , at the @xmath5 confidence level . using the broad @xmath0-space coverage of the maxima-1 and cobe / dmr data we set constraints on a number of cosmological parameters within the class of inflationary adiabatic models . we find : @xmath46 , @xmath2 , @xmath47 and @xmath4 at the @xmath5 confidence level . the constraints we have obtained on @xmath23 are consistent with those of other recent analyses ( melchiorri et al . 1999 ; dodelson & knox  1999 ; tegmark & zaldarriaga  2000 ; lange et al . 2000 ) and provide further support to a flat universe . combining our constraints with those coming from measurements of supernovae at high redshift strongly favors a non - zero cosmological constant , @xmath48 , and a pressureless matter density parameter @xmath49 , both at the @xmath5 confidence level . our analysis was restricted to inflationary adiabatic models . several hints suggest that this may indeed be the right paradigm . the presence of a localized peak in our data in the region @xmath50 is in itself an evidence in favor of inflationary adiabatic models ; alternative theories either predict a broader peak at higher @xmath0 or a broad shelf at @xmath51 ( see e.g. , knox & page 1999 ) . furthermore , from a goodness - of - fit analysis ( with the caveat that our data are not perfectly well - described by a gaussian likelihood ) we find that the class of models we have considered are perfectly consistent with the data . our best fit has @xmath52=41 using the 38 data points of the combined maxima-1/cobe dataset ( @xmath52=7 using only the 10 data points from maxima-1 ) . within inflationary models , the standard cdm model and the open cdm model with @xmath53 both provide a poor fit to our data , having , respectively , @xmath52=67 ( 25 ) and @xmath52=224 ( 159 ) . the @xmath54-cdm ` concordance model ' ( ostriker & steinhardt 1995 ; krauss & turner 1995 ) has @xmath52=50 ( 9 ) . these results are summarized in figure  4 , where we plot the maxima-1 data overlaid with various cosmological models . 0.5 cm 0.7 cm    finally , the agreement of our results with those obtained from other observations lends further credence to the possibility that we are considering the correct family of cosmological models . first , we find an independent constraint on the physical baryon density of the universe : @xmath37 , which , although favoring higher values than the bbn estimate of burles et al . ( 1999 ) , agrees with it within 2@xmath41 . second , we are able to constrain the amount of cold dark matter in the universe : @xmath3 . if we combine this value with our constraint on @xmath27 and the maxima-1/cobe / sn  ia best fit value of @xmath55 derived from figure  3 , we find that the `` shape '' parameter ( commonly used in analysis of large scale structure ; see e.g. , sugiyama 1995 ) is @xmath56 . together with our best estimate of @xmath57 , this is consistent with the value @xmath58 which emerges from a completely independent analysis of galaxy catalogs ( viana & liddle 1999 ; liddle et al . 1995 ; peacock & dodds 1994 ) . we thank s. jha and the high - z supernova search team for kindly providing the combined likelihood from supernova measurements used in this paper . pgf acknowledges fruitful discussions with a. melchiorri . maxima is supported by nasa grants nag5 - 3941 , nag5 - 4454 , by the nsf through the center for particle astrophysics at uc berkeley , nsf cooperative agreement ast-9120005 . the data analysis used resources of the national energy research scientific computing center which is supported by the office of science of the u.s . department of energy under contract no . de - ac03 - 76sf00098 . pa acknowledges support from pparc rolling grant , uk . pgf acknowledges support from the rs . ahj and jhpw acknowledge support from nasa ltsa grant no . nag5 - 6552 and nsf kdi grant no . br and cdw acknowledge support from nasa gsrp grants no . s00-gsrp-032 and s00-gsrp-031 . we acknowledge use of camb .                                                                in the letter `` constraints on cosmological parameters from maxima-1 '' by a. balbi et al . ( apj 545 , l1 [ 2001 ] ) , an error was found in the results : while it is claimed in the letter that the optical depth of reionization , @xmath22 , took values bewteen @xmath59 and @xmath60 , an error in the computer code led to the results being based on @xmath61 . we have regenerated the database of models with the correct ( published ) values of @xmath22 , namely , @xmath22 = 0 , 0.025 , 0.05 , 0.075 , 0.1 , 0.15 , 0.2 , 0.3 , 0.5 . the best - fit model quoted in the letter remains unchanged . however , we have found that the @xmath5 confidence level constraints on the total energy density of the universe , the physical density of baryons and the scalar spectral index of primordial fluctuations change to : @xmath62 , @xmath63 and @xmath64 , respectively . the likelihoods for the remaining parameters are effectively unchanged . in figures 1 and 2 , we present the figures which should replace figures 1 and 2 of the original letter .    2 0.3 cm fig . 1. likelihood function of the total energy density of the universe @xmath23 . the solid line was obtained by maximizing over all other parameters over the ranges described in the text , while the dashed line was obtained by constraining @xmath44 and @xmath65  km  s@xmath26  mpc@xmath26 . the intersections with the horizontal line give the bounds for @xmath5 confidence . 0.5 cm fig . 2. likelihoods of three cosmological parameters : from top to bottom , the physical baryon density , @xmath27 , the physical cold dark matter density , @xmath36 , and the scalar spectral index , @xmath21 . for each of these parameters , the likelihood was maximized over all the remaining parameters . the vertical band in the top panel represents the bbn constraint @xmath44 ( burles et al . 1999 ) . the intersections with the horizontal line give the bounds for @xmath5 confidence", "tags": [], "output_text_a": "The paper discusses the use of the angular power spectrum of the Cosmic Microwave Background (CMB) temperature anisotropy to constrain cosmological models, focusing on data from the MAXIMA-1 balloon-borne experiment and the COBE/DMR data. The authors explore a seven-dimensional space of cosmological parameters within inflationary adiabatic models, using a maximum likelihood analysis. They combine their findings with high-redshift supernovae measurements to set bounds on the fractional density of a cosmological constant and pressureless matter. The analysis reveals constraints on the total energy density of the universe, the physical baryon density, and the spectral index of primordial scalar fluctuations, supporting a flat universe and a non-zero cosmological constant. The results are consistent with other observations and suggest that inflationary adiabatic models may be the correct paradigm for understanding the universe's structure. An error in the original analysis regarding the optical depth of reionization was corrected, leading to updated constraints on some parameters. The study highlights the power of CMB data in cosmological research and the need for additional data to resolve certain degeneracies in parameter estimation.", "output_text_b": "This article presents an analysis of the angular power spectrum of the cosmic microwave background (CMB) temperature anisotropy using data from the MAXIMA-1 experiment and the COBE/DMR. The authors use the data to constrain a seven-dimensional space of cosmological parameters within the class of inflationary adiabatic models. The analysis is based on the angular power spectrum measured in the first flight of the MAXIMA balloon-borne experiment and the 4-year COBE/DMR angular power spectrum. The authors determine constraints on a seven-dimensional space of cosmological parameters, including the amplitude of fluctuations at a given scale, the fractional densities of baryons, cosmological constant, and cold dark matter, the total energy density of the universe, the spectral index of primordial scalar fluctuations, and the optical depth of reionization.\n\nThe analysis is performed using a maximum likelihood technique and a quadratic estimator technique as implemented in the MADCAP software package. The authors consider a seven-dimensional space of parameters, including the amplitude of fluctuations at a given scale, the fractional densities of baryons, cosmological constant, and cold dark matter, the total energy density of the universe, the spectral index of primordial scalar fluctuations, and the optical depth of reionization. They use a likelihood which is Gaussian in the quantity related to the noise properties of the experiment.\n\nThe authors find that the most likely values of the cosmological parameters are obtained by maximizing the likelihood of the data. They also find that the position of the first peak in the angular power spectrum of adiabatic models can be used to constrain the geometry of the universe. The likelihood function of the total energy density of the universe is presented, showing that the total energy density of the universe is constrained to be @xmath35 at the 95% confidence level.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of the CMB angular power spectrum to constrain cosmological models and the correction of an error regarding the optical depth of reionization.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on constraining cosmological models using CMB data.\n4. The methodology, including the use of a maximum likelihood analysis and the combination with high-redshift supernovae measurements, is mentioned.\n5. Significant results, such as constraints on the total energy density, baryon density, and support for a flat universe, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"inflationary adiabatic models\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments and data, such as the MAXIMA-1 and COBE/DMR data, are mentioned.\n10. The summary reflects the paper's significance in cosmological research and the potential impact of CMB data.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the analysis of the angular power spectrum of the CMB and the constraints on cosmological parameters.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the constraint of cosmological parameters using CMB data, is highlighted.\n4. The methodology, including the use of the MAXIMA-1 and COBE/DMR data and the maximum likelihood technique, is mentioned.\n5. Significant results, such as the constraints on the total energy density of the universe, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"angular power spectrum\" and \"cosmological parameters.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments and data, such as the MAXIMA-1 and COBE/DMR, are mentioned.\n10. The summary reflects the paper's significance in constraining cosmological models and understanding the universe's geometry."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "one of the fundamental questions of nuclear structure physics is : what are the limits of nuclear stability ? how many neutrons or protons can we add to a given nucleus before it becomes unstable against spontaneous neutron or proton emission ? if one connects the isotopes with zero neutron separation energy , @xmath2 , in the nuclear chart one obtains the neutron dripline . similarly , the proton dripline is defined by the condition @xmath3 . another limit to stability is the superheavy element region around @xmath4 and @xmath5 which is formed by a delicate balance between strong coulomb repulsion and additional binding due to closed shells . the nuclear chart shows less than 300 stable nuclear isotopes , and about 1700 additional isotopes have been synthesized and studied in accelerator experiments . nuclei in between the proton and neutron driplines are unstable against @xmath6-decay . nuclei outside the driplines decay by spontaneous neutron emission or proton radioactivity . the neutron - rich side , in particular , exhibits thousands of nuclear isotopes still to be explored ( ` terra incognita ' ) . some of these exotic nuclei can be studied with existing first - generation radioactive ion beam facilities ( e.g. hribf at oak ridge , nscl at michigan state university , ganil in france , gsi in germany , and riken in japan ) . several countries are planning to construct new ` second generation ' rib facilities , in particular for the exploration of neutron rich isotopes . in the united states , the doe / nsf long range plan for nuclear physics , published in april 2002 , gives the highest priority for new construction to ria ( rare isotope accelerator ) . ria is a bold new concept in exotic beam facilities in that it combines both of the known rare isotope production techniques : the isol method ( thick - target spallation ) and high - energy projectile fragmentation . theories predict profound differences between the known isotopes near stability and the exotic nuclei at the driplines @xcite : for n - rich nuclei , as the fermi level approaches the particle continuum at @xmath7 ( see fig . [ sketch_pot ] ) weakly bound states couple strongly to the continuum states giving rise to neutron halos and neutron skins . theories also expect large pairing correlations and new collective modes ( e.g. ` pigmy resonance ' ) , a weakening of the spin - orbit force leading to a quenching of the shell gaps , and perhaps new magic numbers .         furthermore , ria will allow us to address fundamental questions in nuclear astrophysics : more than half of all elements heavier than iron are thought to be produced in supernovae explosions by the rapid neutron capture process ( r - process ) . the r - process path contains many exotic neutron - rich nuclei which can only be studied with ria . also , the predicted neutron skins would allow us to measure the properties of pure neutron matter which is of great interest for the study of neutron stars . these experimental developments as well as recent advances in computational physics have sparked renewed interest in nuclear structure theory . there are several types of approaches in nuclear structure theory @xcite : for the lightest nuclei , ab - initio calculations ( green s function monte carlo , no - core shell model ) based on the bare n - n interaction are possible @xcite . medium - mass nuclei up to @xmath8 may be treated in the large - scale shell model approach @xcite . for heavier nuclei one utilizes either nonrelativistic @xcite or relativistic @xcite mean field theories . an accurate treatment of the pairing interaction is essential for exotic nuclei @xcite . as we move away from the valley of stability , surprisingly little is known about the pairing force : for example , what is its density dependence ? neutron - rich nuclei are expected to be highly superfluid due to continuum excitation of neutron ` cooper pairs ' . these large pairing correlations near the driplines can no longer be described by a small residual interaction . it becomes necessary to treat the mean field and the pairing field in a single self - consistent theory , known as the hartree - fock - bogoliubov theory ( hfb ) . near the neutron dripline , the fermi energy approaches @xmath7 and the outermost nucleons are weakly bound ( which implies a large spatial extent ) ; they are strongly coupled to the particle continuum at @xmath9 . these features represent major challenges for the numerical solution . most hfb calculations to date are carried out in a truncated discrete harmonic ocillator basis , see e.g. @xcite . this approach is quite appropriate for nuclei in the vicinity of the stability line . however , farther from stability , the continuum states become important and coordinate - based representations have numerous advantages : for example , the well - known ` french code ' uses a truncated 3-d hartree - fock basis @xcite which consists of both localized states and discretized continuum states ; however , in this approach one can only include continuum states up to about @xmath10 mev of excitation energy . for nuclei in the vicinity of the driplines , continuum states with an equivalent single - particle energy of up to 60 mev must be taken into account . one - dimensional calculations for spherical nuclei have been carried out in coordinate space for many years @xcite , but only recently has our vanderbilt group succeeded in generalizing this approach to the important case of deformed axially symmetric nuclei ( hfb on a 2-d lattice ) @xcite . we utilize a novel computational technique , a basis - spline representation of wavefunctions and operators , which allows us to accurately describe high - energy continuum states in two space dimensions @xmath11 . the many - body hamiltonian in occupation number representation has the form @xmath12 the general linear transformation from particle operators @xmath13 to quasiparticle operators @xmath14 take the form @xcite : @xmath15 the hfb approximate ground state of the many - body system is defined as a vacuum with respect to quasiparticles @xmath16 the hfb ground state energy including the constraint on the particle number @xmath17 is given by @xmath18 where the lagrange multiplier @xmath19 is the fermi energy of the system . the equations of motion are derived from the variational principle @xmath20   =   0 \\ , \\ ] ] where @xmath21 represents the generalized density matrix .      in practice , it is to convenient to transform the standard hfb equations into a coordinate space representation and solve the resulting differential equations on a lattice . for this purpose , one defines two types of quasiparticle wavefunctions @xmath22 and @xmath23 @xmath24 the basis wavefunctions @xmath25 depend on the position vector @xmath26 , the spin projection @xmath27 , and the isospin projection @xmath28 ( @xmath29 corresponds to protons and @xmath30 to neutrons ) . + from these wavefunctions we obtain the following expressions for the normal density @xmath31 and the pairing density @xmath32 @xmath33 the quasiparticle energy @xmath34 is denoted by index @xmath35 for simplicity . in principle , the sums go over all the energy states , but in practice a cutoff is introduced ( see later ) . the physical interpretation of @xmath36 has been discussed in @xcite : the quantity @xmath37 ^ 2 $ ] gives the probability to find a _ correlated _ pair of nucleons with opposite spin projection in the volume element @xmath38 . the kinetic energy density @xmath39 is found to be @xmath40      in our calculations we utilize the skyrme two - body effective n - n interaction @xmath41 the density - dependent term proportional to @xmath42 simulates the three - body n - n interaction @xmath43 . the total binding energy of the nucleus @xmath44 consists of a kinetic energy term , various contributions from the skyrme effective n - n interaction ( including a spin - orbit term ) , coulomb and pairing energy , and a center - of mass correction due to the mean - field approximation @xmath45   \\nonumber \\\\                    & + & \\int d^3r \\sum_q \\left [              - \\frac{b'_0}{2 } \\rho_q^2 - b'_1 \\rho_q \\tau_q             + \\frac{b'_2}{2 } \\rho_q \\nabla^2 \\rho_q             - \\frac{b'_3}{3 } \\rho^{\\alpha } \\rho_q^2          \\right ] \\nonumber \\\\ e_{sky , ls } & = & \\int d^3r \\left [            - b_4 \\rho { \\bf \\nabla \\cdot j } - b'_4 \\sum_q \\rho_q ( { \\bf \\nabla \\cdot j}_q ) \\ . \\right ] \\label{eq : bind1}\\end{aligned}\\ ] ] the coulomb energy contains the direct term as well as an exchange term ( in slater approximation ) @xmath46^{4/3 } \\ .\\ ] ]      in practice , one tends to use _ different _ effective n - n interactions for the p - h / h - p channels and for the p - p / h - h channels . most pairing calculations utilize a local pairing interaction of the form @xmath47 this parameterization describes two primary pairing forces : a pure delta interaction ( @xmath48 ) that gives rise to _ volume pairing _ , and a density dependent delta interaction ( dddi ) that gives rise to _ surface pairing_. in the latter case , one uses the following phenomenological ansatz @xcite for the factor @xmath49 @xmath50 where @xmath51 is the mass density . the pairing contribution to the nuclear binding energy is then @xmath52 an important related quantity is the average pairing gap for protons and neutrons which can be calculated from the general expression given in @xcite @xmath53 where @xmath54 denotes the number of protons or neutrons . note that the pairing gap is a positive quantity because @xmath55 .      for certain types of effective interactions ( e.g. skyrme mean field and pairing delta - interactions ) the particle hamiltonian @xmath56 and the pairing hamiltonian @xmath57 are diagonal in isospin space and local in position space , resulting in the following hfb equations with a 4x4 structure in spin space : @xmath58 with @xmath59 the hfb equations have a mathematical structure that is similar to the dirac equation : the spectrum of quasiparticle energies @xmath60 is unbounded from above _ and _ below . the spectrum is discrete for @xmath61 and continuous for @xmath62 . this is illustrated in fig . [ fig : spectrum ] .     computational challenge in solving the hfb equations in coordinate space : the quasiparticle energy spectrum is unbounded from above and below . ] as explained in @xcite , it is forbidden to choose positive and negative quasiparticle energies at the same time , otherwise it is impossible to satisfy the anticommutation relations for @xmath63 . for even - even nuclei it is customary to solve the hfb equations with a positive quasiparticle energy spectrum @xmath64 and consider all negative energy states as occupied in the hfb ground state . the hfb mean field hamiltonian has the same structure as the binding energy functional @xmath65 the coordinate - dependent effective mass arises from the densities @xmath66 detailed expressions for the skyrme mean fields and the coulomb term are given in reference @xcite . the dddi interaction generates the following pairing mean field for the two isospin orientations @xmath67 for simplicity , we assume that the hfb quasiparticle hamiltonian is invariant under rotations @xmath69 around the z - axis , i.e. @xmath70=0 $ ] . due to the axial symmetry of the problem , it is advantageous to introduce cylindrical coordinates @xmath71 . it is possible to construct simultaneous eigenfunctions of the generalized hamiltonian @xmath72 and the z - component of the angular momentum , @xmath73 with quantum numbers @xmath74 corresponding to each @xmath75 energy state . the simultaneous quasiparticle eigenfunctions take the form @xmath76 we introduce the following useful notation @xmath77 for axially symmetric systems , it is possible to eliminate the dependence on the angle @xmath78 , resulting in the _ reduced 2-d problem _ in cylindrical coordinates @xcite :    @xmath79    with @xmath80    here , quantities @xmath81 , @xmath82 , @xmath83 and @xmath84 are all functions of @xmath85 only . this is the main mathematical structure that we implement in computational calculations . for a given angular momentum projection quantum number @xmath86 , we solve the eigenvalue problem to obtain energy eigenvalues @xmath87 and eigenvectors @xmath88 for the corresponding hfb quasiparticle states . from the definitions of the normal density and pairing density we find the corresponding expressions in axial symmetry : @xmath89 \\\\ \\tilde{\\rho}_q(r , z ) & = & - \\frac{1}{2 \\pi }     \\left(2 \\sum_{\\omega>0}^{\\omega_{max } } \\right )      \\times \\sum_{e_n>0}^{e_{max } }     \\left[u^{(2)}_{n \\omega q}(r , z ) u^{(1)*}_{n \\omega q}(r , z )    + l^{(2)}_{n \\omega q}(r , z ) l^{(1)*}_{n \\omega q}(r , z ) \\right ] \\ .\\end{aligned}\\ ] ] we solve the hfb eigenvalue problem by direct diagonalization on a two - dimensional grid @xmath90 , where @xmath91 and @xmath92 . the four components of the spinor wavefunction are represented on the two - dimensional lattice by an expansion in basis - spline functions @xmath93 evaluated at the lattice support points . further details about the basis - spline technique are given in ref . @xcite .    for the lattice representation of the hamiltonian , we use a hybrid method @xcite in which derivative operators are constructed using the galerkin method ; this amounts to a global error reduction . local potentials are represented by the basis - spline collocation method ( local error reduction ) . the lattice representation transforms the differential operator equation into a matrix form @xmath94 the calculations use as a starting point the result of a _ hf+bcs _ previous calculation , which makes hfb converge substantially faster . since the problem is self - consistent we use an iterative method for the solution . at every iteration the full hfb hamiltonian is diagonalized . due to the axial symmetry in the intrinsic frame , the diagonalization is performed separately for each value of the angular momentum projection quantum number @xmath86 and for the two isospin projections @xmath95 . typically 20 - 30 iterations are sufficient for convergence at the level of one part in @xmath96 for the total binding energy .    note that in this lattice approach , the number of quasiparticle states is determined by the dimensionality of the discrete hfb hamiltonian which is @xmath97 . in the following we discuss some numerical results obtained with our new hfb-2d code . first we present calculations for a light stable nucleus , @xmath98ne . this nucleus was chosen because it has a large prolate g.s . quadrupole deformation . the calculation has been performed with the skyrme sly4 interaction in the p - h channel and a pure delta pairing interaction ( strength @xmath99 ) . for the pairing forces of zero range employed here , one needs to introduce an energy cut - off . in all of our calculations , we use a cut - off energy @xmath100 mev in the _ equivalent s.p . energy spectrum _ , the same value utilized by dobaczewski et al . @xcite in his spherical 1-d calculations . ne mean field potential for neutrons and protons , title=\"fig : \" ] ne mean field potential for neutrons and protons , title=\"fig : \" ]    ne , title=\"fig : \" ] ne , title=\"fig : \" ]    ne , title=\"fig : \" ] ne , title=\"fig : \" ]    fig . [ ne22_pot ] shows the mean field potential @xmath101 for neutrons and protons . both mean fields are fairly similar , except that there is an additional coulomb contribution for the protons . in fig . [ ne22_dens ] we depict contour plots of the normal density for neutrons and protons . the large prolate quadrupole deformation is clearly visible in the density distributions . [ ne22_pairdens ] shows the pairing density for neutrons and protons . the square of the pairing density describes the probability of finding a _ correlated _ nucleon pair with opposite spin directions at position @xmath26 @xcite . because this is a stable isotope , the pairing turns out to be relatively weak . the shell structure of this light nucleus causes significant differences in the neutron- vs. proton pairing . we now present results for the n - rich isotope @xmath0 which is close to the experimentally confirmed @xcite dripline nucleus @xmath102 . because this nucleus turns out to be spherical in our 2-d calculations , we can compare our results to the 1-d spherical code of dobaczewski @xcite and to the 2-d oscillator basis expansion method of stoitsov et al . table [ table : comparison_o22 ] shows several observables for this nucleus : the total binding energy , fermi levels , pairing gaps and the r.m.s . radius . overall , the results of the axially symmetric code of the present work agree with the other two in all observables . .[table : comparison_o22 ] comparison of several hfb calculations for @xmath103 . in all cases , the mean field is calculated with the sly4 interaction , and the pairing force is a pure delta interaction ( strength @xmath104 ) corresponding to volume pairing . the axially symmetric calculations ( 2d ) of this work used a box size @xmath105 with maximum @xmath106 . the spherical calculation of ref . @xcite was made with @xmath107 and a @xmath108 . [ cols=\"<,^,^,^\",options=\"header \" , ] our goal for the near future is to investigate several isotope chains , in particular deformed nuclei , and to calculate observables which are important for the physics near the drip lines , i.e. binding energies , neutron and proton separation energies , pairing gaps , particle densities and pairing densities , rms radii , and electric or magnetic moments . we plan to utilize a variety of skyrme parameterizations for the mean field , and both volume and surface pairing forces . as more data from existing rib facilities become available , it is likely that it will become necessary to develop new effective n - n interactions to describe these exotic nuclei . furthermore , our 2-d hfb code results may be used as input into coordinate - space based qrpa calculations to investigate collective excited states ( surface vibrations and giant resonances ) . we will also study alternative numerical techniques to speed up our 2-d hfb code , in particular damping methods which we have utilized successfully in solving the dirac equation @xcite . provided that the damping method can be successfully implemented in 2-d , we will attempt to solve the 3-d hfb problem in cartesian coordinates . this will certainly be very difficult , but it is worth trying : in the 1996 doe / nsac long range plan , unrestricted hfb theory on the lattice has been described as a computational grand challenge project in nuclear physics . this work is supported by the u.s . department of energy under grant no . de - fg02 - 96er40963 with vanderbilt university . some of the numerical calculations were carried out on supercomputers at the national energy research scientific computing center ( nersc ) . we also like to acknowledge many fruitful discussions with w. nazarewicz and m. stoitsov ( ornl ) and with j. dobaczewski ( warsaw ) .", "tags": [], "output_text_a": "The paper addresses fundamental questions in nuclear structure physics, particularly the limits of nuclear stability and the exploration of exotic nuclei near the neutron and proton driplines. It discusses the challenges and advancements in studying these nuclei, which are unstable against decay processes and often exhibit unique properties like neutron halos and skins. The paper highlights the importance of facilities like the Rare Isotope Accelerator (RIA) for studying neutron-rich isotopes, which are crucial for understanding processes like the rapid neutron capture process (r-process) in supernovae. Theoretical approaches, including the Hartree-Fock-Bogoliubov (HFB) theory, are used to model these exotic nuclei, emphasizing the need for accurate treatment of pairing interactions. The paper presents computational techniques for solving HFB equations in coordinate space, particularly for deformed nuclei, and discusses results for specific isotopes like Ne-22 and O-22. Future goals include investigating isotope chains, calculating various nuclear observables, and developing new effective interactions as more experimental data becomes available. The work is supported by the U.S. Department of Energy and involves collaborations with other researchers and institutions.", "output_text_b": "The article discusses the study of nuclear stability limits and the exploration of exotic nuclei using Radioactive Ion Beam (RIB) facilities. Theories predict significant differences between known isotopes near stability and exotic nuclei at the driplines, such as neutron halos, neutron skins, large pairing correlations, new collective modes, and quenching of shell gaps. The Rare Isotope Accelerator (RIA) in the US, which combines both spallation and projectile fragmentation techniques, is given priority for new construction to study these exotic nuclei. The Hartree-Fock-Bogoliubov (HFB) theory, which treats the mean field and pairing field in a single self-consistent theory, is essential for accurately describing exotic nuclei. However, the numerical solution of HFB equations near the driplines presents major challenges due to large spatial extents and strong coupling to the particle continuum.\n\nThe article also highlights the importance of the Skyrme two-body effective nuclear interaction and the density-dependent delta interaction (DDDI) for describing pairing forces in nuclear systems. The particle hamiltonian and pairing hamiltonian are diagonal in isospin space and local in position space for certain types of effective interactions, resulting in hfb equations with a 4x4 structure in spin space.\n\nThe authors plan to investigate isotope chains, particularly deformed nuclei, and calculate important observables for physics near the drip lines using various Skyrme parameterizations and both volume and surface pairing forces. They also aim to develop new effective nuclear interactions for exotic nuclei and utilize coordinate-space based QRPA calculations for investigating collective excited states.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper, discussing the limits of nuclear stability, the exploration of exotic nuclei, and the importance of facilities like RIA.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of nuclear stability limits and the exploration of exotic nuclei.\n4. The summary mentions the methodology, including the use of the Hartree-Fock-Bogoliubov (HFB) theory and computational techniques.\n5. Significant results, such as the study of specific isotopes and future goals, are included.\n6. The language is clear and professional.\n7. The summary uses some technical terms like \"neutron halos\" and \"HFB theory\" but does not explain them, which may be necessary for clarity.\n8. The structure is logical, with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research.\n10. The potential impact of the research is reflected by mentioning the significance of studying neutron-rich isotopes and the support from the U.S. Department of Energy.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the study of nuclear stability limits, the exploration of exotic nuclei, and the use of RIB facilities and HFB theory.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the research problem of nuclear stability limits and the exploration of exotic nuclei.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of RIB facilities, HFB theory, and Skyrme interactions.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results such as the differences between known isotopes and exotic nuclei, and the challenges in solving HFB equations.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like HFB theory and Skyrme interactions but does not explain them, which may not be necessary for the target audience.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by mentioning the potential impact of RIA and the study of exotic nuclei."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "when a wave propagates with a low energy in a quasi - one - dimensional ( q1d ) wave guide with an uniform cross section , the guide is effectively one - dimensional ( 1d ) since only the first transverse mode plays a role . however , when a guide comprises discontinuities such as bends and branching junctions , higher transverse modes come into play at the vicinity of the discontinuities . therefore , in principle , a full - mode or full - wave analysis is required , which means a substantial increase in the amount of calculation and the physics is often obscured . knowing that the guide is essentially 1d in the uniform sections , such a full - wave analysis for the entire system is actually unnecessary . it is the purpose of this paper to present a scheme to eliminate those redundancies and simplify the calculations , yet have those low - energy properties faithfully preserved . historically , there has been a number of schemes related to this purpose . the earliest one was due to kuhn and dates back to 1949 @xcite . then it was made more well - known by griffith in 1953 @xcite , and henceforth it has been called the griffith boundary condition @xcite . the scheme contains a set of equations relating the wave functions and their first derivatives on the lines connected to a junction @xcite . the equations are simple equations that satisfy the unitarity condition at the junction . the scheme has been intuitively stated and has no undetermined parameters . however , recently it has been pointed out by the author @xmath0 @xcite that it is not clear what kind of realistic q1d guides the scheme describes . later than kuhn , there was another scheme by shapiro in 1983 @xcite . the scheme starts by an unitary matrix relating the amplitudes of the inward and outward waves @xcite . though this scheme contains free parameters , it also has not been mentioned how the parameters are related to the guides in realistic spaces .    to the present , approaches to the related problems are belong to either one of the mentioned two categories @xcite . and a common feature of most of the schemes @xcite is that the relation between the reduced systems and the original systems is not addressed , and this hinders the application to the study of realistic systems .    in 2006 , the author _ et al . _ proposed a scheme @xcite , which has been the first attempt to relate reduced and unreduced systems . the scheme resembles that by kuhn @xcite , but has an extra phenomenological term with a tuning parameter . the parameter is to be fixed by a comparison between results from the reduced and unreduced systems . the scheme was shown to be a substantial improvement , and many low - energy transport properties were shown to be captured . but still , it is pointed out later in this paper that this simple phenomenology can be inadequate and a more general scheme is needed . section [ form ] illustrates the derivation of the connecting equations to be used in reduced systems , for two typical component structures  the l - bend and the t - junction . then in sec . [ examples ] , these two structures are assembled into more elaborated structures , and the wave propagation in the structures are studied in and compared between , the reduced and unreduced systems . in sec . [ conc ] , a few concluding remarks are given . the scheme to be proposed can be summarized as in the following . for a particular discontinuity , the scattering matrix ( @xmath1-matrix ) is evaluated using a full - wave treatment , and then the matrix is truncated leaving only those elements relating the first transverse modes in the branch guides . the truncated @xmath1-matrix is then used to connect the 1d wave functions in reduced systems . the two - dimensional ( 2d ) time - independent schr@xmath2dinger equation ( tise ) @xmath3 [ \\partial_x ^2 \\psi + \\partial_y ^2 \\psi ] + v(x , y ) \\psi = e \\psi$ ] , with @xmath4 and hard wall boundaries is considered . for a wave with an energy @xmath5 in a guide having a width @xmath6 , the wave function can be written as a sum of direct products of transverse modes and longitudinal waves . labeling the guide by @xmath7 and defining a coordinate system @xmath8 in the guide , where @xmath9 is in the longitudinal direction and @xmath10 is in the transverse direction ( @xmath11 ) , the wave function can be written as @xmath12 where @xmath13 is the longitudinal wave number for the @xmath14-th transverse mode , which can be propagating or evanescent , and @xmath15 is a large enough integer . in a 1d space , the tise becomes @xmath16 \\partial_x ^2 \\psi + v(x ) \\psi = e \\psi$ ] . for a line labeled by @xmath7 , and with a coordinate @xmath9 defined on it , the wave function for @xmath17 is @xmath18 where @xmath19 is the longitudinal wave number given by @xmath20 . when results from 2d guides and 1d lines are compared , @xmath21 ( @xmath22 ) is compared with @xmath23 ( @xmath24 ) , and @xmath25 is compared with @xmath19 . two discontinuities in 2d wave guides are considered , the l - bend and t - junction as shown in fig . [ discontinuities](a ) and [ discontinuities](b ) respectively . the discontinuities are divided into regions which are labeled by 1 , 2 , 3 , and d in our discussion . coordinates are also defined in the branch guides , and wave functions in the branch guides are in the form given by eq . ( [ psi_2d ] ) . the @xmath1-matrices are to be presented in terms of these coordinates . the symbols used to denote the l - bend and t - junction in reduced systems are shown in fig . [ discontinuities](c ) and [ discontinuities](d ) respectively . we only sketch the evaluation of the @xmath1-matrices here , since the techniques are well - established and are detailed in the literatures @xcite . the wave function in region d [ see figs . [ discontinuities](a ) and [ discontinuities](b ) ] is also expanded in terms of undetermined amplitudes , and they are connected to wave functions in other regions by the conditions of continuities of wave functions and normal derivatives of wave functions at the boundaries between the regions . otherwise , one may also solve the tise in a discretized space , where the tise is a set of finite - difference ( fd ) equations .    for the t - junction shown in fig . [ discontinuities](b ) , we can get an equation for the amplitudes of the waves in the branch guides ( regions 1 , 2 , and 3 ) such as @xmath26 = \\left [ \\begin { array } { cccc } s_{11 } ^{\\rm t } & s_{12 } ^{\\rm t } & s_{13 } ^{\\rm t } & ... \\\\ s_{21 } ^{\\rm t } & s_{22 } ^{\\rm t } & s_{23 } ^{\\rm t } & ... \\\\ s_{31 } ^{\\rm t } & s_{32 } ^{\\rm t } & s_{33 } ^{\\rm t } & ... \\\\ ... & ... & ... & ... \\\\ \\end { array } \\right ] \\left [ \\begin { array } { c } a^{(1)}_1 \\\\ a^{(1)}_2 \\\\ a^{(1)}_3 \\\\ ... \\end { array } \\right ] , \\label { st_2d}\\end{aligned}\\ ] ] where @xmath27 ( @xmath28 ) is an amplitude for an inward ( outward ) wave in eq . ( [ psi_2d ] ) . truncating the matrices in eq . ( [ st_2d ] ) and retaining only terms related to the first transverse modes in the branch guides , we get @xmath29 = s _ { \\rm t } \\left [ \\begin { array } { c } a_1 \\\\ a_2 \\\\ a_3 \\end { array } \\right ] , \\label { teqs}\\end{aligned}\\ ] ] where @xmath23 and @xmath24 , @xmath30 and 3 are amplitudes in eq . ( [ psi_1d ] ) , and @xmath31 , \\label { st_1d}\\end{aligned}\\ ] ] where the coordinates are chosen as toward the junction , and @xmath32 at the junction as shown in fig . [ discontinuities](d ) . for the scheme to work , it is necessary that the energy is such that only the first transverse mode is propagating , and the exponential tails of the evanescent waves of higher modes emanated from the discontinuities are shorter than the distances between the discontinuities . we can also write eq . ( [ teqs ] ) in terms of @xmath33 . using @xmath34 / 2 $ ] and @xmath35 / 2 $ ] at @xmath36 , the connecting equation can be rewritten as @xmath37 = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\psi_1 \\\\ \\psi_2 \\\\ \\psi_3 \\end { array } \\right ] , \\label { st_psi}\\end{aligned}\\ ] ] where the wave functions and their derivatives are evaluated at the discontinuity , and the directions of the coordinates are defined to be toward the discontinuity . note that in eq . ( [ st_psi ] ) , it is not necessary that the origins of the coordinates be located at the discontinuity .    likewise , the connecting equation for the l - bend shown in fig . [ discontinuities](a ) can be written as @xmath38 = \\left ( 1 - s _ { \\rm l } \\right ) \\left [ \\begin { array } { c } \\psi_1 \\\\ \\psi_2 \\end { array } \\right ] , \\label { sl_psi}\\end{aligned}\\ ] ] where the directions of the coordinates are defined to be toward the discontinuity as shown in fig . [ discontinuities](c ) . note that , the @xmath1-matrices are symmetric ( @xmath39 and @xmath40 ) and unitary ( @xmath41 and @xmath42 ) . the unitarity implies @xmath43 / [ 2 e^{ik x_\\eta } ] $ ] and @xmath44 / [ 2 e^{-ik x_\\eta } ] $ ] , the unitarity can be rephrased as a more intuitive equality @xmath45 , or there is no net inflow of probability current to the discontinuity . the numerical results for the magnitudes and arguments of the elements of @xmath46 are plotted in figs . [ smat](a ) and [ smat](b ) respectively , and the results for @xmath47 are plotted in figs . [ smat](c ) and [ smat](d ) respectively , versus a dimensionless longitudinal wave number @xmath48 defined by @xmath49 . for the reference of the readers , the cutoff of the second transverse mode is at @xmath50 . the results are obtained using discretized spaces with 20 sites across a width of @xmath6 , and they are found to be in congruence with results from 10 sites within windows of @xmath51 on the horizontal axes , and windows of @xmath52 and @xmath53 \\simeq 0.005 $ ] on the vertical axes , which implies that the continuous space limit has been approached . since the l - bend and t - junction appear quite often in practical problems , it may be convenient to have their @xmath1-matrices in analytic forms . within a finite range of @xmath48 , it is possible to approximate a @xmath1-matrix by analytic functions . for the @xmath46 at @xmath54 , we may approximate the magnitudes and arguments of the elements by @xmath55 within @xmath54 , the approximation for @xmath56 in eq . ( [ sl11mag_approx ] ) and the approximation for @xmath57 in eq . ( [ sl11arg_approx ] ) approximate the numerical results in figs . [ smat](a ) and [ smat](b ) respectively up to @xmath58 and @xmath59 < 0.01 $ ] accuracy . the exact equalities eqs . ( [ sl12mag])-([sl_approx ] ) are due to the symmetry and unitarity of the @xmath1-matrix and the exchange of leads 1 and 2 .    for the @xmath47 at @xmath54 , it is found that the numerical results for the elements can be approximated by @xmath60 for @xmath54 , the above approximations for @xmath61 and @xmath62 approximate the results in figs . [ smat](c ) and [ smat](d ) respectively up to @xmath63 and @xmath64 < 0.01 $ ] accuracy . the exact equalities are due to the symmetry and unitarity of the @xmath1-matrix , and the exchange of leads 2 and 3 . in this section , three wave guides which are composites of the discussed l - bend and t - junction are analyzed . the scattering amplitudes from the original 2d structures and the reduced multiply - connected 1d structures are compared . cases of far apart and close discontinuities , different orientations of guides , and straight and smoothly curved guides are considered . the first example is a 2d square loop resonator with two leads as depicted in fig . [ loop1](a ) . the translational invariant sections have the same width @xmath6 . for simplicity , the distances between the discontinuities are chosen to be the same , and are denoted by @xmath65 as shown . in fig . [ loop1](b ) , a reduced version for the structure in fig . [ loop1](a ) is shown . the magnitude of the transmission scattering amplitude @xmath66 has been plotted versus @xmath48 for the unreduced and reduced systems , in figs . [ loop1](c ) and [ loop1](d ) , for @xmath67 and @xmath68 respectively . the @xmath69 for the 2d structure is the scattering amplitude from the first transverse mode in lead 2 to the first transverse mode in lead 1 , and the dimensionless wave number @xmath48 is now defined by @xmath49 or @xmath70 depending on the context . the procedure for a full - wave evaluation of @xmath66 for the 2d structure is standard @xcite and it is not to be repeated here , but only the result is given . the result here is obtained with a fd tise , and the number of sites across a width @xmath6 is equal to 20 .    in the reduced system shown in fig . [ loop1](b ) , a line labeled by @xmath7 and given a coordinate @xmath9 has a wave function in the form given in eq . ( [ psi_1d ] ) . for the coordinates defined in fig . [ loop1](b ) , the wave functions on the lines are connected by @xmath71 = \\left ( 1 - s _ { \\rm l } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_3 \\right| _ { x_3=d } \\\\ \\left . \\psi_4 \\right| _ { x_4=0 } \\end { array } \\right ] ,    \\label { node1 } \\\\ \\displaystyle { { 1 + s _ { \\rm l } } \\over { ik } } \\left [ \\begin { array } { c } \\left . ~ \\displaystyle { { d\\psi_4 } \\over { dx_4 } } \\right| _ { x_4=d }   \\\\ \\left . - \\displaystyle { { d\\psi_5 } \\over { dx_5 } } \\right| _ { x_5=0 }   \\end { array } \\right ] = \\left ( 1 - s _ { \\rm l } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_4 \\right| _ { x_4=d } \\\\ \\left . \\psi_5 \\right| _ { x_5=0 } \\end { array } \\right ] , \\label { node2 } \\\\ \\displaystyle { { 1 + s _ { \\rm t } } \\over { ik } } \\left [ \\begin { array } { c } \\left . - \\displaystyle { { d\\psi_3 } \\over { dx_3 } } \\right| _ { x_3=0 }   \\\\ \\left . ~ \\displaystyle { { d\\psi_1 } \\over { dx_1 } } \\right| _ { x_1=0 }   \\\\ \\left . ~ \\displaystyle { { d\\psi_6 } \\over { dx_6 } } \\right| _ { x_6=d }   \\end { array } \\right ] = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_3 \\right| _ { x_3=0 } \\\\ \\left . \\psi_1 \\right| _ { x_1=0 } \\\\ \\psi_6 \\right| _ { x_6=d } \\end { array } \\right ] ,   \\label { node3 } \\end{aligned}\\ ] ] and @xmath72 = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_5 \\right| _ { x_5=d } \\\\ \\left . \\psi_2 \\right| _ { x_2=0 } \\\\ \\left . \\psi_6 \\right| _ { x_6=0 } \\end { array } \\right ] . \\label { node4a}\\end{aligned}\\ ] ] this contains 10 equations with 10 unknowns , when @xmath73 and @xmath74 are given . the scattering amplitude @xmath69 is obtained as @xmath75 at @xmath76 and @xmath77 . the magnitude @xmath66 is plotted in figs .  [ loop1](c ) and [ loop1](d ) , for values of @xmath65 corresponding to the original 2d structure . in the calculation , @xmath46 and @xmath47 use the numerical values shown in fig . [ smat ] .    in the case of @xmath67 [ see fig . [ loop1](c ) ] , results from the original 2d and the reduced systems are nearly indistinguishable when seen in the size of the plot , while in the case of @xmath68 [ see fig .  [ loop1](d ) ] , the two results have a perceptible difference , especially when @xmath48 becomes large . a criterion for the applicability of the one - mode reduction scheme is @xmath78 , which means that the exponential tails of the evanescent waves for the higher transverse modes emanating from the discontinuities , is much shorter than the distances between the discontinuities . in this regime , the evanescent waves from neighboring discontinuities do not overlap each other , and the discontinuities communicate with each other only via the first transverse modes in the translational invariant sections . hence , the higher transverse modes in the sections are redundant , and a single - mode description is adequate . the length of an exponential tail of the second transverse mode is of the order of @xmath79 . the values of @xmath80 are approximately equal to 0.18 ( @xmath81 ) , 0.23 ( @xmath82 ) , 0.28 ( @xmath83 ) , 0.37 ( @xmath84 ) , 0.48 ( @xmath85 ) , 0.96 ( @xmath86 ) , and 1.56 ( @xmath87 ) , for the values of @xmath48 given in the brackets @xcite . it is seen that @xmath88 becomes large only when @xmath48 approaches @xmath89 . for @xmath67 , @xmath90 at @xmath83 , and that justifies the reduction scheme in the entire range of @xmath48 in fig . [ loop1](c ) [ and also fig . [ loop2](c ) later in this section ] . for @xmath68 , @xmath91 at @xmath92 , and @xmath93 is certainly not `` large '' for fig . [ loop1](d ) [ and also fig . [ loop2](d ) later in this section ] . in spite of this , the scheme might still perform up to certain precision , until it really starts to breakdown at @xmath94 as seen in fig . [ loop1](d ) [ see also fig .   [ loop2](d ) ] . however , its reliability in this regime of @xmath48 is uncontrolled in general . another 2d wave guide as shown in fig . [ loop2](a ) is also analyzed . this structure resembles the one in fig . [ loop1](a ) , except that one of the leads is rotated by 90-degree . the width of the uniform sections are also denoted by @xmath6 , and the distances between the discontinuities are also denoted by @xmath65 . a reduced structure for the guide is shown in fig . [ loop2](b ) , and the magnitude of the transmission scattering amplitude @xmath66 is also plotted for both of the reduced and unreduced structures in figs . [ loop2](c ) [ for @xmath67 ] and [ loop2](d ) [ for @xmath68 ] . the connecting equations for the reduced structure in fig . [ loop2](b ) are eqs . ( [ node1 ] ) , ( [ node2 ] ) , ( [ node3 ] ) , and @xmath97 = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_6 \\right| _ { x_6=0 } \\\\   \\left . \\psi_2 \\right| _ { x_2=0 } \\\\ \\left . \\psi_5 \\right| _ { x_5=d } \\end { array } \\right ] . \\label { node4b}\\end{aligned}\\ ] ] the transmission scattering amplitude @xmath69 is found as in the previous example . likewise , it is seen in fig . [ loop2](c ) that the reduction scheme is guaranteed to work in the @xmath78 regime . also , it is seen in fig . [ loop2](d ) that the scheme might still work qualitatively or semi - quantitatively , when @xmath48 is departed from this regime .    comparing the result in fig . [ loop1](c ) with that in fig . [ loop2](c ) , and the result in fig . [ loop1](d ) with that in fig . [ loop2](d ) , it is seen that scattering amplitudes can depend significantly on the orientations of the branch guides at a discontinuity . this indicates that reduction schemes with symmetric branch lines such as those in refs . @xcite are not adequate for some cases . the third example is a 2d annulus structure with an inner and an outer radii of @xmath98 and @xmath99 respectively , and two mutually perpendicular leads of width @xmath6 radially connected to the annulus as shown in fig . [ ring](a ) . figure [ ring](b ) shows a reduced version of it . for the 2d annulus , we may follow a mode - matching full - wave treatment formulated by xia and li @xcite . in the annulus the wave function @xmath100 can be expanded by radial and angular modes , @xmath101 , where a radial mode is given by @xmath102 , and @xmath103 . the @xmath104 and @xmath105 are the radial and angular coordinates respectively ; and the @xmath106 and @xmath107 are the bessel functions of the first and second kinds respectively . at the inner radius , @xmath108 for any @xmath105 ; at the outer radius , @xmath109 when @xmath105 is away from the leads , and @xmath110 , when @xmath105 is in the range of lead @xmath7 . in addition , the radial derivative @xmath111 is equated with the longitudinal derivative @xmath112 when @xmath100 and @xmath113 meet at the outer arc of the annulus . the difference between the straight transverse cuts of the leads and the outer arcs of the annulus is neglected . the wave functions in the leads and the annulus are hence matched , and one can get a set of equations relating the coefficients of the modes in the different regions . the transmission scattering amplitude @xmath66 for the 2d annulus is plotted for @xmath114 [ fig . [ ring](c ) ] and @xmath115 [ fig .  [ ring](d ) ] .    to apply a reduced calculation to the reduced system in fig . [ ring](b ) , note that for smoothly curved guides with small curvatures , the back - scattering is small and the guides can be treated as reflectionless for most purposes . guides with constant curvatures are translational invariant and indeed reflectionless , though the lengths and widths may not be rigorously defined . the junctions are treated as t - junctions . for the left junction , @xmath116 = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_1 \\right| _ { x_1=0 } \\\\ \\left . \\psi_3 \\right| _ { x_3=0 } \\\\ \\left . \\psi_4 \\right| _ { x_4=d_4 } \\end { array } \\right ] ; % \\label { } \\end{aligned}\\ ] ] for the right junction , @xmath117 = \\left ( 1 - s _ { \\rm t } \\right ) \\left [ \\begin { array } { c } \\left . \\psi_2 \\right| _ { x_2=0 } \\\\ \\left . \\psi_3 \\right| _ { x_3=d_3 } \\\\ \\left . \\psi_4 \\right| _ { x_4=0 } \\end { array } \\right ] . % \\label { } \\end{aligned}\\ ] ] we let @xmath118 , where @xmath119 and @xmath120 , and the subtraction is to approximately exclude the regions in the junctions [ see region d in fig .  [ discontinuities](b ) ] . the radius @xmath114 gives @xmath121 and @xmath122 , and @xmath115 gives @xmath123 and @xmath124 . results for @xmath66 are plotted in figs . [ ring](c ) and [ ring](d ) . if one analyzes the reduced system using the griffith scheme @xcite for a junction with three branches , the left junction has @xmath125 and the right junction has @xmath126 note that the equations at a junction are symmetric with respect to an interchange of any two branches . using the same @xmath127 and @xmath128 , results for @xmath66 are also plotted in figs . [ ring](c ) and [ ring](d ) . comparing the results from our scheme and the griffith scheme with the result from the 2d calculation , it is seen that the griffith result is qualitatively different from the 2d result in general , while our scheme captures the essential features in the 2d result , especially in the case of longer guide sections [ fig .  [ ring](c ) ] . the lengths of the guide sections in fig . [ ring ] are about the sizes of those in figs . [ loop1 ] and [ loop2 ] , but the disagreement between the 2d and reduced calculation results are seen to be more severe in fig . [ ring ] , especially in the case of short guide sections [ fig . [ ring](d ) ] . this is mainly due to vaguer notions of the lengths and widths of the guide sections between the discontinuities , and a stronger distortion of the shapes of the junctions from a `` t '' [ fig . [ discontinuities](b ) ] , when the guide sections are curved and short , in addition to a violation of the criterion @xmath129 . comparing figs . [ ring](c ) and [ ring](d ) , it is also seen that our scheme performs better when the discontinuities are more apart . this study has shown that the higher transverse modes in the uniform - cross - sectional sections in wave guides can give only a minor effect on the low - energy properties of the guides . a scheme to remove these modes and a criterion for the energy range ( @xmath78 ) in which the scheme applies have been proposed . in the scheme , a reduced system and its corresponding system in a realistic space have a sound relationship , and therefore the scheme may find more practical use in the analyses of realistic wave guides than previously reported schemes @xcite . the electronic spin degrees of freedom may also be included into the scheme by expanding the current one - mode @xmath1-matrices to two - mode @xmath1-matrices , for the up and down spin channels , and in the same way as in sec . [ examples ] , the two - mode @xmath1-matrices are calibrated by full - wave calculations for systems in realistic spaces . likewise , the precision of the scheme at short guide sections can also be refined by including more transverse modes and using multi - mode @xmath1-matrices . k. ruedenberg and c. w. scherr , j. chem . phys . * 21 * , 1565 ( 1953 ) . p. exner and p. seba , rep . * 28 * , 7 ( 1989 ) . t. kottos and u. smilansky , ann . of phys . * 274 * , 76 ( 1999 ) . xia , phys . rev . b * 45 * , 3593 ( 1992 ) . j. m. mao , y. huang , and j. m. zhou , j. appl . * 73 * , 1853 ( 1993 ) . p. singha deo and a. m. jayannavar , phys . b * 50*,11629 ( 1994 ) . m. v. moskalets , low temp . * 23 * , 824 ( 1997 ) . ryu and s. y. cho , phys . b * 58 * , 3572 ( 1998 ) . s. bandopadhyay , p. singha deo , and a. m. jayannavar , phys b * 70 * , 75315 ( 2004 ) . d. bercioux , m. governale , v. cataudella , and v. m. ramaglia , phys . * 93 * , 56802 ( 2004 ) . p. foldi , b. molnar , m. g. benedict , and f. m. peeters , phys . b * 71 * , 33309 ( 2005 ) . u. aeberhand , k. wakabayashi , and m. sigrist , phys . b * 72 * , 75328 ( 2005 ) . x. f. wang and p. vasilopoulos , phys . b * 72 * , 165336 ( 2005 ) . o. kalman , p. foldi , m. g. benedict , and f. m. peeters , arxiv:0806.2734 ( unpublished ) .", "tags": [], "output_text_a": "This paper addresses the challenge of simplifying wave propagation analysis in quasi-one-dimensional (q1D) waveguides with discontinuities, such as bends and junctions, where higher transverse modes become significant. Traditionally, a full-wave analysis is required, which is computationally intensive and obscures the physics. The authors propose a scheme to reduce computational redundancy while preserving low-energy properties. This involves using a truncated scattering matrix that only considers the first transverse modes, effectively connecting one-dimensional wave functions in reduced systems. The paper reviews historical approaches, including the Griffith boundary condition and Shapiro's scheme, and highlights their limitations in realistic q1D guides. The proposed method is tested on structures like L-bends and T-junctions, showing that it captures essential low-energy transport properties. The study also suggests that the scheme can be extended to include electronic spin degrees of freedom and refined for short guide sections by incorporating more transverse modes. The results indicate that the scheme is more practical for analyzing realistic waveguides compared to previous methods.", "output_text_b": "This paper presents a scheme to simplify calculations for wave propagation in quasi-one-dimensional waveguides with discontinuities, such as bends and branching junctions. The scheme aims to preserve low-energy properties faithfully while reducing redundancies and obscuring physics in full-mode or full-wave analysis. The authors propose a method that resembles the Griffith boundary condition but includes an extra phenomenological term with a tuning parameter. This scheme significantly improves the capture of many low-energy transport properties.\n\nThe paper derives connecting equations for two typical component structures, the L-bend and the T-junction, and assembles them into more elaborate structures. The wave propagation in these structures is studied and compared between reduced and unreduced systems.\n\nThe proposed scheme can be summarized as follows:\n\n1. Evaluate the scattering matrix using a full-wave treatment for a particular discontinuity.\n2. Truncate the matrix, leaving only elements relating the first transverse modes in the branch guides.\n3. Use the truncated matrix to connect 1D wave functions in reduced systems.\n\nThe paper also discusses the relationship between reduced and unreduced systems, which is often not addressed in other schemes, hindering the application to realistic systems.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions by discussing the proposed scheme for simplifying wave propagation analysis in q1D waveguides and its advantages over previous methods.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of simplifying wave propagation analysis in q1D waveguides with discontinuities.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the methodology of using a truncated scattering matrix to connect one-dimensional wave functions.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the scheme capturing essential low-energy transport properties and its potential extension to electronic spin degrees of freedom.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"truncated scattering matrix.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear beginning, middle, and end.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by stating its practicality for analyzing realistic waveguides compared to previous methods.", "1. **Accurate Reflection of Main Findings and Contributions**: The summary accurately reflects the main findings and contributions of the paper by describing the proposed scheme to simplify calculations for wave propagation in quasi-one-dimensional waveguides with discontinuities.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of simplifying calculations in waveguides with discontinuities while preserving low-energy properties.\n\n4. **Methodology or Approach**: The summary mentions the methodology of using a scheme that resembles the Griffith boundary condition with an extra phenomenological term and describes the process of evaluating and truncating the scattering matrix.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the improvement in capturing low-energy transport properties and the relationship between reduced and unreduced systems.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"scattering matrix\" and \"transverse modes.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Mention of Key Experiments or Data**: The summary does not mention specific experiments or data used in the research, which is a requirement.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance by discussing its potential impact on simplifying waveguide analysis."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "giving a talk on three dimensional ( 3d ) gravity at a meeting in cracow is like carrying coal to newcastle : the beginnings of the subject are usually traced back to the paper @xcite by andrzej staruszkiewicz , alumnus and later professor at the jagellonian university in cracow . staruszkiewicz s paper , published in 1963 , is about classical 3d gravity and its special features . the subject of 3d _ quantum _ gravity started only five years later with the realisation by ponzano and regge @xcite that angular momentum theory plays an important role in this context . gravity in 3d is now a large subject in its own right , which i can not possibly review here . however , in this introductory part of the talk i will at least attempt to identify a few of the main themes and relate them to the approach followed here . influential papers by deser , t hooft and jackiw written in the 1980s @xcite on classical and quantum scattering of particles demonstrated the possibility of carrying out non - perturbative calculations of quantum scattering processes in 3d gravity . as we shall see , they also contain indications of the relevance of the braid group in describing such processes . these indications are elaborated in the later literature , see for example @xcite , and turn out to be closely related to the quantum group approach pursued in this talk . the chern - simons formulation of 3d gravity , observed in @xcite and elaborated in @xcite , establishes a connection between 3d gravity and a host of areas in mathematical physics , including topological field theory , knot theory , the theory of poisson - lie groups and of quantum groups . since this talk is based on the chern - simons approach , we will see many of these connections . the early paper by ponzano and regge , mentioned above , provides the foundation of the spin foam approach to 3d quantum gravity . this is perhaps the approach to 3d quantum gravity that contains the most directly useful lessons for 4d quantum gravity . i will not discuss this approach in this talk , and shall not attempt to summarise the large literature on it . however , it is worth pointing out that there are close links with chern - simons theory ( spin foam state sums may be viewed as discretisation of the path integral ) and to quantum groups , see @xcite for an early paper and @xcite for examples of recent papers with many references .    the possibility that non - commutative geometry is needed to describe spacetime at the quantum level has long been a theme in quantum gravity research @xcite , see @xcite for a recent discussion with some references . it is therefore interesting to ask if one can use the relatively tractable 3d situation to establish the role of non - commutative geometry in quantum gravity in a mathematically convincing way . early discussions of non - commutative spacetime coordinates appear in the paper @xcite . spacetime non - commutativity in 3d quantum gravity is studied , in different approaches , in @xcite . putting these approaches into one coherent picture is one of the objectives of this talk . finally , i should mention two further important themes of 3d gravity research which i will not be able to touch on in this talk . one is the study of btz black holes , an introduction to which can be found in the book @xcite . the other is the relation to 3d hyperbolic geometry , where the papers and books @xcite may provide good starting points . the einstein field equations ( without cosmological constant and in units where the speed of light is 1 ) @xmath3    determine the ricci tensor of a spacetime in terms of the energy momentum tensor . in spacetime dimensions greater than three , the ricci tensor does not fix the riemann tensor and it is possible to have metrically non - trivial ( i.e. curved ) spacetimes satisfying the vacuum ( @xmath4 ) field equations . in three spacetime dimensions , this is not possible . the ricci tensor determines the riemann tensor and , as a result , the only vacuum solutions of the einstein equations with vanishing cosmological constant are flat @xcite . this result simplifies einstein s theory of gravity in 3d dramatically , but does not render it trivial . there are non - trivial solutions of the einstein equations in the presence of matter , and , if the topology of the three - dimensional manifold representing the universe is non - trivial , there may be vacuum solutions which , though flat , have non - trivial holonomy . these observations are often summarised in the slogan that in 3d gravity there are no gravitational waves but that the theory has topological degrees of freedom .    the simplest solution of the einstein equations illustrating the previous paragraph is the spacetime surrounding a point - particle . the energy - momentum tensor is a dirac delta - function with support on the world line of the particle.the metric solving the field equations is flat away from the world line and is singular on the world line . more precisely it is a direct product of a cone ( space ) and @xmath5 ( representing time ) @xcite . the line element , in terms of polar coordinates @xmath6 , with @xmath7 , and a time coordinate @xmath8 is simply [ pointsolution ] ds^2 = c^2dt^2 -dr^2 - r^2 d^2 . however , the range of @xmath9 is @xmath10 , where the parameter @xmath11 is related to the particle s mass @xmath12 and to newton s constant @xmath13 via @xmath14 in three dimensions , the physical dimension of @xmath13 is that of an inverse mass so that @xmath11 is a dimensionless , angular parameter . the effect of a particle on the geometry of spacetimes is , then , to cut out a wedge of size @xmath11 from the spacetime surrounding the particle s world line . it is instructive to consider the effect of the geometry on light test particles . such particles travel on geodesics , which are simply straight lines on the cone after it has been cut open . it is easy to check that geodesics passing the particle of mass @xmath12 on one side are deflecting relative to particles who pass it on the other side by the angle @xmath11 ( in the coordinate system @xmath15 ) . this relative deflection is illustrated in fig . [ conedeflection ] and is independent of the distance of closest approach between the heavy particle of mass @xmath12 and the test particles ( impact parameter ) . the interaction is topological in the sense that it only depends on whether the test particle passes on the left or the right of the heavy particle , and not on the relative distance . this kind of interaction is familiar from the aharonov - bohm interaction between electrons and a magnetic flux , and this analogy can be made precise : both interactions can be related to the braiding of the world lines of the interacting particles @xcite .    ] the four physical constant entering 3d quantum gravity are the speed of light @xmath1 , newton s constant @xmath13 , planck s constant @xmath16 and the cosmological constant @xmath2 . from these , we can form two length constants ( remembering that the dimension of @xmath13 is an inverse mass ) , namely [ constants ] _ p= , _ c = . in this talk we will deal with both lorentzian and euclidean gravity , and we parametrise euclidean and lorentzian metrics in a unified fashion by allowing @xmath17 in the euclidean situation . as a result , both the length parameters in may be imaginary , depending on the sign of @xmath18 and @xmath2 . from the ratio of the two length parameters we can form a dimensionless quantity . we define the deformation parameter [ qpara ] q= e^- , which may take values on the real line or the unit circle in the complex plane . it is useful to clarify the role played by the various constants in 3d gravity in general terms at this stage . the observation of the previous section that , in the absence of matter , solutions of the einstein equations are locally flat generalises in the presence of a cosmological constant to the statement that vacuum solutions are locally isometric to model space times , which depend on the parameters @xmath1 and @xmath2 . for lorentzian gravity with vanishing cosmological constant , for example , the model spacetime is minkowski space while for euclidean gravity with positive cosmological constant it is the four - sphere with the round metric . the isometry groups of the model spacetimes inherit a dependence on @xmath1 and @xmath2 . in the examples above they are , respectively , the poincar group in 3d and the 4d rotation group @xmath19 . constant @xmath13 enters when one studies the dynamics of spacetime and plays the role of a parameter in the poisson structure and that of a coupling constant to matter . finally , @xmath16 enters in the quantisation and the dimensionless parameter @xmath20 in , combining all four constant , controls the quantum theory when all the constants @xmath21 are non - zero . the goal of this talk is give a unified account of aspects of classical and quantum gravity in 3d , in which the physical parameters of the previous section enter as deformation parameters . our account of classical gravity is based on the formulation of 3d gravity as a chern - simons gauge theory , where the local isometry groups play the role of the gauge groups . as well shall see , the parameters @xmath1 and @xmath2 enter in this description via the structure constants of the lie algebra of the gauge group , while the parameter @xmath13 enters via the inner product ( or trace ) on the lie algebra which is used in the chern - simons action . we sketch the description of the phase space of 3d gravity as the moduli space of flat connections , and review the description of its poisson structure in a formulation , due to fock and rosly @xcite , which makes essential use of classical @xmath22-matrices . the description of the poisson structure in terms of @xmath22-matrices is tailor - made for the quantisation via the combinatorial or hamiltonian scheme pioneered in @xcite , @xcite and @xcite . in this scheme , the quantisation is controlled by quantum groups which are deformations of the local isometry groups of the model spacetimes , with deformation parameters @xmath13 and @xmath16 in addition to @xmath1 and @xmath2 . these quantum groups naturally act on non - commutative spaces , which one may interpret as deformations of the classical model spacetimes . this framework thus provides a concrete mathematical setting for exploring the proposal that , in quantum gravity , spacetime should be mathematically modelled in terms of non - commutative geometry . we end our talk with an evaluation of the successes and limitations of this approach to 3d quantum gravity . the following treatment of the model spacetimes follows closely that in @xcite . we use roman letters @xmath23 for 3d spacetimes indices , with range for @xmath24 ( in both the euclidean and lorentzian case ) . the model spacetimes arising in 3d gravity can be described in a simple an unified fashion in terms of the metric [ 4dmetric ] g_=(-c^2,1,1,1 ) in an auxiliary @xmath25 . here we use greek indices for the range @xmath26 . the model spacetimes can be realised as embedded hypersurfaces via [ hypersur ] h_c,= \\{(t , x , y , w)^4| -c^2t^2 + x^2 + y^2 + w^2 = } . this two - parameter family includes the three - sphere @xmath27 ( @xmath17 , @xmath28 ) , doubles covers of hyperbolic space @xmath29 ( @xmath30 , @xmath31 ) , de sitter space ds@xmath32 ( @xmath33 , @xmath28 ) and anti - de sitter space ads@xmath32 ( @xmath33 , @xmath31 ) . double covers of euclidean space @xmath34 and minkowski @xmath35 space arise in the limit @xmath36 , which one should take _ after _ multiplying the defining equation in by @xmath2 . in fig .  [ modelspaces ] we show the embedded model spacetimes ( with one spatial dimension suppressed ) .     according to ( the second spatial coordinate @xmath37 is suppressed ) . euclidean and minkowski space at the top , spherical and de sitter space in the middle , hyperbolic and anti - de sitter space at the bottom , title=\"fig : \" ] +   according to ( the second spatial coordinate @xmath37 is suppressed ) . euclidean and minkowski space at the top , spherical and de sitter space in the middle , hyperbolic and anti - de sitter space at the bottom , title=\"fig : \" ]   according to ( the second spatial coordinate @xmath37 is suppressed ) . euclidean and minkowski space at the top , spherical and de sitter space in the middle , hyperbolic and anti - de sitter space at the bottom , title=\"fig : \" ] +   according to ( the second spatial coordinate @xmath37 is suppressed ) . euclidean and minkowski space at the top , spherical and de sitter space in the middle , hyperbolic and anti - de sitter space at the bottom , title=\"fig : \" ]   according to ( the second spatial coordinate @xmath37 is suppressed ) . euclidean and minkowski space at the top , spherical and de sitter space in the middle , hyperbolic and anti - de sitter space at the bottom , title=\"fig : \" ]    in order to be able to take the limit @xmath38 for the associated isometry groups it is best to work with the inverse metric [ invmet ] g^=(-,1,1 , ) . the lie algebra generators of the isometry groups of can conveniently be defined in terms of the clifford algebra associated to @xcite . thus we define generators @xmath39 via \\{^,^}=-2g^ , so that the six lie algebra generators are given by m^=1 4 [ ^,^ ] . they have the commutation relations [ masterlie ] [ m^ , m^ ] = g^ m^ + g^ m^- g^ m^-g^ m^. the advantage of the clifford algebra approach is that one can immediately write down two naturally defined invariant bilinear forms . one , denoted @xmath40 is defined by carrying out the clifford multiplication and projecting onto the invariant , central element @xmath41 . multplying by @xmath42 for later convenience , the resulting inner product is non - zero whenever the indices on the basis vectors are complementary , for example @xmath43 another bilinear form @xmath44 is obtained by carrying out the clifford multiplication and projecting onto the identity . again rescaling by @xmath42 for convenience we have a non - zero answer whenever the indices on the basis vectors match : @xmath45 as we shall see shortly , this is the killing form on the lie algebra    we now express the above generators in more conventional 3d notation . for this purpose we define the three - dimensional totally antisymmetric tensor with downstairs indices via @xmath46 . then we define the rotation generator @xmath47 , the boost generators @xmath48 and translation generators @xmath49 via [ liegens ] _ abcm^bc,_a = g_abm^b3 , where we used the spacetime part of the 4d metric @xmath50 to lower indices , and refer to @xcite for a discussion of physical dimensions and interpretation of these generators ( which are denoted by the same letters , but without tilde there ) . the lie algebra brackets are now [ t21alg ] [ _ a,_b]=_abcj^c , = _ abc ^ c ,=- c^2 _ abc^c , with indices raised via the inverse metric @xmath51 . the combination @xmath52 which occurs in the lie brackets plays an important role in what follows , and we introduce [ algebraicconstant ] = -c^2 . the bilinear form @xmath44 , already advertised as the killing form , is [ nongravin ] ( _ a,_b)=_ab,(_a,_b)=_ab , where _ g_ab = ( 1 , - , - ) . the metric @xmath53 is the most natural one on the lie algebra @xmath54 respectively @xmath55 spanned by @xmath56 and @xmath57 . note that it differs from the spacetime metric @xmath58 , but that it has the right physical dimensions and that imaginary @xmath1 gives the usual euclidean metric , as required . it is one of the coincidences of 3d that spacetime and the lie algebra of rotations and/or boosts are both three - dimensional . both are equipped with euclidean respectively lorentzian metrics , but our derivation shows that , in a physically natural normalisation and construction , the spacetime and lie algebra metrics come out differently . this is potentially confusing in calculations where indices are raised and contracted with these metrics , and most papers on 3d gravity use conventions where the two kinds of metrics coincide . we can achieve this by switching from the physical lie algebra basis used thus far to a geometrical basis according to @xmath59 in this geometrical basis , all the generators @xmath60 are dimensionless , and all the translation generators @xmath61 have the dimension of inverse time . one checks that the killing metric now takes the form [ 3dmetric ] ( j_a , j_b)= _ ab:=(1,- , - ) , which is diag@xmath62 in the euclidean and diag@xmath63 in the lorentzian case . moreover , the lie brackets take the _ same _ form as in , [ 21alg ] [ j_a , j_b]=_abcj^c , = _ abc p^ c,= _ abcj^c , but all indices are now raised with the lie algebra metric @xmath64 . this is convenient and we shall work in this basis for the remainder of this talk . we denote the lie algebra with these brackets by @xmath65 . the conventions regarding the metric then agree with @xcite , but the convention regarding the naming of @xmath66 agrees with @xcite and differs from @xcite , where @xmath2 was used for what we call @xmath66 now . conventions regarding the naming of the cosmological constant and the combination differ in the literature , and the reader will need to take good care when comparing results from different sources . the other bilinear form introduced in the clifford language gives the following non - zero pairings [ 3dgravin ] j_a , p_b = c^2_ab . this pairing is non - degenerate for any value of @xmath66 and is crucial for the chern - simons formulation of 3d gravity , as we shall see .    in table [ isogroups ] we list lie groups whose lie algebras are . we have used the isomorphisms @xmath67 and @xmath68 , the identity component of @xmath69 . the isometry groups are determined by their lie algebras only up to coverings , and our choice in table  [ isogroups ] is one of convenience . in the following , we write @xmath70 for this family of lie groups . .local isometry groups in 3d gravity [ cols=\"^,^,^ \" , ] we have seen that the combinatorial quantisation of the chern - simons formulation of 3d gravity gives a unified picture of the various regimes of 3d gravity , with the physical parameters @xmath71 and @xmath16 entering as deformation parameters in distinctive ways . quantum groups naturally replace the classical isometry groups in this approach to 3d quantum gravity , and non - commutative spacetimes replace the classical model spacetimes . in general , the relation between the quantum isometry groups and the physical hilbert space of 3d quantum gravity is a formal one , but we have seen that aspects of the quantum isometry groups like the non - commutative momentum addition and the braiding via the quantum @xmath72-matrix have a direct physical interpretation . it is worth noting that it is possible to take a galilean limit @xmath73 in the framework discussed here @xcite , and that the non - commutative quantum space is the moyal plane in that case , with a time - dependent non - commutativity of the spatial coordinates .    in order to clarify the physical interpretation of quantum isometry groups and the associated non - commutative spacetimes it may be useful to consider universes with a boundary instead of the spatially compact universes considered in this talk . the treatment of boundaries in the classical theory is discussed in @xcite but a general treatment of the quantisation has not been given . another approach would be to work directly on the physical phase space as in @xcite , and to attempt the quantisation there . other quantum groups than quantum doubles have been discussed in relation to 3d quantum gravity , notably bicrossproducts or @xmath74-poincar algebras which were originally introduce in 4d @xcite . as shown in @xcite , the @xmath74-poincar algebra with the usual time - like deformation parameter is _ not _ compatible with 3d gravity in the combinatorial framework . on the other hand , @xmath74-poincar algebras with space - like deformation parameters are possible . this and other quantisation ambiguities of 3d quantum gravity are discussed in the forthcoming paper @xcite . g.  ponzano and t.  regge , semiclassical limit of racah coefficients , in spectroscopic and group theoretical methods in physics , ed . f.  bloch , s.  g.  cohen , a.  de - shalit , s.  sambursky and i.  talmi , north holland , amsterdam , 1968 .                                g.  t hooft , quantisation of point particles in 2 + 1 dimensional gravity and space - time discreteness , class .  quant . grav .  13 ( 1996 ) 1023 - 1039 . h.  j.  matschull and m.  welling , quantum mechanics of a point particle in ( 2 + 1)-dimensional gravity , class . grav .  15 ( 1998 ) 29813030 . l.  freidel and e.  r.  livine , effective 3d quantum gravity and non - commutative quantum field theory . 96 ( 2006 ) 221301 . e.  joung , j.  mourad , and k.  noui , three dimensional quantum geometry and deformed symmetry j.  math . 50 ( 2009 ) 052503 . l.  andersson , t.  barbot , r.  benedetti , f.  bonsante , w.  m.  goldman , f.  labourie , k.  p.  scannell and j.  -m . schlenker , notes on a paper of mess , geometriae dedicata 126 ( 2007 ) , 4770 , see also arxiv:0706.0640 . r.  benedetti and f.  bonsante , canonical wick rotations in 3-dimensional gravity , memoirs of the american mathematical society , volume 198 ( 2009 ) number 926 , see also e - print : math/0508485 [ math - dg ] and e - print : math/0412470 [ math - dg ] . schaller and t.  strobl , diffeomorphisms versus non abelian gauge transformations : an example of ( 1 + 1)-dimensional gravity , phys . b337 ( 1994 ) 266270 . h.  -j . matschull , on the relation between ( 2 + 1 ) einstein gravity and chern - simons theory , class . 16 ( 1999 ) 25992609 . b.  j.  schroers , lessons from ( 2 + 1)-dimensional quantum gravity , proceedings pos ( qg - ph ) 035 for workshop  from quantum to emergent gravity : theory and phenomenology  , trieste 2007 ; see also arxiv:0710.5844 [ gr - qc ] . b.  j.  schroers , combinatorial quantisation of euclidean gravity in three dimensions , in : n.  p.  landsman , m.  pflaum , m.  schlichenmaier ( eds . ) , quantization of singular symplectic quotients , birkhuser , in : progress in mathematics , vol .  198 , 2001 , 307328 ; math.qa/0006228 .", "tags": [], "output_text_a": "The paper discusses the development and key themes of three-dimensional (3D) gravity, tracing its origins to Andrzej Staruszkiewicz's 1963 work on classical 3D gravity. The quantum aspect of 3D gravity began with Ponzano and Regge's realization of the importance of angular momentum theory. The paper highlights influential contributions by Deser, 't Hooft, and Jackiw in the 1980s, which demonstrated non-perturbative calculations in 3D gravity and hinted at the relevance of the braid group. The Chern-Simons formulation of 3D gravity connects it to various areas in mathematical physics, including topological field theory and quantum groups. The paper also touches on the spin foam approach, non-commutative geometry, and the study of BTZ black holes and 3D hyperbolic geometry. It emphasizes the simplification of Einstein's theory in 3D, where vacuum solutions are flat but can have non-trivial holonomy due to topological degrees of freedom. The paper further explores the role of physical constants in 3D gravity, the formulation of 3D gravity as a Chern-Simons gauge theory, and the quantization of 3D gravity using quantum groups. It concludes by evaluating the successes and limitations of this approach and suggests further exploration of quantum isometry groups and non-commutative spacetimes. The paper provides a comprehensive overview of the theoretical framework and mathematical structures underlying 3D gravity research.", "output_text_b": "This article discusses three-dimensional (3D) gravity, which started with Staruszkiewicz's paper on classical 3D gravity in 1963. The subject of quantum 3D gravity began in 1968 with the work of Ponzano and Regge, who discovered the role of angular momentum theory in this context. The article highlights the main themes in 3D gravity research, including non-perturbative calculations of quantum scattering processes and the relevance of the braid group and quantum groups. The authors also discuss the Chern-Simons formulation of 3D gravity, which connects it to topological field theory, knot theory, and the theory of Poisson-Lie groups and quantum groups. The early paper by Ponzano and Regge is the foundation of the spin foam approach to 3D quantum gravity, which has close links with Chern-Simons theory and quantum groups. The authors aim to explore the role of non-commutative geometry in quantum gravity using the relatively tractable 3D situation.", "score": 0.29999999999999993, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main themes and contributions of the paper, such as the development of 3D gravity, the Chern-Simons formulation, and the role of quantum groups.\n\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly state the research problem or question addressed by the paper.\n\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the Chern-Simons formulation and the use of quantum groups, which are part of the methodology.\n\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary mentions the simplification of Einstein's theory in 3D and the exploration of quantum isometry groups, but it does not clearly state specific results or conclusions.\n\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"Chern-Simons formulation\" and \"quantum groups\" without explanation, which may not be accessible to all readers.\n\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any key experiments or data, as the paper seems to be theoretical.\n\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the significance of the paper by mentioning its comprehensive overview and potential impact on understanding 3D gravity.", "1. **Accurate Reflection**: The summary captures the main themes of the paper, such as the historical context of 3D gravity, the role of quantum groups, and the Chern-Simons formulation. However, it does not mention the specific findings or contributions of the paper, such as the unified account of classical and quantum gravity in 3D or the exploration of non-commutative geometry.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary does not clearly state the research problem or question addressed by the paper.\n4. **Methodology**: The summary mentions the Chern-Simons formulation and the role of quantum groups but does not detail the methodology or approach used in the paper.\n5. **Significant Results**: The summary lacks specific results or conclusions drawn by the authors.\n6. **Language**: The language is clear and professional.\n7. **Technical Jargon**: The summary uses terms like \"Chern-Simons formulation\" and \"quantum groups\" without explanation, which may not be clear to all readers.\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary does not reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [false, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [false, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "a continuous water jet falling gently downward through a tap and its subsequent breakup into discontinuous drops is an everyday - witnessed common phenomenon . there have been many attempts theoretically as well as experimentally to understand the physical mechanism behind the breaking up of jets into drops instead of continuing to keep reducing its cross - sectional area forever . however , the complete understanding of this macroscopic phenomenon has eluded so far . the scientific study of this phenomenon has a long history . savart ( 1833 ) experimentally observed the instability of liquid jets that clearly indicated that the liquid column ( jet ) undergoes changes before breaking up into disjoint droplets . savart s experimental observations suggested that the liquid column develops necks and bulges in the form of waves which ultimately leads to the formation of disjoint droplets out of the continuous column . this problem of instability of liquid jets was taken up by plateau and then by rayleigh ( 1879 ) and developed a theory which came to be known as plateau - rayleigh theory . rayleigh@xcite showed that perturbations of wavelengths larger than a certain value ( larger than the jet diameter ) grow rapidly with time which ultimately make the column unstable ( rayleigh instability ) against formation of droplets based on surface energy considerations of inviscid liquids . chandrasekhar@xcite later extended the theory to viscous liquids . many experimental investigations have been conducted to examine the validity of plateau - rayleigh theory@xcite . the investigations on the instability of water jet and related phenomena have been extensively reviewed@xcite . the study continues to be of current interest@xcite . the plateau - rayleigh theory , describes how the response of perturbations of certain wavelengths keep growing with time whereas those with lower wavelengths decay with time . it is the fastest growing perturbation that utimately breaks the jet . however , the theory is silent about the origin of the perturbations . the experiment of goedde and yuen , for example , applied external perturbations to study the length of the liquid jet ( measured from the root of the jet ) before it breaks up . however , even if no external perturbations are applied , one obtains a finite deterministic length of the liquid jet . in this case , obviously , the perturbation must have an origin at the root of the jet at the mouth of the nozzle , through which the liquid flows out to form the jet . naturally , the perturbations will have amplitudes of random sizes . as a consequence , the length of the jet should have random values . however , on the average , the length turns out to be a deterministically fixed number depending on the conditions of the experiment . in some recent works , in order to overcome this difficulty of fixing the origin of the perturbations , umemura and co - workers@xcite emphasized the idea that the perturbations get generated and sustained self - consistently . this is based on the observed fact that soon after the jet breaks up ( at one of the points on the lowermost neck ) the tip of the remaining column contracts to make its shape round once again to minimize the surface energy . the tip contraction gives rise to an upstream propagating capillary wave which upon reflection at the mouth of the nozzle moves downstream with doppler modified wavelengths . some of these waves with the right wavelength ( as discussed by rayleigh ) cause the liquid column to break producing another contraction of the tip of the column and the process repeats once again . we set up and conduct an experiment to verify the existence and effect of recoil capillary waves on the length of continuous water jet . this we accomplish by damping the recoil capillary wave using an earlier used method@xcite . the experimental set up ( figs.1,2 ) consists of two water tanks , the first one ( tank 1 ) is placed at a lower height to maintain the constant level of water ( i.e. , to keep same pressure throughout the experiment ) and the second one ( tank 2 ) is placed at a higher height to supply water at a constant rate to the tank 2 . both of these tanks are fitted with one tap each . the tap of the tank 2 is connected to the inlet of tank 1 by a rubber pipe . a glass nozzle is connected to a tap of the tank 1 by a rubber pipe through a flow control valve , which permits us to control the flow rate of water . the excess water in the tank 1 flows out through the level outlet to the lower reservoir tank ( tank 3 ) ( this tank is kept at the bottom level ) . the water from the tank 3 is pumped up to the tank 2 by using a water pump . a transparent rectangular beaker with a level outlet on one of its vertical sides is placed vertically below the nozzle so that the water jet falls directly on the water kept in the beaker . the water level in the beaker is maintained fixed by letting the excess water flow out through the level outlet of the beaker . the beaker is placed on a horizontal platform fitted to a travelling microscope so that the beaker can be smoothly moved vertically up and down and its position measured . a laser - pointer - and - detector arrangement is also fitted to the platform so that the horizontal laser beam incident normally on the vertical surface of the beaker and passes through the path of the water jet and then through the opposite surface of the beaker before it is collected by the detector . the laser - detector arrangement can be moved vertically and fixed as desired and the vertical position of the horizontal laser beam measured . a six digit counter mounted with a 24-hour clock is connected to the detector to count the number of drops and also to pin - point the first initial breaking point of the jet . our experimental set up is similar in essentials to that of goedde and yuen ( compare fig.1 of ref.@xcite ) . the ambient condition of temperature and humidity is controlled and allowed to settle down at desired values before the experiment is conducted and the condition is kept fixed throughout the duration of experiment . the water is issued ( jetted ) vertically downward through a long glass nozzle ( of length larger than about ten times its internal diameter , @xmath0 ) in to the water in the beaker through the stagnant ambient air atmosphere . as long as the jet remains continuous the detector remains quiescent . however , a breakup into a drop ( disjoint of the jet ) is detected as a count . the vertical distance between the nozzle exit and the laser beam gives the breakup length . initially , the laser beam is made to face the continuous jet by moving the platform up and then the platform is gradually lowered so that the beam position distance from the nozzle exit increases . at every position of the laser - detector arrangement the counts are recorded for two minutes for several times and their average calculated to obtain the average number of drop - counts per second . the platform is slowly and gradually lowered by small steps and at each position the experiment is repeated to obtain the average count rate . naturally , the count rate begins from zero , reaches a threshold at which the rate just begins to show nonzero value and then gradually keeps increasing as the platform is slowly lowered in small steps . the process continued till the rate reaches a maximum ( saturation ) value . throughout the above process the water flow rate is kept fixed . the same process is then repeated for several values of flow rates . note that after each change of flow rate the flow and the jet is allowed to become steady before the measurement process is begun .    for our purpose , we perform two distinct kinds ( sets ) of experiments . in one we let the laser beam pass grazing the water level in the beaker ( just about 0.2 cm above the water surface on the beaker ) . in the other the beam is kept at a height of about 1.5 cm above the water surface . in the first set of experiments , if the point of separation between a drop and the tip of the remaining jet is such that before the moving tip recoils it just touches the water surface , the process of jet - tip recoil is prevented and thus the recoil capillary wave propagating up the jet length is damped whereas in the other set of experiments this situation never occurs . the experiment is performed in an enclosure where the air current is minimized and , as stated earlier , the temperature and humidity are kept fixed for all sets of measurements . thus , the enclosure inside the lab is made sure to be stagnant and the external disturbance on the jet is minimized . ) as a function of distance of the laser beam from the nozzle exit at the flow rate of 55.5 cc / min and @xmath1 mm for the two sets of experiments ( laser beam close to the water surface and far from the surface . the inset shows a magnified graph to show the first ( jet ) breakup point.,width=377,height=264 ]    ) as a function of distance of the laser beam from the nozzle exit ( same as fig.3 but only for the set close to the surface ) . it also shows the corresponding unnormalized breakup length distribution.,width=377,height=264 ]    figure 3 shows the average number of counts ( drops ) per second , for a water flow rate of 55.5 cc / min and the nozzle inner diameter of 1.71 mm , as the vertical distance of the laser beam from the lower tip of the nozzle is increased . each point on the graph corresponds to an average of three set of counts for a duration of two minutes each . the counts begin from zero ( indicating continuous jet ) to a saturation value ( indicating the finality of the breakup process ) . from this data we calculate the distribution , @xmath2 , of breakup lengths . the probabilty density of breakup lengths is roughly calculated as the derivative of the count rate with respect to breakup length , fig . 4 . in fig.4 the distribution @xmath2 is not normalized . the normalized distribution @xmath3 will be obtained as @xmath4 . the distribution provides information about the mean value of breakup lengths . the mean values are plotted in fig.5 for the same nozzle of inner diameter 1.71 mm but for different flow rates for the two sets of experiments ( with and without damping ) . the two sets of mean values lie in a band . the approximate equality of the two mean values is understandable , however , because once the water level in the observation beaker is `` well below '' the breakup point , it is as good as being far below and equivalent to a point of the set without damping . the inset of fig.3 gives a magnified diagram of the curves of fig . 3 in the lower range of the distance of laser beam from the nozzle exit . from this graph one can obtain the first ( initial ) breakup lengths in the two cases ( with and without damping ) and are plotted in fig . 5 as a function of water flow rates . the figure clearly shows that the first breakup length with the damped recoil capillary wave is larger than that without the damping for all values of flow rates measured . this indicates that the recoil capillary waves do exist and they aid in making the water jet unstable against breakup . the mean breakup lengths plotted in fig.5 , though not exactly identical to the earlier reported results ( for example , p. 104 of ref.@xcite ) , the qualitative features are very similar , showing various regimes of jet breakup . however , information on the first breakup length is entirely new . it shows that the first breakup lengths peak at a smaller reynolds number ( mean re=1079.3 ) and weber number ( we=7.54 ) than in case of the mean breakup lengths ( re=1392.6 , mean we=12.51 ) . our measurements are done at the temperature of ( 25@xmath5.5)@xmath6c and at relative humidity of 80@xmath53% . however , in order to calculate re and we , we have used the tabulated values of surface tension of water @xmath7nm@xmath8 and coefficient of viscosity @xmath9 kg m@xmath8s@xmath8 .        the inset of fig.3 gives a magnified diagram of the curves of fig . 3 in the lower range of the distance of laser beam from the nozzle exit . from this graph one can obtain the first ( initial ) breakup lengths in the two cases ( with and without damping ) and are plotted in fig . 5 as a function of water flow rates . the figure clearly shows that the first breakup length with the damped recoil capillary wave is larger than that without the damping for all values of flow rates measured . this indicates that the recoil capillary waves do exist and they aid in making the water jet unstable against breakup . we have performed a very simple experiment the results of which may be considered to directly give a proof of the existence of recoil capillary waves and their effect on the jet breakup length . though the experiment is not so precise and sophisticated the qualitative features shown are unmistakable . a high speed photographic measurement may help in arriving at a result with more confidence . we hope to obtain a conclusive result once we have the required facility . lord , j. w. s. rayleigh , proc . london math . soc . , 4 ( 1879 ) . rayleigh , , vol . ii , pp . 351 - 375 , dover publications , new york , 1945 . s. chandrasekhar , , dover publications , new york , 1961 . e. f. goedde , and m. c. yuen , j. fluid mech . , 495 ( 1970 ) . j. eggers , rev . , , 865 ( 1997 ) . j. eggers , and e. villermaux , rep . prog . , 036601 ( 2008 ) . s. p. lin , , cambridge university press , 2010 . s. rajendran , , m. s. thesis ( in mechanical engineering ) , university of cincinnati , 2012 . a. umemura , phys . e , 046307 ( 2011 ) . a. umemura , s. kawanabe , s. suzuki , and j. osaka , phys . e , 036309 ( 2011 ) . mahato , k. singh , and s. taraphdar , solid state physics ( india ) , 167 ( 2001 ) .", "tags": [], "output_text_a": "The paper investigates the phenomenon of a continuous water jet breaking into droplets, a common occurrence that has intrigued scientists for centuries. The study builds on the Plateau-Rayleigh theory, which explains how perturbations in the jet lead to instability and eventual breakup into droplets. However, the origin of these perturbations remains unclear. The authors conduct experiments to explore the role of recoil capillary waves in this process. By damping these waves, they demonstrate that the breakup length of the jet increases, suggesting that recoil capillary waves contribute to the instability. The experiments, though simple, provide evidence for the existence and impact of these waves on jet breakup. The study highlights the need for further research, potentially using high-speed photography, to gain a more precise understanding of the phenomenon.", "output_text_b": "This arXiv paper discusses the phenomenon of a continuous water jet breaking up into disconnected drops. The authors review the history of studying this phenomenon, starting from Savart's experimental observations in 1833, through Rayleigh's theory in 1879, and later extensions to viscous liquids. The paper highlights that the origin of perturbations in the jet, which eventually lead to the formation of droplets, is not addressed by existing theories. The authors propose a self-sustaining mechanism for generating these perturbations based on capillary waves. They set up an experiment to verify the existence and effect of recoil capillary waves on the length of a continuous water jet by damping the recoil capillary wave. The experimental setup consists of two water tanks, a glass nozzle, a transparent beaker, a laser-pointer-and-detector arrangement, and a six-digit counter. The authors perform experiments at two different heights of the laser beam from the water surface and observe the average number of drop counts per second as the vertical distance of the laser beam from the nozzle exit is increased. They calculate the distribution of breakup lengths and find that the first breakup length with the damped recoil capillary wave is larger than that without the damping for all values of flow rates measured, indicating the existence of recoil capillary waves and their role in making the water jet unstable against breakup.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions by discussing the investigation of water jet breakup and the role of recoil capillary waves.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding the breakup of a continuous water jet into droplets.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the experimental approach used to study the role of recoil capillary waves.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the increase in breakup length when recoil capillary waves are damped.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"recoil capillary waves.\"\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the key experiments involving damping of recoil capillary waves.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by highlighting the need for further research and its contribution to understanding jet breakup.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the phenomenon of water jet breakup, the historical context, and the proposed mechanism involving capillary waves.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the origin of perturbations leading to droplet formation, is highlighted.\n4. The methodology, including the experimental setup and approach to verify the existence of recoil capillary waves, is mentioned.\n5. Significant results, such as the finding that the first breakup length with damped recoil capillary waves is larger, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"capillary waves\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments, such as the use of a laser-pointer-and-detector arrangement to measure breakup lengths, are mentioned.\n10. The summary reflects the paper's significance by indicating the role of recoil capillary waves in jet instability."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the goal of the project is the fabrication of a semi - digital hadronic calorimeter ( 2 bits readout ) of 1 m@xmath0 that can be used to perform measurements of high energy particle shower properties . at the same time this prototype should be as close as possible to an ilc - like module , fulfilling the constraints on power consumption , geometry and electronic integration . the calorimeter will be composed of 40 layers of 1.89 cm thick stainless steel absorbers separated by 8 mm planar micromegas chambers of 1 m@xmath1 size . it should be optimized for particle flow calorimetry and has therefore a very fine transverse granularity of 1cm@xmath1 @xcite . the 1m@xmath1 micromegas prototype consists of 6 printed circuit boards of 32@xmath348cm@xmath1 placed in the same gas chamber . the reason for this arrangement is to avoid a too large energy to be stored in the mesh which could be released in the front - end electronics circuitry during a spark . the 3 mm drift gap between the cathode plane and the meshes is defined by means of insulating spacers . the latter are inserted in the 0.5 mm wide gap between boards which creates a dead area of 1.6% only . copper pads of 1@xmath31cm@xmath1 are first patterned on one side of each board . in a second time , front - end chips and spark protection circuits are connected on the opposite side . finally , an electron multiplying mesh ( bulk micromegas ) is laminated on the pad side @xcite . these boards equipped with a micro - mesh on the pad side and front - end chips on the opposite side are called active sensor units or asus . in this scheme , a very small detector thickness of 6 mm is achieved including 1 mm of pcb material , 2 mm for the chips and passive components and 3 mm of gas . the chamber stainless steel base plate and cover are not taken into account because they will be part of the absorbing medium . the anode plane is segmented into 1536 pads of 1@xmath31cm@xmath1 which are wired through the board to the input pins of the front - end chips . every chip has 64 channels and is used to read out the signals from an 8@xmath38cm@xmath1 area . an asu is equipped with 24 chips intended for processing the detector signals into digital signals . the latter are coded to 2 bits ( 3 thresholds ) and then routed to one board edge to be read out by a detector interface board ( dif ) . an additional board , placed between the asu and the dif distributes the detector hv . the 32@xmath348cm@xmath1 asus fabricated so far are equipped with hardroc2 chips . these chips are composed of an analog part with a current preamplifier , a fast and a slow shaper and a digital part with 3 discriminators with variable charge thresholds and a 128 event depth memory . in view of an application at an ilc detector with a 30 millions channels dhcal , the hardroc2 can operate in a power - pulsing mode . the shaping time of the fast shaper being very short _ w.r.t . _ the detector signal duration , a new chip optimized for the detection of micromegas signals called dirac has been developed @xcite .      the detector is operated in a mixture of ar/__i__c@xmath4h@xmath5 95/5 . ar was chosen for its good ionisation yield ( 90e@xmath6/cm for mips ) and low price . isobutane is a very efficient uv quencher and thanks to its low ionisation potential , high gains can be achieved at relatively low mesh voltages . it should be noted that any other standard mixtures such as ar / co@xmath7 or ar / ch@xmath4 can be used @xcite . in typical working conditions the voltage difference across the 128@xmath8 m amplification gap is 420v . at such voltage , in ar/__i__c@xmath4h@xmath5 95/5 , a gas gain of about 15000 was measured . the cathode voltage is set 50v higher to provide a large ratio between the amplification and drift field and hence a good electron transparency of the mesh . the first micromegas prototypes were three 6@xmath316cm@xmath1 chambers and one of 12@xmath332cm@xmath1 with 3 mm gas gap and 1@xmath31cm@xmath1 pads . the front - end electronic boards were equipped with gassiplex chips which perform a measurement of the charge induced on the pads . in contrast with the asus , these chambers had the gassiplex boards connected on the chamber sides , outside the sensitive area . a test structure containing the 4 chambers was tested in 2008 in a 200 gev / c muon beam at the cern / sps facility .    after a selection of events detailed in @xcite , the landau charge distribution was measured on all pads showing an mpv of 22fc with about 11% variations over all chamber pads . at a charge threshold of 1.5fc , an efficiency between 91 and 97% was found for all chambers . for a given chamber , the efficiency variation was as small as 1% while the hit multiplicity stood between 1.03 and 1.12 depending on the threshold . at an ilc detector , the capability to separate individual showers within jets will be essential to reach the desired jet energy resolution . in that respect a low multiplicity as the one measured will help as the detector will add very little to the overlap of shower patterns in the calorimeter .    in 2009 , the behaviour of the chambers in 2gev / c electron and hadron showers was studied in the cern / ps beam lines @xcite . the energy deposited in the largest chamber by electron shower secondaries was measured for different number of lead plates placed in front of the stack . the longitudinal profile can be found in @xcite and agrees well with the trend of a geant4 simulation . asus of 32@xmath348cm@xmath1 are the basic units that compose the micromegas 1m@xmath1 prototype . in order to first validate the manufacturing process , the signal routing and the overall detector functioning , however , asu of smaller sizes were first developed . the first asu had an active area of 8@xmath38cm@xmath1 . it was equipped with a dirac chip and irradiated with muons and pions at the cern facilities in 2008 @xcite . later , 8@xmath332cm@xmath1 chambers with 4 hardroc1 chips were produced . two detector stacks with dirac and hardroc chambers were tested in ps beams in 2009 @xcite . in what follows , the test procedure of the 32@xmath348cm@xmath1 asus prior to the m@xmath1 prototype assembly is detailed . the study of the electronic characteristics consists in the determination of the noise level of the 1536 channels ( 64 channels / chip , 24 chips / asu ) . the number of hits recorded on a channel is measured as a function of the chip lowest threshold ( common to the 64 chip channels ) . the measured curve is called an s - curve : its inflexion point _ p _ is the pedestal and its width _ w _ relates to the noise level . these quantities depend on the chip configuration like the shaping time or the preamplifier gain . once they are known , the working threshold is determined as _ _ p__@xmath9 + 5__w__@xmath9 where the index `` k '' refers to the channel with the highest _ _ p__+5_w _ value .    the dispersion of the s - curve parameters of the channels of a chip should be minimum in order to have the smallest detection threshold on each channel and also very little channel to channel threshold variations . chips feature an 8-bit adjustable gain preamplifier per channel . besides changing the preamplifier gain , it also changes the s - curve parameters and can eventually be used to align either the s - curve inflexion points _ p _ or the s - curve endpoint _ _ p__+5_w_. the result of the s - curve alignment procedure is illustrated in fig.[scurves ] . when no gain corrections are applied , the difference between the minimum and maximum inflexion points is equal to 8.6 dac units . this corresponds to an average threshold of 7.6fc with an rms of 1.0fc over the chip channels . when the s - curve parameters are aligned ( _ e.g. _ _ _ p__+5_w _ ) , the s - curves fall over a dac range of 3.4 units : the average threshold drops to 3.4fc with 0.4fc variations .              the response uniformity of the asu is determined mainly by the drift and amplification gap uniformity ( primary ionisation yield and gas gain ) and the preamplifier gain and charge threshold uniformity . when the most probable value of the preamplifier output signal is large compared to the threshold ( _ e.g. _ mpv/__t__@xmath1022/1.5 , cf . section [ gassiplex ] ) , the threshold uniformity has very little influence and the preamplifier gains can be adjusted to correct for detector gap non - uniformity . as a first exercise , the detector gap effects were ignored and only the spread of the preamplifier gain distribution was minimized .         a calibration input available on the hardroc2 is used to inject a known charge to the preamplifier input of each channel . the gain is calculated as the slope of the s - curves inflexion point versus injected charge trend _ p_(__q__@xmath11 ) . the gain of every channel is then corrected according to its measured raw value . after this equalization procedure , the _ p_(__q__@xmath11 ) trends are parallel and the inflexion point distribution at a given charge exhibits a reduced dispersion . this can be seen in fig.[equaliz ] ( left ) where the distribution _ p_(100fc ) with and without equalization is shown . the natural dispersion of 4% is reduced to 1.2% . this procedure also works at different input charges as is illustrated in fig.[equaliz ] ( right ) at 200fc . a dedicated gas chamber has been fabricated to perform tests of the asus with @xmath12fe 5.9 kev x - rays . the chamber can house one asu . it has a perforated aluminium cover onto which is glued a cathode foil with a few nm thin conductive deposit on one side . it is therefore transparent to @xmath12fe quanta which are almost all absorbed in the 3 cm thick drift gap . when absorption by the photo - electric effect on an argon atom , the quanta creates a point - like cloud of 230 electrons which drift towards the mesh . during electron multiplication , the signal induced at the preamplifier input is amplified . it is then shaped and fed to a discriminator . if higher than the threshold , the signal is detected and a hit is recorded . because the digital clock frequency is much higher than the quanta conversion rate in the chamber gas , there is basically no dead time and the number of hits _ _ n__@xmath13 recorded in a given time is an indication of the detection efficiency . such a counting experiment was performed on a given pad for different chip configurations and bias voltages , the counting time was 30s . the effect of the threshold can be appreciated in fig.[testbox ] ( left ) where _ _ n__@xmath13 falls off at increasing threshold . this trend does not depend on the preamplifier gain ( measurements at gains of 0.5 , 1 and 1.5 ) because the signal to noise ratio is constant . + the multiplication factor is an exponential function of the mesh voltage which should strongly influence _ _ n__@xmath13 . this is illustrated in fig.[testbox ] ( right ) where the first @xmath12fe quanta are being counted at 370v . a detection plateau is reached at 410v at a gas gain of 10@xmath14 . fe quantum conversions as a function of chip threshold at different preamplifier gains ( left ) and mesh voltage ( right).,title=\"fig:\",scaledwidth=49.0% ] fe quantum conversions as a function of chip threshold at different preamplifier gains ( left ) and mesh voltage ( right).,title=\"fig:\",scaledwidth=49.0% ] at an ilc detector with pfa - oriented calorimeters , the measurement of the energy of jets relies both on the tracking and the calorimetry . in particular , the capability to group calorimeter hits together and to separate individual showers within jets will be crucial @xcite . such a performance can be investigated with simulation programs . also , the influence of the absorber material , particle energy , calorimeter depth and segmentation on the energy resolution , linearity , shower profiles and leakage can be studied with the simulation . the comparison between analog and digital readout is reported below . for further studies , the reader is referred to @xcite . the geometry of the hadronic calorimeter is based on the one proposed for the sid detector @xcite but twice deeper ( 9 @xmath15 instead of 4.5 @xmath15 ) . the lateral size is 1@xmath31m@xmath1 while the depth varies from 1.70 to 2.39 m depending on the absorber material . monte carlo data for negative pions were generated by a geant4-based simulator slic with lhep physics list . when calculating the performance with a digital readout , a threshold of 10% of the mip mpv is applied to the energy deposited in each 1cm@xmath1 cells . the energy resolution as a function of pion energy of a stainless steel calorimeter and different readouts is displayed in fig.[reso ] ( left ) . at low pion energy , the energy resolution is dominated by landau fluctuations which are suppressed when applying a threshold . as a result , the digital readout provides a better resolution . at higher energy , however , the number of hits saturates due to the finite size of the anode pads and a loss of linearity is observed in the digital case . yet , the digital readout shows a superior resolution . the loss of linearity can in principle be overcame with a semi - digital readout where more than one threshold would be applied . in contrast with rpcs , micromegas is well suited for a semi - dhcal because no saturation effects take place in the gas volume and the read out signals are proportional to the primary ionisation yield ( fig.[reso ] ( right ) ) . the determination of the charge thresholds and their corresponding weights is the subject of current investigation . the micromegas semi - dhcal 1m@xmath0 project has been surveyed . at detection thresholds of a few fc , high efficiency and low hit multiplicity were measured with small chambers and analog readout . the challenge is to maintain these performance on larger area detectors with pcb embedded digital electronics ( active sensor units ) . the technique to manufacture such compact detectors is well controlled and can be used for the production of m@xmath1 planes . in parallel to that , a strong effort is made on the simulation . this aspect of the project is essential for designing and predicting the main performance of a micromegas semi - dhcal . the 1m@xmath1 micromegas prototype will be composed of 6 asus which are individually tested in the laboratory prior to the assembly . a careful study of the front - end chip noise characteristics has been carried out to minimize the detection threshold and a gain equalization procedure has been established in order to improve the response uniformity . finally , the overall functioning of the asus has been verified by performing x - ray tests in a dedicated gas chamber . at the moment of writing , the first 1m@xmath1 micromegas prototype has been assembled and tested in a muon beam at the cern / sps facility in june / july 2010 . preliminary results are promising and the data analysis is on - going . the author would like to thank rui de oliveira and olivier pizzirusso from the cern en - ice - dem group for the lamination of the bulk micromegas mesh on the boards as well as d. atti , p. colas and w. wang from irfu / saclay for their participation to the 2009 test beams . finally , the fruitful collaboration between the lal / omega and lapp / lc group should be underlined : many thanks to n. seguin and c. de la taille for their participation on the test of the first hardroc2 equipped asus and on the recent asic developments . 99 ilc reference design report , detectors ( 2007 ) . brient , proceedings of the calor 2004 conference . s. andriamonje _ . instr . and meth . a _ * 560 * ( 2006 ) 405 . r. gaglione , h. mathez , _ ieee - nss conference records _ * 1 * 1815 ( 2008 ) . c. adloff _ et al . _ , 2009 _ jinst _ * 4 * p11023 ( 2009 ) . c. adloff _ et al . _ , 2010 _ jinst _ * 5 * p01013 ( 2010 ) . j. blaha , proceedings of the calor 2010 conference , + to be published in _ journal of physics : conference series_. c. adloff _ et al . _ , 22009 _ jinst _ * 4 * p11011 ( 2009 ) . thomson , _ nucl . instr . and meth . a _ * a611 * 2540 ( 2009 ) . c. adloff _ et al . _ , 2009 _ jinst _ * 4 * p11009 ( 2009 ) . sid detector , http://silicondetector.org/display/sid/home . f. sauli , cern yellow reports 77 - 09 ( 1977 ) .", "tags": [], "output_text_a": "The paper discusses the development of a semi-digital hadronic calorimeter prototype designed for high-energy particle shower measurements, with a focus on integration into an International Linear Collider (ILC) module. The calorimeter consists of 40 layers of stainless steel absorbers and micromegas chambers, optimized for particle flow calorimetry with fine transverse granularity. The prototype uses active sensor units (ASUs) equipped with Hardroc2 chips for signal processing, operating in a power-pulsing mode suitable for ILC detectors. The detector operates in an argon-isobutane gas mixture, achieving high gas gain and efficiency. Initial tests with smaller chambers showed promising results in terms of efficiency and low hit multiplicity. The paper also explores the potential of digital and semi-digital readouts for improved energy resolution and linearity. The first 1m\u00b2 micromegas prototype has been assembled and tested, with ongoing data analysis. The project emphasizes the importance of simulation for design and performance prediction, and highlights successful collaborations in the development process. Preliminary results from tests at CERN's SPS facility are promising.", "output_text_b": "The article describes the development of a semi-digital hadronic calorimeter for high energy particle shower measurements, aiming to replicate an ILC-like module with power consumption, geometry, and electronic integration constraints. The calorimeter consists of 40 layers of stainless steel absorbers and micromegas chambers. The micromegas prototype is made up of six printed circuit boards with 1cm granularity and equipped with HardROC2 or DIRAC chips for signal processing and coding. The detector is operated in a Ar/iC4H5 95/5 mixture and has been tested with muon, pion, and electron beams, demonstrating efficient performance and low multiplicity.", "score": 0.7, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper, mentioning the development of a semi-digital hadronic calorimeter prototype and its integration into an ILC module.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem, which is the measurement of high-energy particle showers and integration into an ILC module, is highlighted.\n4. The methodology, including the use of stainless steel absorbers, micromegas chambers, and active sensor units with Hardroc2 chips, is mentioned.\n5. Significant results, such as high gas gain and efficiency, and promising preliminary test results, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"micromegas chambers\" and \"active sensor units\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments, such as tests at CERN's SPS facility, are mentioned.\n10. The summary reflects the paper's significance in terms of its potential impact on ILC detector development.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary provides a general overview of the paper's focus on developing a semi-digital hadronic calorimeter and mentions the use of micromegas chambers and specific chips, but it lacks detail on the main findings and contributions, such as the specific performance metrics or innovations introduced.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and well within the 250-word limit.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary does not explicitly state the research problem or question, although it implies the goal of developing a calorimeter for high energy particle shower measurements.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary briefly mentions the use of micromegas chambers and specific chips, but it does not detail the methodology or approach used in the research.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary mentions efficient performance and low multiplicity but lacks specific results or conclusions drawn by the authors.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"micromegas chambers\" and \"HardROC2 or DIRAC chips\" without explanation, which may not be clear to all readers.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary briefly mentions testing with muon, pion, and electron beams but lacks detail on the experiments or data.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not clearly convey the significance or potential impact of the research in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "in june 2015 , the large hadron collider ( lhc ) has resumed its physics program with proton - proton ( pp ) collisions at @xmath4 = 13 tev . currently , this is the highest centre - of - mass energy reached in the laboratory . a full description of particle production in pp collisions can not be obtained from perturbative quantum chromodynamics and hence modelling efforts typically employ various empirical components that have to be adjusted based on experimental data . the measurement of light flavour particles production in pp collisions provides important input for event generators to model the soft parton interactions and the hadronization processes . furthermore , pp collisions are used as reference to isolate medium effects present in larger colliding systems . previous alice measurements @xcite , @xcite , @xcite on identified particles in pp collisions at lower energies show that the models usually give a fair description of the shapes of the @xmath1 spectra but fail on the description of the pion , kaon and proton yields . @xmath5 , k@xmath6 , p and @xmath7 are identified in the rapidity window @xmath8 0.5 using several particle identification ( pid ) techniques in the different alice sub - detectors : the inner tracking system ( its ) , the time projection chamber ( tpc ) , the time of flight detector ( tof ) and high momentum particle identification detector ( hmpid ) . the combined information of these detectors in different @xmath1 regions allows us to measure the particle production in the region starting from 150 mev/_c _ up to 20 gev/_c_.    the @xmath9 and @xmath10 mesons are measured with invariant - mass analyses via the reconstruction of their hadronic decays . the combinatorial background is subtracted using either a like - sign or event mixing technique . the resulting invariant - mass distributions are then fitted . previous measurements by alice and details on the analysis procedure can be found in @xcite . the multi - strange @xmath11 , @xmath12 , @xmath13 , @xmath14 baryons are reconstructed via their weak hadronic decay products . candidates are selected with restrictions on the topology of the decay and the signal is extracted from the resulting invariant mass distributions . the full analysis procedure is described in @xcite . the @xmath1-dependent @xmath15 and @xmath16 ratios measured in central rapidity ( @xmath17 0.5 ) at @xmath4 = 2.76 , 7.0 and 13 tev are shown in fig . [ ratios ] . the comparison to pythia 8 @xcite ( monash-2013 @xcite ) for the different energies is also shown .    within the systematic uncertainties the @xmath16 ratio is consistent for the three different energies . the @xmath15 ratio for the low - intermediate @xmath1 region shows a slight shift towards higher @xmath1 when increasing @xmath4 . within our systematic uncertainties the ratio is compatible for the three different energies in the @xmath1 region above 10 gev/_c_. this shift is also observed on the monte carlo predictions from the pythia 8 model . the origin of the peak in pythia 8 is attributed to the colour reconnection mechanism @xcite , and is expected to become more important at higher centre - of - mass energy .    the @xmath1-integrated @xmath16 and @xmath15 ratios in pp collisions as a function of @xmath4 are shown in fig.[ratios_energies ] . results at different energies for different experiments are also shown . results from e735 at @xmath4 = 0.3 , 0.54 , 1.0 and 1.8 tev @xcite , @xcite , from phenix at @xmath4 = 62.4 and 200 gev @xcite and cms at @xmath4 = 0.9 , 2.76 and 7 tev @xcite are compared for both particle ratios . the last added point at 13 tev confirms the similar trend and saturation for @xmath18 900 gev observed in alice previous measurements . the hyperon - to - pion ratio as a function of @xmath4 measured in alice is shown in fig . [ hyperon_ratio ] . in comparison with the kaon- and proton - to - pion ratio the strange- and multi - strange - to - pion ratios show a hint of increase at 13 tev with respect to the lower collision energies . this enhanced production may be related to the enhancement observed as a function of multiplicity in pp collisions at @xmath4 = 7 tev @xcite , as the charged particle multiplicity density increases with the collision energy . the @xmath9 and @xmath10 meson production has been also measured in pp collisions at @xmath4 = 13 tev . the @xmath1-integrated @xmath19 and @xmath20 ratios are shown in fig . [ ratios_resonances ] . however , no energy evolution is observed in the range from rhic to the highest lhc energy . the @xmath1 dependence of the @xmath21 and @xmath16 is the same at lhc energies within our systematic errors . pythia 8 describes the shape but exhibits large deviations from the data for transverse momenta larger than 2 gev/_c_. above @xmath22 900 gev the @xmath21 and @xmath16 ratios are energy independent within systematic uncertainties . the relative production of strange resonances ( @xmath19 and @xmath20 ) remains constant within a wide range of centre of mass energy . multiplicity dependent studies in pp collisions at 13 tev will help disentangle the role of collision energy and event multiplicity in the identified particle production of pp collisions . 9    alice collaboration 2011 , _ eur . phys . j. c _ * 71 * 1655 . alice collaboration 2014 , _ phys . lett . b _ * 736 * 196 - 207 . alice collaboration 2015 , _ eur phys . j.c _ * 75 * 226 . alice collaboration 2012 , _ eur . j. c _ * 72 * 2183 . alice collaboration 2012 , _ phys . b _ * 712 * 309 - 318 . t. sjstrand , s. mrenna , and p. z. skands 2008 , _ comput . commun . _ * 178 * 852 - 867 . z. skands , s. carrazza , and j. rojo 2014 , _ eur . j. c _ * 74*. e735 collaboration , 1993 _ phys.rev . d _ * 48 * 984 - 997 . e735 collaboration 1992 , _ phys.rev . d _ * 46 * 2773 - 2786 . phenix collaboration 2011 , _ phys.rev . c _ * 83 * 064903 . cms collaboration 2012 , _ eur.phys.j . c _ * 72 * 2164 . alice collaboration 2016 , arxiv:1606.07424 [ nucl - ex ] .", "tags": [], "output_text_a": "The Large Hadron Collider (LHC) resumed its physics program in June 2015 with proton-proton (pp) collisions at a center-of-mass energy of 13 TeV, the highest achieved in a laboratory setting. This paper discusses the measurement of light flavor particle production in these collisions, which is crucial for refining event generators used to model soft parton interactions and hadronization processes. The study uses various particle identification techniques across different ALICE sub-detectors to measure particle production from 150 MeV/c to 20 GeV/c. The analysis includes the measurement of mesons and multi-strange baryons through invariant-mass analyses and weak hadronic decay products, respectively.\n\nThe paper presents the transverse momentum (pT) dependent particle ratios at different energies (2.76, 7.0, and 13 TeV) and compares them with predictions from the Pythia 8 model. The results show consistency in the K/\u03c0 ratio across energies, while the p/\u03c0 ratio shifts slightly towards higher pT with increasing energy. The study also examines the hyperon-to-pion ratio, which shows a potential increase at 13 TeV, possibly linked to enhanced production observed with higher multiplicity at 7 TeV. Additionally, the production of \u03c1 and K* mesons is analyzed, showing no significant energy evolution from RHIC to LHC energies. The findings suggest that the relative production of strange resonances remains constant across a wide range of energies. Future multiplicity-dependent studies at 13 TeV are expected to further clarify the roles of collision energy and event multiplicity in particle production.", "output_text_b": "The Large Hadron Collider (LHC) resumed its physics program in June 2015 with proton-proton (pp) collisions at a center-of-mass energy of 13 TeV, the highest energy reached in the laboratory. A complete description of particle production in pp collisions cannot be obtained from perturbative quantum chromodynamics, and empirical components need to be adjusted based on experimental data. This paper discusses the measurement of light flavor particles production in pp collisions, which is essential for event generators to model soft parton interactions and hadronization processes. Additionally, pp collisions serve as a reference to isolate medium effects present in larger colliding systems.\n\nThe ALICE collaboration measured the production of pions, kaons, and protons (identified as \u03c0, K, p, and K\u2070\u207f) in the rapidity window 0.5 using several particle identification techniques in different ALICE sub-detectors. The combined information of these detectors in different p\u209c regions allows for the measurement of particle production starting from 150 MeV/_c up to 20 GeV/_c. The \u03c6 and \u03c6(1020) mesons are measured with invariant-mass analyses via the reconstruction of their hadronic decays, and the combinatorial background is subtracted using either a like-sign or event mixing technique. The resulting invariant-mass distributions are then fitted.\n\nThe \u039b\u207a, \u039e\u207b, \u03a9\u207b, and \u039e(1530)\u2070 baryons are reconstructed via their weak hadronic decay products, and candidates are selected with restrictions on the topology of the decay. The signal is extracted from the resulting invariant mass distributions.\n\nThe \u221as-dependent \u039b/K\u2070\u207f and K\u2070\u207f/\u03c0 ratios measured in central rapidity (|y| < 0.5) at \u221as = 2.76, 7.0, and 13 TeV are shown in the figures. The comparison to Pythia 8 (Monash-2013) for different energies is also shown. The \u039b/K\u2070\u207f ratio is consistent for the three different energies within systematic uncertainties. The \u039a\u2070\u207f/\u03c0 ratio for the low-intermediate p\u209c region shows a slight shift towards higher p\u209c when increasing \u221as.\n\nThe \u221as-integrated \u039b/K\u2070\u207f and K\u2070\u207f/\u03c0 ratios in pp collisions as a function of \u221as are shown in the figures, with results from different experiments at various energies. The hyperon-to-pion ratio as a function of \u221as measured in ALICE shows a hint of an increase at 13 TeV with respect to the lower collision energies. The strange- and multi-strange-to-pion ratios show a similar trend. This enhanced production may be related to the enhancement observed as a function of multiplicity in pp collisions at \u221as = 7 TeV, as the charged particle multiplicity density increases with the collision energy.\n\nThe \u03c6 and \u03c6(1020) meson production has been measured in pp collisions at \u221as = 13 TeV. The \u221as-integrated \u03c6/K\u2070\u207f and \u03c6(1020)/K\u2070\u207f ratios are shown in the figures. However, no energy evolution is observed in the range from RHIC to the highest LHC energy. The \u03c6/K\u2070\u207f and \u03c6(1020)/K\u2070\u207f ratios are energy independent within systematic uncertainties above \u221as > 900 GeV. The relative production of strange resonances (\u03c6 and \u03c6(1020)) remains constant within a wide range of center-of-mass energy.\n\nMultiplicity dependent studies in pp collisions at 13 TeV will help disentangle the role of collision energy and event multiplicity in the identified particle production of pp collisions.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, discussing the measurement of light flavor particle production and the comparison with Pythia 8 model predictions.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of measuring light flavor particle production in high-energy pp collisions.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of various particle identification techniques and invariant-mass analyses.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the consistency of the K/\u03c0 ratio and the potential increase in the hyperon-to-pion ratio.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"invariant-mass analyses\" and \"transverse momentum,\" but these are necessary and relevant to the context.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear progression of ideas.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of ALICE sub-detectors and the comparison with Pythia 8 model predictions.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing its contribution to refining event generators and understanding particle production.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the measurement of light flavor particles production in pp collisions and its importance for event generators and isolating medium effects.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the challenges of describing particle production in pp collisions.\n4. The methodology, including the use of ALICE sub-detectors and invariant-mass analyses, is mentioned.\n5. Significant results, such as the consistency of the \u039b/K\u2070\u207f ratio and the hint of increased hyperon-to-pion ratios at 13 TeV, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is used but is necessary for the context; however, some terms like \"rapidity window\" and \"p\u209c regions\" could be explained for clarity.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments and data, such as the use of ALICE sub-detectors and the comparison to Pythia 8, are mentioned.\n10. The summary reflects the paper's significance by discussing the potential impact of the findings on understanding particle production and event generators."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "from the sizes of protoplanetary disks , we expect planets to form out to tens of au . the many giant planets found on small orbits by radial velocity and transit techniques are believed to have formed beyond the water ice lines of their stars and migrated inward . inward migration of massive planets can have a profound ( and usually destructive ) effect on the smaller objects in a planetary system , such as earth - sized planets within the habitable zones . it is therefore important to determine how many systems retain their giant planets on wide orbits . direct detection of these planets is limited to the most massive examples . indirect detection through the use of debris disks addresses this limitation . a debris disk consists of the circumstellar solid material that remains after the protoplanetary disk gas has dispersed and giant planets might have formed . although most of the mass in a debris disk is harbored by the parent bodies ( planetesimals ) , dust generated in their collisions accounts for the majority of the disk s surface area , and observations of debris disks via their thermal emission or reflected stellar radiation trace this dust . while tens of debris disks have been spatially resolved , the majority are detected only as an infrared excess in the spectral energy distribution ( sed ) of their star . typical debris disk temperatures are tens to a few hundred kelvins , emitting as modified blackbodies that peak in the mid to far infrared . these wavelengths are well - suited for study with the _ spitzer space telescope _ @xcite infrared spectrograph ( irs ; @xcite ) and multiband imaging photometer for _ spitzer _ ( mips ; @xcite ) . for a recent review of debris disks , see @xcite . debris disks often appear constrained to one or two discrete rings . this is evident from images of resolved disks such as fomalhaut @xcite , and from seds of unresolved debris disks that are fit well by one or two blackbody functions , corresponding to dust at one or two distinct radial locations . of the 28 disks without strong emission features presented by @xcite , all but one were fit better with a blackbody function than with a continuous disk model . the exception was hr8799 , which was later determined to be best modelled by two blackbodies @xcite . @xcite originally fit some excess seds with a power law , representing a continuous radial distribution of dust ; however , @xcite argued that these power law fits require the optical depth of the disk to increase with orbital radius ( which is theoretically implausible ) , and they found that these targets can be fit well by two blackbodies instead . these  warm \" and  cold \" debris disk components may be analogous to the asteroid belt and kuiper belt in the solar system . why do rings form , and what sets their location ? ice lines are one possibility . during the protoplanetary disk phase , a radial pressure gradient in the gas partially counteracts the gravitational force on the gas , allowing it to rotate at a sub - keplerian velocity . solid particles orbit at keplerian rates , and thus experience a head wind that slows their rotation and makes them spiral inwards . when these solids reach the ice line , the volatile component sublimates , producing a local pressure increase that counteracts the overall pressure gradient . this creates a zone where the particles can settle without a headwind . thus , there is a tendency to have a planetesimal belt near the ice line , and this belt can then produce grains that assume a specific temperature . @xcite found similar warm disk temperatures ( 190 k ) around stars of different stellar types . this can potentially be explained by the presence of the water ice line at 150 - 170 k. @xcite argue that ice lines of other species ( e.g. co , @xmath0 , @xmath1 ) at lower temperatures may play an important role in planet formation in the outer solar system . if ice lines are also responsible for setting the location of the cold components , we would expect these components to have similar temperatures over a range of stellar types . planets may also cause the discrete ring structures . planetesimals will be scattered away once a planet is massive enough to dominate the gravity in its vicinity . observations support the expected relation between planets and disk structure : the four giant planets imaged around hr 8799 @xcite are located in the gap between the warm and cold debris disk components @xcite ; the imaged planet orbiting @xmath2 pic appears to sculpt the inner edge of its debris disk @xcite ; the well - resolved cold debris ring around fomalhaut is likely confined by planets @xcite ; and in the solar system , neptune sculpts the inner edge of the kuiper belt @xcite . if the locations of debris disks are set by planets , we can use cold debris disks to investigate wide - orbit planets , which are not easily studied by other means . of the over 850 confirmed exoplanets , 35 have orbits larger than 5 au , and only 17 have orbits larger than 10 au ( nasa exoplanet archive ) . this is likely due to the observational biases of the radial velocity and transit detection techniques . direct imaging can detect wide - orbit planets , but the current technology is only sensitive to very massive planets around young , nearby stars . uranus and neptune , for instance , could not be directly detected from outside the solar system . the planet formation processes beyond 5 - 10 au are poorly understood . for example , did the planets around hr 8799 form at their current locations or did they ( or at least their cores ) form on smaller orbits , then migrate outwards via scattering interactions with other planets or planetesimals ? cold debris disks provide an observational test of these planet formation and migration theories . planet formation by core accretion becomes less efficient farther from the star due to a radial increase in the dynamical timescale and decline in the surface density of solids in the protoplanetary disk @xcite . therefore , the inner edge of a cold debris disk may represent the outer limit of efficient core accretion @xcite . a planet migrating outwards into a debris disk will push the inner edge of the disk outward as well . uranus and neptune may have formed on smaller orbits and migrated into the kuiper belt @xcite . in this alternate scenario , the inner edge of a cold debris disk may represent the limits of outward migration . in this paper , we focus on _ spitzer _ measurements of cold debris disks , showing how their temperatures vary with the temperature of their central star and what this implies about planet formation and migration on wide - orbits . first , we describe the selection of our target stars (  [ sec : targetselection ] ) . then , we outline our photometric (  [ sec : photometry ] ) and irs (  [ sec : irsdatareduction ] ) data acquisition / reduction . next , we detail our modeling of the stellar photosphere sed (  [ sec : photospheremodel ] ) , our derivation of the infrared excess , and our fitting of blackbodies to the excess (  [ sec : blackbodyfitting ] ) . finally , we analyze the results (  [ sec : results ] ) and discuss the implications for wide - orbit planet formation and migration (  [ sec : discussion ] ) , before offering a summary and concluding remarks (  [ sec : conclusions ] ) . we searched the _ spitzer _ observers log for main - sequence stars that were observed with the irs long low ( ll ) module ( both orders ) in staring mode and with mips at 24 @xmath3 and 70 @xmath3 , and we accumulated a sample of 546 targets . the stellar properties of our target list are summarized in table [ table : stellarproperties ] . after reducing and analyzing the data , we refined the sample as described in [ sec : blackbodyfitting ] . this yielded 225 stars with significant excess ( of which 174 had cold components ) , which are detailed in table [ table : excessdata ] . it is important to note that our sample comprised stars from a variety of _ spitzer _ observational programs , each having targets selected in a different manner ( e.g. nearby stars , stars with previously detected infrared excess , stars with rv - detected planets , etc . ) . hence , our sample was not selected to be statistically representative in any one sense ; rather , it was designed to include as many relevant targets as possible . we calculated the stellar temperature , @xmath4 , from the star s v-@xmath5 color using tabulated values for main - sequence stars ( or interpolations between these values ) from @xcite , and we estimated a 200 k one - sigma uncertainty on these values . @xmath4 is listed for targets with significant excess in table [ table : excessdata ] . over the range of spectral types and metallicities of our sample of stars , v-@xmath5 is an accurate indicator of stellar effective temperature , with a peak - to - peak scatter of less than @xmath6 1.5% and weak metallicity dependence @xcite . we use @xmath4 to parametrize stellar type , and this degree of accuracy is sufficient for our purpose . some of the uncertainty in @xmath4 reflects the effect of interstellar reddening on v-@xmath5 , although the great majority of stars in this sample are within the local bubble and therefore should not be strongly reddened ( of the 174 targets for which we detect cold components , only 29 are beyond 100 pc , 19 are beyond 120 pc , and 4 are beyond 150 pc ) .    ages for these stars were estimated from a combination of chromospheric activity measurements , x - ray emission , placement on the hr diagram , surface gravity , membership in clusters and associations , and gyrochronology collected from the literature . @xcite describe the intercomparison of these methods and how they are applied , and the quoted ages are on the scale calibrated by @xcite . the ages are listed in table [ table : stellarproperties ] , along with references for the measurements used to derive the ages and a quality flag for the age accuracy ( ranging from 0 if no age could be determined to 3 if there were three or more age measurements with good agreement ) . cccccccccc hip110 & hd224873 & & g5 & 49.6 & 0.42 & 2 & 2,20 & 5346816 & not included + hip345 & hd225200 & hr9102 & a0v & 124.8 & 0.1 & 2 & 31 & 12720128 & warm + cold + hip394 & hd225239 & hr9107 & g2v & 39.2 & 0.25 & 1 & 2 & 4028672 & not included + hip490 & hd105 & & g0v & 39.4 & 0.17 & 3 & 2,3,4,5,6,9,12 & 5295616 & cold + hip522 & hd142 & hr6 & f7v & 25.7 & 4.8 & 2 & 3,17,27 & 22296064 & not included + hip544 & hd166 & hr8 & k0ve & 13.7 & 0.24 & 3 & 1,2,6,15,23 & 12717824 & warm + cold + hip560 & hd203 & hr9 & f3vn & 39.4 & 0.01 & 2 & 38 & 14983424 & cold + hip682 & hd377 & & g2v & 39.1 & 0.22 & 3 & 2,4,9,12,20,32 & 5268736 & warm + cold + hip910 & hd693 & hr33 & f8vfe-08h-05 & 18.7 & 3 & 3 & 3,4,23,24 & 14494720 & not included + & & & & & & & & 4008448 & + hip919 & hd691 & & k0v & 34.2 & 0.24 & 3 & 2,9,12,14,18,20,39 & 5345280 & not included + hip1031 & hd870 & & k0v & 20.2 & 2.3 & 2 & 3,5 & 16026112 & cold + hip1134 & hd984 & & f5 & 47.1 & 0.25 & 3 & 2,4,9,20 & 5271808 & not included + hip1292 & hd1237 & & g8.5vk : & 17.5 & 0.3 & 3 & 2,3,4,5,6 & 22290176 & not included + hip1368 & & & k7 & 15 & 0.9 & 3 & 1,2,39 & 25674240 & cold + hip1473 & hd1404 & hr68 & a2v & 41.3 & 0.45 & 1 & 7 & 14160384 & warm +      although we built our target list around the _ spitzer _ irs spectra , we supported these spectra in our analysis with a suite of photometric data . the properties of the photometric systems we used are summarized in table [ table : photometrybands ] and the photometric data for the targets with significant excess ( see  [ sec : blackbodyfitting ] ) are given in table [ table : excessdata ] . mips photometry at 24 @xmath3 provided an important calibration reference for the irs data (  [ sec : irsdatareduction ] ) , while 70 @xmath3 photometry provided a crucial constraint on the temperature of cold debris disks (  [ sec : blackbodyfitting ] ) . we used our in - house debris disk pipeline to reduce and extract photometry for the mips data as part of the effort to preserve the legacy of _ spitzer _ measurements on debris disk studies ( @xcite ; k. su et al . 2013 , in prep ) . basic reduction ( up to the post - bcd mosaics ) and calibrations of the mips data follow the descriptions by @xcite and @xcite . in addition , the extraction of the 24 @xmath3 photometry was briefly described in @xcite , where the source position at 24 @xmath3 is determined by a combination of psf fitting and 2d gaussian fitting . both psf fitting and aperture photometry aperture photometry used an aperture radius of 6.255@xmath7 , a sky annulus of 19.92 - 29.88@xmath7 , and an aperture correction factor of 1.6994 . ] were performed , and we preferentially used the aperture photometry at 24 @xmath3 because this was used to calibrate the photosphere model at 24 @xmath3 , as described in  [ sec : photospheremodel ] and the appendix ( the psf and aperture photometry agree to within a few percent ) . we then used the 24 @xmath3 source position to perform psf fitting for data at 70 @xmath3 by minimizing the residual signal at the source position ( for details , see k. su et al . 2013 , in prep ) . for faint sources located in areas with structured background , the resultant 70 @xmath3 photometry can be negative , which reflects non - detection . the 1@xmath8 photometry uncertainty ( listed in table [ table : excessdata ] ) includes the pixel - to - pixel variation near the source of interest , and detector repeatability ( 1% and 5% of the source flux at 24 and 70 @xmath3 , respectively ) . mips photometry data for all of our targets can be found in @xcite , @xcite , and k. su et al . ( 2013 , in prep ) . v , j , h , and @xmath5 photometry were used to model the stellar photosphere sed (  [ sec : photospheremodel ] ) and to estimate @xmath4 (  [ sec : targetselection ] ) . we obtained _ hipparcos _ v band @xcite and 2mass j , h , and k band photometry @xcite from the vizier online database . many of the targets in the sample are nearby stars and are severely saturated in the 2mass data . to overcome this , we used heritage aperture photometry , which we transformed to match the 2mass system . when both 2mass and transformed heritage photometry of high quality were available , we averaged them . the references for the heritage photometry are in table [ table : excessdata ] . irac photometry ( 3.6 @xmath3 ) was also used to model the stellar photosphere sed (  [ sec : photospheremodel ] ) . these data were taken in _ spitzer _ cycle 7 ( pid 70076 , pi : su ) . all the irac data were taken in subarray mode with four dithered positions to avoid saturation . we used the basic calibrated data ( bcd ) products provided by the _ science center ( pipeline version s18.18 ) , and performed the necessary steps ( pixel solid angle correction and pixel phase correction ; k. su et al . 2013 , in prep ) to extract the photometry . aperture photometry was used for each individual data frame ( 64 frames per dithered position ) ; and the final quoted flux is the median value of all measurements per star . wise data @xcite were obtained from vizier , but are not included in table [ table : excessdata ] . because wise photometry is less accurate than _ spitzer _ photometry , we did not use it quantitatively . instead , we used it as a qualitative confirmation of our _ spitzer _ data . our irs reduction started with the level 1 bcd products , downloaded from the _ spitzer _ heritage archive . in addition to irs ll data , we also reduced short low ( sl ) module data , when available , and included them in our analysis . the astronomical observation requests ( aors ) used for each target are listed in table [ table : stellarproperties ] . the basic reduction was performed using the spectroscopic modeling analysis and reduction tool ( smart ) software package @xcite , scripted into a series of automated routines . for each spectral order of each irs aor , three files ( 2d spectra , uncertainty , and mask ) were combined into a single 3-plane file . bad and rogue pixels were removed by the routine irsclean with the clean parameter set to 4096 ( pixels with this value or higher were included in the clean ) . next , when available , multiple data collection events ( dces ) for the same nod position were combined , and then the background was removed from each 2d spectrum by subtraction of the opposite nod . the 2d spectra were then converted into 1d spectra using smart s optimal 2 nod extraction @xcite . the 1d spectra from both nods were combined . the result was a wavelength , flux , and uncertainty vector of each spectral order for each aor . the  bonus \" third order data were not used . the remainder of the data reduction and analysis was performed with the matlab software package . irs data at wavelengths near the order edges often were of poor quality , so data longward of 38 @xmath3 and shortward of 20.75 @xmath3 were discarded from the ll first order , data shortward of 14.3 @xmath3 were discarded from the ll second order , data longward of 14.7 @xmath3 and shortward of 7.55 @xmath3 were discarded from the sl first order , and data shortward of 5.25 @xmath3 were discarded from the sl second order . systematic offsets in flux existed between irs orders , which we fixed by applying a multiplicative correction factor to the ll first order spectrum and to both sl order spectra ( if they existed ) , in order to align them with the ll second order flux . initially , we determined the order correction factors using an automated routine , but due to the variety of shapes of the spectra and the presence of outlying data points , we found that fine - tuning these factors by eye was more reliable . the data from all available orders and modules were then combined into a single spectrum . next , we cut outlying data points from the spectrum in an iterative process . the spectrum was fit with a polynomial and the standard deviation of residual flux values around the fit was calculated . points lying more than three standard deviations from the fit were discarded . this process was iterated six times . because the scatter of the data generally increased towards longer wavelengths , we applied this process separately to the short and long ends of our spectrum ; if sl data were available , the two sections were divided at 14 @xmath3 and each section fit with a fourth degree polynomial , whereas if no sl data were available , the sections were divided at 25 @xmath3 and each section was fit with a second degree polynomial . this procedure , on average , cut 10 data points from each spectrum , with the first iteration typically cutting five points , and the sixth iteration only cutting zero , one , or two points ( nearly 90% of spectra had no points cut in the sixth iteration ) . before cutting , the spectra had 181 , 296 , or 373 points , depending on the available orders . after the outliers were cut , the spectrum was smoothed by binning to a wavelength resolution of 0.7 @xmath3 . the absolute calibration of irs data is only accurate to @xmath910% , whereas the mips calibration is accurate to @xmath92% @xcite . to reduce systematic errors in our irs data , we multiplicatively scaled our spectrum to be consistent with the measured mips 24 @xmath3 flux density for each target . the irs spectra were calibrated as point sources , so if a source was slightly extended , it would have an incorrect slit - loss correction . the stellar photospheres ( point - like ) are dominant in the irs spectra for the majority of sources in the sample ; therefore , this has no significant impact on the result . if the mips photometry for a source was contaminated by background emission , this contamination would be passed to the irs spectrum of the source through this scaling ( the irs data may or may not have picked up the contamination , depending on the slit orientation ) . nevertheless , an additional multiplicative factor was later applied to the irs data ( see  [ sec : photospheremodel ] ) , which corrected any lingering errors from this process . some targets were observed with more than one irs aor . we combined the spectra from these aors , interleaving their data points , then re - smoothing to a spectral resolution of 0.7 @xmath3 . although the spectrum of a main - sequence star peaks in the visible or near - ir , the stellar photosphere can still be the dominant source of flux density in the mid - ir . thus , to extract the thermal emission of the debris disk ( the infrared excess ) , an accurate model spectrum of the stellar photosphere must be generated and subtracted from the data . it is common to use photosphere spectra from detailed numerical models of stellar structures , such as kurucz / atlas9 @xcite . however , these models are not well - tested in the mid- and far - infrared . @xcite compared various families of models ( kurucz / atlas9 , marcs , and nextgen / phoenix ) and found that the choice of model family can affect whether a star is determined to have an infrared excess or not . we opted for a simpler model , a rayleigh - jeans relation given by @xmath10 , where rj is an amplitude scale factor . this model is appropriate for wavelengths beyond 5 @xmath11 m because stars in this study , mostly a through k dwarfs , have virtually no spectral features in the mid - ir , behaving as blackbodies in the rayleigh - jeans regime . for example , in the range of most interest for this study , the departure of a reference a0 star spectrum @xcite from a rayleigh - jeans fit between 15 and 30 @xmath3 is no more than @xmath6 0.3% , and the atlas9 @xcite solar model follows rayleigh - jeans behavior to within @xmath6 0.24% from 20 to 40 @xmath3 . however , the theoretical spectra show minor systematic differences from the observations @xcite , so use of them to improve the knowledge of the seds would be risky .    modeling the photosphere thus came down to finding the appropriate scale factor ( rj ) for each star in our sample . we used a set of color relations ( derived from a sample of stars known to have no ir excess ) to predict the mips 24 @xmath3 magnitude of the photosphere , [ 24 ] , from measured v , j , h , @xmath5 , and irac magnitudes bands where ir excesses due to very close - in dust are very rare . the details of these relations are described in the appendix . this procedure estimates the 24 @xmath11 m photospheric outputs to about 2% rms , based solely on data at wavelengths short of 4 @xmath11 m . we then converted [ 24 ] to flux density units and used it to find the scaling factor for the photosphere model , which is given in table [ table : excessdata ] for targets with significant excess ( see  [ sec : blackbodyfitting ] ) . we finally applied a small multiplicative factor to the irs data if it clearly looked slightly offset from the photosphere model . then , we subtracted the photosphere model from the irs spectra and mips 70 @xmath3 point to obtain the infrared excess , @xmath12 . the photosphere model was assumed to have an uncertainty of 2% , thus the uncertainty in the excess flux density was @xmath13 ^ 2}.\\ ] ]       data are omitted from the right panels , as these points were not used to constrain the fits . ]    to interpret the excesses in a general way , we needed to assign them fiducial temperatures . the emission of disk grains is a function of their optical constants ; however , as discussed in [ sec : introduction ] , debris disks radiate like blackbodies at one or two temperatures . the simplest possible description of the emission is in terms of these temperatures . in this section , we describe how we determined if each target had significant excess and whether the excess was best described by one or two blackbodies . we fit @xmath14 with a one component blackbody model @xmath15 where @xmath16 is the planck function . the best - fit parameters , @xmath17 and @xmath18 were found by minimizing the reduced chi - squared , @xmath19 ^ 2 } { \\sigma_\\text{excess}\\left(\\lambda_i\\right)^2 } \\nonumber\\\\ & + 28\\frac { \\left[f_{\\nu\\,\\text{excess}}\\left(70 \\micron\\right)-f_{\\nu\\,\\text{model}}\\left(70 \\micron\\right)\\right]^2 } { \\sigma_\\text{excess}\\left(70 \\micron\\right)^2 } \\bigg\\},\\end{aligned}\\ ] ] where @xmath20 , n is the number of data points in the irs excess data , and n is the number of free parameters in the fit ( n=2 ) . the mips 70 @xmath3 data point was weighted in the fit as 28 irs data points , equivalent to the number of irs data points ( 0.7 @xmath3 resolution ) that would fit inside the equivalent width of the mips 70 @xmath3 spectral response function ( 19.65 @xmath3 ) . the fit was performed using matlab s lsqcurvefit algorithm . @xmath18 was constrained to between 0 and 500 k.    while @xmath17 represents the amplitude of the debris disk emission , a more useful measure of a debris disk s brightness is the fractional excess , @xmath21 . we calculated @xmath22 according to @xmath23 from equation 2 of @xcite . @xmath24 and @xmath25 are the peak flux density values of the disk emission and stellar photosphere emission , respectively , which occur at wavelengths @xmath26 and @xmath27 . while the peak flux densities for the disk components were easily calculated from our best fit model , the rayleigh - jeans stellar photosphere model had no maximum . to overcome this , we created a blackbody function using the temperature of the star from table [ table : stellarproperties ] , and scaled it to match the flux density of our rayleigh - jeans model at 24 @xmath3 . from this representation of the photosphere , we found the maximum flux density , and calculated @xmath22 . data are omitted from the right panels , as these points were not used to constrain the fits . ]    with our best fits in hand , we refined our sample to only those targets with statistically significant excess . first , we inspected all fits by eye and discarded targets with poor quality data that resulted in clearly unrealistic fits . second , we discarded targets with excess that was too faint , @xmath28 . third , we inspected the fits and identified all targets whose excess relied solely on the mips 70 @xmath3 data point ( i.e. there was no excess in the irs data ) . for these cases , we required this mips point to represent a significant excess , so we discarded targets where @xmath29 or where @xmath30 . this process resulted in 321 of the original 546 stars having no significant excess .    of the remaining 225 targets with significant excess , we next determined whether the excess consisted of one or two components . to do this , we fit the excess sed of each target with a model consisting of the sum of two blackbodies , @xmath31 finding the optimal set of the four parameters @xmath32 , @xmath33 , @xmath34 , and @xmath35 was again done by minimizing the reduced chi - squared ( equation [ eq : reducedchisq ] ) , now with n=4 . data are omitted from the right panels , as these points were not used to constrain the fits . ] our definition of  cold \" was the coldest well - detected component of the excess that was below 130 k. @xcite found a continuous distribution of warm components above @xmath9130 k , centered around 190 k , whose temperatures were set by the water ice line . thus , any component above 130 k was considered warm \" for the purposes of this study . a component with a temperature of 110 k , for example , would be considered warm if another , colder temperature component was also detected , but would be considered cold if no colder component was detected . to implement this , we fit each target once using 100 k as the division between warm and cold , and again with the division at 130 k. we then selected the better of these two cases ( based on reduced chi - squared ) to represent the best two - component model . for many targets , these two cases yielded identical fits . in both cases , the minimum cold temperature allowed by the fit was 0 k , and the maximum allowed warm temperature was 500 k.    deciding if each target warranted a two - component model was a two - step process . first , we required that the reduced chi - squared of the two - component fit be at least three times better than that of the one - component fit ( i.e. all targets where @xmath36/@xmath37 were deemed to be better fit by a single component ) . second , for the remaining targets , we identified those for which the presence of the cold component relied entirely on the mips 70 @xmath3 point , meaning the irs excess was entirely fit by the warm component . for these targets to have significant cold components , we required their mips 70 @xmath3 excess to fall more than 3@xmath8 above the excess predicted by the warm component . that is , if one of these targets had @xmath38 we concluded that it was best fit by one component . this step was analogous to the third step we performed when deciding if each target had excess or not . the targets that passed both of these criteria were deemed to have two components . this process identified 100 single - component cold disks , 51 single - component warm disks , and 74 two - component disks . we found only one target ( hip45585 ) that required two warm components ( both @xmath39130 k ) to fit properly , and we discarded this target from our results as it had no cold components ( it is counted in the 321 targets that we discarded ) . we found no targets requiring two components colder than 100 k. our methods were insensitive to possible additional cold components below @xmath950 k. we concluded that our fitting procedure allowed us to find all cold components above this limit . equivalently , our method reliably fit the inner edges of the cold disks . for the two - component disks , we calculated the fractional excesses for the warm and cold components , @xmath40 and @xmath41 , using equation [ eq : fwyatt2 ] . one - component excesses were deemed warm or cold depending if they had temperatures above or below 130 k. the verdicts for all targets are given in table [ table : stellarproperties ] and the parameters of our best fits for targets with significantly - detected components are listed in table [ table : excessdata ] . we estimated that the uncertainty in @xmath33 was 10 k. this estimate was conservative ; warmer cold components had more irs data points in excess of the photosphere , so their fits were more constrained , with a temperature uncertainty of 3 to 7 k.    we were unable to accurately constrain the temperatures of very cold components , which were detected only at 70 @xmath11 m . with only one data point , blackbodies at a wide range of cold temperatures could be given the amplitude necessary to match the point , so a degeneracy existed between t and @xmath22 in blackbody fits to the excess sed . we made this distinction at 45 k ; above this temperature there was enough information in the irs spectra to constrain the temperature . cold temperatures above 45 k were considered true detections , while cold temperatures below 45 k were considered unconstrained and were replaced with upper limits at 45 k. by using the 70 @xmath3 data to determine if such targets had significant excesses , we ensured that these disks were truly very cold , rather than warm but very faint . of the 174 cold components in our sample , 25 had temperature upper limits . some irs spectra exhibit mineralogical emission features ( e.g. hip41081 , hip57971 ) . our model did not explicitly account for these features , but they peak sharply at @xmath910 @xmath3 and do not resemble blackbody functions . these features did not influence our fits , except to raise the value of the minimum reduced chi - squared . the data and best fits for a small sample of our targets are shown in figures [ fig : twocompgallery ] , [ fig : coldcompgallery ] , and [ fig : warmcompgallery ] ( for targets with two components , one cold component , and one warm component , respectively ) . the left panels in all of these figures show the measured data with the photosphere and blackbody models , while the right panels illustrate the excess data and models with the photosphere subtracted . histograms of the significant warm and cold debris disk temperatures are shown in figure [ fig : temphistogram ] . 45 k around cooler stars . the green line is the best fit trend to the data , determined by a bayesian linear regression , @xmath42 . a representative error bar is in the lower right . ] @xcite studied the behavior of the warm disk components in detail , but their sample ( restricted to stars with ages less than 1 gyr ) had too few 70 @xmath3 detections of solar - type stars ( 9 ) to determine any trends between the cold component temperature and stellar type . to look for such a trend in our larger sample , we plot the cold component temperature versus stellar temperature in figure [ fig : tdisktstarscatter ] . well - constrained disk temperatures are black circles ( open circles are young systems with age less than 25 myr ) , and upper limits are downward facing blue triangles . although there is substantial scatter in the cold component temperatures , a positive correlation between cold debris disk temperature and stellar temperature is evident .    to quantify this trend , we fit a linear relation to the data by bayesian analysis using the routine linmix_err . the routine properly handles upper - limits , and it uses uncertainties in both x and y directions ( we assumed an uncertainty of 10 k in @xmath33 and 200 k in @xmath4 ) . in its model , the routine also includes the normally - distributed intrinsic scatter of the data around the trend . the posterior distributions of the slope , intercept , and intrinsic scatter from the bayesian regression are show in figure [ fig : trendposteriors ] . the slope of the linear regression was @xmath43 , thus the existence of a trend between @xmath33 and @xmath4 is significant at level greater than 4.5@xmath8 . the 1@xmath8 intrinsic scatter around the trend was @xmath44 k. the best - fit trend line from the bayesian analysis , @xmath42 , is plotted in green in figure [ fig : tdisktstarscatter ] . the choice of a linear fit is not physically motivated ; its purpose is to show that  to first order  there is a correlation between cold debris disk temperature and stellar type .    a significant source of scatter around the trend results from the 10 targets with @xmath45 k and @xmath46 k. six of these stars ( hip560 , hip64184 , hip64995 , hip65875 , hip67497 , and hip78663 ) are less than 25 myr old ( most are part of the scorpius - centaurus association ) . although we show in  [ sec : discussion ] that there is no significant trend in @xmath33 with age across the broad range of stellar ages in our sample , the excesses of these targets may be a product of their relatively young ages . they represent a period ( 5 - 50 myr ) when considerable collisional activity may still be occurring as a result of planet building @xcite .     vs. @xmath4 trend slope , intercept , and intrinsic scatter , generated by the linmix_err routine . ] we now consider what determines the temperature of cold debris disks and how a trend with stellar type might arise .    as discussed in  1 , @xcite found similar warm disk temperatures ( 190 k ) around stars of different stellar types , and they attributed the effect to a particle trap at the water ice line . if ice lines of other species set the location of cold debris disks , we would expect cold disks around different type stars to have a common temperature . however , the trend of cold component temperature with stellar type ( figure [ fig : tdisktstarscatter ] ) is inconsistent with any strictly temperature - dependent mechanism for setting the location of cold debris disks . @xcite show that during the protoplanetary disk phase , the water ice line location is time dependent , and predicting it requires accounting for viscous heating in the disk , as well as the evolution of the pre - main - sequence stellar luminosity . such considerations have not been applied to potential ice lines of species other than water , and we do not consider this level of detail here .    delayed stirring , in which the radial location of dust in a debris disk moves outwards with time , is a postulated mechanism for debris disk evolution @xcite . this could occur if the parent bodies are distributed in a broad ring . particles in a debris disk collide and grind into dust faster on smaller orbits where the dynamical timescale is shorter . thus , the location of the emitting dust moves outward with time , and , therefore , becomes cooler with time . because late type stars have longer lifetimes than early type stars , the late type stars in our sample are generally older than the early type stars . if delayed stirring occurs , then this age bias in our sample could explain the observed trend in @xmath33 with @xmath4 . to test this hypothesis , we plot @xmath33 against the age of the system ( if available ) for targets in three @xmath4 bins ( 5000 to 6000 k , 6000 to 7000 k , and 7500 to 9500 k ) , shown in figure [ fig : agevstdisk ] . we see no trend in @xmath33 with age in any bin , suggesting that delayed stirring does not produce the trend of disk temperature with stellar type . is plotted against the age of the system for targets in three @xmath4 bins . no trend is seen with age , suggesting age does not play a confounding role in our discovered @xmath33 vs. @xmath4 trend . this also argues against the occurrence of delayed stirring . ] perhaps cold debris disks are all at roughly the same orbital distance , regardless of stellar type . assuming the disk is heated to its equilibrium temperature , the relation between the disk s temperature , location , and stellar type is given by @xmath47 the second and third lines of equation [ eq : equilibriumtemp ] are derived assuming @xmath48 and @xmath49 ( valid in the roughly solar mass range ) . so with @xmath50 constant , early type stars would host warmer disks . @xcite perform detailed simulations of the evolution of debris disks with inner and outer edges at 30 and 150 au , respectively , around stars with mass ranging from 1 to 3 @xmath51 . their models output the disk emission at 24 and 70 @xmath3 , which show that the ( color ) temperature of these cold debris disks does increase with stellar mass , in agreement with this expectation . but is the orbital location of cold debris disks truly constant with stellar type ? if the size of cold debris disks traces the size of the original protoplanetary disks , we can use observations of the latter to address this question . @xcite find that protoplanetary disk mass and radius are related by @xmath52 furthermore , observations @xcite show that @xmath53 combining these relations yields @xmath54 so protoplanetary disk size does increase with earlier stellar type , albeit slowly . how quickly must the disk size increase for it to maintain a constant temperature ? from equation [ eq : equilibriumtemp ] , @xmath55 although the size of disks does increase with earlier spectral type , it does so more slowly than required to maintain a constant temperature , thus disks are expected to be warmer around early type stars , consistent with our findings . substituting equation [ eq : ppradius ] into equation [ eq : equilibriumtemp ] reveals how the disk temperature would vary with spectral type in this case : @xmath56 new results from @xcite suggest that equation [ eq : ppandstarmass ] may hold only for @xmath57 , with disk mass constant or possibly even decreasing as @xmath58 for higher mass stars . if this were true and translated into a flat or decreasing @xmath50 with @xmath59 , then the disk temperature would increase even faster with spectral type than derived in equation [ eq : migresult ] . is it plausible that the inner edge of cold debris disks scales with the size of the original protoplanetary disk ? some mechanism must clear the material inside cold debris disks and set their inner edge , and planets are a common explanation . an outwardly migrating planet would set an inner edge , but migration from planet - planet scattering can be a chaotic and unpredictable phenomenon ; simulations show that the planet s final location depends sensitively on the initial conditions of the system @xcite . this suggests that a trend with stellar temperature would not arise . outward migration via scattering through a smooth disk of planetesimals would proceed in a more orderly manner , and the planet would halt its migration when the surface density of planetesimals decreased below a certain threshold , at a location that scales with the size of the original protoplanetary disk . planet formation by core accretion ( without migration ) would also clear debris inside the cold component and create its inner edge . planetesimals would be either incorporated into the planets as they formed , or scattered away once the planets became massive enough to dominate the gravitational field in their vicinity . as mentioned in [ sec : introduction ] , core accretion efficiency declines with increasing orbital radius , leaving an outer zone of planetesimals beyond the planets . the timescale for the formation of a planet with a given mass scales as @xmath60 where p is the orbital period and @xmath61 is the surface density of solids . substituting kepler s third law , @xmath62 ( @xmath63 is the orbital distance ) and the typical protoplanetary disk structure , @xmath64 @xcite into equation [ eq : formationtime ] gives @xmath65 after a time ( @xmath66 ) planets will have formed out to a given orbital location ( @xmath63 ) , which sets the inner edge of the cold debris disk . so setting @xmath66 constant and @xmath67 predicts that the size of the disk would scale with spectral type as @xmath68 by comparing this with equation [ eq : equilibriumradius ] , we see that in this case as well , the size of the disk grows more slowly with stellar type than required to maintain a constant equilibrium temperature , consistent with our observational results . substituting equation [ eq : formradius ] into equation [ eq : equilibriumtemp ] shows how the disk temperature would vary with stellar type if its inner edge were set by the limits of planet formation : @xmath69 we studied the circumstellar environment of 546 main - sequence stars via the mid infrared emission of their debris disks , as measured by the _ spitzer _ space telescope . after subtracting a model of the flux expected from the stellar photosphere , we obtained an sed of the infrared excess for each target . we found 225 targets with significant excess : 100 with a single cold component , 51 with a single warm component , and 74 with two components . examining the results revealed a trend between the temperature of the inner edge of the cold debris disk component and that of its host star . photosphere magnitude for a sample of 1037 stars . the blue curve shows the gaussian fit to the distribution with @xmath70 and @xmath71 . ] this trend is inconsistent with theories that predict the location of cold debris disks to be strictly temperature - dependent , i.e. we rule out the dominance of ice lines in sculpting the outer regions of planetary systems . we also rule out delayed stirring as the source of this trend . the trend can potentially be explained if the outward migration of planets traces the extent of the primordial protoplanetary disk , which tends to be limited to warmer equilibrium temperatures for hotter stars . the trend can also be explained if planets form in situ out to a distance where the core accretion efficiency drops below a certain threshold , leaving a cold debris disk that is warmer around earlier type stars . we thank scott kenyon and benjamin bromley for helpful science discussions , and the referee for many useful comments . we also thank vianney lebouteiller for help in scripting the irs reduction pipeline . this work was supported by contract 1255094 from caltech / jpl to the university of arizona . we used the simbad database and the vizier catalogue access tool , operated at cds , strasbourg , france . we also used the nasa / ipac infrared science archive , which is operated by the jet propulsion laboratory , california institute of technology , under contract with nasa . this work is based on observations made with the _ spitzer _ space telescope , which is operated by the jet propulsion laboratory , california institute of technology under a contract with nasa . and we used data products from the two micron all sky survey , which is a joint project of the university of massachusetts and the infrared processing and analysis center / california institute of technology , funded by nasa and the nsf . finally , we used data products from the wide - field infrared survey explorer , which is a joint project of the university of california , los angeles , and the jet propulsion laboratory / california institute of technology , funded by nasa . here we describe how we used photometry to derive a model photosphere magnitude at 24 @xmath3 . the relation among v , @xmath5 , and [ irac ] used to predict [ 24 ] is equation [ eq : mips24fromivk ] , but a number of other relations were used beforehand to improve the accuracy of the result . first , we preprocessed @xmath5 , h , and j photometry to remove small nonlinearities in the relations . these small corrections to the 2mass photometry were derived by comparison with our all - sky warm mission measurements in irac band 1 . the preprocessing replaced @xmath5 with @xmath72 according to @xmath73 h with h according to @xmath74 and j with j according to @xmath75    equation [ eq : mips24fromivk ] utilizes @xmath76 , a combination of measured and derived @xmath5 magnitudes . one of these , @xmath77 , was derived by solving the relation among v , @xmath77 , and j , given by @xmath78 where @xmath79 . this relation is a fit to the behavior of more than 1000 main - sequence stars , as are the other relations that are given below . @xmath80 was derived ( if h was measured ) by solving the relation among v , @xmath80 , and h , given by @xmath81 where @xmath82 . @xmath76 was then calculated by averaging @xmath72 , @xmath77 , and @xmath80 with relative weights of 1 , 0.75 , and 0.47 , respectively . the weights were determined from typical 2mass errors and by minimizing the residuals in comparing the projected photospheric levels with the 24 @xmath11 m measurements . equation [ eq : mips24fromivk ] also uses @xmath83_\\text{super}$ ] , a combination of measured and derived irac magnitudes . the derived irac magnitude , @xmath83_1 $ ] , was calculated by solving @xmath84_1 = k_{s\\,\\text{super } } + 0.0012x^4 - 0.01448x^3 + 0.0419x^2 - 0.056x + 0.0295,\\ ] ] where @xmath85 . the measured [ irac ] and derived @xmath83_1 $ ] were averaged together with relative weights of 1 and 0.5 , respectively , yielding @xmath83_\\text{super}$ ] . finally , [ 24 ] was calculated with @xmath86 = [ \\text{irac}]_\\text{super } + 0.001x^5 - 0.0097x^4 + 0.0179x^3 + 0.0305x^2 - 0.0821x + 0.0312,\\ ] ] where , again , @xmath85 . this process required v and at least one of j , h , or @xmath5 to proceed . targets that did not have this minimum photometry available were not included in our sample , although nearly all targets in our sample had a complete suite of v , j , h , and @xmath5 photometry available ( table [ table : excessdata ] ) .    the accuracy and precision of this method is illustrated in figure [ fig:24accuracy ] , which shows the distribution of the difference between the observed and predicted [ 24 ] for over 1000 stars . a gaussian fit to this distribution ( the blue curve ) has a mean of 0.00158 and a standard deviation of 0.0224 . cccccccccccccccc hip345 & 6.39 & 6.28 & 6.25 & 6.26 & & 8843 & & 35.7 @xmath6 0.38 & 97.24 @xmath6 5.35 & 11.9 & 94.9 @xmath6 5.35 & 53 & 185 & 9.42 & 4.56 + hip490 & 7.53 & 6.46 & 6.19 & 6.12 & & 5923 & & 28.39 @xmath6 0.3 & 152.7 @xmath6 9.71 & 14.2 & 149.9 @xmath6 9.71 & 48 & & 42 & + hip544 & 6.13 & 4.73 & 4.63 & 4.31 & & 5405 & & 159.1 @xmath6 1.58 & 105.8 @xmath6 6.32 & 72.6 & 91.57 @xmath6 6.33 & 50 & 126 & 4.99 & 4.78 + hip560 & 6.19 & 5.45 & 5.33 & 5.24 & & 6635 & & 117.2 @xmath6 1.12 & 67.08 @xmath6 7.06 & 31.6 & 60.89 @xmath6 7.06 & 129 & & 18.4 & + hip682 & 7.59 & 6.42 & 6.15 & 6.12 & & 5809 & & 36.49 @xmath6 0.39 & 170.6 @xmath6 10.62 & 14.7 & 167.7 @xmath6 10.6 & @xmath8745 & 119 & 47.3 & 11.6 + hip1031 & 7.23 & 5.85 & 5.47 & 5.38 & & 5372 & 1.9 @xmath6 0.03 & 50.67 @xmath6 0.51 & 22.51 @xmath6 4.98 & 27.8 & 17.07 @xmath6 4.99 & 50 & & 3.29 & + hip1368 & 9 & 6.38 & 5.75 & 5.58 & & 3903 & 1.7 @xmath6 0.03 & 46.6 @xmath6 0.48 & 20.74 @xmath6 5.15 & 26.5 & 15.55 @xmath6 5.15 & @xmath8745 & & 9.99 & + hip1473 & 4.52 & 4.34 & 4.42 & 4.46 & & 9164 & & 154.4 @xmath6 1.56 & 43.82 @xmath6 6.5 & 65.7 & 30.94 @xmath6 6.51 & & 133 & & 1.38 + hip1481 & 7.46 & 6.46 & 6.25 & 6.15 & & 6258 & & 34.76 @xmath6 0.36 & -0.83 @xmath6 2.98 & 13.7 & -3.518 @xmath6 2.98 & & 217 & & 11.9 + hip1499 & 6.46 & 5.33 & 5.04 & 4.89 & & 5692 & 2.95 @xmath6 0.03 & 80.94 @xmath6 0.81 & 61.43 @xmath6 6.81 & 43.1 & 52.98 @xmath6 6.81 & 54 & & 5.54 & + hip2072 & 3.9 & 3.74 & 3.58 & 3.51 & & 8131 & & 311.2 @xmath6 3.1 & 72.97 @xmath6 4.43 & 143 & 44.94 @xmath6 4.47 & @xmath8745 & 169 & 0.577 & 1.47 + hip2472 & 4.77 & 4.67 & 4.77 & 4.7 & & 9096 & & 112.5 @xmath6 1.12 & 76.98 @xmath6 6.54 & 49.5 & 67.27 @xmath6 6.54 & 69 & 192 & 1.47 & 1.5 + hip2578 & 5.07 & 5.06 & 5.16 & 4.99 & & 9028 & & 232 @xmath6 2.31 & 56.48 @xmath6 4.13 & 35.5 & 49.52 @xmath6 4.13 & & 194 & & 15.6 + hip2710 & 6.91 & 6.04 & 5.85 & 5.75 & & 6473 & 1.33 @xmath6 0.02 & 40.62 @xmath6 0.44 & 104.7 @xmath6 6.5 & 19.8 & 100.8 @xmath6 6.5 & @xmath8745 & 110 & 16.5 & 2.94 + hip2843 & 6.71 & 5.84 & 5.66 & 5.59 & & 6510 & 1.57 @xmath6 0.03 & 42.13 @xmath6 0.46 & 21.54 @xmath6 3.76 & 23.3 & 16.98 @xmath6 3.76 & 64 & & 2.43 & +    ccc v & 0.5423 & 3729 + 2mass j & 1.241 & 1623 + 2mass h & 1.6513 & 1075 + 2mass @xmath5 & 2.1657 & 676 + wise 1 & 3.35 & 309.54 + wise 2 & 4.60 & 171.79 + wise 3 & 11.56 & 31.67 + wise 4 & 22.09 & 8.36 + irac 1 & 3.6 & 269.53 + mips 24 & 23.675 & 7.17 + mips 70 & 71.42 & 0.778 +", "tags": [], "output_text_a": "The paper investigates the formation and migration of giant planets in planetary systems, focusing on the role of debris disks as indicators of wide-orbit planets. It highlights the destructive potential of inward migration of massive planets on smaller, habitable zone planets and emphasizes the importance of identifying systems with giant planets on wide orbits. The study uses data from the Spitzer Space Telescope to analyze debris disks, which consist of solid material left after the protoplanetary disk gas has dispersed. These disks are often detected as infrared excesses in the spectral energy distribution of their stars.\n\nThe research examines the temperatures of cold debris disks and their correlation with the temperature of their central stars, suggesting that the location of these disks is influenced by the presence of ice lines and planets. The study finds a trend between the temperature of cold debris disks and stellar type, indicating that disks are warmer around earlier type stars. This trend is inconsistent with theories that predict the location of cold debris disks to be strictly temperature-dependent, such as those dominated by ice lines.\n\nThe paper proposes that the trend can be explained if the outward migration of planets traces the extent of the primordial protoplanetary disk or if planets form in situ out to a distance where core accretion efficiency drops. The study concludes that the inner edge of cold debris disks is likely set by the limits of planet formation or migration, rather than by temperature-dependent mechanisms like ice lines. The findings provide insights into the processes of planet formation and migration on wide orbits, contributing to our understanding of planetary system evolution.", "output_text_b": "This arXiv paper discusses the formation and migration of giant planets in planetary systems, with a focus on how inward migration of these planets can affect smaller objects in the system, such as Earth-sized planets within the habitable zones. The paper highlights the importance of determining how many systems retain their giant planets on wide orbits, as direct detection of these planets is limited to the most massive examples. Indirect detection through debris disks is used to address this limitation. A debris disk consists of the circumstellar solid material that remains after the protoplanetary disk gas has dispersed and giant planets might have formed. Although most of the mass in a debris disk is harbored by the parent bodies (planetesimals), dust generated in their collisions accounts for the majority of the disk's surface area. Observations of debris disks via their thermal emission or reflected stellar radiation trace this dust.\n\nThe paper explains that debris disks often appear constrained to one or two discrete rings, which can be explained by ice lines or planets causing the discrete ring structures. If ice lines are responsible for setting the location of the cold components, it is expected that these components would have similar temperatures over a range of stellar types. Planets may also cause the discrete ring structures, as planetesimals will be scattered away once a planet is massive enough to dominate the gravity in its vicinity.\n\nThe authors also discuss the use of cold debris disks to investigate wide-orbit planets, which are not easily studied by other means. They focus on Spitzer measurements of cold debris disks, showing how their temperatures vary with the temperature of their central star and what this implies about planet formation and migration on wide orbits.", "score": 0.5, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper, discussing the role of debris disks in understanding planet formation and migration.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem, focusing on the formation and migration of giant planets and the role of debris disks.\n4. The methodology, involving the use of data from the Spitzer Space Telescope, is mentioned.\n5. Significant results, such as the trend between cold debris disk temperature and stellar type, are included.\n6. The language is clear and professional.\n7. Technical jargon is minimized, and terms like \"debris disks\" and \"infrared excess\" are explained.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key data from the Spitzer Space Telescope is mentioned.\n10. The summary reflects the paper's significance in understanding planetary system evolution.", "1. **Accurate Reflection of Main Findings**: The summary captures the main findings related to the formation and migration of giant planets and the role of debris disks in detecting wide-orbit planets. However, it lacks specific details about the trend between the temperature of cold debris disks and their host stars, which is a significant finding in the paper.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary mentions the research problem of understanding the formation and migration of giant planets and their impact on smaller objects in planetary systems.\n\n4. **Methodology or Approach**: The summary briefly mentions the use of Spitzer measurements and indirect detection through debris disks but lacks detail on the specific methods used, such as photometric data analysis and blackbody fitting.\n\n5. **Significant Results or Conclusions**: The summary mentions the importance of determining systems with giant planets on wide orbits and the role of debris disks but does not highlight the specific results regarding the correlation between disk temperature and stellar type.\n\n6. **Clear and Professional Language**: The language used is clear and professional.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like debris disks and ice lines.\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary does not mention specific experiments or data, such as the sample of 546 stars or the use of MIPS and IRS data.\n\n10. **Significance or Potential Impact**: The summary does not explicitly reflect the paper's significance or potential impact, such as its contribution to understanding planet formation and migration theories."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the precise test of semiclassical approximations in the presence of chaos is of grest interest to establish the limits of applicability of periodic orbit theory and its resummations . this test can be done in model systems both on approximations to the spectrum or to the stationary states . for the calculation of the spectrum the most efficient tool in this respect seems to be the spectral determinant @xcite and several calculations @xcite have demonstrated that , given enough periodic orbits , the spectrum can be accurately represented semiclassically . however , a more sensitive test - and still a great challenge - is the semiclassical representation of single eigenfunctions . this includes the study of the scar phenomena @xcite and the eventual deviations from uniformity of eigenfunctions in accordance to the berry - voros hypothesis @xcite and schnirelman s theorem @xcite .    just as for spectral problems , the use of fredholm methods allows for the most efficient encoding of classical information in the calculation for single eigenfunctions @xcite . in this paper we review these methods and apply them to the calculation of husimi distributions of stadium eigenfunctions . this paper is organized as follows . in sec . [ secform ] we review the fredholm method for billiard eigenfunctions . fredholm theory allows us to find the solution to certain type of integral or operator equations @xcite . for billiards these methods can be applied to the boundary integral equation . in sec . [ secapro ] we make the semiclassical approximation that is based on the approximation of the traces and powers of the propagator as sums over the periodic points of the underlying classical system . the propagator itself is taken as bogomolny s @xmath0 operator @xcite . we choose the coherent state representation and obtain an expression for the semiclassical husimi representation of the eigenfunctions in terms of classical invariants : periodic points , their monodromy matrices and maslov indeces . in sec . [ secauto ] we apply this scheme for the stadium billiard . our conclusions and perspectives are presented in sec . [ secconclu ] . fredholm theory gives the solution to a certain class of integral equations , which can also be written as operator equations @xcite . a fredholm integral equation of second type is ( q)=_0(q)+dq * t*(q,q ) ( q ) . all the functions are defined in a finite domain . if the known functions @xmath1 and @xmath2 are well behaved , the fredholm alternative holds : there is a unique solution @xmath3 with the same analytic properties or the homogeneous equation ( @xmath4 ) has a solution . there is a set of complex parameters @xmath5 for which the solution is not unique . in operator notation , the inverse of @xmath6 exists if @xmath7 . in this case , this inverse can be written as [ fredexp ] 1=*m * ( ) , where the operator @xmath8 and the function @xmath9 are series in @xmath10 . if @xmath0 is a compact operator , @xmath9 and @xmath8 are entire in @xmath10 and , thus , absolutely convergent . the explicit form for the series expansion in terms of powers of @xmath0 is given below . in what follows we apply this general theory assuming @xmath11 to be unitary and of finite dimension @xmath12 . both assumptions are justified in the semiclassical limit for the quantization of billiards @xcite . the @xmath13 s eigenvalues are given by the secular equation @xmath14 . we can expand this determinant as p(k )  =  _ n=0^n _ n(k ) , where the coefficients @xmath15 are related to the traces of @xmath16 , @xmath17 , through [ betac ] _ n(k )  =  -1 _ j=1^n _ n - j(k ) b_j(k ) . thus , knowledge of the traces up to a certain @xmath18 implies the knowledge of the coefficients @xmath19 up to the same @xmath18 . if @xmath16 is unitary , @xmath20 is self reversive , meaning that its coefficients satisfy _ n - j(k )  =  ( -1)^n      this condition alone forces the eigenvalues of @xmath11 at fixed @xmath13 to be symmetric with respect to the unit circle : if @xmath10 is an eigenvalue , then @xmath21 is an eigenvalue too . of course , if @xmath11 is unitary , then this condition is automatically satisfied but we can use it in our semiclassical approach to partially restore unitarity . the contributions from coefficients @xmath22 with @xmath23 $ ] can be expressed in terms of coefficients @xmath22 with @xmath24 $ ] . ( @xmath25 $ ] is the integer part of @xmath26 . ) so , if @xmath12 is even : p(k)=(k)+  |(k ) , + ( k)=_j=0^n/2 - 1 _ j(k)+12 _ n/2 ,   = _ n/2 . if @xmath12 is odd : p(k)=(k)-  |(k ) , + ( k)=_j=0^(n-1)/2 _ j(k ) ,   = -_(n+1)/2 . as a consequence of the imposition of this symmetry on the operator @xmath0 we obtain two advantages : only traces up to half the heisenberg time @xmath27 are needed and the eigenvalues are constrained to lie on the unit circle or in symmetric pairs . these formulae relate @xmath20 with the traces of powers of @xmath16 which , in turn are related semiclassically to periodic orbits and to the smoothed density of states @xcite . they have been tested extensively for the hyperbola billiard by keating and sieber @xcite .      to extend these methods to the calculation of eigenfunctions , we define a generalized green function @xmath28 : ( k )  =  * t*(k ) . this operator has poles at the billiard eigenvalues @xmath29 and its residues are the projectors onto the corresponding eigenfunctions . it has a fredholm expression as ( k)= * t*(k ) * c*^t(1- * t*(k ) ) , where @xmath30 is the transpose of the cofactor matrix of @xmath31 and , as in eq . ( [ fredexp ] ) , has an expansion in powers of @xmath16 . it is then convenient to define a _ normalized green operator _ as ( k )  =  * g*(k ) , where the singularities in the denominator have been eliminated . the normalized green operator has the property @xmath32 , where @xmath33 is the eigenvector corresponding to eigenvalue @xmath34 . then , we can write @xmath35 in the following way : ( k )  =   * t*(k )  c^t(1- * t*(k ) )    as the cofactor matrix can be expanded in powers of the propagator and as the propagator itself is unitary we write the normalized green operator in terms of the powers of the propagator and their traces up to @xmath36 ( if @xmath12 is even ) : [ proyec ] * g*(k)= _ i=0^n 2 - 1 c_i(k ) * t*^i+1(k ) - ( k )   _ i=0^n 2 - 1 |c_i(k ) * t*^ i(k ) , where the coefficients @xmath37 are given by [ cico ] c_i(k )  =  _ n = i^n 2 - 1 _ n - i(k ) . an analogous formula can be derived in case @xmath12 is odd . the coefficients @xmath37 are dependent on the traces of @xmath38 through eqs . ( [ betac ] ) and ( [ cico ] ) and thus are independent of the chosen representation . on the other hand , the expression for the powers of the propagator will depend on the representation chosen for the calculation of the eigenfunctions . if the coordinate representation @xmath39 is chosen , eq . ( [ proyec ] ) relates the probability density @xmath40 to the diagonal powers of the propagator @xmath41 . if the weyl representation is chosen , then eq . ( [ proyec ] ) gives the wigner distribution of @xmath42 in terms of the weyl propagator @xcite . here we choose the coherent state representation to find the equivalent husimi distribution . we remark that eq . ( [ proyec ] ) is a very compact and representation independent derivation of formulae that were previously very laboriously derived for the wigner case . it prepares in an optimal way the grounds for the semiclassical approximation because its ingredients are all dependent on classical elements , namely periodic orbits , phase space volume and generating function .    using the fact that at @xmath29 the normalized green function is the projector onto the corresponding eigenstate , we can obtain the husimi distribution as [ husimm ] h__(z,|z )  =   z| * g*(k_)|z  =  1   _ i=0^n 2 - 1 c_i(k ) z| * t*^i+1(k)|z  -   ( k )   _ i=0^n 2 - 1 |c_i(k ) z| * t*^  i(k)|z . this scheme was successfuly applied in simple quantum maps @xcite . green s theorem allows us to reduce the schrdinger equation for the billiard with dirichlet boundary conditions to the following linear homogeneous equation for the normal derivative on the border @xmath43 [ intecphi ] ( s ) = -2 ds ( s ) * k*(s , s;k ) , where the kernel is ( s , s;k ) = -ik2 ( s )   h_1^(1)(k|*r*(s)-*r*(s)| ) , with @xmath13 the wave number , @xmath44 the angle between the normal at @xmath45 and the line that connects @xmath46 with @xmath47 ( see fig . [ figbillar ] ) and @xmath48 the hankel function of first type and order one . we introduce the wave function @xmath49 ( p)=1 ( p ) , with @xmath50 and @xmath51 the momentum representations of @xmath43 and @xmath49 . this transformation makes the kernel symmetric and turns eq . ( [ intecphi ] ) to [ intecbogo ] ( s )  =  ( s,s;k ) ( s ) ds.    the semiclassical theory of the kernel @xmath52 @xcite is based on two fundamental properties : @xmath0 is semiclassically unitary and has an effective dimension @xmath53 , where @xmath54 is the length of the billiard . moreover , the kernel is given by the generating function of the classical birkhoff map ( see eq.([bogot ] ) ) . these properties have been extensively tested @xcite and will be assumed in what follows . thus , we make the semiclassical approximation by taking @xmath0 as bogomolny s operator ( [ bogot ] ) and by evaluating all integrals by stationary phase approximation . the @xmath0 operator for convex billiards in the plane , taking its border as poincar section and using birkhoff coordinates is [ bogot ] * t*(s,s;k)= ( k ) ^ 1 2 | ^2 l(s,s ) |^1/2 ( i k l(s,s ) - i 2 ) , where the bounce map generated by @xmath55 , the arc length between @xmath45 and @xmath56 ; @xmath57 is the maslov index . the quantization condition is @xmath58 .    in the semiclassical theory for the spectral determinant p(k)=(1-*t*(k ) ) the approximate unitarity of @xmath11 can be used efficiently to reduce the number of periodic orbits needed for the computation of the spectrum . similar manipulations of the fredholm formulae allow for the same reduction in the semiclassical calculation of single eigenfunctions of the billiard . we write down a formula giving the projector on single eigenfucntions as a finite sum involving powers of the map @xmath11 and its traces . first we need the traces . it is a well known fact that they adopt the following semiclassical expression @xcite : _ scl= _ po , n = n_pr   n_p   ( i r ( k l_p - _ p /2 ) ) , where the sum goes over all the primitive po s of the billiard with period @xmath59 , which must be a divisor of @xmath60 , maslov index @xmath61 , length @xmath62 and monodromy matrix @xmath63 . the maslov index can be interpreted geometrically : @xmath64 is the angle swept by the unstable manifold of @xmath63 along the po . the determinant of @xmath0 can be obtained as @xcite _ scl=(-1)^n   ( 2 in(k ) ) , where @xmath65 , the number of states between 0 y @xmath13 , is ( k)=1 a k^2 - 1 l k , with @xmath66 the area of billiard and @xmath54 its length . these are the semiclassical ingredients needed for the calculation of the spectrum and of the coefficients @xmath37 . we first obtain the coherent state representation for one iteration of the bounce map : z|*t*|z=  ds  ds  z|s  s|*t*|s  s|z . that is to say : [ repec ] z|*t*|z=(k ) ^1/2 ( k ) ^1/2 ^(-i/2 ) ds ds |^2 l |^1/2 where ( s,s)= i2z^2+i2z^2 i s^2- izs+ i s^2- i|zs+l(s,s ) , and @xmath67 and @xmath68 . the most important contributions come from those points @xmath69 and @xmath70 that make stationary the phase @xmath71 : [ spa ] ( s^*,s^*)= i s^*- i |z+ l(s^*,s^*)=0 + ( s^*,s^*)= i s^*- i z+ l(s^*,s^*)=0 . the solution to ( [ spa ] ) satisfying the reality conditions is s^*=q  l(s^*,s^*)=-p + s^*=q  l(s^*,s^*)=p. this is a classical trajectory from @xmath72 to @xmath73 . thus , the matrix element @xmath74 will be non zero only if @xmath75 and @xmath76 are connected by the classical dynamics . let us call these points @xmath77 and @xmath78 and let us calculate the matrix element to next order in their neighbourhoods , @xmath79 . to this effect we expand @xmath80 in eq . ( [ repec ] ) to second order and , after some algebra : [ phiphi ] ( s,s ) l(q_c , q_c ) + + + + + , where @xmath81 and @xmath82 . we change to new integration variables @xmath83 and @xmath84 and obtain : [ repec2 ] z_c+z|*t*|z_c+z(k ) ^1/2 ( k ) ^1/2  ds   ds   |^2 l |^1/2 we now insert eq . ( [ phiphi ] ) in eq . ( [ repec2 ] ) . all terms are constant with respect to integration except the last one in square brackets . the resulting integral is the coherent state representation , with respect to @xmath85 , of the linearized map , whose generating function is quadratic , which we have introduced in ec . ( [ reprelin ] ) : [ potprop ] z|*t*|z  =   1   , where @xmath86 y @xmath87 are the matrix elements of the linearized map in complex coordinates . finally we arrive at : [ final ] z_c+z|*t*|z_c+z + z|*t*|z . this result lets us evaluate the matrix element we were looking for , @xmath88 , that will be a sum of contributions of periodic points @xmath89 of period @xmath60 in the semiclassical limit : _ pp , n z_pp+z|*t*^n|z_pp+z . to obtain the composition @xmath90 we use the expression ( [ final ] ) and the composition rule of eq . ( [ compo ] ) . then _ pp , n 1   _ pp , where @xmath91 can be calculated by eq . ( [ compo2 ] ) , @xmath92 ( because of the dirichlet boundary conditions ) and @xmath93 is the length of the po starting from @xmath94 . as we can see , the matrix element behaves as a gaussian in the vecinities of the periodic point . this allows us to write the husimi representation of the @xmath60-th power of the propagator as a sum of contributions from periodic points of period @xmath60 . each term of the sum is a gaussian packet in phase space whose parameters are related to the monodromy matrix in complex coordinates . a po composed by @xmath60 points will give @xmath60 _ different _ contributions to this sum , due to the fact that the monodromy matrices at each point differ . however , the invariant properties of these matrices are the same and the usual gutzwiller - tabor trace formula @xcite can be recovered by integration . of course , a periodic point of period @xmath60 will contribute also to the @xmath95 ( @xmath96 natural ) powers of the propagator . we should remark at this point that the different semiclassical representations of the propagator in terms od the corresponding generating function are only _ semiclassically _ equivalent and thus can give different results at finite @xmath12 . this is not true for the calculation fo the spectral determinant , whose semiclassical expression in terms of periodic orbits is the same in all representations . it is because of this that the different ways of computing eigenfunctions are not equivalent . for the calculation of @xmath97 the closed ( but not necesarily periodic ) orbits are needed @xcite . for the wignaer function calculation only periodic points are needed but each contribution is extended in phase space . in the present formalism we will obtain the husimi distributions of eigenfunctions in terms of deformed localized gaussians centered in the periodic points , constructed solely in terms of classical information .    our system , the stadium billiard , has two discrete spatial symmetries : @xmath98 and @xmath99 , the two reflections with respect of the coordinate axes . these spatial symmetries in the domain reflect in the border and , thus , in the classical and quantum map on it . their action on the birkhoff coordinates of phase space @xmath72 is [ simets ] r_x ( q , p )   ( l - q ,- p ) ,   r_y ( q , p )   ( l 2-q ,- p ) ,   r_x r_y ( q , p )   ( l2+q,+p ) . in order to have coherent states on the border with correct symmetries we need to project them using @xmath100 and @xmath101 , the unitary representations of the symmetries @xmath102 and @xmath103 . then we define |z__x _ y  =   ( 1+_x * r*_x2 ) ( 1+_y * r*_y2 ) |z , where @xmath104 and @xmath100 and @xmath101 move the center of the coherent state according to ec . ( [ simets ] ) .    in this way , the diagonal matrix elements of the propagator in symmetrized coherent state representation are [ cssim ] 1 z|*t * ( 1+_x * r*_x2 ) ( 1+_y * r*_y2 ) |z = 1 ( z|*t*|z+ _ x z|*t**r*_x|z+ _ y z|*t**r*_y|z+_x _ y z|*t**r*_x*r*_y|z ) . we have already calculated @xmath105 . we still have to calculate the other three contributions , @xmath106 , @xmath107 and @xmath108 . we can conclude using the results we have already obtained that each of them will be a sum of gaussians centered in those points @xmath75 that the dynamics connects with their symmetric partners , @xmath109 , @xmath110 , @xmath111 , respectively . these points belong to pos whose periods are @xmath112 which are symmetric under the operations @xmath98 , @xmath99 , @xmath113 , respectively . the increment @xmath114 with respect to @xmath115 ( @xmath116 ) is related to the increment @xmath117 with respect to @xmath75 through : r z = t_r z ,   t_r=\\ {    lc -1 r = r_x + -1 r = r_y + 1 r = r_xr_y . +    . thus we arrive at : _ pp,2n 1   _ pp , where the sum goes over the periodic points of period @xmath112 that belong to pos symmetric under @xmath118 . the quantities @xmath119 , @xmath120 , @xmath93 , @xmath121 and @xmath91 are calculated along the trajectory that connect @xmath75 to @xmath122 , i.e. , half po . we use the semiclassical approach we introduced above for the stadium billiard . we choose odd - odd symmetries ( @xmath123 ) and @xmath124 . we have periodic points with desymmetrized period up to 8 ( around 800 ) . we have used the symbolic dynamics developed by biham and kvale @xcite to obtain them . the wave number @xmath13 is related to the maximum period used in the expansion ( [ husimm ] ) by @xmath125 . in this way we can obtain semiclassical approximations of eigenfunctions of wave number @xmath126 .    in fig . [ propquan ] we show the phase space representations of the first six powers of bogomolny s @xmath0 operator for @xmath127 ; in fig . [ propsemi ] , the semiclassical approximations . we see that the exact representations show global maxima in the bouncing ball region that can not be reproduced semiclassically for the lowest powers . however , the overall semiclassical behaviour is very close to that of the exact representations . ( because of the symmetries we chose , we have no semiclassical approximation to the first power of the operator because the contribution of the only periodic point of period 1 is zero . ) we select two energy ranges : @xmath128 $ ] and @xmath129 $ ] . there are 4 eigenenergies in each of these ranges . we show the absolute value of the secular determinant , @xmath130 , for each of them in figs . [ detsecu1 ] and [ detsecu2 ] . the full line is the semiclassical approximation , the dashed line is the secular determinant for bogomolny s operator . the vertical lines are the exact quantum @xmath13 eigenvalues calculated by the scaling method @xcite . we see a good approximation when we use the periodic point expansion . the agreement shows that in this region the spectrum is well represented semiclassically . ( the discontinuities come from the change in dimension of the operator ) .    to keep the method consistent we evaluated the semiclassical husimi expansion in those values of @xmath13 that minimize the semiclassical secular determinant . we see in figs . [ semih1 ] and [ semih2 ] the exact eigenfunctions ( first column ) and their corresponding semiclassical husimi representations ( second column ) obtained as the real part of eq . ( [ husimm ] ) . the global behaviour is well reproduced ; however , the finer details are hard to mimic . the bouncing ball region is problematic : in some functions ( e.g. , @xmath131 ) some probability leaks to this region . probably pos with longer periods that approximate the bouncing ball orbits could make a better picture for this region . one of the advantages of formula ( [ proyec ] ) for the projector is that it has no singularities between eigenvalues . it is possible to study continualy its behaviour as a function of @xmath13 in order to see its sensitivity to changes in @xmath13 . some properties of the exact distribution as a function of @xmath13 are :    * the distribution is positive at the eigenvalues @xmath132 . * the distribution has @xmath133 zeros at eigenvalues @xmath132 . these two properties follow from the fact that @xmath134 is the modulus of an analytic function . the distributions between eigenvalues can become negative . in particular , it can be shown that at the value of @xmath13 that maximizes @xmath20 , the distribution is constant . this properties can be used to control the semiclassical approximations .    in figs . [ movie1 ] and [ movie2 ] we show the behaviour of the distribution @xmath135 between the semiclassical eigenvalues @xmath136 and @xmath137 . when @xmath136 the distribution is positive and has well defined minima that approach zero . as we move away from the eigenvalue , the distribution changes smoothly . initialy it moves away from the plane @xmath138 in the positive direction , then it comes back and turns negative . during this `` evolution '' it flattens visibly and we ca nt discern its features . at @xmath139 , aproximately the maximum of the secular determinant , see fig . [ detsecu1 ] , the distribution is constant . at the semiclassical eigenvalue @xmath137 the distribution is positive again with well defined minima . we can see from figs . [ semih1 ] and [ semih2 ] that the semiclassical approximation is relatively good . it is not trivial to obtain a positive defined distribution with @xmath12 zeroes adding several hundreds of gaussians , each with its phase and deformation . using fredholm theory we have given a very compact and representation independent derivation of the projector on a single eigenfunction for unitary quantum maps . expressing the projector in the coherent state basis we wrote a semiclassical expression for the husimi distributions of the billiard s eigenfunctions . each periodic point contributes with a gaussian centered in it whose parameters are calculated only with classical information . we should not underestimate the difficulties and complexities inherent to this method . hundreds of gaussian contributions have to conspire to make a positive definite distribution with @xmath12 that approximate the quantum husimi distributions . the projector ( [ proyec ] ) can be represented in coordinate space . we obtain @xmath140 , whose semiclassical approximation can be directly compared to the probability density in the section . this representation has an additional difficulty , since the semiclassical approximation is written as a sum over closed trajectories , periodic or not , in configuration space . those that are not periodic are more in number and more difficult to find . anyway , we can apply our scheme for bogomolny s @xmath2 operator and compare the results with the exact quantum calculation . in fig . [ psi2bogo ] we see that the approximation is excelent at this level . the maximum period @xmath141 in the expansions is related to the energy in the way @xmath142 . due to the exponential proliferation of orbits in chaotic systems , the method can not be applied for arbitrarily high energies . the measure of this proliferation is the topologic entropy @xmath143 which relates the number @xmath144 of pos of a given period @xmath141 with the period itself , @xmath145 @xcite . for the stadium , @xmath146 . then , for @xmath147 we need pos of periods up to @xmath148 , whose number is @xmath149 ! the fredholm method we developed is a first step and shows that the eigenfunctions can be described as expansions in terms of the periodic points of the underlying classical system . it eliminates the divergencies associated that the schemes based on smoothings in energy have . however , the exponential divergence of periodic orbits poses a serious practical problem , as discussed in the previous paragraph . this method can only become practical for large @xmath34 if some way of selecting a few `` important '' orbits at each value of @xmath13 can be developed . some results in this direction have been obtained by vergini and carlo @xcite . we introduce the following symplectic transformation @xmath150 , depending upon parameter @xmath151 , acting on a point of classical phase space @xmath72 @xcite : [ defz ] (    lc z + p_z +    )  =   z (    lc q + p +    )  =   (    lclc 1/ & -i/ + -i/ & / +    ) (    lc q + p +    ) . imposing reality conditions on the inverse transformation we see that @xmath152 . a linear transformation @xmath153 in @xmath72 phase space has a representation @xmath154 in @xmath155 phase space by conjugation with @xmath150 m_z = z m z^-1= (    lclc |s & -ir + i|r & s +    )  \\ {    lc s  =  1 2 + r  =  1 2    . . this @xmath155 phase space allows a passage to quantum mechanics . this is done in a hilbert bargmann space by introducing operators @xmath156 and @xmath157 that satisfy the conmutator relations = i ,  [ * z*,*z*]= [ * p_z*,*p_z*]=0 . any vector @xmath158 in hilbert space can be represented in this new space as @xmath159 , where the coherent states are @xmath160 . the scalar product is @xmath161 with norm @xmath162 . we now define the husimi representation of a vector @xmath163 as _ ( z )   | z | |^2 . it is a real positive function for every @xmath75 in the complex plane . the representation of a linear symplectic transformation @xmath164 in phase space in terms of a unitary operator of hilbert bargmann space is @xcite [ reprelin ] m  =   (    lclc a & b + c & d +    )   z|*u*(m)| z = 1 |  ( -i 2 ( |s ) ) . this representation is up to a phase @xcite and its composition law is [ compo ] z|*u*(m_1)| z z|*u*(m_2)| z d(z )   =  ( m_1,m_2,m_1m_2 )   z|*u*(m_1m_2)| z  , with [ compo2 ] ( m_1,m_2,m_1m_2 ) =  =  1 . the accumulated phase due to succesive transformations leads to the maslov index of the trajectory .    in case the phase space shows periodicity in coordinate or momentum , we have to periodize the coherent states as in @xcite .    99    e. b. bogomolny , nonlinearity * 5 * , 805 ( 1992 ) . a. voros , j. phys . a * 21 * , 685 ( 1988 ) . j. p. keating and m. sieber , proc . a * 447 * , 413 ( 1994 ) . e. j. heller , in _ chaos and quantum physics _ , proceedings from les houches 1989 ( north - holland , amsterdam , 1989 ) . e. b. bogomolny , physica d * 31 * , 169 ( 1988 ) . m. v. berry , proc . a * 423 * , 219 ( 1989 ) . o. agam and s. fishman , phys . lett . * 73 * , 806 ( 1994 ) . d. klakow and u. smilansky , j. phys . a * 29 * , 3213 ( 1996 ) . f. p. simonotti , e. vergini and m. saraceno , phys . e * 56 * , 3859 ( 1997 ) . l. kaplan and e. j. heller , ann . ( ny ) * 264 * , 171 ( 1998 ) . m. v. berry , j. phys . a * 10 * , 2083 ( 1977 ) . a. voros , in _ stochastic behaviour in classical and quantum hamiltonian systems _ , eds . g. casati y g. ford , lectures notes in physics * 93 * ( springer , berlin , 1979 ) , p. 326 . a. shnirelman , usp . mat * 29 * , 181 ( 1974 ) . s. fishman , b. georgeot and r. e. prange , j. phys . a * 29 * , 919 ( 1996 ) . f. smithies , _ integral equations _ , cambridge tracts in mathematics and mathematical physics * 49 * , ( cambridge university press , cambridge , 1962 ) . a. ozorio de almeida , phys . rep . * 295 * , 267 ( 1998 ) . a. lichtemberg and m. lieberman , _ regular and stochastic motion _ , springer - verlag , ( 1983 ) . j. m. tualle and a. voros , chaos solitons fractals , * 5 * , 1085 ( 1995 ) . u. smilansky , in _ mesoscopic quantum physics _ , proceedings from les houches 1994 ( north holland , amsterdam , 1995 ) . gutwiller , j. math . phys . * 12 * , 343 ( 1971 )    v. bargmann , _ group representations on hilbert spaces of analytic functions _ in  analytic methods in mathematical physics \" ( r. p. gilbert and r. g. newton eds . ) , gordon and breach , new york , 1968 . o. biham and m. kvale , phys . a * 46 * , 6334 ( 1992 ) . p. kramer , m. moshinsky and t. h. seligman , _ complex extensions of canonical transformations and quantum mechanics _ , in  group theory and its applications \" , academic press ( 1975 ) . r. g. littlejohn , phys . * 13 * , 193 ( 1986 ) . e. vergini and m. saraceno , phys . rev . e * 52 * , 2204 ( 1995 ) . p. a. boasman , nonlinearity * 7 * , 485 ( 1994 ) .    m. v. berry and m. wilkinson , proc . london , ser . a * 392 * , 15 ( 1984 ) . g. tanner , j. phys . a * 30 * , 2863 ( 1997 ) . m. tabor , physica d * 6 * , 195 ( 1982 ) . a. monastra and m. saraceno , unpublished . e. vergini , submitted to j. phys . a.    g. carlo and e. vergini , submitted to j. phys .", "tags": [], "output_text_a": "This paper explores the semiclassical approximations in chaotic systems, focusing on the limits of periodic orbit theory and its resummations. The study aims to test these approximations in model systems, particularly in calculating spectra and stationary states. The spectral determinant is highlighted as an efficient tool for spectrum calculation, while the semiclassical representation of single eigenfunctions remains a challenge. The paper reviews Fredholm methods for calculating Husimi distributions of stadium eigenfunctions, applying them to the stadium billiard. The Fredholm theory is used to solve integral equations, and the semiclassical approximation is based on periodic points of the classical system. The paper discusses the semiclassical Husimi representation of eigenfunctions, using coherent state representation and classical invariants. The study also examines the impact of spatial symmetries on the coherent states and the semiclassical approximation of eigenfunctions. The results show that while the global behavior of eigenfunctions is well-reproduced semiclassically, finer details and certain regions, like the bouncing ball region, pose challenges. The paper concludes that the method is a first step in describing eigenfunctions in terms of periodic points, but the exponential proliferation of orbits in chaotic systems limits its practical application for high energies. Future work may focus on selecting important orbits to improve the method's practicality.", "output_text_b": "This article discusses the application of Fredholm methods to the semiclassical approximation of quantum billiard systems. The authors review the use of the spectral determinant for calculating the quantum spectrum and the use of coherent states for the semiclassical representation of single eigenfunctions. They then apply these methods to the calculation of Husimi distributions of stadium eigenfunctions.\n\nThe article begins by discussing the use of the spectral determinant for calculating the quantum spectrum. The spectral determinant is a Fredholm determinant that encodes the classical information of the billiard system in a more efficient way than other methods. The authors then discuss the semiclassical approximation, which is based on the approximation of the traces and powers of the propagator as sums over the periodic points of the underlying classical system. They choose the coherent state representation and obtain an expression for the semiclassical Husimi representation of the eigenfunctions in terms of classical invariants: periodic points, their monodromy matrices, and Maslov indices.\n\nThe authors then apply this scheme to the stadium billiard and present their conclusions and perspectives.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing semiclassical approximations, Fredholm methods, and the challenges in representing eigenfunctions.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of testing semiclassical approximations in chaotic systems.\n4. **Methodology**: The summary mentions the use of Fredholm methods and semiclassical approximations based on periodic points.\n5. **Significant Results**: The summary includes significant results, such as the challenges in representing eigenfunctions and the limitations of the method for high energies.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses some technical terms like \"Fredholm methods\" and \"Husimi distributions\" but does not explain them, which might be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance by discussing the potential impact of the method and future work.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the application of Fredholm methods to the semiclassical approximation of quantum billiard systems and the calculation of Husimi distributions of stadium eigenfunctions.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the semiclassical approximation of quantum billiard systems, is highlighted.\n4. The methodology, including the use of the spectral determinant and coherent state representation, is mentioned.\n5. Significant results, such as the application to the stadium billiard, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"spectral determinant\" and \"coherent state representation.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention any specific experiments or data used in the research.\n10. The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "a linear operator @xmath0 is positive if it maps a cone @xmath1 into itself , i.e. @xmath2 @xcite . for linear dynamical systems @xmath3 , @xmath4 , positivity has the natural interpretation of invariance ( and contraction , if the positivity is strict ) of the cone @xmath1 along the trajectories of the system . for continuous systems @xmath5 positivity reads @xmath6 for any @xmath7 . positivity has strong implications for the trajectories of the linear system @xcite . under irreducibility assumption , perron - frobenius theorem guarantees the existence of a dominant ( largest ) real eigenvalue for @xmath0 whose associated eigenvector - the perron - frobenius vector @xmath8 - is the unique eigenvector that belongs to the interior of @xmath9 . as a consequence , the subspace spanned by @xmath8 is an attractor for the linear system , that is , for any vector @xmath10 , @xmath11 , @xmath12    a classical geometric interpretation of perron - frobenius theorem is the _ projective contraction _ of linear positive systems @xcite : the rays of the cone converge towardss each other along the system dynamics . positivity is at the core of a number of properties of markov chains , consensus algorithms and large - scale control @xcite . a straightforward example in linear algebra is the convergence of the power iteration algorithm ( * ? ? ? * chapter 7 ) , directly expressed by . _ differential positivity _ extends linear positivity to the nonlinear setting . a nonlinear system @xmath13 ( or a nonlinear iteration @xmath14 ) is differentially positive if its linearization along any given trajectory is positive . a detailed characterization is provided in section [ sec : diff+ ] . the intuitive idea is that the linearized flow @xmath15 along the trajectory @xmath16 , @xmath17 , maps the cone ( field ) @xmath1 into itself . differentially positive systems generalize the important class of monotone dynamical systems @xcite , which are differentially positive with respect to a _ constant _ cone field ( on vector spaces ) . not surprisingly , differential positivity restricts the asymptotic behavior of a nonlinear system : figure [ fig : fw ] illustrates the dichotomic behavior of a differentially positive system . analog to the perron - frobenius vector in the linear case , the perron - frobenius vector field is an attractor for the linearized dynamics ( dashed line in figure [ fig : fw ] ) . the main results of differential positivity @xcite is that the trajectories of a differentially positive system either converge asymptotically to the image of an integral curve of the perron - frobenius vector field , or they move transversally to the perron - frobenius vector field . in the latter case the perron - frobenius vector field defines a direction of maximal sensitivity @xcite .    . right : trajectories move transversally to the perron - frobenius vector field @xmath8 , which defines a direction of sensitivity.,title=\"fig : \" ] . : trajectories move transversally to the perron - frobenius vector field @xmath8 , which defines a direction of sensitivity.,title=\"fig : \" ]    in the former case of convergence , the image of an integral curve of the perron - frobenius vector field defines a one - dimensional attractor for the nonlinear dynamics . this attractor generalizes the subspace spanned by the perron - frobenius vector of linear positivity ( the perron - frobenius vector field is not constant in general ) . it is either a collection of fixed points and connecting arcs or a limit cycle @xcite . for this reason , differential positivity is a relevant analysis tool for the study of bistable and periodic behaviors . further to the general exposition @xcite , the present paper strengthens the theory in the special case of _ hyperbolic _ attractors . the main result is the following converse theorem    [ thm : converse_diff+ ] a smooth dynamical system is ( strictly ) differentially positive in the basin of attraction of a one - dimensional normally hyperbolic compact attractor . the paper is organized as follows . section [ sec : hyperbolic_fixed_points ] recalls briefly the connections between differential stability ( contraction of riemannian metrics ) and hyperbolic fixed points , emphasizing the relevance of linearization methods for the characterization of asymptotic convergence to a fixed point . a similar approach is pursued in sections [ sec : diff+ ] , [ sec : diff+_behavior ] and [ sec : converse ] to emphasize the analog role of differential positivity in the characterization of asymptotic convergence to a one - dimensional attractor . in particular , section [ sec : diff+ ] introduces the notion of differential positivity ; section [ sec : diff+_behavior ] illustrates the main properties of differentially positive systems , providing novel insights on the results in @xcite ; section [ sec : converse ] completes and extends the results in @xcite by proving theorem [ thm : converse_diff+ ] . section [ sec : example ] further discusses the importance of the assumption of normal hyperbolicity . conclusions follow . a linear system @xmath5 , @xmath18 , is lyapunov stable if for some positive definite matrix @xmath19 the lyapunov function @xmath20 is non - increasing along the system trajectories @xmath21 the strict inequality @xmath22 entails exponentially stability , that is , the exponential contraction in time @xmath23 of the ball @xmath24 of radius @xmath25 . analog to the linear case , a nonlinear system @xmath26 represented by @xmath13 , @xmath18 , is _ differentially _ exponentially stable ( or contractive ) if its linearization along any trajectory is exponentially stable . this property has a pointwise geometric characterization based on the construction of lyapunov - like functions for the prolonged system @xmath27 @xcite @xmath28 where @xmath29 is the differential of @xmath30 at @xmath31 . let @xmath32 be any riemannian metric . consider a function @xmath33 such that    * there exist @xmath34 , a positive integer @xmath35 @xmath36 * there exists @xmath37 @xmath38    then , the nonlinear system is contractive in @xmath39 ( * ? ? ? * theorem 1 ) . the reader will notice that @xmath40 is just a lyapunov function lifted to the tangent bundle . in the riemannian metric @xmath32 replaces the norms of classical lyapunov theory . the inequality characterizes the exponential stability of the linearization . for instance , using @xmath41 to denote the nonlinear flow , we have that the pair @xmath42 is a trajectory of the prolonged system from the initial condition @xmath43 . thus , and guarantee the exponential contraction @xmath44 of any infinitesimal ball @xmath45 , as illustrated in figure [ fig : ball ] .    the reader is referred to @xcite for a detailed lyapunov characterization of contraction and for further extensions of the theory to general manifolds and finsler metrics . fundamental results of contraction theory and applications can be found in @xcite .    . ]      the exponential stability of the linearization , guarantees the contraction of the riemannian metric along the system trajectories over a uniform time horizon . as a consequence , there exists @xmath46 such that @xmath47 where @xmath48 is the geodesic distance given by the riemannian metric ( * ? ? ? * theorem 1 ) , as shown in remark [ rem : contraction ] for completeness . thus , @xmath49 is a contraction whenever @xmath50 satisfies @xmath51 . using the semigroup property of the flow , by banach fixed - point theorem a contractive system has a unique exponentially stable fixed point @xmath52 , provided that the riemannian metric @xmath32 makes @xmath39 geodesically complete . a simple direct argument exploits the identity @xmath53 which holds along any trajectory @xmath16 . the identity shows that any pair @xmath54 is a trajectory of the prolonged system . therefore , by and , every trajectory @xmath16 converges to a fixed point since @xmath55 uniqueness follows from , by contradiction . furthermore , @xmath52 is exponentially stable by lyapunov s first theorem , since and hold at @xmath52 . the existence of a unique fixed point is indeed a necessary condition for contractive time - invariant systems . [ rem : contraction ] consider and . for any @xmath56 , consider the geodesic curve @xmath57 \\to { \\mathcal{u}}$ ] connecting @xmath58 to @xmath59 with length @xmath60 . then , the geodesic distance @xmath48 satisfies since    @xmath61    for some @xmath46 , where the second inequality follows from and . for instance , for any curve @xmath62    @xmath63    which shows that @xmath64 is a trajectory of the linearized dynamics @xmath65 from the initial condition @xmath66 . thus , by and @xmath67 for some @xmath68 .      by hartman - grobman theorem , the trajectories of the system in a small neighborhood of a hyperbolic fixed point are topologically conjugated to the trajectories of the linearized dynamics @xcite . thus , at any equilibrium @xmath69 , the eigenvalues of the jacobian matrix @xmath70 dictate the stability property of the fixed point . if @xmath70 is a hurwitz matrix then @xmath52 is locally asymptotically stable . a hurwitz jacobian matrix also guarantees that the nonlinear system is contractive in a small neighborhood @xmath71 of the fixed point : by continuity , there exists @xmath72 such that @xmath73 holds for each @xmath31 in a small neighborhood @xmath71 of the fixed point . thus , and hold in @xmath71 for @xmath74 .    as a matter of facts , the existence of a unique hyperbolic fixed point is also a sufficient condition for contraction in the whole @xmath39 , as summarized in the next theorem . a detailed analysis can be found in @xcite . we provide a new proof based on ( * ? ? ? * theorem 2.3 ) . a smooth dynamical system is contractive in the basin of attraction of a hyperbolic fixed point .    without loss of generality , consider a hyperbolic fixed point @xmath75 and let @xmath76 be the basin of attraction of @xmath52 . by * theorem 2.3 ) there exists a differentiable @xmath77 such that @xmath78 is a @xmath79 diffeomorphism with @xmath80 and @xmath81 . by hyperbolicity , there exists a symmetric and positive definite matrix @xmath19 such that @xmath82 for some @xmath83 .    in the @xmath84 coordinates , consider now the riemannian metric @xmath85 defined by @xmath86 at each @xmath84 . and are trivially satisfied by selecting @xmath87 . from * theorem 1 ) the nonlinear system is contractive in the basin of attraction @xmath88 . in the original coordinates , the metric is represented by @xmath89 at each @xmath31 and @xmath90 . differential positivity replaces the contraction of a metric , the shrinking ball in figure [ fig : ball ] , with the contraction of a cone , illustrated in figure [ fig : cone ] . projective contraction - the contraction of the rays of the cone - frees one direction of the contraction property . the result is that the trajectories are not forced to converge to a fixed point anymore . the unique fixed point is replaced by one - dimensional attractors , the image of a curve .    . ]    differential positivity is defined below for complete continuous systems @xmath13 , whose state belongs to a smooth @xmath91-dimensional riemannian manifold @xmath92 . in such a case the state @xmath43 of the prolonged system belongs to the tangent bundle @xmath93 . the manifold @xmath92 is endowed with a cone field @xmath94 which makes @xmath92 a conal manifold @xcite . each cone @xmath95 is closed and solid , and satisfies the following properties : for all @xmath96 , ( i ) @xmath97 , ( ii ) @xmath98 for all @xmath99 , ( iii ) @xmath100 ( i.e. convex and pointed ) . we assume that @xmath1 is continuous and piecewise differentiable , i.e. the boundary of @xmath1 has a continuous and piecewise differentiable parameterization . positivity of the linearization has the precise interpretation of forward invariance and contraction of the cone field along the prolonged dynamics @xmath101 @xcite , as clarified in the following definition . for simplicity , in what follows we use @xmath102 to denote @xmath103 where @xmath104 . [ def : diff_pos ] the system @xmath26 is differentially positive ( with respect to the cone field @xmath9 ) in @xmath92 if the flow of the prolonged system leaves the cone invariant @xmath105 in addition , a differentially positive system @xmath26 is ( uniformly ) strictly differentially positive if there exist a constant @xmath106 and a cone field @xmath107 such that @xmath108    to avoid pathological cases , we assume that for every pair of points @xmath109 , there exists a linear invertible mapping @xmath110 such that @xmath111 and @xmath112 .    strict differential positivity guarantees that every tangent vector @xmath113 on the boundary of @xmath114 is mapped into @xmath115 at time @xmath116 . combining this property with the linearity of the mapping leads to the projective contraction in figure [ fig : cone ] . the result has a metric characterization based on a generalization of the argument in @xcite . in particular , @xcite shows that linear positive maps contract the hilbert metric ( projective metric ) . @xcite reduces the existence of the perron - frobenius eigenvector for linear positive maps to an application of the banach fixed point theorem . differentially positive systems enjoy a similar property .    from ( * ? ? ? * section vi ) , for any given @xmath117 , take any @xmath118 and define @xmath119 when @xmath120 . ] and @xmath121 . the hilbert metric @xmath122 reads @xmath123    @xmath122 is a projective metric that measures the distance between rays of the cone . in particular , for any @xmath124 , @xmath125 if and only if @xmath126 with @xmath127 , and @xmath128 for any @xmath129 and @xmath130 . the hilbert metric @xmath122 reduces to a metric in @xmath131 . we make the following standing assumption .    [ assume : completeness ] for all @xmath117 , the pair @xmath132 and @xmath122 is a complete metric space . we recall that @xmath32 is the riemannian metric on @xmath92 . examples of complete metric spaces on cones can be found in @xcite . the contraction of the cone field along trajectories is captured by the exponential convergence of the hilbert metric . following ( * ? ? ? * theorem 2 ) , for a strictly differentially positive system there exist @xmath133 and @xmath83 such that , for all @xmath117 , @xmath134 , and @xmath116 , @xmath135 where @xmath136 . assumption [ assume : completeness ] and the projective contraction lead to the existence of the so - called perron - frobenius vector field @xmath137 , the differential equivalent of the perron - frobenius eigenvector of linear positive mappings . by ( * theorem 3 ) , for any @xmath117 , @xmath8 is a continuous vector field such that @xmath138 @xmath8 is invariant as a field of rays , that is , @xmath139 . furthermore , for any @xmath117 and @xmath140 , @xmath141    the observation in makes clear that is at the root of the dichotomic behavior illustrated in figure [ fig : fw ] . in brief , for any trajectory @xmath142 , either @xmath143 for some @xmath144 , which forces the trajectory to converge asymptotically towardss an integral curve of the perron - frobenius vector field , or @xmath145 for all @xmath144 , which determines the transversality between @xmath146 and @xmath147 , leading to sensitivity .    in what follows , for simplicity , we call _ perron - frobenius curve _ any integral curve of the perron - frobenius vector field .    differential positivity makes contact with the alekseev and moser criterion which infers the hyperbolicity of an attractor @xmath148 from the existence of two invariant cone fields defined at each @xmath149 . * chapter 3 ) . differential positivity also requires the existence of an invariant cone field . differential positivity exploits the contraction of the cone field everywhere in the system state manifold ( or in any forward invariant subset ) to characterize the global asymptotic behavior of the system . in this sense , differential positivity shows similarities with @xcite , which uses the invariance of cone fields on @xmath92 to characterize the lyapunov exponents of the system . in order to make the paper self - contained , we summarize in this section the main results of @xcite , which characterize the asymptotic behavior of differentially positive systems .    the @xmath150-limit set @xmath151 , @xmath152 , is the set @xmath153 where @xmath154 denotes the closure of the set . for every @xmath155 , the @xmath150-limit set of a ( complete ) strictly differentially positive system whose trajectories are all bounded satisfies one of the following two properties ( * ? ? ? * theorem 4 ) :    * the vector field @xmath156 is aligned with the perron - frobenius vector field @xmath157 for each @xmath158 ( i.e. @xmath159 , @xmath160 ) , and @xmath151 is either a fixed point or a limit cycle or a set of fixed points and connecting arcs ; * the vector field @xmath156 is not aligned with the perron - frobenius vector field @xmath157 for each @xmath161 such that @xmath162 , and either @xmath163 or @xmath164 . the behavior ( i ) is akin to poincar - bendixson theorem for planar systems @xcite . it holds if the perron - frobenius vector field is complete and if the following holds : @xmath165 in such a case the attractor is given by the image of a perron - frobenius curve . the combination of with the projective contraction of strict differential positivity leads to contraction transversally to the perron - frobenius vector field : @xmath166 directions of contraction for an @xmath91-dimensional state manifold @xmath92 . as a consequence , every pair of trajectories in @xmath167 converge asymptotically to the image of a unique perron - frobenius curve . the completeness of the vector field ensures existence and uniqueness of such a curve . a detailed argument is developed in remark [ rem : horizontal_contraction ] . [ rem : horizontal_contraction ] we first establish contraction transversal to the perron - frobenius vector field : for every @xmath168 and @xmath169 ,    * @xmath170 ; and * either @xmath171 * or @xmath172 for some @xmath173 . if @xmath174 then ( a ) follows from the fact that @xmath175 is a dominant direction and @xmath176 is a linear operator . ( b2 ) follows by projective contraction and linearity of @xmath176 . ( b1 ) may also occur . for @xmath177 either there exists @xmath178 such that @xmath179 and ( a),(b2 ) follow by the argument above , and ( b1 ) may occur , or @xmath180 for all @xmath181 . for this last case , take @xmath182 . for @xmath129 sufficiently large @xmath183 and ( a),(b2 ) hold for @xmath184 . therefore @xmath185 , as claimed in ( b1 ) ( and ( b1 ) implies ( a ) ) . we now look at the convergence among trajectories by parameterizing their initial conditions with a curve @xmath57 \\to { \\mathcal{c}}$ ] . for each @xmath186 $ ] , @xmath187 converge asymptotically to the image of a perron - frobenius curve as @xmath188 . this follows from the observation that for each @xmath189 $ ] @xmath190 and the pair @xmath191 , @xmath192 satisfies ( a),(b2 ) or ( b1 ) along the flow of the system . the perron - frobenius limit curve must be unique . otherwise , there exists a curve @xmath57 \\to { \\mathcal{c}}$ ] connecting several perron - frobenius limit curves such that , for some @xmath186 $ ] , the tangent vector @xmath193 along the linearized flow @xmath194 does not satisfy one of ( a ) and ( b2 ) , and it does not satisfy ( b1 ) . various assumptions may ensure the ultimate boundedness property . for instance , ( * ? ? ? * corollary 2 ) ensures the existence of a unique attractive limit cycle in @xmath167 under the simpler assumption @xmath195 guarantees that the trajectories do not converge to a fixed point , since the magnitude of the vector field is bounded from below @xmath196 on any orbit ( by boundedness of trajectories ) . also implies ( see lemma 1 in @xcite ) thus transversal contraction with respect to the perron - frobenius vector field . finally , guarantees that every @xmath150-limit set in @xmath167 satisfies ( i ) . the vector field @xmath156 at each point @xmath31 of the @xmath150-limit set is aligned with the perron - frobenius vector field , therefore every trajectory in the neighborhood of the @xmath150-limit set is attracted transversally towards the @xmath150-limit set . as a consequence , the return map on a poincar section transversal to the @xmath150-limit set is necessarily contractive , leading to the existence of a closed orbit . the reader is referred to ( * ? ? ? * corollary 2 ) and ( * ? ? ? * theorem 6 ) for a detailed discussion . the asymptotic stability of the limit cycle readily follows from the analysis of the linearization . let @xmath31 be a point on the closed orbit and let @xmath178 be the period such that @xmath197 . by strict differential positivity , in satisfies @xmath198 . @xmath200 is thus a positive linear operator with dominant eigenvector @xmath201 since , by periodicity of @xmath200 and using , @xmath202 . the dominant eigenvalue clearly has magnitude 1 . by strict differential positivity the other eigenvalues - the floquet s characteristic multipliers of the system - have magnitude less than one . it follows that the closed orbit is asymptotically stable ( * ? ? ? * chapter 13 ) . \\(ii ) characterizes @xmath150-limit sets of points @xmath117 for which does not hold . in such a case , the perron - frobenius vector field is a direction of maximal sensitivity . fixed points or periodic orbits are unstable because of the asymptotic separations among trajectories in a small neighborhood of the @xmath150-limit set , in the direction of the perron - frobenius vector field . however , strict differential positivity still allows for one - dimensional attractors defined by a collection of fixed points and connecting arcs . the simplest example is given by a bistable system , with two stable fixed points and a saddle point @xmath52 . if the linearization of the system at the saddle has @xmath166 eigenvalues with negative real part , then strict differential positivity guarantees that all the fixed points belong to the image of a perron - frobenius curve . indeed , the whole heteroclinic orbit connecting the unstable manifold of the saddle to any stable fixed points is contained within the image of a perron - frobenius curve . this follows from the continuity of the perron - frobenius vector field , combining the fact that the tangent space of the unstable manifold at @xmath52 is spanned by @xmath203 with the invariance of the perron - frobenius vector field @xmath139 and with the invariance of the unstable manifold . further results related to case ( ii ) can be found in @xcite and @xcite . notably , the relevant property of almost global convergence of monotone systems is revisited through differential positivity . in general , however , the relation between differential positivity and nonlinear behavior for case ( ii ) requires further investigation . it is an open question , for example , whether or not a strictly differentially positive system may have strange attractors . at a fixed point @xmath52 , strict differential positivity reduces to classical positivity of the linearization since @xmath204 for all @xmath7 . in such a case , @xmath205 is the dominant eigenvector of @xmath70 and the stability of the fixed point is determined by the associated eigenvalue @xmath206 . @xmath205 can be an unstable direction - @xmath207 where @xmath208 and @xmath209 is given by the span of the remaining eigenvectors of @xmath70 . the linearized flow contracts @xmath210 more sharply than @xmath211 or it expands @xmath211 more sharply than @xmath210 , that is , for some @xmath212 , @xmath213 a separation of subspaces and rates is akin to normal hyperbolicity @xcite .    on any fixed point @xmath52 , strict differential positivity guarantees that @xmath214 which makes @xmath205 an eigenvector of @xmath70 . the real part of an eigenvalue @xmath215 associated to any other eigenvector @xmath216 of @xmath70 must satisfy @xmath217 , otherwise would not hold . @xmath218 is thus any positive constant such that @xmath219 . we need the following definitions and assumptions . [ def : normal_attractor ] a connected manifold @xmath220 is an attractor for the flow @xmath221 if it satisfies the following two properties :    * @xmath222 for all @xmath223 ; * there exists a neighborhood @xmath224 of @xmath225 such that , for any @xmath226 , the limit set @xmath227 is in @xmath225 .    definition [ def : normal_attractor ] allows for the existence of a smaller closed subset satisfying the above properties . for example , the definition includes the case of a set of fixed points and their connecting orbits .    in what follows we will use the notion of invariant splitting of the tangent bundle of @xmath228 over @xmath225 , represented by @xmath229 with @xmath230 and @xmath231 for all @xmath149 and @xmath232 . [ def : hyperbolic ] the attractor @xmath225 is normally hyperbolic ( with respect to the flow @xmath221 ) if there exists an invariant splitting of the tangent bundle at @xmath225 which satisfies the following property : there exist a riemannian metric @xmath233 and real constants @xmath234 , @xmath235 , @xmath236 , @xmath237 such that , for all @xmath238 and @xmath181 ,    [ eq : hyperbolic_splitting ] @xmath239 consider a dynamical system @xmath26 on a riemannian manifold @xmath92 , represented by @xmath240 where @xmath117 and @xmath30 is a @xmath79 vector field . let @xmath241 be a normally hyperbolic compact attractor for @xmath26 with basin of attraction @xmath242 . if @xmath243 for all @xmath238 then @xmath26 is strictly differentially positive in @xmath244 .    . according to ( * ? ? ? * remark 3 ) the normal hyperbolicity property with @xmath243 implies that one can define an adapted metric @xmath245 in @xmath246 , @xmath238 , such that - are satisfied with @xmath247 , i.e. for all @xmath248 , there exist real constants @xmath236 and @xmath237 such that for all @xmath248 , i.e. @xmath249 for all @xmath250 ( see e.g. @xcite ) . this corresponds to . in addition , since @xmath243 , there exists a function @xmath251 such that @xmath252 for all @xmath223 and @xmath253 , and implies @xmath254 . for @xmath255 , we can define the metric @xmath256 where @xmath257 is large enough . we have @xmath258_{\\tau=0 } = -\\lambda_2 |v|^ * + |v| ( e^{(\\lambda_2-\\lambda(t))t}-1)\\ ] ] where the second term is positive for @xmath257 large enough . then we obtain . ] @xmath259    consider the continuous vector field @xmath260 such that @xmath261 for all @xmath248 and @xmath262 given any @xmath263 , at each point @xmath149 , we define the cone fields    [ eq : kandr ] @xmath264    directly from the definition @xmath114 is solid and closed at each @xmath149 . @xmath114 is a convex cone since for any @xmath265 and @xmath266 , we have @xmath267 and @xmath268 , so that @xmath97 . clearly @xmath269 for @xmath270 . finally , if @xmath271 , then @xmath272 and @xmath273 , so that @xmath274 . thus @xmath275 , which makes @xmath114 pointed . the same holds for @xmath276 . we show strict differential positivity . for all @xmath223 , @xmath149 and @xmath250 , we have @xmath277 and @xmath278 since the splitting is invariant . we obtain @xmath279 for all @xmath181 since @xmath280 and @xmath237 . follows . furthermore , uniformly on @xmath31 , there exists @xmath281 such that @xmath282 for all @xmath283 , so that @xmath284 for all @xmath285 , which implies .    . for any positive constant @xmath286 , denote by @xmath287 the ( compact ) set of points @xmath288 whose distance from @xmath225 is less than or equal to @xmath286 . by the hyperbolicity of @xmath225 , for any given @xmath289 sufficiently small , there exists a constant @xmath290 such that @xmath291 for all @xmath181 and @xmath292 . since @xmath225 is normally hyperbolic and compact , there exists an invariant fibration of its stable manifold , i.e. of the basin of attraction @xmath244 , in the compact set @xmath287 ( see theorem 4.1 in @xcite and theorem 2 in @xcite ) . denote by @xmath293 the fiber characterized by a section @xmath248 and denote by @xmath294 the tangent space of the fiber @xmath295 at @xmath296 . note that the invariance property implies @xmath297 . define a continuous extension @xmath298 of the vector field @xmath299 on @xmath287 such that for all @xmath300    * @xmath301 ; * @xmath302 ; * whenever @xmath303 , there exists @xmath304 such that @xmath305 .    at each point @xmath306 define the cone fields @xmath1 and @xmath307 as in . we show strict differential positivity on @xmath308 , for @xmath309 sufficiently small . by continuity of the vector field @xmath299 on the compact set @xmath287 and by continuity of the prolonged flow with respect to initial conditions , for @xmath286 sufficiently small , there exists a bound @xmath310 as @xmath311 such that ,    [ eq : l ] @xmath312    the bound @xmath313 arises from ( i ) the loss of contraction rate of @xmath314 in the direction @xmath315 between @xmath316 and @xmath317 ; ( ii ) the variation of the expansion / contraction rate of @xmath314 in the direction @xmath318 between @xmath316 and @xmath317 .    for any @xmath319 and any @xmath320 , we have @xmath321 where @xmath322 and @xmath272 . then , by , for all @xmath232 @xmath323 since @xmath324 as @xmath325 and therefore @xmath326 implies @xmath327 for @xmath286 sufficiently small . it follows that holds . for strict differential positivity , as before , there exists @xmath328 such that , for all @xmath329 , @xmath330 note that @xmath331 as @xmath332 .    . consider the boundary @xmath333 of @xmath71 . following , for each @xmath334 , define the @xmath304-parametrized cone fields    @xmath335    clearly , @xmath336 for any @xmath337 , since @xmath338 implies @xmath339 . furthermore , @xmath340 for @xmath341 . in fact , @xmath342 if and only if @xmath343 , and @xmath344 . we are ready to define the cone fields on @xmath345 . for @xmath346 , take @xmath347 and let @xmath348 be the ( unique ) initial condition that satisfies the identity @xmath349 . define    [ eq : cones_ba_minus_u ] @xmath350    @xmath1 and @xmath307 are well defined since the class of cones is closed under the action of linear maps . @xmath1 and @xmath307 are continuous by construction . we prove differential positivity . using , for all @xmath351 and @xmath352 , we have @xmath353 where we have used the identities @xmath354 and @xmath355 . the inclusion follows from the property @xmath336 for any @xmath337 . for all @xmath351 and @xmath356 , we have @xmath357 the second inclusion follows from differential positivity in @xmath71 . differential positivity is thus established . for strict differential positivity , by repeating the argument above , note that and hold when @xmath1 is replaced by @xmath307 . thus , we have only to show that there exists a uniform time @xmath257 for which @xmath358 . for instance , consider the case @xmath359 , where @xmath341 . exploiting the identity @xmath360 , we have @xmath361 for @xmath362 , @xmath363 for some @xmath364 $ ] . thus strict differential positivity follows from and , for a uniform @xmath365 . the contracting cone field @xmath95 proposed in the proof is not unique . several definitions can be provided , starting from the parameterization @xmath366 whose constant @xmath367 can be replaced by any function @xmath368 , @xmath334 , such that @xmath369 and @xmath370 is strictly increasing for each @xmath31 . looking at section [ sec : diff+ ] , this implies that , in principle , different perron - frobenius vector fields could arise from different cone fields . in general , the perron - frobenius vector field is uniquely defined only at @xmath371 . the contracting cone field @xmath95 is continuous and piecewise differentiable on @xmath244 . in fact , it is not @xmath79 on the boundary of @xmath71 . however , we suspect that one can obtain a contracting cone field that is @xmath79 everywhere in @xmath244 by choosing a properly parametrized cone field @xmath366 .    theorem [ thm : converse_diff+_detailed ] extends and completes the work initiated in @xcite on converse theorems for normally hyperbolic attractors given by a unique fixed point or by a limit cycle . the argument for these converse results is based on the properties of the koopman operator @xcite . in particular , the proof derives and exploits an interesting connection between the koopman eigenfunctions related to the attractor @xcite and the existence of an invariant ( and contracting ) cone field . the proof is constructive , leading to a numerical algorithm for the construction of the cone field ( * ? ? ? * section 5 ) . however , the approach in @xcite does not extend to the general one - dimensional normally hyperbolic attractors considered in theorem [ thm : converse_diff+_detailed ] . for attractors containing several fixed points , a cone field from koopman eigenfunctions is well - defined in the basin of attraction of each fixed point , but the patching of these cone fields in the whole basin of attraction of the one - dimensional attractor is not necessarily well defined . the relevance of the normal hyperbolicity property for theorem [ thm : converse_diff+_detailed ] is readily illustrated by a comparison of the attractors in figure [ fig : example ] . the one - dimensional attractor @xmath372 on the left of the figure is given by two stable fixed points , a saddle point @xmath52 , and the heteroclinic orbits connecting the fixed points to the saddle - the unstable manifold of the saddle . the one - dimensional attractor @xmath373 on the right of the figure is characterized by a stable fixed point , a saddle point @xmath52 , the heteroclinic orbit connecting the fixed point to the saddle , and the homoclinic orbit connecting unstable and stable manifolds of the saddle . we assume that each fixed point is hyperbolic . for simplicity we take @xmath374 and @xmath375 . @xmath372 is normally hyperbolic . the transversal convergence towardss the attractor is dominated by the motion within the attractor . this attractor is compatible with differential positivity . indeed , by theorem [ thm : converse_diff+ ] , the attractor @xmath372 makes the system strictly differentially positive in @xmath92 . @xmath373 is not normally hyperbolic since unstable and stable manifolds of the saddle merge . thus , there is no invariant splitting of the tangent bundle at @xmath373 . in fact , the system can not be strictly differentially positive . we show this by contradiction . suppose that the system is strictly differentially positive with respect to some cone field @xmath1 . the perron - frobenius vector field @xmath8 is a continuous vector field that satisfies @xmath376 at each @xmath377 . however , for any point @xmath31 on the homoclinic orbit we have that @xmath378 despite @xmath379 . this contradicts the continuity of @xmath8 . a similar argument can be developed from the invariance of the cone field @xmath1 . by invariance , @xmath380 must contain both the tangent vectors @xmath381 and @xmath382 respectively tangent to the stable and unstable manifolds of the saddle . for instance , ( i ) @xmath383 is the dominant eigenvector of the linearized flow on @xmath52 therefore @xmath384 ; ( ii ) by continuity , @xmath385 for any @xmath31 on the homoclinic orbit . thus , the tangent vector @xmath113 to the homoclinic orbit at @xmath31 belongs to @xmath114 and , by differential positivity @xmath386 . therefore , @xmath387 . however , considering the eigenvalues @xmath388 of the linearization at the saddle @xmath52 , we have @xmath389 and @xmath390 which contradicts the projective contraction property , since @xmath391 . differential analysis , or the study of the nonlinear map through the properties of its linearization , is a classical topic of dynamical systems theory . we have shown that behaviors that asymptotically converge to a one - dimensional normally hyperbolic attractor can be characterized differentially : their linearizations are _ positive _ , they contract a cone field . this characterization can be thought as analog to the differential characterization of behaviors that asymptotically converge to a hyperbolic fixed point ; those behaviors that contract a `` ball field '' , that is , a riemannian metric . the result once more stresses the importance of hyperbolicity in differential analysis . it also emphasizes a fruitful connection between the property of positivity in linear analysis and a geometric characterization of dynamical systems with one - dimensional asymptotic behaviors . m.  hirsch , h.  smith , monotone dynamical systems , in : p.  d. a.  canada , a.  fonda ( eds . ) , handbook of differential equations : ordinary differential equations , vol .  2 , north - holland , 2006 , pp . 239  357 . [ ] .                      g.  russo , m.  di  bernardo , e.  sontag , global entrainment of transcriptional systems to periodic inputs , plos computational biology 6  ( 4 ) ( 2010 ) e1000739 . http://dx.doi.org/10.1371/journal.pcbi.1000739 [ ] . a.  mauroy , i.  mezi , j.  moehlis , isostables , isochrons , and koopman spectrum for the action angle representation of stable fixed point dynamics , physica d : nonlinear phenomena 261  ( 0 ) ( 2013 ) 19  30 . a.  mauroy , i.  mezic , a spectral operator - theoretic framework for global stability , in : 52nd ieee annual conference on decision and control ( cdc ) , 2013 , pp . http://dx.doi.org/10.1109/cdc.2013.6760712 [ ] .", "tags": [], "output_text_a": "The paper discusses the concept of differential positivity, which extends the idea of positivity from linear to nonlinear dynamical systems. A linear operator is positive if it maps a cone into itself, and this concept is naturally interpreted as invariance or contraction in linear systems. Differential positivity applies this idea to nonlinear systems by considering the positivity of their linearization along trajectories. The paper explores the implications of differential positivity, such as its ability to restrict the asymptotic behavior of nonlinear systems, leading to convergence towards one-dimensional attractors or directions of maximal sensitivity.\n\nThe paper also delves into the relationship between differential positivity and hyperbolic attractors, presenting a converse theorem that states a smooth dynamical system is differentially positive in the basin of attraction of a one-dimensional normally hyperbolic compact attractor. The paper is structured to first establish connections between differential stability and hyperbolic fixed points, then introduce differential positivity, and finally discuss its implications and provide a detailed proof of the converse theorem.\n\nThe study highlights the importance of hyperbolicity in differential analysis and draws parallels between positivity in linear systems and geometric characterizations of dynamical systems with one-dimensional asymptotic behaviors. The paper also discusses the role of the Perron-Frobenius vector field as an attractor in differentially positive systems and its implications for the system's dynamics. Overall, the paper provides a comprehensive analysis of differential positivity and its significance in understanding the behavior of nonlinear dynamical systems.", "output_text_b": "Positivity in linear operators has a natural interpretation in linear dynamical systems as invariance and contraction of a cone along the trajectories of the system. The Perron-Frobenius theorem, under irreducibility assumption, guarantees the existence of a dominant real eigenvalue for a positive linear operator, whose associated eigenvector is the unique eigenvector that belongs to the interior of the cone. This has strong implications for the trajectories of the linear system, as they converge towards the subspace spanned by the Perron-Frobenius vector.\n\nDifferential positivity extends this concept to the nonlinear setting, where a nonlinear system is differentially positive if its linearization along any given trajectory is positive. This implies that the linearized flow maps the cone field into itself, and it generalizes the important class of monotone dynamical systems, which are differentially positive with respect to a constant cone field. Differential positivity restricts the asymptotic behavior of a nonlinear system, as the trajectories either converge asymptotically to the image of an integral curve of the Perron-Frobenius vector field or move transversally to it.\n\nThe Perron-Frobenius vector field plays an important role in the analysis of differentially positive systems, as it defines a direction of maximal sensitivity in the latter case. The paper also discusses the importance of normal hyperbolicity in the study of bistable and periodic behaviors, and strengthens the theory in this special case with a converse theorem.", "score": 0.30000000000000004, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings and Contributions**: The summary accurately reflects the main findings and contributions of the paper by discussing the concept of differential positivity and its implications for nonlinear dynamical systems.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem by mentioning the extension of positivity from linear to nonlinear systems and the implications of differential positivity.\n\n4. **Methodology or Approach**: The summary mentions the methodology by discussing the application of differential positivity to nonlinear systems and the exploration of its implications.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the convergence towards one-dimensional attractors and the relationship with hyperbolic attractors.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like differential positivity and Perron-Frobenius vector field.\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary does not mention any key experiments or data used in the research, which is a requirement.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance by discussing the importance of hyperbolicity in differential analysis and the potential impact of understanding nonlinear dynamical systems.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the extension of positivity to nonlinear systems through differential positivity and the role of the Perron-Frobenius vector field.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary does not explicitly state the research problem or question addressed by the paper.\n4. **Methodology**: The summary mentions the concept of differential positivity and its application to nonlinear systems but lacks details on the specific methodology or approach used in the paper.\n5. **Significant Results**: The summary includes significant results, such as the implications of differential positivity on the asymptotic behavior of nonlinear systems.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"Perron-Frobenius vector field\" and \"differential positivity\" but does not explain them, which may be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in extending the theory of positivity to nonlinear systems and its potential impact on the study of dynamical systems."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "understanding the chemical history of heavy elements (  metals \" ) in the interstellar medium ( ism ) of galaxies is an important , but difficult undertaking . because refractory elements are found to be depleted from the gas phase ( locked into grains ) , they provide a substantial reservoir of coolants in the solid - state phase . interstellar grain surfaces are believed to furnish formation sites for molecular hydrogen ( h@xmath1 ) , which is both a coolant and the starting point for a rich cloud chemistry . grains also provide a critical transfer mechanism for reprocessing uv / o starlight into far - infrared and sub - mm emission from interstellar molecular clouds and high - redshift galaxies . in the high - redshift universe , the first dust grains may influence the thermodynamics of the primordial gas and thereby control rates of star formation . recent observations of dust grains at high redshift have been puzzling in the context of their formation . several observations of damped ly@xmath2 systems ( pettini 1994 ; ledoux , bergeron & petitjean 2002 ) have shown evidence of dust grains in them . also , thermal emission ( at @xmath3 mm ) from dust in high redshift ( @xmath4 ) qsos in the sloan digital sky survey ( sdss ) have been reported ( bertoldi 2003 ) . the implied dust mass of @xmath5 m@xmath6 within a gyr after the big bang appears difficult to explain with traditional models of grain formation in evolved low mass stars ( dunne 2003 ) , from which grains are thought to be transported to the interstellar medium ( ism ) through stellar winds ( whittet 1992 ) . recent models have , therefore , focused on other sites of dust grain formation , such as ejecta of core - collapse supernova explosions that can occur on shorter time scales than that of the evolution of low mass stars ( dwek & scalo 1980 ) . core - collapse supernovae are thought to be capable of synthesizing a significant amount of dust in the sn ejecta . applying a theory of nucleation and grain growth developed by kozasa & hasegawa ( 1987 ) , kozasa ( 1989 ; 1991 ) and todini & ferrara ( 2001 ) have studied grain formation in expanding sn ejecta , the latter estimating the dust mass formed @xmath7 m@xmath8 . nozawa ( 2003 ) have extended it to the case of zero - metallicity sne for population iii stars ( see also schneider , ferrara & salvaterra 2004 ) . although the sn `` dust factory model '' would explain the large observed dust masses in high - redshift galaxies , observations of dust in nearby sne appear inconsistent with this model , falling factors of 10100 short of the required amounts ( @xmath9 ; see above ) . as an example , in a review of type  ii sn  2003gd ( ngc  628 ) , sugerman et al . ( 2006 ) state that  radiative transfer models show that up to 0.02 solar masses of dust has formed within the ejecta \" . however , a recent study ( meikle et al .  2007 ) of the same remnant concludes that the mid - ir flux  is consistent with emission from @xmath10 of newly condensed dust in the ejecta \" . in a young , oxygen - rich snr in the smc , stanimirovic et al . ( 2005 ) found only @xmath11 of hot dust ( @xmath12  k ) . the claimed sub - mm detection ( dunne et al . 2003 ) of @xmath13 of cold dust toward the cas  a remnant was later shown to arise from interstellar dust in an adjacent molecular cloud ( krause et al . 2004 ) . observational tests of predictions made by models of sne are difficult , involving far - ir and sub - mm observations of young snrs . one must disentangle far - ir backgrounds , separate newly synthesized dust from circumstellar and interstellar dust , and understand the role of snr reverse shocks , which can destroy newly synthesized dust in high - speed ejecta . a case in point is sn 1987a . dust formation was inferred in ejecta of sn  1987a , but only @xmath11 was detected ( dwek 2006 ; dwek & arendt 2007 ) . additional dust is almost certainly present , because of observed changes in the optical and bolometric fluxes and emission - line asymmetries in the red and blue wings ( mccray 1993 , 2007 ) . moreover , the reverse shock has not yet reached the interior of the supernova debris in sn  1987a . these inner ejecta are most prone to dust formation , since they are cold , dense , and metal - enriched . a challenging theoretical issue is whether high - velocity dust ( @xmath14 km  s@xmath15 ) can survive the shocks , thermal sputtering , and grain - grain collisions , as the ejecta are slowed down by the surrounding ism . a goal of this paper is to determine how much dust survives the sn event and is incorporated into the surrounding ism . the relative speed of reverse shocks with respect to the expanding ejecta can be very large , and can raise the temperature of the ejecta to the extent of destroying the nascent dust grains in it . it is therefore important to study the effect of reverse shocks in detail . recently , nozawa ( 2007 ) have considered this problem and came to the conclusion , with the help of hydrodynamical simulation , that reverse shocks can destroy a fraction of dust mass of order @xmath16% depending on the ambient gas density and explosion energy . bianchi & schneider ( 2007 ) also used numerical simulations and semi - analytical methods to conclude that only a small amount of dust mass survives ; e.g. , @xmath17% dust mass survives in the case of a sn with a progenitor of mass @xmath18 m@xmath8 and ambient particle density of @xmath19 @xmath20 . nozawa ( 2007 ) have included the motion of dust relative to gas within the sn remnant and calculated the evolution of dust grains over a period spanning the radiative phase ( @xmath21 yr ) , whereas bianchi & schneider ( 2007 ) neglected the effect of motion of grains on dust destruction and calculated dust evolution up to the non - radiative phase ( @xmath22 yr ) . we study in this paper a simple and analytically tractable problem , namely the effect of reverse shocks for a power - law mass distribution of the ejecta , in the regime of self - similar evolution of both forward and reverse shocks . although the simple formalism does not allow us to study several important processes including motion of dust grains and its effect on evolution of dust grains our approach allows one to segregate the processes of destruction within the reverse shock itself from those occuring between forward and reverse shocks ( which can be dealt with in numerical simulations involving grain motion ) . we first summarize the results of the theoretical predictions of dust grain formation in snrs . todini & ferrara ( 2001 ) calculated the formation of different types of dust grains amorphous carbon ( ac ) , silicates ( enstatites : @xmath23 , forsterites : @xmath24 ) and iron - bearing magnetites ( @xmath25 ) and others , in ejecta with different metallicities . they found that ac grains are generally of larger size , in the range of @xmath26  m , whereas silicates are produced with sizes @xmath27  m. nozawa ( 2003 ) reached similar conclusions for pop iii sn events , with sizes of newly synthesized grains spanning a range of three orders of magnitude , with maximum grain size being less than @xmath28 m . the dust grain parameters in the ism are inferred to be somewhat different from these estimates . the extinction observations are satisfactorily reproduced by assuming mostly of two components graphite and silicate with a common power - law size distribution , @xmath29 , truncated at a minimum size @xmath30 m and a maximum size @xmath31 m ( draine 2003 , and references therein ) . there also appears to be a population of very small grains with pah composition . nozawa ( 2003 ) found for grains synthesized in pop iii sn ejecta a size distribution with index @xmath32 for smaller grains and with @xmath33 for larger grains ( with the grain size at crossover point depending on supernovae models ) . we use these two power laws to bracket the possible size distributions of grains synthesized in sn ejecta , and assume that grains are formed in the range @xmath34 cm ( see figure 11 of nozawa ( 2003 ) . we also consider the case of an upper limit of @xmath35 cm and compare our results for both upper limits . it is instructive to estimate the destruction time scales before we calculate the effect of reverse shock in detail . the sputtering time scale for dust ( graphite , silicate and iron ) grains of size @xmath36 is approximately @xmath37 yr , for ambient temperatures larger than @xmath38 k ( draine & salpeter 1979 ) , where @xmath39 is electron density . for grains with size @xmath7 @xmath40 ( which incidentally contain most of the dust mass for a @xmath41 distribution ) , and for @xmath42 @xmath43 , the sputtering time scale is @xmath44 yr . we now briefly discuss the self - similar evolution of forward and reverse shocks in sn ( see truelove & mckee 1999 , hereafter referred to as tm99 , for further details ) . the parameters used to describe a supernova remnant which affect its evolution are the energy of the explosion ( @xmath45 ) , the mass contained in the expanding ejecta ( @xmath46 ) , the maximum velocity of the material within the ejecta ( @xmath47 ) , and the density of the ism ( @xmath48 ) . denoting the time of the explosion as @xmath49 , we construct our initial conditions at a later time , still early in the history of the remnant , assuming the ejecta to have already expanded to a radius @xmath50 without any deceleration due to the ambient medium . if we consider sn to be a point explosion , then the radial velocity profile will be linear as ejecta with velocity @xmath51 will travel out to a distance @xmath52 : @xmath53 this profile becomes flatter as time progresses and the faster - moving ejecta are flung out to greater distances . the corresponding radial density distribution of the ejecta matter is given by : @xmath54 where @xmath55 is the time - independent structure function of the density profile and the @xmath56 term arises from the free expansion of the ejecta . we define a dimensionless parameter to label shells of the ejecta starting from the centre outwards as w = , 0 w 1 following tm99 we consider the situation when _ f _ is given by a power law in _ w _ : f(w ) = \\ {    ll f_0 , & + f_nw^-n , &    . where we have separated the ejecta into a uniform density core region and a power - law envelope region . the continuity of _ f _ at @xmath57 and the normalization of @xmath58 translate to expressions for parameters @xmath59 and @xmath60 in terms of the free parameters @xmath57 and _ n _ : f_0 & = & f_nw_c^-n + f_n & = & .      as the freely expanding ejecta come into contact with the ambient medium , with the contact discontinuity moving at @xmath47 , a speed much larger than the sound speed in the ambient medium , a forward shock is set up in the surrounding gas which propagates into the medium . the ejecta at the contact surface decelerates suddenly as it hits the ambient gas , and consequently , a reverse shock is set up that propagates inwards through the ejecta . while the mass of this matter swept by the forward shock is less than the total mass of the ejecta driving the shock , the remnant is said to be in the _ ejecta dominated _ or ed stage . it is in this stage , before the reverse shock has attained a significant velocity , that the ejecta can be approximated as a spherical piston freely expanding into the ambient gas . when the mass swept by the forward shock becomes approximately equal to the ejecta mass , the corresponding late - time limit is known as the _ sedov - taylor _ or st stage of the evolution of the remnant . we follow tm99 to follow the evolution of the reverse shock analytically . let @xmath61 and @xmath62 denote the radii of the forward and reverse shocks , and @xmath63 and @xmath64 be the velocities of the forward and reverse shock waves respectively , all in the rest frame of the unshocked ambient medium . we have the velocity of the unshocked ejecta as seen by the reverse shock as it propagates into the ejecta : _ r v(r_r , t ) - v_r(t ) = - v_r(t ) . @xmath65 _ be the ratio of the pressures behind the reverse and forward shock waves and _ l _ be the ratio of the radii of the two shocks at a given time : ( t ) , l(t ) , w_f(t ) . it is useful to express various parameters in dimensionless forms in the units of characteristic values of these variables . so that , @xmath66 , @xmath67 , and @xmath68 . for example , the characteristic scales of length , time and velocity are given by , r_ch&= & m_ej^1/3 _ 0 ^ -1/3 5.25 n_0 ^ -1/3 pc , + t_ch&= & e^-1/2 m_ej^5/6 _ 0 ^ -1/3 1.66 10 ^ 3 n_0 ^ -1/3 yr , + v_ch&= & r_ch / t_ch 3.16 10 ^ 3 km s^-1 . [ eq : char ] ( we have assumed @xmath69 for he / h@xmath70 by number . ) we have estimated the numerical values for the case @xmath71 erg , @xmath72 g and @xmath73 @xmath20 . we will therefore write @xmath74 , @xmath75 , and @xmath76 , and the radius of the reverse shock , in particular , as @xmath77 .      the values of @xmath65 and @xmath78 approach constant values as @xmath79 if the solutions remain self - similar in the same limit . we write @xmath80 and @xmath81 , and also @xmath82 . the solution to reverse shock evolution exists in the form of two branches , which we label the _ envelope _ ( @xmath83 ) and _ core _ ( @xmath84 ) branches . denoting @xmath85 , the evolution of the reverse shock is given by , & & t^(r_r^ ) = ( ) ^1/2r_r^ + & & \\ {    ll ^-2/(3-n ) , + ^-2/3 ,    . [ eq : ednl3_1 ] where the first part corresponds to the case @xmath86 and the second part , to @xmath87 . the corresponding velocity of reverse shock in these two cases are , & & v^(r_r^ ) = ( ) ^1/2 + & & \\ {    ll , & + , &    . the relative velocity of the reverse shock in the frame of reference of the expanding ejecta , for the case when the reverse shock is in the envelope region , is given by , _ r^(r_r^ ) = lr_r^3/2 ( ) . [ eq : ednl3_2 ] note that , since @xmath88 describes the reverse shock , we will define it as ` @xmath89 ' and use it to label shells in the ejecta . this solution is valid ( in the ed stage ) only as long as the reverse shock remains in the envelope @xmath90 . in the case of @xmath91 ejecta , there is no need for a core and we can take the limit @xmath92 . for @xmath93 however , we must have a `` flat profile '' core to keep the integrated mass finite . for the steep index scenario , therefore , the functional form of the solution will change when the reverse shock reaches the core and we will return to this point later . we now describe the sedov - taylor stage , which is the late - time evolution limit of the non - radiative phase of a supernova remnant . following tm99 , we assume that the shocks trace a constant acceleration path after transition to the st stage at @xmath94 , which ( approximately ) begins when the mass of the ambient medium shocked by the forward shock equals the mass ejected by the supernova . thus the velocity of the oncoming ejecta in the frame of the reverse shock is _ r^*(t^ * ) = _ r , st^ * + _ r , st^*(t^ * - t_st^ * ) , [ eq : stnl3_2 ] where @xmath95 is the constant acceleration and @xmath96 is the velocity of the ejecta w.r.t the reverse shock at @xmath94 . note that @xmath97 . using this and integrating the resulting expression from @xmath94 to @xmath98 gives r_r ^(t^ ) = t^. [ eq : stnl3_1 ]    for the @xmath91 case , we therefore have an implicit solution for the reverse shock position in the ed stage @xmath99 and an explicit solution in the form of a uniform acceleration description in the st stage . for the @xmath100 case , we again have an implicit solution in the ed stage at least while @xmath101 . in fact , an explicit solution for @xmath102 can be determined from the implicit solution in the ed stage for @xmath100 remnants . we have ( see equation ( 74 ) of tm99 ) , t^(r_r^ ) = ( ) ^1/2r_r^ ^-2/(3-n ) . in this expression , we can take the limit @xmath92 by allowing @xmath103 , the ejecta energy @xmath104 remaining finite . in this limit @xmath105 and when the second term in the brackets becomes much larger than unity , we have r_r^(t^ ) = ^1/n ( t^ ) ^ . [ eq : tlc_n5_1 ] this gives us the velocity of the reverse shock as , _ r ^(t^ ) = ^1/n ( t^ ) ^ -3/n , and correspondingly , _ r^(t^)&= & - v_r^ + & = & ^1/n t^-3/n . [ eq : tlc_n5_2 ] this is the result arrived at by chevalier ( 1982 ) and nadyozhin ( 1985 ) - henceforth referred to as ` the cn solution ' . the transition of a supernova remnant with @xmath100 to this stage has been shown to occur extremely fast ( tm99 ) . thus for all practical purposes , we may assume that the remnant begins with the cn stage . the reverse shock then moves into the core at @xmath106 . tm99 assumed that the reverse shock motion after this time is also described by a sedov - taylor trajectory - which leads to better match between the two regimes in terms of continuity of the shock radius and velocity . in the case of @xmath100 , therefore , if we replace @xmath94 by @xmath107 in the st stage equations above , the same analysis follows through . the numerical values of the parameters @xmath108 and @xmath109 are , of course , different from the parameters for the @xmath91 case : viz @xmath94 and @xmath95 . we have , r_r^(t^ ) & = & t^ + _ r^(t^ ) & = & _ r , core^+ _ r , core ^(t^- t_core^ ) . [ eq : tmc_n5_1 ] the values of the parameters used in our calculations have been taken from tm99 , which have been checked with results from simulations . we thus have the final solutions for the reverse shock as follows . in the case of @xmath91 , equations ( [ eq : ednl3_1 ] ; first part ) and ( [ eq : ednl3_2 ] ) describe the solutions in the ed stage , and , thereafter , equations ( [ eq : stnl3_1 ] ) and ( [ eq : stnl3_2 ] ) are appropriate for solutions in the st stage . for the case of @xmath110 , solutions are given by equations ( [ eq : tlc_n5_1 ] ) and ( [ eq : tlc_n5_2 ] ) in the @xmath101 stage . afterwards , in the @xmath111 stage , equations ( [ eq : tmc_n5_1 ] ) describe the solutions . the analytical solutions remain valid until @xmath112 ( tm99 ) , and we calculate the evolution of shocks until this point ( except for @xmath113 ; see below ) .    for a given set of values of @xmath104 and @xmath46 , we can therefore solve for reverse shock position and relative velocity , assuming a density distribution described by index @xmath114 . the parameter @xmath2 in different cases of @xmath114 , is given by , =( 3 -n 5-n ) ( w_core^-(5-n)-n/5 w_core^-(3-n)-n/3 ) w_core^2 , for @xmath115 , we calculate this in the limit of @xmath116 , and for @xmath110 ( including the case of @xmath113 ) we assume ( following tm99 ) a value of @xmath117 . values of other parameters ( such as @xmath118 ) are taken from appropriate tables of tm99 for the relevant values of @xmath114 . we also consider the special case of @xmath113 , for which the mass integral diverges without a core . we follow the prescriptions of tm99 ( their section 8) for this case ( and , again , assume @xmath117 ) , and track the reverse shock with only ed solution without any transition to the st case . according to tm99 , based on their comparison of analytical and numerical results , this prescription gives tolerably good results ( accurate to within @xmath119 ) until @xmath120 . we have introduced a label to a given shell in the supernova ejecta by @xmath121 , the ratio of the velocity of the ejecta in the shell to the maximum ejecta velocity . the ejecta in a shell specified by a given @xmath89 first undergoes free expansion ( in the ed stage ) and self - similar expansion ( in the st stage ) until hit by the incoming reverse shock wave . this occurs at a time , which we call @xmath122 , which is a function of @xmath89 and which is found by equating @xmath89 to the @xmath123 found from the position of the reverse shock . that is , w = = r_r = w r_ej = w v_ej t_hit . or , in terms of dimensionless variables , r_r^= w = ( w ) t_hit ^. this expression for @xmath124 in terms of @xmath125 is equated to the explicit solution for the reverse shock , when available , as a function of time , and the resultant linear equation in @xmath126 and @xmath89 is solved using the bisection method for each given @xmath89 . this is applicable to the steep ( @xmath100 ) ejecta case ( both the cn and st stage ) as well as to the st stage for shallow ( @xmath91 ) ejecta . for the ed stage of shallow ejecta , we use @xmath126 as a function of @xmath127 in equation ( [ eq : ednl3_1 ] ) and then employ the bisection method exactly as before to solve for @xmath128 . either way , we can determine @xmath128 given any shell labeled by a @xmath89 in the sn ejecta . we assume that gas in a given shell of the ejecta evolves adiabatically before @xmath122 . the temperature is then raised to the postshock temperature and the density acquires a jump , corresponding to the value of relative shock velocity @xmath129 . after @xmath122 , the gas again evolves adiabatically , that is , its density decreases as @xmath56 ( equation [ eq : den ] ) . its temperature decreases as @xmath130 , for @xmath131 appropriate for monoatomic gas . for a shell with a certain value of @xmath89 , therefore , we have the following evolution of density , ( t , w ) = \\ {    ll f(w)t^-3 , & + 4 f(w ) t^-3 , &    . [ eq : den_ev ] and temperature , t(t , w ) = \\ {    ll t_i ( ) ^-2 , & + t_rshock ( ) ^-2 , , &    . where @xmath132 , the post - shock temperature due to the reverse shock with relative velocity @xmath133 . for a completely ionized gas the mean molecular weight @xmath134 . we assume a value of @xmath135 k at @xmath136 days , motivated by photometric observations of sn1987a ( catchpole 1987 ) where it was estimated that the photospheric temperature at @xmath137 d after the explosion was @xmath138 k. we have also checked that our results do not depend strongly on these assumptions .      given the above mentioned evolution of density and temperature in shells of ejecta labeled by different values of @xmath89 , we can compute the steady decrease in grain radius , for different types of dust grains . we use the polynomial fit given by tielens et al ( 1994 ) for graphites and silicates as a function of gas temperature . they expressed the rate , @xmath139 in powers of @xmath140 , with coefficients for different grain composition tabulated in their table 4 ( see their equation 4.21 ) . these rates are consistent with recent results of nozawa ( 2006 ) . we follow a shell of ejecta material labeled by a value @xmath141 from @xmath142 10 years after the explosion ( by which time dust grains are believed to have formed in the cooling ejecta , since the formation time scale is of order a few years ( see , e.g. , todini & ferrara 2001 ) ) , to when the reverse shock hits the shell at @xmath122 and beyond , until a time @xmath143 , which is the limit of the validity of the analytical solutions . we have calculated the effect of reverse shocks on sputtering of graphite and silicate grains for typical value of explosion energy , stellar ejecta mass and ambient density . below we show the results for @xmath71 erg , @xmath144 g , @xmath145 g @xmath20 . first , we show the evolution of grain radius ( for graphites and silicates ) for two dust grains embedded in two particular shells , for example , in ejecta characterized by @xmath146 and @xmath71 erg . we show in figure 1 the cases for the shells marked @xmath147 , and @xmath148 . the reverse shock passes through these two shells , first hitting the @xmath149 shell at @xmath150 yr , and then the @xmath147 shell at @xmath151 yr . the bottom panel of figure 1 shows the rise in temperature for these two shells followed by adiabatic cooling . initially the temperature drops to very low temperatures due to strong adiabatic cooling , although , in reality , gas can not be cooled below the temperature of the cosmic microwave background , but we have not used such a lower bound in our calculations . at any rate , the post - shock temperature does not depend on the low temperature of the gas upstream , being determined only by the strength of the reverse shock , and so the results of our calculation remains realistic in spite of the strong cooling before the reverse shock hits the gas in a given shell . figure 2 plots the ratio of final to initial grain sizes as a function of the initial grain sizes for silicates and graphites forming ( and being sputtered ) in shells @xmath152 for the particular case of @xmath146 . _ since the sputtering yield of silicate grains is larger than that of graphites for a given set of parameters _ , silicates are eroded more rapidly than graphite grains for sputtering in a given ejecta shell . also , the relatively outer shell of @xmath149 experiences less sputtering than the inner shells of @xmath153 and @xmath154 . this is expected since the reverse shock ( relative ) speed picks up as it plows through the ejecta , increasing with decreasing values of @xmath89 . to illustrate this point , we plot the trend of the relative velocity of the reverse shock as a function of @xmath89 for the shells hit by the shock in figure 3 , for @xmath146 ( solid ) , @xmath155 ( dotted ) , and @xmath156 ( dashed ) . the relative velocity is a rising function with decreasing @xmath89 , for @xmath146 and for @xmath110 , and it is a peaked function for @xmath155 ( and also for @xmath113 , which is not shown here , but as shown by tm99 ) .    however , we notice in figure 2 that grains ( both graphites and silicates ) in shell @xmath153 ( solid curve ) are sputtered to a somewhat lesser extent than grains in the @xmath157 shell , although the relative speed of the reverse shock should be ( according to figure 3 , solid curve for @xmath146 ) higher when it hits the @xmath153 shell than at the @xmath157 shell . although the post - shock temperature at @xmath153 is higher than at @xmath157 , the shells in the inner region encounter the reverse shock later than shells in the outer region of ejecta , and by the time they encounter it , the density in the inner shells would have decreased rapidly ( see equation [ eq : den_ev ] ) . the rarefaction in the inner shells at the time of encounter with the reverse shocks lessens the effect of dust sputtering in these shells . we illustrate this point by considering grains which are sputtered below a certain size , say , @xmath158 cm ( @xmath159 m ) , as a function of the shell in which they reside ( and get sputtered ) . we determine the maximum size of grains which are sputtered below a size @xmath160 cm , as a function of @xmath89 , for different shells , and present the results in figure 4 . curves for different values of @xmath114 show the maximum size of grains sputtered below @xmath161 m as a function of the parameter @xmath89 ( left panels ) , as well as against the fraction of ejecta mass that is contained inside of the concerned shell , @xmath162 in the right panels . results for graphites and silicate grains are shown in the upper and lower panels respectively . figure 4 clearly shows that sputtering becomes intense in intermediate shells , and decreases ( as a result of rarefaction ) with decreasing value of @xmath89 for small values of @xmath89 . the sizes of grains which are sputtered below @xmath163 m lie in the range of @xmath164 m @xmath165 m , with silicates more strongly sputtered than graphites . in all cases , the curves of the maximum size of sputtered grains increases with decreasing values of @xmath89 and @xmath162 , finally plunging to very low values for @xmath166 , indicating negligible effect of the reverse shock deep inside the ejecta . for example , the ( dotted ) curve for @xmath155 shows a peak at @xmath167 below which the maximum size of sputtered grains decreases .    also , although it is not explicitly shown in figure 4 , the corresponding results for @xmath168 show that reverse shocks do not penetrate most of the ejecta mass in the time period of the validity range of analytical solutions @xmath112 . analytical means allow us to probe deep into the ejecta mass distribution only for @xmath91 , and full hydrodynamical models are needed to address the cases of steeper profiles . for steep density distributions , the limiting time of @xmath169 is reached by the time the reverse shock only skims the surface of the ejecta , as far as mass fraction is concerned . the characteristic time in the case considered here ( @xmath71 erg , @xmath72 g , ambient density @xmath145 g @xmath20 ) is @xmath170 yr . although , by the limiting time of @xmath171 yr for the validity of self - similar regime , reverse shocks can hit shells with small @xmath89 in these steep cases , the mass contained inside of these shells remains very large . in other words , in these cases we can not probe what happens to most of the ejecta mass , or the dust contained in them with analytical means , within the limits of the self - similar regime of shock evolution . we also note that a substantial amount of grain sputtering takes place in the hot gas between the forward and reverse shock that analytical methods can not capture . detailed hydrodynamical calculations are needed to address these issues , and our result can only provide a lower limit to the total mass fraction of dust that is destroyed .    finally , we calculate the total dust mass sputtered away as a function of initial grain sizes in the following manner . we first calculate for a given shell @xmath89 , the final grain size @xmath172 corresponding to the initial grain size @xmath173 . then the fraction @xmath174 is the total dust mass sputtered for grains formed in this shell . we then calculate the total dust mass sputtered for all shells ( for a given initial grain size @xmath173 ) , weighted by the shell mass in which they are situated , as given by , f_d ( a_i)= d m(<w ) m_ej , where @xmath175 is the ejecta mass contained within the shell @xmath89 .    we plot these weighted fractions @xmath176 for graphite and silicate grains as functions of @xmath173 for @xmath177 in figure 5 . thick curves denote the results for silicates and thin ones are for graphite grains . as expected , the sputtered fraction decreases with increasing @xmath173 , and the fraction for silicates is in general larger than that for graphites . the total dust mass fraction that is destroyed can then be evaluated from these results by convolving @xmath176 with an initial grain size distribution . as mentioned earlier , nozawa ( 2003 ) found that the size distribution of synthesized grains is bounded by two power laws , with indices @xmath33 for larger grains and @xmath32 for smaller grains . we therefore estimate the total dust mass fraction destroyed , assuming a size distribution @xmath178 , with @xmath179 and @xmath180 . the destroyed fraction of dust mass is given by , f = n(a ) a^3 f_d(a ) da n(a ) a^3 da + , where the grain volume scales as @xmath181 . the results for graphites and silicates are presented in table 1 , for @xmath177 ( @xmath71 erg , @xmath144 g ) , leaving the cases of @xmath100 for which the reverse shocks do not reach the interiors of the ejecta within the validity range of self - similar solutions . we assume the lower and upper limit for the integral to be @xmath158 cm and @xmath182 cm respectively , as explained earlier in  2 . we also calculate the destroyed fractions for a truncated grain size distribution , with an upper limit of @xmath35 cm , and the results are shown inside brackets in table 1 for comparison . we have further studied the variation of the destroyed dust mass fraction with explosion energy and ejected mass . tables 2 and 3 show the fraction of dust mass supttered for two sets of parameters : table 2 for @xmath144 g and @xmath183 erg , and table 3 for @xmath184 g and @xmath71 erg . figure 6 plots the varition of ( logarithm ) of the destroyed dust mass fraction , @xmath185 , for silicates , for different values of explosion energy and ejected mass , and for different mass profiles ( @xmath177 ) . in the upper panel , we plot the variation of @xmath185 with @xmath46 ( in logarithm ) , keeping the explosion energy constant at @xmath71 erg , and in the lower palnel , we plot ( logarithms of ) @xmath185 with explosion energy @xmath104 , keeping the ejected mass fixed at @xmath186 g. the destroyed fraction generally increases with ejected mass , but its variation with explosion energy is not monotonic . the reason is that the process of dust destruction depends mainly on two factors : the speed of the reverse shock ( which depends on the characteristic speed @xmath187 ) and the characteristic time , @xmath188 . now , @xmath189 , whereas @xmath190 . it would appear that a change in ejected mass manifests itself in increasing @xmath188 , and thereby increasing the destroyed fraction , whereas , a change in @xmath104 affects @xmath188 and @xmath187 in a complicated manner , which results in the variation shown in the bottom panel of figure 6 . we therefore find that a mass fraction @xmath191 % of silicates and graphite grains created in cooling ejecta can be sputtered away by the reverse shock if the density distribution of the ejecta has a shalow profile ( @xmath192 ) . nozawa et al ( 2007 ) recently studied sputtering of dust in reverse shock and found a destroyed dust mass fraction of @xmath193 ; their result for an ambient hydrogen number density of @xmath194 @xmath20 and a progenitor mass of @xmath195 m@xmath8 is @xmath196 ( their table 1 ) . in fact , their result for the ` unmixed grains ' model ( which has to do with spatial mixing of the core heavy - element distribution ) in which the maximum size is @xmath197 m is @xmath198 . it should be noted , however , that a considerable amount of sputtering in their calculation is caused by the hot plasma between the forward and the reverse shocks ( see  3.3 in nozawa et al ( 2007 ) ) , which we have not considered . in our case , for analytical simplicity , we have assumed the post - reverse shocked gas to be cooling adiabatically . our results are , therefore , expected to give lower bounds on the actual dust mass fraction destroyed in sn remnants . there is another reason why the destroyed fraction of dust mass calculated here is lower than that of nozawa et al ( 2007 ) and bianchi & schneider ( 2007 ) . strictly speaking , the destruction rate of tielens et al ( 1994 ) used here is valid for a gas with solar abundance . the gas in the dust formation region in the supernova ejecta is expected to be metal rich , and the destruction of dust grains in this gas can be more efficient in this case , since sputtering yields by metal ions are much higher in general than by hydrogen and helium ions . it should be noted that our results for the destroyed fraction is independent of the ambient density , since the gas density enters into our calculation only to change @xmath188 ( notice in equations [ eq : char ] that @xmath187 is independent of ambient density , and so the relative speed of reverse shock , and in turn the post - shock temperature , are also independent of ambient density ) . in reality , however , a lot of grain sputtering would take place between the forward and reverse shock , where the gas density will crucially depend on the ambient density . this aspect of grain sputtering is neglected in our analytical calculation , but is captured in the simulation results of bianchi & schneider ( 2007 ) and nozawa ( 2007 ) . another difference between our results and those of bianchi & schneider ( 2007 ) arises from the assumption of initial grain size distribution . bianchi & schneider ( 2007 ) used grains of small size in their calculation , with silicate grains smaller than @xmath199 m and graphites smaller than @xmath200 m . also , their size distribution is more confined to a narrow range than the power law distribution assumed here . both these factors would enhance the destroyed fraction of dust mass in reverse shocks . for example , if the sizes of @xmath201 grains have a delta - function distribution around @xmath202 ( see figure 1 of bianchi & schneider 2007 ) , then the curves in figure 2 of the present paper ( say , for @xmath153 ) yield a mass destruction fraction of @xmath203 % ( with @xmath204 ) . for @xmath205 grains of size @xmath206 , we similarly estimate a destroyed mass fraction of @xmath207 % . from figure 2 , we estimate that one requires @xmath208 in order to get @xmath209% destruction of silicate grains . a note on the observed density distribution of supernovae ejecta is in order here . chevalier & fransson ( 1994 ) studied a model of the ejecta from a type ii supernova with a shallow ( @xmath115 ) core surrounded by a steep ( @xmath110 ) envelope . in the case of type ia supernovae , a steep density distribution in the ejecta mass has also been discussed in the literature ( colgate & mckee ( 1969 ) ; dwarakadas & chevalier ( 1997 ) ) . there has been success , however , in modelling data of type ia supernova with uniformly distributed ( @xmath210 ) ejecta ( hamilton & sarazin ( 1984 ) ; hamilton , sarazin & szymkowiak ( 1986 ) ) . it is worth considering what observations might improve our understanding of the net dust production by sne . far - infrared and sub - millimeter observations of reverse - shocked dust in young sne by _ spitzer _ , _ herschel _ , and other facilities will help , but our theoretical studies suggest that unshocked ( cold ) dust may harbor a considerable mass of undetected dust . to constrain this dust and distinguish it from surrounding interstellar clouds will probably require sub - mm observations with small beam sizes . this brings in complications of the circumstellar environment of young sne . furthermore , the long times ( thousands of years ) required for reverse shocks to reach the core ejecta suggest that late - time observations of supernova remnants would be useful . we have studied the effect of reverse shocks analytically , in the regime of self - similar evolution , on the sputtering of dust grains that are believed to form in cooling ejecta . for representative cases we found that fractions of dust mass that is destroyed are of order of order @xmath211 % of silicates and graphites , for sn of explosion energy @xmath212 erg , ejecta mass @xmath213 g , and an ambient density @xmath214 g @xmath20 . our analytical formalism provides only a lower bound on the dust mass fraction that is destroyed by the reverse shock , since it ignores further sputtering of grains in hot plasma between the forward and reverse shocks . our results are , therefore , consistent with the recent estimates from numerical simulations which include these additional effects . furthermore , our study provides a formalism to generalize these results to cases with different values of sn parameters . we thank drs . r. chevalier , e. dwek , t. nozawa , a. ray and y. shchekinov for helpful discussions . this work was supported at the university of colorado by nasa theory grant nnx07-ag77 g and nsf theory grant ast07 - 07474 . bertoldi , f. , carilli , c. l. , cox , p. , fan , x. , strauss , m. a. , beelen , a. , omont , a. & zylka , r. 2003 , a&a , 406 , l55 bianchi , s. & schneider , r. 2007 , mnras , 378 , 973 catchpole , r. m. et al . , mnras , 229 , 15 chevalier , r. a. 1982 , apj , 258 , 790 colgate , s. a. & mckee , c. 1969 , 157 , 623 deneault , e. a. , clayton , d. d. & heger , a. 2003 , apj , 594 , 312 dunne , l. , eales , s. , ivison , r. , morgan , h. , edmunds , m. 2003 , nature , 424 , 285 dwek , e. 2006 , science , 313 , 178 dwek , e. , & arendt , r. g. 2007 , in aip conf . proc . , supernova 1987a : 20 years after , ed . s. immler , k. weiler , r. mccray , vol . 937 , 58 dwek , e. , & werner , m. w. 1981 , apj , 248 , 138 gerardy , c. l. , fessen , r. a. , hfflich , p. & wheeler , j. c. 2000 , aj , 119 , 2968 gerardy , c. l. 2002 , apj , 575 , 1007 hamilton , a. j. s. & sarazin , c. l. 1984 , apj , 281 , 682 hamilton , a. j. s. , sarazin , c. l. & szymkowiak , a. e. 1986 , apj , 300 , 698 kozasa , t. , hasegawa , h. & nomoto , k. 1989 , apj , 344 , 325 krause , o. , et al . 2004 , nature , 432 , 596 ledoux , c. , bergeron , j. , petitjean , p. 2002 , a&a , 385 , 802 mccray , r. 1993 , ara&a , 31 , 175 mccray , r. 2007 , in aip conf . proc . , supernova 1987a : 20 years after , ed . s. immler , k. weiler , r. mccray , vol . 937 , 3 meikle , w.p.s . , mattila , s. , et al . 2007 , apj , 665 , 608 morgan , h. l. & edmunds , m. g. 2003 , mnras , 343 , 427 moseley , s. h. , dwek , e. , giaccum , w. , graham , j. r. , loewenstein , r. f. , silverberg , r. f. 1989 , nature , 340 , 697 nadyozhin , d. k. 1985 , ap&ss , 112 , 225 nozawa , t. , kozasa , t. , umeda , h. , maeda , k. & nomoto , k. 2003 , apj , 598 , 785 nozawa , t. , kozasa , t. , habe , a. 2006 , apj , 648 , 435 nozawa , t. et al . 2007 , astro - ph/0706.0383 pettini , m. , smith , l. j. , hunstead , r. w. & king , d. l. 1994 , apj , 426 , 79 schneider , r. , ferrara , a. & salvaterra , r. 2004 , mnras , 351 , 1379 seab , c. g. & shull , j. m. 1983 , apj , 275 , 652 shull , j. m. 1978 , apj , 226 , 858 stanimirovic , s. , et al . 2005 , apj , 632 , l103 sugerman , b. e. k. et al . 2006 , science , 313 , 196 tielens , a. g. g. m. , mckee , c. f. , seab , c. g. & hollenbach , d. j. , 1994 , apj , 431 , 321 todini , p. & ferrara , a. 2001 , mnras , 325 , 726 truelove , j. k. & mckee , c. f. 1999 , apj , 120 , 299 ( tm99 ) whittet , d. c. b. 1992 , _ dust in the galactic environment _ , iop publishing , great britain .", "tags": [], "output_text_a": "This paper explores the chemical history and formation of dust grains in the interstellar medium (ISM) of galaxies, focusing on the role of supernovae (SNe) in dust production. The study highlights the challenges in understanding dust formation, especially in high-redshift galaxies, where traditional models of grain formation in low-mass stars fall short. The paper discusses alternative models, such as dust formation in core-collapse supernovae, which can occur on shorter timescales. However, observations of nearby supernova remnants (SNRs) show inconsistencies with these models, as the observed dust masses are significantly lower than predicted.\n\nThe authors investigate the effect of reverse shocks on dust survival in SNRs, using analytical models to estimate the destruction of dust grains. They find that reverse shocks can destroy a significant fraction of dust, depending on factors like ambient gas density and explosion energy. The study uses self-similar solutions to model the evolution of forward and reverse shocks in SNRs, considering different ejecta density profiles. The results suggest that a substantial fraction of dust mass can be sputtered away by reverse shocks, with silicates being more affected than graphites.\n\nThe paper concludes that while analytical models provide a lower bound on dust destruction, detailed hydrodynamical simulations are needed to capture the full extent of dust sputtering, especially in the hot plasma between forward and reverse shocks. The study emphasizes the need for further observations and simulations to better understand dust production and survival in SNe, which has implications for the chemical evolution of galaxies and the early universe.", "output_text_b": "The article discusses the importance of understanding the chemical history of heavy elements, or metals, in the interstellar medium (ISM) of galaxies. These refractory elements are often depleted from the gas phase and locked into grains, providing a substantial reservoir of coolants in the solid-state phase. Interstellar grain surfaces are believed to be formation sites for molecular hydrogen, which is both a coolant and the starting point for a rich cloud chemistry. Grains also provide a critical transfer mechanism for reprocessing UV/optical starlight into far-infrared and sub-mm emission from interstellar molecular clouds and high-redshift galaxies. In the high-redshift universe, the first dust grains may influence the thermodynamics of the primordial gas and thereby control rates of star formation. Recent observations of dust grains at high redshift have been puzzling in the context of their formation.\n\nTraditional models of grain formation in evolved low-mass stars have difficulty explaining the large observed dust masses in high-redshift galaxies. Recent models have focused on other sites of dust grain formation, such as ejecta of core-collapse supernova explosions that can occur on shorter time scales. Core-collapse supernovae are thought to be capable of synthesizing a significant amount of dust in the SN ejecta. Applying a theory of nucleation and grain growth, several studies have estimated the dust mass formed in expanding SN ejecta. However, observations of dust in nearby SNe appear inconsistent with this model, falling factors of 10^100 short of the required amounts.\n\nThe paper aims to determine how much dust survives the SN event and is incorporated into the surrounding ISM. The relative speed of reverse shocks with respect to the expanding ejecta can be very large, raising the temperature of the ejecta and potentially destroying nascent dust grains. The paper studies the effect of reverse shocks in detail, using a simple and analytically tractable problem in the regime of self-similar evolution of both forward and reverse shocks.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the role of supernovae in dust production and the challenges in understanding dust formation, especially in high-redshift galaxies.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is understanding the chemical history and formation of dust grains in the ISM of galaxies, is highlighted.\n4. The methodology, including the use of analytical models and self-similar solutions to estimate dust destruction, is mentioned.\n5. Significant results, such as the impact of reverse shocks on dust survival and the need for further simulations, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"reverse shocks\" and \"sputtering\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The potential impact of the research on understanding the chemical evolution of galaxies and the early universe is mentioned.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the importance of understanding the chemical history of heavy elements in the ISM, the role of dust grains, and the challenges in explaining dust masses in high-redshift galaxies.\n2. **Conciseness**: The summary is concise but slightly exceeds the 250-word limit.\n3. **Research Problem**: The summary highlights the research problem of understanding dust grain formation and survival in the ISM.\n4. **Methodology**: The summary mentions the use of a theory of nucleation and grain growth and the study of reverse shocks.\n5. **Significant Results**: The summary includes significant results, such as the inconsistency of observations with traditional models and the potential destruction of dust grains by reverse shocks.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"reverse shocks.\"\n8. **Logical Structure**: The summary is logically structured with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding dust formation and its impact on star formation rates."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the past decade has transformed our understanding of the neutrino ; nevertheless , the absolute scale of the neutrino mass remains unknown . the best neutrino mass limits from direct measurements come from the tritium endpoint experiments mainz and troitsk  @xcite , both of which place @xmath1  ev . measurements of the cosmic microwave background , coupled with cosmological models , have led to somewhat better ( but model - dependent ) constraints of @xmath2  ev  @xcite . the next generation of tritium endpoint measurement is now being pursued by the katrin experiment  @xcite . they expect to push the limit on the neutrino mass as low as @xmath3  ev . an independent avenue of research is neutrinoless double @xmath0-decay , which could test the majorana nature of the neutrino and possibly determine its mass  @xcite . we propose here a new approach , fundamentally different from both katrin and neutrinoless double @xmath0-decay . our work is motivated by the recent development of general methods for trapping and cooling of atoms , which enable the creation of a sample of ultracold atomic tritium . we first describe the atomic trapping and cooling methods and then outline a prototype of a neutrino mass experiment . we present detailed simulation results and the detector requirements necessary to reach sub - ev sensitivity on the neutrino mass . cooling of atomic translational motion has been the topic of intense research for the past thirty years . the standard approach to date is laser cooling  @xcite , which has been applied to cooling and trapping of radioactive alkali atoms in order to probe the weak interaction  @xcite . despite the enormous success of this method , it has been limited to a small set of atoms due to the requirement of a cycling transition that is accessible with lasers . in particular , hydrogenic atoms have not been amenable to laser cooling . trapping and cooling of hydrogen atoms was accomplished in a dilution refrigerator , followed by evaporative cooling , but these methods have not been extended to other isotopes of hydrogen  @xcite .    over the past few years a more general method has been demonstrated in a series of experiments . the starting point is the supersonic molecular nozzle which creates a very monochromatic but fast beam  @xcite . paramagnetic atoms or molecules are seeded into the beam in a region of high density and decouple from the carrier gas downstream . these atoms are stopped with a series of pulsed electromagnetic coils , an `` atomic coilgun . '' such a device has been used to stop a beam of metastable neon , molecular oxygen , and atomic hydrogen  @xcite . once the atoms are magnetically trapped , they can be further cooled using a method of single - photon cooling , which is based on a one - way barrier  @xcite . together the atomic coilgun and single - photon cooling provide a general two - step solution to the trapping and cooling of paramagnetic atoms or molecules . in particular , these methods will work well on atomic tritium , which has a suitable 12.3 year half - life . we consider an experiment to observe the @xmath0 decay of ultracold atomic tritium . the decay produces an outgoing @xmath4he@xmath5 ion and a @xmath0 , both of which can be detected . we need a spectrometer to measure the energy of the @xmath0 , along with a non - invasive technique for measuring two components of its momentum . by utilizing the coincidence between the @xmath0 and the @xmath4he@xmath5 ion , we can determine the ion s three momentum components from its time - of - flight . measurement of the four - momenta of the ion ( @xmath6 ) and the @xmath0 ( @xmath7 ) yields the neutrino mass squared : @xmath8    the advantages of this approach include : an extremely thin source that results in low scattering ; an atomic tritium source with simple final state effects ; a coincidence measurement with the @xmath0 to reduce background ; a direct neutrino mass peak reconstruction ; and the utilization of at least 500  ev of the @xmath0 energy spectrum . nevertheless , this approach faces several experimental challenges , particularly regarding the measurement of the @xmath0 momentum to sufficient precision , and trapping enough tritium atoms to obtain sufficient statistics . we address these challenges with a proposed experimental setup that would consist of three detectors shown in figure 1 : a microchannel plate ( mcp ) to detect the helium ion , a spectrometer to measure the @xmath0 s energy , and an optical lattice of rubidium rydberg atoms capable of measuring two of the @xmath0 s three momentum components . we can place the @xmath0-spectrometer close to the source , with the mcp for the @xmath4he@xmath5 ion detection several meters away from the source . using the @xmath0 event detected by the spectrometer as the initial time , we can determine the time - of - flight of the ion to the mcp . combining the time - of - flight with the mcp hit position yields the three momentum components of the helium ion . for example : @xmath9 where @xmath10 and @xmath11 and @xmath12 are reconstructed from the mcp hit position assuming the tritium decay came from the center of the source . here @xmath13 is the distance from the mcp to the source . the background event rate from the mcp would be @xmath14  event/@xmath15/s  @xcite , where cosmic ray events are eliminated either by deploying the detector in an underground laboratory or by implementing an efficient veto . although the coincidence in the @xmath0-spectrometer would be helpful , for any given @xmath0 event of the correct energy there will be a @xmath16 chance of seeing a background mcp hit , given that the coincidence time between the @xmath0 and the ion will be on the order of 0.3  ms . in order to evaluate our ability to discriminate true events from backgrounds , we simulated data in which the mcp hit position was randomized , and we studied how our reconstruction algorithm evaluated the neutrino mass squared for such random events . such events typically reconstruct to be more negative than @xmath17  ev@xmath18 and would be clearly separated from true helium ion hits . our simulations indicate it is possible to reduce backgrounds to @xmath19x@xmath20 , not including the rejection due to the coincidence requirement , simply by cutting any events that reconstruct the neutrino mass squared to be more negative than @xmath21  ev@xmath18 . this cut introduces negligible bias into the neutrino mass squared peak .    in order to measure the momentum of the @xmath0 without significantly altering its energy , we propose exploiting the effect of a passing electron on rydberg atoms  @xcite . in the @xmath0 s flight path before it reaches the spectrometer , we create an optical lattice filled with rubidium atoms in the ground state  @xcite . using laser excitation , we can excite the atoms to a high rydberg state  @xcite , such as 53s . when the @xmath0 passes one of these atoms , it can excite the atom from a 53s state to a 53p state , and the atom will remain trapped in its optical lattice position . we propose slowing the electrons with a controlled voltage soon after they leave the source so that by the time they reach the optical lattice , they have a maximum energy of 900  ev , which increases their cross section for exciting a rydberg atom to 0.36 x 10@xmath22 @xmath15 times larger than the transition energy , and the transition is dipole allowed . we numerically computed the radial part of the transition matrix element by using a numerov algorithm to compute the radial orbitals on a square root mesh in @xmath23 . we numerically integrated the radial orbitals times the bessel function , @xmath24 , for the transition operator using 4th order integration . to obtain the total cross section , we numerically integrated over the momentum transfer @xmath25 from @xmath26 to a @xmath27 using equally spaced points in @xmath25 with a @xmath28 = 0.01/@xmath29 . ] . when a @xmath0 signal is detected downstream in the spectrometer , the 53s atoms are optically de - excited using stirap ( stimulated raman adiabatic passage )  @xcite , and an electric field of 100 v / cm is ramped within @xmath30130  ns to ionize any rydberg atoms in a 53p state . once the atoms are ionized , they will be detected by a multi - hit position - sensitive mcp . based on realistic density limits , the @xmath0 will excite several rydberg atoms as it passes through the optical lattice , so we will be able to obtain the projection of a track from the passing @xmath0 .    in order to obtain the two @xmath0 momentum components necessary for reconstruction , we need to have a second optical lattice to project the momentum component in a direction orthogonal to the first . by combining the track projections from these two mcps with the energy measurement from the spectrometer , we can reconstruct the momentum of the @xmath0 that traversed the optical lattices using equation ( 2 ) and the reconstructed velocity : @xmath31 where @xmath32 is the kinetic energy of the @xmath0 as measured in the spectrometer and @xmath11 and @xmath12 are obtained from the @xmath0 tracks in the optical lattices . using rydberg atoms with a principal quantum number n=53 would result in a negligible change in the @xmath0 s four - momentum as it passes . we estimate that we can obtain a density of 10@xmath33 atoms/@xmath34 in the optical lattice  @xcite , and we expect the passing @xmath0 to excite an atom within 5 @xmath35 m , leading to a high spatial resolution . the two major sources of backgrounds that must be eliminated for this rydberg technique are collisions and black body excitations . holding the rydberg atoms in an optical lattice eliminates collisions that could cause spurious transitions to the 53p state  @xcite . by surrounding the optical lattice with a wire mesh , we can eliminate most of the black body radiation that could excite atoms from the 53s to the 53p state . the spacing of the mesh would be small compared to the microwave wavelength , suppressing blackbody emission of the mesh itself . additionally , the rubidium atoms can be periodically cycled back to the ground state and then up to the rydberg 53s state  @xcite , which will prevent background 53p events from accumulating , while still allowing the atoms to spend most of their time in the 53s state . this non - invasive method may find other applications in the detection of low - energy electrons . our current experimental simulation makes several assumptions about detector precision in order to determine the required equipment . we assume an mcp of 15  cm x 15  cm with a timing resolution of 20  ps and a high spatial resolution of 2  @xmath35 m  @xcite . it is placed 5  m from the tritium source and has a 44@xmath36 efficiency for detecting an ion when it is hit . the tritium source is modeled as a 100  @xmath35 m sphere at a temperature of 1  @xmath35k . given that the density of the source can not exceed 10@xmath37 atoms/@xmath34 and that the radius of the source is 50  @xmath35 m , the column density of the source is less than 10@xmath38 atoms/@xmath15 . we therefore estimate multiple scattering within the source to be small and do not include it in the simulation . the @xmath0-spectrometer is a hemispherical analyzer with an energy resolution of 5  mev , which is reasonable given current devices  @xcite . simulations indicate that the rydberg atom method of measuring the @xmath0 momentum results in a resolution that varies from 40  mev / c to 2.8  ev / c depending on the @xmath0 s four - momentum . we assume a large rydberg atom optical lattice with dimensions 10 cm x 10 cm x 1 cm placed 2 m from the source , which optimizes the detector s resolution and solid - angle acceptance . our simulated @xmath0 spectrum includes first - order final state corrections . in tritium @xmath0-decay , the helium ion is formed in the ground state in 70@xmath36 of the decays , and our simulation simplifies the true spectrum of final states by assuming that the helium ion goes into the first excited state for the remaining 30@xmath36 of the decays . for more than 99.9@xmath36 of the events , the magnitude of the reconstructed neutrino mass is larger when the wrong state is assumed for the helium ion , which provides us with a simple method of determining the true state of the helium ion . this method does not bias the neutrino mass fit in any significant way . both the neutrino s reconstructed mass peak and the shape of its @xmath0-spectrum contain information about its mass . in order to utilize all of this information , we perform a maximum - likelihood fit using two - dimensional probability density function ( pdf ) . we create a series of 2d pdfs using much higher statistics than we use for our simulated data . each of the six pdfs we create has a different assumed neutrino mass , and the assumed mass values are @xmath39  ev apart . figure 2 shows the 2d pdf for the case of zero neutrino mass . by interpolating between the pdfs , we find the most likely value for the neutrino mass for a particular data set .    unlike previous tritium @xmath0-decay experiments that utilize information only a few ev away from the endpoint , our fit extends back to 18.1  kev , a full 500  ev from the endpoint . the statistics gained by moving away from the endpoint substantially improve the precision on the neutrino mass even as the spread in reconstructed mass gets broader . figure 3 shows how individual detector and reconstruction uncertainties contribute to broadening the reconstructed neutrino mass squared peak , especially the @xmath0 momentum measurement and the initial @xmath4h temperature . these smearings create large uncertainties for each reconstructed event , but the uncertainty in the mean of the peak decreases with added statistics . combining this neutrino mass peak information with the information from the beta spectrum fit allows for a sub - ev determination of the neutrino mass . clearly , systematic shifts in the mean of the reconstructed mass spectrum would have to be controlled at a very high level , but calibrations of the spectrometer using the conversion electron from @xmath40kr as well as information from the energy spectrum itself should allow us to mitigate these effects . .minuit fit results and minos errors for simulated data runs which had different assumed neutrino masses . [ cols=\"^,^,^,^\",options=\"header \" , ]     in order to reach an @xmath41 limit comparable to katrin s , on the order of @xmath42 tritium decays would have to occur , which corresponds to trapping  @xmath43x@xmath44 tritium atoms as a source if the experimental live runtime is @xmath45 of one year . that many atoms can not be contained in a single @xmath46 m diameter trap , which can not have a density exceeding @xmath47 atoms / cm@xmath4 without contributing significant scattering in the source . any feasible experiment , therefore , will require an array of tritium traps spaced far enough apart to allow the fit reconstruction to accurately determine the decay origin . a third optical lattice filled with rydberg atoms could also be used to detect a track from the beta as it leaves the source , aiding in the reconstruction of where the decay occured in the extended source . tritium sources can be stacked by repeated launching and trapping . the primary limitation to the number that can be stacked is the trap lifetime . this trap lifetime can be on the order of 5 - 10 minutes using appropriate cryogenic cold fingers and careful bake - out of the chamber . we estimate that the necessary 10@xmath38 tritium atoms can be accumulated in this fashion . table 1 shows the results of the fit assuming @xmath42 tritium decays for six different assumed neutrino masses . figure 4 shows the pull distribution of the fit results shown in table 1 , and its shape is consistent with a normal gaussian . figure 5 indicates how the size of the fit uncertainties increases as the number of tritium decays decreases . our method of investigating tritium @xmath0-decay has the potential to establish an interesting limit on the neutrino mass . although several engineering challenges remain , such an experiment provides an independent and complementary method of measuring the neutrino mass . we acknowledge support from the alfred p. sloan foundation ( jrk ) and the department of energy ( fr , jrk ) . we also acknowledge support from the sid w. richardson foundation , the state of texas advanced research program , and the national science foundation ( mgr ) . we thank huaizhang deng for helpful discussions .", "tags": [], "output_text_a": "This paper proposes a novel approach to measure the absolute scale of neutrino mass, which remains unknown despite significant advancements in neutrino physics. The proposed method differs from existing techniques like the KATRIN experiment and neutrinoless double beta decay. It leverages recent developments in trapping and cooling ultracold atomic tritium to observe its beta decay. The experiment aims to measure the energy and momentum of the emitted beta particle and helium ion to determine the neutrino mass squared. The setup includes a microchannel plate for ion detection, a spectrometer for energy measurement, and an optical lattice of rubidium Rydberg atoms to measure momentum components. The paper discusses the experimental challenges, such as precision in momentum measurement and sufficient tritium atom trapping, and presents simulation results indicating the feasibility of achieving sub-eV sensitivity. The method could complement existing techniques and provide an independent measurement of neutrino mass, although it faces engineering challenges that need to be addressed. The research is supported by various foundations and acknowledges contributions from several collaborators.", "output_text_b": "The article discusses a proposal for a new approach to measuring the neutrino mass, which is currently unknown. The best limits from direct measurements come from tritium endpoint experiments, with the Mainz and Troitsk experiments providing a limit of 2 eV. Cosmic microwave background measurements, combined with cosmological models, give a more model-dependent constraint of 0.2-2 eV. The KATRIN experiment aims to push the limit down to 0.2 eV. The proposed approach is based on the trapping and cooling of atoms, specifically atomic tritium, using an atomic coilgun and single-photon cooling. This method can provide a general two-step solution to trapping and cooling paramagnetic atoms or molecules. The proposed experiment would observe the decay of ultracold atomic tritium and measure the energy and momentum of the decay products to determine the neutrino mass.", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions by describing the novel approach to measure neutrino mass and the experimental setup proposed in the paper.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of measuring the absolute scale of neutrino mass.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the methodology of using ultracold atomic tritium and the experimental setup involving a microchannel plate, spectrometer, and optical lattice.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes the conclusion that the method could achieve sub-eV sensitivity and complement existing techniques.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains the terms used, such as the experimental setup components.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the key experiment involving the measurement of beta decay of ultracold atomic tritium.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by stating its potential to provide an independent measurement of neutrino mass.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by discussing the proposal for a new approach to measuring the neutrino mass and mentioning the current best limits and the KATRIN experiment.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of determining the absolute scale of the neutrino mass.\n4. **Methodology**: The summary mentions the methodology of trapping and cooling atomic tritium using an atomic coilgun and single-photon cooling.\n5. **Significant Results**: The summary does not explicitly mention significant results or conclusions drawn by the authors, such as the potential to establish an interesting limit on the neutrino mass.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"atomic coilgun\" and \"single-photon cooling.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions the observation of the decay of ultracold atomic tritium as a key experiment.\n10. **Significance**: The summary does not explicitly reflect the paper's significance or potential impact in its field, such as the independent and complementary method of measuring the neutrino mass."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "quantum computing rely on two - states quantum systems ( qubits ) to store information and quantum gates to process it @xcite . although other formulations exists @xcite , this formulation have dominated the field due to its close analogy with classical binary information processing , among other reasons . one of the important elements of this analogy is design of quantum gates @xcite , which , in many cases , can be understood in terms of classical gate procedures applied to binary - labeled basis states . this means that quantum system must be driven by classical external field to perform rotation of basis @xcite . the amplitudes are driven or adiabatically carried through certain trajectories that start and end at some qubit basis states . in the case of entanglement - manipulating gates , such trajectories must also involve states that are formed due to physical interaction between qubits @xcite . these intermediate states , however , do not have to belong to qubits computational basis @xcite .    while qubits are binary quantum objects , physical systems that are used to represent them are not @xcite . record coherence times and successful multi - qubit manipulations recently achieved in systems of superconducting qubits that are nearly harmonic oscillators have brought this fact into focus @xcite . in these systems qubits are still encoded by the two lowest energy states . yet , higher energy states are easily accessible and are not that distinct from the qubit states @xcite . recently , it was experimentally demonstrated @xcite that interaction via one of such higher energy state in a superconducting system of two transmons @xcite can be used to perform entangling quantum gates . entangling quantum gates in other architectures , particularly involving optical control @xcite , have also relied on similar higher energy states participating in physical interactions between qubits . in all these cases the physics of performing entangling quantum gates involves driving the system through such auxiliary interacting state to accumulate a non - local phase .    in our recent work @xcite it was suggested that quantum gates can use physical interactions @xcite between systems that represent qubits more effectively if classical driving is replaced by temporarily - enabled continuous time quantum walks @xcite . this approach gives multi - qubit multi - state systems freedom to explore multiple quantum states involved in interaction , hence , potentially enabling more effective phase accumulation . in the present paper we investigate this approach in greater details focusing on the gates involving one to three qubits . we formulate general requirements on control and interaction between multi - state systems that are necessary to perform quantum gates via quantum walks . the procedure is illustrated with examples of one- , two- , and three - qubit gates . in the case of two- and tree - qubit gates , we obtain a class of solutions for systems involving one auxiliary state . this class of solutions incorporates specific cases derived earlier in @xcite . we present a detailed analysis of graphs involved in quantum walks performing these gates . specifically , exact analytical solutions for continuous time quantum walks on non - symmetric linear chain graphs , with up to five states , and square graphs are obtained . the paper is organized as follows : section  [ sec : qw ] outlines the approach introduced recently in @xcite . in this section we also formulate general requirements on control ( driving ) field needed to perform quantum gates on qubits via continuous time quantum walks . in section  [ sec : qb ] we discuss the structure of transition in interacting multiqubit system in which extra ( auxiliary ) states are available for each qubit , and construct quantum gates based on quantum walks . we focus on systems that have at least one accessible ( higher energy ) auxiliary state in addition to two qubit states . we start with the case of single - qubit gates in subsection [ sec:1qb ] . this gates are formulated via simple quantum walks through a @xmath0-system . although quantum walk perspective in this case is redundant , it helps to illustrate the approach which is , then , used for larger systems to construct entangling gates . in subsection [ sec:2qb ] we formulate a class of quantum walk solutions representing control z gates ( cz @xcite ) . in subsection [ sec:3qb ] , a set of quantum walks performing diagonal toffoli gate ( control control z @xcite ) is introduced . detailed analytical investigation of continuous time quantum walks on all related graphs is given in the subsequent sections ( secs . [ sec : lg]-[sec : sq ] ) . specifically , in sec . [ sec : lg ] we investigate quantum walks on non - symmetric linear chain graphs with two to five nodes . in sec . [ sec : tg ] we discuss quantum walks on single - level tree graphs . in sec . [ sec : sq ] we investigate quantum walks on symmetric and non - symmetric square graphs . qubits are defined as binary ( two - state ) quantum systems @xcite . a distinction is often made between logical qubits used in quantum algorithms @xcite and hardware - defined ( physical ) qubits that are parts of the physical system used for quantum computing . while this distinction is important because logical qubits can incorporate error correction procedures @xcite based on operations involving multiple physical qubits , having a reliable set of entangling operations ( gates ) is crucial in both cases . here we focus on physical qubits formed as parts of a larger quantum system @xcite , each defined via hamiltonian @xmath1 although not a matter of necessity @xcite , qubits are typically constructed such that they are well isolated from each other @xmath2 to facilitate simpler error correction and algorithms development @xcite . we will focus on such case as it is relevant to many existing advanced qubit designs @xcite . all of these physical systems naturally incorporate a set of well defined states beyond states @xmath3 and @xmath4 of each qubit . for many quantum computing designs these states are relied on for single - qubit rotations and initializations , and , in some cases , simple two - qubit manipulations @xcite . when physical interaction between systems that encode qubits is present , these auxiliary states @xmath5 are not necessarily local to each qubit @xcite , i.e. , @xmath6 for @xmath7 that have at least one non - binary digit ( notation @xmath8 ) . however , we will assume that they approach local states in the limit of no interaction between ( physical ) qubit systems . this adiabatic connection will allow us to use the same labeling for interacting and non - interacting states to simplify further discussion . we will also assume that qubits states are not participating in any interaction ( except with external control pulses ) and remain local . in this case @xmath9 for @xmath8 , when interaction is adiabatically turned off . there can also be states that become completely disconnected from any of the qubit s local physical system when interaction is removed @xmath10 these states , depending on the architecture , may originate from additional quantum systems , unused qubits , or control apparatus , and will not be considered in the present paper . the overall hamiltonian of the system incorporating all relevant states is @xmath11 where @xmath12 represents external classical control @xcite and has a general form of @xmath13 where @xmath14 and @xmath15 are dimensionless time - dependent and constant amplitudes of @xmath16 harmonic of the control field . the slow functions @xmath14 define pulse envelops for each frequency , such that @xmath17 .    in order to eliminate local accumulation of phases due , to possibly distinct , qubit state energies @xmath18 , we define qubits and focus on evolution in the rotating frame of reference ( interaction representation , see @xcite ) @xmath19 in this case , @xmath20 corresponds to trivial evolution ( idling ) of qubits , because qubit states do not participate in interaction . if @xmath21 for some period of time from @xmath22 to @xmath23 , a non - trivial evolution ( quantum gate ) that involve one or more qubits and , possibly , interacting higher energy auxiliary states can occur . the corresponding evolution operator is @xmath24 p\\end{aligned}\\ ] ] where @xmath25 is time - ordering and @xmath26 is projector operator that projects onto qubit ( boolean ) domain ( [ eq : qw : h_qbs ] ) . the projection signifies the fact that , ultimately , only qubit evolution is of interest : a leak from the qubit subspace can be a source of strong decoherence that is not addressable with standard error correction procedures . it is , therefore , crucial to ensure that @xmath27 is unitary @xmath28    in this paper we will focus on the case in which only one @xmath29 term is present in @xmath12 and frequencies @xmath30 are in resonance with transitions in the system . in this case , dynamics leading to @xmath27 can be evaluated analytically . when rotating wave approximation is appropriate , the system can be mapped onto continuous time quantum walks on a graph with time - independent edges and nodes . to demonstrate this , note that within rotating wave approximation @xcite @xmath31 and that the gate operator simplifies to @xmath32 where @xmath33 is the effective time . quantum computing is based on the principle that qubit amplitudes remain hidden ( unknown ) during the evolution ( gates ) . as the result , quantum gates are designed to perform deterministic ( classical ) rotations of the basis , rather than change of amplitudes , @xmath34 \\end{aligned}\\ ] ] therefore , if we define @xmath35 and @xmath36 , quantum gate @xmath27 maps onto a set of continuous time quantum walks @xmath37 where @xmath38 is the effective time of the walks and @xmath0 plays the role of a constant adjacency matrix corresponding to a graph that defines each walk . note that when rotating wave approximation is not appropriate , @xmath0 can still be defined , but it will become a function of time as well @xcite .    to ensure conservation of probability within boolean ( qubit ) domain we must restrict ourselves only to a sub - set of graphs that satisfy @xmath39 where @xmath40 . in the trivial case when @xmath41 the walk never leaves the boolean domain ( qubit subspace ) . another important subgroup of graphs that satisfy [ eq : qw : qlp ] are graphs that enable `` _ return _ '' quantum walks  walks that return the population back to the initial state with probability 1 at some finite time @xmath38 . in what follows we investigate graphs with @xmath42 that satisfy ( [ eq : qw : qlp ] ) . particular emphasis is made on two types of _ return _ quantum walks : ( i ) walks that accumulate no phase when the population is returned to the original state ( trivial return walks ) , and ( ii ) walks that accumulate a phase of @xmath43 when return to the initial state ( non - trivial return walks ) . the simplest example of such walks is evolution of a driven two state quantum system @xcite . in this section we discuss structure of @xmath0 necessary to implement entangling and local ( single - qubit ) quantum gates and give several examples of such implementations . in the systems introduced in sec . [ sec : qw ] , the adjacency matrix is a collection of complex rabi frequencies originating from the control pulse ( [ eq : qw : v - gen ] ) @xmath44 the graph corresponding to this adjacency matrix is a set of vertices representing states @xmath45 , connected via complex hopping amplitudes @xmath46 . because these hopping amplitudes represent strengths of fourier harmonics of external control field , they are adjustable parameters of the problem and can be chosen to perform the desired quantum walks and , ultimately , quantum gate . not all of these amplitudes , however , are independent .    when multi - state systems that hold qubits are well isolated from one another , the set of rabi frequencies describing transitions in the system obeys strict symmetry relations . all graph node states @xmath47 are product states , and external control field can rotate each individual isolated multi - state system independently of the state of other such systems . this means that @xmath48 where all rabi frequencies @xmath49 in each row correspond to the same physical harmonic of the external control field . this symmetry can be partially or completely lifted when there are physical interactions between parts of the system that encode different qubits , i.e. , graph vertex states @xmath50 are no longer separable ( factorisable ) for some or any @xmath51 . note , however , that even in the case of strong interaction between qubit systems , groups of indistinguishable @xmath49 edges may still exist if the spectrum of ( [ eq : qw : h ] ) has degenerate transitions . in addition , degeneracy in graph edges ( values of @xmath49 ) can be artificially introduced , even if not present originally , by choosing appropriate envelop of the external control pulse .    in what follows we will focus on one specific case of lifting non - interacting symmetry ( [ eq : qb : ni - omega ] ) , which is based on `` intermediate resonance regime '' introduced in our earlier work for several different qubit designs @xcite . the intermediate resonance regime assumes that all qubits are physically interacting with each other via transitions to higher energy auxiliary states . in order to provide the simplest illustration , we take @xmath52 as such state and allow only one transition @xmath53 in each qubit system . in this specific case , symmetry ( [ eq : qb : ni - omega ] ) for @xmath54 and @xmath55 is lifted when combinations @xmath56 and @xmath57 have non - equal number of indexes referring to states outside of the computational basis . this includes , e.g. , pairs 01 ... and 02 ... , 11 ... and 12 ... , 11 ... and 21 ... , 21 ... and 22 ... , etc . , but does not include 12 ... and 21 ... , or 00 ... and 01 ... , assuming ( for this particular illustration ) that the other indexes do not have non - binary numbers @xcite . when degeneracy ( [ eq : qb : ni - omega ] ) is lifted differently , the gates can be constructed in a similar fashion , although different graphs might be necessary in each case . furthermore , because violation of symmetry ( [ eq : qb : ni - omega ] ) is a manifestation of physical interactions between qubits , some entangling gates might not be accessible in certain cases . this is not surprising because necessary physical interactions might simply be absent . single - qubit quantum gates in systems with actively used auxiliary states are the simplest examples of @xmath58 gates implemented via quantum walks . here we give few examples of gates , some of which are performed routinely in different quantum computing systems @xcite , to demonstrate their connection with a ( more general ) quantum - walks - based approach investigated in this paper . the first example is @xmath59 gate @xcite . this gate flips the sign of the amplitude for one of the qubit s state , i.e. , @xmath60 in the simplest case , a single auxiliary state is sufficient and we can choose the graph with the following adjacency matrix @xmath61 in the basis @xmath62 , i.e. transition between states @xmath3 and @xmath52 is addressed ( activated ) by external pulse with rabi frequency @xmath49 . upon examination of the solution of this effectively two - state problem ( see sec  [ sec : lg : ch2 ] ) it is evident that ( [ eq:1qb : uz ] ) is obtained from eqs . ( [ eq : qw : ug ] ) , ( [ eq : qw : evolve ] ) , and ( [ eq : qw : walk ] ) when the walk is terminated at @xmath63 , where @xmath64 is any ( non - negative ) integer . another example is a ( single - qubit ) swap gate with arbitrary phase change , i.e. , @xmath65 using the same three states as before , one of which is auxiliary state , we can set the graph to have adjacency matrix @xmath66 in the basis @xmath67 . examination of quantum walks on such graph ( chain of three states , see sec . [ sec : lg : ch3 ] ) shows that if we set @xmath68 and @xmath69 , gate ( [ eq:1qb : u - swap ] ) is obtained provided the walk is terminated at time @xmath70 , where @xmath64 is any ( non - negative ) integer .    finally , we consider an example of implementing the hadamard gate @xmath71 which is widely used in algorithms and error correction codes @xcite . similarly to the previous example , it can be performed via a quantum walk on the graph with adjacency matrix ( [ eq:1qb : lambda - swap ] ) . in this case ( see sec . [ sec : lg : ch3 ] ) we must set @xmath72 and @xmath73 . hadamard gate evolution operator ( [ eq:1qb : u - swap ] ) is obtained when the walk is terminated at time @xmath74 , where @xmath64 is any ( non - negative ) integer . note that in all three cases , eq . ( [ eq : qw : qlp ] ) is satisfied and the probability is completely returned back to the qubit nodes ( @xmath3 and @xmath4 ) at time @xmath38 . while such abrupt termination of the walk may seem unnatural , we should note that @xmath38 is not the physical time in the system . it is the overall integral magnitude of the external control field [ see eq . ( [ eq : qw : tau ] ) ] , which can be controlled with high accuracy in experiment . the change of the control field with real physical time is typically a smooth function with maximum at ( physical ) time @xmath75 and with sufficiently small values starting at @xmath22 and @xmath23 , e.g. , @xmath76 ^ 2\\}$ ] . one of the most important two - qubit entangling gates is the @xmath77 ( control - not ) gate @xcite , which is defined as @xmath78 in the basis of , e.g. , @xmath79 . it can be represented via two local hadamard gates acting on one of the qubits and cz ( control - z ) gate @xmath80 the cz gate has a simple structure : it requires a non - trivial _ return _ walk with the adjacency matrix restricted to @xmath81 moreover , for the version of cz given in eq . ( [ eq:2qb : cz ] ) , the quantum walk terminated at time @xmath38 must yield @xmath82    this is most easily achieved if the graph , corresponding to @xmath0 , is separable into four disconnected subgraphs , each containing one of the two - qubit basis states , and each performing a _ return _ quantum walk when terminated at exactly the same time @xmath38 . only one subgraph must implement a non - trivial return walk . other subgraphs are only required to produce a trivial return walk ( effectively no evolution ) .    as an example , consider a single auxiliary state @xmath52 in each qubit system that is set to interact with analogous state in the other qubit system ( via , e.g. , a cavity mode coupled to transition out of the qubit subspace @xcite ) . in this case , states @xmath83 , @xmath84 , and @xmath85 , with @xmath86 are not separable , and the `` non - interacting '' symmetry [ eq : qb : ni - omega ] is broken : we can have @xmath87 , etc . if we assume that the only practically accessible transition in each qubit system is transition @xmath53 , which is the case , e.g. , for transmon superconducting qubits @xcite , we obtain a disconnected set of graphs shown in fig . [ fig:2qb ] . in this case ( [ eq:2qb : walk-00 ] ) describes a walk on the trivial single - node graph ( no evolution ) ; eqs . ( [ eq:2qb : walk-10 ] ) and ( [ eq:2qb : walk-01 ] ) describe walks on a two - state graphs ( see sec .  [ sec : lg : ch2 ] ) ; and eq . ( [ eq:2qb : walk-11 ] ) involves a walk on a four - state square graph ( see sec . [ sec : sq ] ) . a set of complex hopping amplitudes ( edges ) that satisfy eqs . ( [ eq:2qb : walk-00]-[eq:2qb : walk-11 ] ) is not unique : an infinite number of solutions is possible . to demonstrate this we , first , define @xmath88 for every edge . this makes all walks to propagate over the same time interval @xmath38 . we , then , set @xmath89 ) in sec . [ sec : lg : ch2 ] ] for all walks that start from states @xmath90 and @xmath91 , thus satisfying eqs . ( [ eq:2qb : walk-01 ] ) and ( [ eq:2qb : walk-10 ] ) . continuous time return walk through a square graph in fig . [ fig : lin - sq](f ) that contains state @xmath92 is investigated in sec . [ sec : sq ] . the absolute values of hopping amplitudes for the two bottom edges of this graph are already defined above . we have freedom to adjust the remaining two complex amplitudes , @xmath93 and @xmath94 , and two phases , @xmath95 and @xmath96 . as demonstrated in sec . [ sec : sq ] , a return walk on a square graph can be mapped onto a walk on a linear chain graph of four states ( sec . [ sec : lg : ch4 ] ) . the latter allows for both trivial and non - trivial return walks [ see ( [ eq : lg : ch4:r_0 ] ) and ( [ eq : lg : ch4:r_pi ] ) in sec .  [ sec : sq ] ] . a non - trivial solution that satisfy eq .  ( [ eq:2qb : walk-11 ] ) is parameterized by two odd integers @xmath29 and @xmath64 . without loss of generality we can set @xmath97 . in this case the hopping amplitudes in graph  [ fig:2qb](d ) are bounded by condition @xmath98 and the solution is found from @xmath99    one specific example can be derived if we set @xmath100 , @xmath101 , @xmath102 , and assume no complex phases for @xmath103 and @xmath104 . in this case @xmath105 where @xmath106 and @xmath107 are two arbitrary real numbers . in this example all available transitions are activated to produce hopping amplitudes @xmath103 , @xmath104 , @xmath93 , and @xmath94 given by eqs . ( [ eq:2qb : n1n2 ] ) and ( [ eq:2qb : sol-123 ] ) . this , however , is not a necessary condition .    as another example , we can set @xmath108 ( do not activate @xmath104 transition , see fig . [ fig:2qb ] ) and set @xmath109 to be an _ odd _ positive integer . this defines a non - trivial return walk for state @xmath91 instead of @xmath92 [ the standard cz gate ( [ eq:2qb : cz ] ) is recovered if we apply single - qubit z gate to the first qubit ] . the graphs with @xmath110 and @xmath90 states are now trivial one - node graphs . the graph that has @xmath92 node is now a linear chain graph with four nodes ( see sec . [ sec : lg : ch4 ] ) , which is a subgraph of the square graph discussed above . the walk starting at @xmath92 must be a trivial return walk parameters @xmath29 and @xmath64 must be non - equal _ even _ integers . because @xmath109 is odd , it can always be chosen between @xmath29 and @xmath64 to satisfy eq . ( [ eq:2qb : nm - limit ] ) . as an illustration , we chose @xmath111 , @xmath112 , and @xmath113 . from eq . ( [ eq:2qb : sol ] ) we obtain @xmath114 and @xmath115 . in this case the phases of all hopping amplitudes can be arbitrary . a set of graphs representing a two qubit system with one active auxiliary state in each qubit and only one allowed transition , @xmath53 , in each qubit system . ]      here we investigate an example of a non - trivial entangling three - qubit quantum gate that performs three - qubit toffoli gate @xcite up to a single - qubit rotation . a three - qubit toffoli gate , when represented via cnot gates , requires at least six cnot gates applied sequentially @xcite . a faster implementation of three - qubit entangling gates that bypasses this limitation is , therefore , beneficial . toffoli ( or ccnot ) gate can be factored into a sequence @xmath116 where h@xmath117 is the hadamard gate applied to the third qubit and ccz is control - z gate with two control and one target qubits @xmath118 similar to cz gate , `` -1 '' can be brought to a different location by single - qubit z gates and overall phase factor ( which is not important in quantum computing ) . similar to the cz gate , the ccz gate needs a non - trivial _ return _ walk with the adjacency matrix restricted by relation ( [ eq:2qb : walk ] ) . as an illustration , we will focus on the variation of the ccz gate in which the amplitude residing on state @xmath119 acquires a phase of @xmath43 , i.e. , @xmath120 the simplest example of a set of graphs implementing the above evolution is shown in fig . [ fig:3qb ] . using a dimensionless representation for each rabi frequency , @xmath88 , as before , we ensure that all walks terminate at the same time @xmath38 . we obtain a non - trivial return walk for the graph in fig . [ fig:3qb](b ) corresponding to eq . ( [ eq:3qb : walk-100 ] ) when @xmath121 ) . walks on all other graphs must be trivial return walks . this is trivially the case for graphs ( a ) , ( c ) , ( d ) , and ( g ) , because the corresponding qubit basis states are not connected to any other state via the external field ( corresponding rabi frequencies are zero ) . in the case of graphs ( e ) and ( f ) , a trivial return walk is achieved when @xmath122 and @xmath29 and @xmath123 are even integers ( see sec . [ sec : lg : ch3 ] ) .    in order to understand the return walk on graph ( h ) , note that it is in fact a square graph ( see sec . [ sec : sq ] ) with an additional node attached to it . as explained in sec . [ sec : sq ] , a square graph can be transformed into a linear chain of four states ( see sec .  [ sec : lg : ch4 ] ) . therefore , the entire graph ( e ) becomes effectively a linear chain of five states discussed in sec . [ sec : lg : ch5 ] [ see also fig .  [ fig : lin - sq](d ) ] . the hopping amplitudes corresponding to this chain are @xmath124 the walk on such graph returns with trivial phase when @xmath125 and @xmath126 and @xmath127 are even integers ( see sec . [ sec : lg : ch5 ] ) . this later system of two equation has two unknowns : @xmath128 and @xmath129 , and two real parameters : @xmath130 and @xmath131 , set by walks on the other graphs . the overall solution for the original rabi frequencies , however , is not unique because @xmath128 and @xmath129 depend on complex phases of @xmath132 , @xmath133 , @xmath134 , and @xmath135 ( see eqs . [ eq:3qb : ampl - c ] and [ eq:3qb : ampl - d ] ) . in addition , the overall solution is parameterized by five integer parameters @xmath64 , @xmath29 , @xmath123 , @xmath126 , and @xmath127 ( @xmath64 is odd , others are even ) . one specific solution mentioned in our earlier work @xcite that satisfy eqs . ( [ eq:3qb : n])-([eq:3qb : kkp ] ) can be obtained assuming all rabi frequencies are real and @xmath136 , @xmath137 , @xmath138 . in this case we have @xmath139     a set of graphs representing a three - qubit system with one active auxiliary state in each qubit and only one allowed transition , @xmath53 , in each qubit system . dotted lines are guide to the eye . solid lines indicate resonant transitions activated with external field . dashed lines are transitions that are allowed but are not used . dimensionless rabi frequencies are defined as @xmath140 , where @xmath141 is @xmath142 , @xmath143 , or @xmath144 with appropriate indexes . indexes indicate the largest number of auxiliary states in vertexes each transition connects . the symmetry of transitions in this example corresponds to that of the intermediate resonance regime @xcite . note that graphs corresponding to different qubit basis states are not connected with one another because transitions @xmath145 are not allowed ( or not used ) in our case this is the case in a number of relevant qubit systems @xcite . if such transitions are allowed ( or are used ) , more complex gates can be constructed . ] in this section we discuss return quantum walks on graphs that are a set of states connected in linear chains of various ( finite ) length . these graphs can be used to implement single - qubit gates ( see sec .  [ sec:1qb ] ) and will become essential building blocks for more complex graphs needed to implement entangling quantum gates ( see secs . [ sec:2qb ] and [ sec:3qb ] ) . two distinct types of return walks in these systems will be emphasized : ( i ) trivial return walk , @xmath146 , in which amplitudes returns back to initial state and acquire no phase , and ( ii ) non - trivial return walk , @xmath147 , in which phase @xmath43 is accumulated when the system returns back to its initial state . the second type , @xmath147 walk , is only possible if adjacency matrix is not singular , which can be readily verified by calculating the evolution operator via eigendecomposition ( see examples below ) . in general , it is , therefore , expected that linear chain graphs with even number of vertexes can support both @xmath146 and @xmath147 walks ( i.e. , both @xmath148 are possible ) , while linear chain graphs with odd number of vertexes can not produce @xmath149 . the latter statement , does not strictly eliminate @xmath147 walks , as it remains a possibility that @xmath147 exists even when @xmath150 . four examples of linear chain graphs are discussed below . detailed derivation of the walks are given in appendixes  [ app : lg : ch3]-[app : lg : ch5 ] . some of more complex graphs , which appear in two- and three - qubit gates , and which simplify to linear chain graphs , are discussed in the next sections . the simplest linear chain graph that we discuss here briefly for completeness is the one that corresponds to a two - state quantum system [ see fig .  [ fig : lin - sq](a ) ] . the adjacency matrix is @xmath151 the evolution operator can be easily found by direct re - summation of odd and even terms of the exponential series @xmath152 the `` return '' condition , which is identical to condition ( [ eq : qw : qlp ] ) in this case , is satisfied provided @xmath130 is an integer number . we have @xmath153 where the former defines a trivial return walk and the latter defines a non - trivial return walk that accumulates the phase of @xmath43 . linear chain graphs ( a - d ) , a fan graph ( e ) , and a square graph ( f ) ; for details see secs . [ sec : lg : ch2 ]  -  [ sec : lg : ch5 ] , sec . [ sec : tg : f ] , and sec . [ sec : sq ] , respectively . in each case dimensionless amplitudes are defined as @xmath154 , where @xmath155 are rabi frequencies due to external control corresponding to each transition , and @xmath141 stand for @xmath142 , @xmath143 , @xmath144 , etc . ] a graph of three states connected in a chain [ see fig .  [ fig : lin - sq](b ) ] is described by the adjacency matrix @xmath156 the evolution operator corresponding to this system can be found explicitly as in the previous case , although the exact expression becomes cumbersome , see appendix  [ app : lg : ch3 ] . a more elegant approach , also applicable to larger systems , is to notice that diagonalization of ( [ eq : lg : ch3:lambda ] ) @xmath157 yields three eigenvalues @xmath158 one of which is zero . the evolution operator , therefore , becomes @xmath159 as the result , irrespective of @xmath160 , we have @xmath161 this , strictly speaking , does not imply that @xmath147 is not possible . however by inspecting the complete solution ( see appendix  [ app : lg : ch3 ] ) we see that @xmath147 walk is not accessible in this system if the initial state is state @xmath4 or @xmath162 .    * special case : integer amplitudes*. it is interesting to note that the system allows integer amplitudes , which can become useful when implementing quantum gates via quantum walks on graphs with small number of free parameters . note that @xmath163 describes pythagorean triples ( or triangles ) , therefore @xmath164 irreducible triples have odd @xmath64 and , therefore , must be multiplied by an even integer to produce @xmath146 walk ( [ eq : lg : ch3:r_0 ] ) , e.g. , @xmath165 , @xmath166 , @xmath167 . the adjacency matrix of a chain of four states [ see fig .  [ fig : lin - sq](c ) ] is @xmath168 due to symmetry , the eigenvalues are @xmath169 and @xmath170 . the system does not have zero eigenvalues and , thus , unlike in the previous case ( [ eq : lg : ch3:u ] ) , does allow @xmath171 and @xmath149 evolution . by setting @xmath172 and @xmath173 , where @xmath64 and @xmath29 are integers of the same parity , we obtain ( see appendix  [ app : lg : ch4 ] ) @xmath174 as the result , we have @xmath175    it is interesting to note that if we solve system ( [ eq : lg : ch4:system ] ) for @xmath143 we obtain @xmath176 this defines the range of valid values for @xmath130 and @xmath128 @xmath177 the system becomes disconnected into a pair of two - state systems , when @xmath178 . * special case : integer amplitudes*. integer amplitudes can be used in the symmetric case when @xmath179 . from system ( [ eq : lg : ch4:system ] ) we obtain @xmath180 therefore , for any positive integer @xmath130 , one can define integer amplitudes @xmath181      the adjacency matrix of a chain of five states shown in fig .  [ fig : lin - sq](d ) @xmath182 is singular . one of the eigenvalues is zero , and the remaining eigenvalues are @xmath169 and @xmath170 , where @xmath183 are given in appendix  [ app : lg : ch5 ] . the evolution operator is a trivial identity matrix if @xmath172 and @xmath173 , where @xmath64 and @xmath29 are even integers . solving these two equation we obtain ( see appendix  [ app : lg : ch5 ] ) @xmath184 as the result , we have @xmath185    * special case : integer amplitudes*. integer amplitudes are possible for a symmetric chain with @xmath186 and @xmath187 . we obtain @xmath188 [ sec : tg : f ]    these graphs are structures that branch from a single vertex , as shown in fig . [ fig : lin - sq](e ) . they are natural parts of a network of transitions in multiqubit systems with at least one `` local '' transition allowed for each qubit . the corresponding adjacency matrix is @xmath189 quantum evolution on such graphs can be mapped onto that of a two state quantum system . to perform the map , define state @xmath190 such that @xmath191 , i.e. , @xmath192 which is identical to ( [ eq : lg : ch2:lambda ] ) . we obtain @xmath193 this is the graph [ see fig . [ fig : lin - sq](f ) ] that naturally appears in the simplest quantum walk implementation of a cz gate in the system with one ( active ) auxiliary state per qubit . the adjacency matrix is @xmath194 similarly to symmetric fan graphs discussed above , it can be mapped onto a graph representing linear chain of states . we can define state @xmath195 such that @xmath196 where state @xmath197 is orthogonal to @xmath195 . this gives to possibilities . one possibility is to have @xmath198 , in which case @xmath199 where @xmath200 the adjacency matrix becomes that of the linear chain graph of three states . in this case the solution is @xmath201 as obtained earlier in sec . [ sec : lg : ch3 ] . the other possibility is to have @xmath202 . in this case , adjacency matrix is @xmath203 where @xmath204 this corresponds to the linear chain graph of four states discussed in sec .  [ sec : lg : ch4 ] . the solution is @xmath205 and @xmath206 as obtained earlier in sec . [ sec : lg : ch4 ] . in this case a non - trivial return walk is possible . it is interesting to note that the square graph can be partitioned into two non - trivial two - node graphs , one having state @xmath207 and the other having state @xmath208 , in an infinite number of ways . this is achieved by setting hopping amplitude @xmath209 to zero , or , explicitly , by requiring @xmath210 the two specific straightforward cases of partitioning are obtained for @xmath211 or @xmath212 . such partitioning can be particularly advantageous when performing similar analysis for larger graphs , for which analytical solutions may be difficult or impossible to find . this approach can simplify construction of multiqubit gates performed via quantum walks in larger systems . we include solution obtained from exact diagonalization of a three - states system ( chain of three states , sec . [ sec : lg : ch3 ] ) here for completeness . the adjacency matrix ( hamiltonian ) of the system is @xmath213 the evolution operator @xmath214 $ ] , found from the eigenvalue decomposition of @xmath0 , is    @xmath215    note that both , the first and the last entry on the diagonal can not be set to @xmath216 when @xmath217 and @xmath218 . the central matrix element , however , can become @xmath216 . the evolution becomes trivial ( identity matrix ) when @xmath219 with @xmath220 . when @xmath221 evolution started initially from the middle state returns back with a phase of @xmath43 . the dimensionless adjacency matrix of a chain of four states can be formulated as @xmath222 it has four eigenvalues @xmath223 and @xmath224 , where @xmath225 in order to obtain a return walk ( evolution ) we must set @xmath226 this produces a system @xmath227 which can be further simplified to yield eq . ( [ eq : lg : ch4:system ] ) . the dimensionless adjacency matrix of a chain of five states is @xmath228 one of the eigenvalues of this matrix is always zero . the other two are @xmath223 and @xmath224 , where @xmath229    because one of the eigenvalues is always zero , exponentiation of the diagonalized @xmath230 can not produce negative identity matrix . therefore we must set @xmath231 this yields the system @xmath232 which can be further simplified to produce eq . ( [ eq : lg : ch5:system ] )                      t. gaebel , m. domhan , i. popa , c. wittmann , p. neumann , f. jelezko , j. r. rabeau , n. stavrias , a. d. greentree , s. prawer , j. meijer , j. twamley , p. r. hemmer , j. wrachtrup , nature physics 2 , 408 ( 2006 ) . h. paik , d. i. schuster , l. s. bishop , g. kirchmair , g. catelani , a. p. sears , b. r. johnson , m. j. reagor , l. frunzio , l. i. glazman , s. m. girvin , m. h. devoret , and r. j. schoelkopf , phys . 107 , 240501 ( 2011 ) .    c. rigetti , j. m. gambetta , s. poletto , b. plourde , j. m. chow , a. d. corcoles , j. a. smolin , s. t. merkel , j. rozen , g. a. keefe , m. b. rothwell , m. b. ketchen , and m. steffen , phys . b 86 , 100506(r ) ( 2012 ) .", "tags": [], "output_text_a": "This paper explores the use of continuous time quantum walks as an alternative to classical driving for implementing quantum gates in multi-qubit systems. Traditional quantum computing relies on qubits and quantum gates, often driven by classical external fields, to perform operations. However, the authors propose that quantum walks, which allow systems to explore multiple quantum states, could enhance the effectiveness of phase accumulation necessary for quantum gates. The paper delves into the requirements for control and interaction in multi-state systems to perform quantum gates via quantum walks, providing examples for one-, two-, and three-qubit gates. It presents a detailed analysis of the graphs involved in these quantum walks, offering exact analytical solutions for various graph structures. The study highlights the potential of quantum walks to improve the implementation of entangling gates, such as the control-Z and Toffoli gates, by utilizing higher energy auxiliary states and specific graph configurations. The findings suggest that quantum walks could offer a more efficient approach to quantum gate design, particularly in systems where physical interactions between qubits are present.", "output_text_b": "This arXiv paper discusses the implementation of quantum gates using physical interactions between quantum systems, specifically in the context of superconducting qubits. The authors suggest that replacing classical driving with temporarily-enabled continuous time quantum walks can lead to more effective phase accumulation in multi-qubit, multi-state systems. They investigate this approach for gates involving one to three qubits and present a detailed analysis of graphs involved in quantum walks performing these gates. The paper is organized into several sections, each focusing on different aspects of the approach and its implementation.", "score": 0.20000000000000007, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by discussing the use of continuous time quantum walks as an alternative to classical driving for quantum gates.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of improving quantum gate implementation through quantum walks.\n4. **Methodology**: The summary mentions the methodology of using continuous time quantum walks and analyzing graph structures.\n5. **Significant Results**: The summary includes significant results, such as the potential for more efficient quantum gate design.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"quantum walks.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in potentially improving quantum gate design.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, focusing on the implementation of quantum gates using continuous time quantum walks in superconducting qubits.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of improving phase accumulation in multi-qubit systems.\n4. **Methodology**: The summary mentions the use of continuous time quantum walks as the methodology.\n5. **Significant Results**: The summary does not explicitly mention significant results or conclusions drawn by the authors.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains the terms used.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any specific experiments or data used in the research.\n10. **Significance/Impact**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the 2-leg , @xmath2 ladder represents one of the simplest systems which exhibits some of the phenomena associated with high @xmath3 cuprate superconductivity @xcite . the ground state of the undoped system , a 2-leg heisenberg ladder , is a spin liquid with a finite spin gap and exponentially decaying antiferromagnetic spin - spin correlations . upon doping , the spin gap remains and there appear power law cdw and singlet superconducting pairing correlations . in addition , the pairing correlations have an internal @xmath4-like symmetry with a relative sign difference between the leg and rung singlets which make up a pair . despite all of the numerical and analytical work which has been done on this system , we still lack a picture of the ground state which accommodates all of these physical properties . there are , however , many hints of what that picture may look like . it is the purpose of this paper to take one step further in that direction . short - range resonating valence bonds ( rvb ) provide a useful basis for representing the ground state of spin liquids@xcite . for the @xmath2 ladder , a @xmath5-order picture has been provided by the study of the strong coupling limit where the exchange coupling constant along the rungs , @xmath6 , is much larger than any other scale in the problem . the other coupling constants of the model are , @xmath1 : the exchange coupling constant along the legs , and @xmath0 and @xmath7 : the hopping parameters along the legs and the rungs respectively . in the limit @xmath8 , the ground state of the undoped ladder is simply given by the coherent superposition of singlets across the rungs . addition of one hole requires the breaking of one of these singlets , in which case the hole gets effectively bound to the unpaired spin , becoming a quasiparticle with spin @xmath9 and charge @xmath10 . addition of another hole leads to the binding of two holes in the same rung in order to minimize the cost in energy . in this picture there is no spin - charge separation , a fact that remains valid down to intermediate and weak couplings , as confirmed by various numerical and analytical studies . based on this picture it is possible to construct an effective theory describing the motion and interactions of the hole pairs @xcite . it is given by a hard - core boson model ( hcb ) characterized by an effective hopping parameter @xmath11 and interaction @xmath12 of the hole pairs . the hcb model describes the doped ladder as a luther - emery liquid , with gapped spin excitations and gapless charge collective modes , which are responsible for the cdw and sc power law correlations . we summarize the @xmath5-order picture in figure 1 , which shows a typical state of hcb s , as well as the two building blocks that are used its construction .    in order to go beyond this picture , we need to consider the fluctuations of the states of the hcb model . to lowest order in perturbation theory they are shown in fig .  2 . the admixture of the state shown in fig . 2(a ) is of order @xmath13 and represents a resonance of two nearest neighbor rung singlets . according to the standard rvb scenario , this resonance effect leads to a substantial lowering of the ground state energy . the state in fig . 2(b ) is of order @xmath14 , and it can be though of as a bound state of two quasiparticles , whose characteristic feature is the diagonal frustrating bond across the holes . from the rvb point of view , 2(b ) is a resonance of a singlet and a hole pair . the importance of this state , even for intermediate couplings such as @xmath15 , was emphasized in the dmrg study of reference @xcite , where it was shown to be the most probable configuration of two dynamical holes in a 2-leg ladder . in the hcb model of @xcite , the states of the form of fig . 2(b ) are taken into account as intermediate or virtual states , which lead to the effective hoping , @xmath11 and interaction , @xmath12 between the hole pairs . it is clear however that  integrating out \" the diagonal states through perturbation theory , erases the internal structure of the hole pairs . here we want to extend the hcb description to include the internal structure of the hole pairs .    in order to define an effective model which would retain the degrees of freedom associated with the internal structure of the hole pairs , we need to consider the states that appear in second order in the strong coupling expansion . they are given in fig . let us comment on them . the state of fig . 3(a ) is of order @xmath16 and it is a higher order rvb state , whose contribution to the ground state of the undoped ladder was studied in @xcite . in this reference it was shown that its inclusion in a variational ansatz improves the numerical results , but does not change the qualitative picture obtained using the dimer ansatz @xcite . the state of fig . 3(b ) , which is in fact first order in @xmath7 , can be seen as a bound state of two quasiparticles , while 3(c ) and 3(d ) are higher order corrections to the diagonal state shown in fig . for these reasons it seems consistent to keep the state 3(b ) on an equal footing with the states 2(a ) and 2(b ) . to give further support to this choice , we notice that the exact solution for two holes on the @xmath17 cluster requires a superposition of the states shown in 2(b ) and 3(b ) along with 1(a ) and 1(b ) ( see fig . 4 ) @xcite .    in summary , we conjecture that in order to discuss the nature of the superconducting order parameter of the doped 2-leg , @xmath2 ladder , in the strong coupling regime , it is sufficient to consider states built up from 5 possible local configurations , given by rung - singlet - bonds ( fig . 1(a ) ) , rung - hole - pairs ( fig . 1(b ) ) , two - leg - bonds ( fig . 2(a ) ) , hole - pairs with a singlet diagonal bond ( fig .  2(b ) ) and hole - pairs with a singlet leg bond ( fig . a typical state constructed using these building blocks is shown in fig . we shall call these types of states _ dimer - hole - rvb _ states . the effective model that governs their dynamics will be called the _ dimer hard - core boson model _ ( dhcb ) and its hamiltonian can be determined by considering the fluctuations of the dimer - hole states , in a manner similar to the one considered above for the hcb states . the dhcb model contains spin and charge degrees of freedom , together with their couplings , and in that sense is an interesting model to study the interplay between the two types of degrees of freedom , although here we will focus on the variational ground state of the model . the mathematical formulation of the dhcb model involves an interesting but complicated combination of vertex and interaction round a face ( irf ) models . the latter terminology is borrowed from statistical mechanics @xcite . the vertex variables describe the number of electrons per rung , i.e. @xmath18 , while the irf variables describe the number and type of bonds connecting two rungs , i.e. @xmath19 , where the subindices @xmath20 , @xmath21 indicate the diagonal or horizontal nature of the bond . the only allowed configurations for two consecutive irf variables @xmath22 are : @xmath23 together with their permutations . moreover the vertex variables are subject to certain constraints imposed by the irf ones . namely , a ) if @xmath24 or @xmath25 then @xmath26 and b ) if @xmath27 then @xmath28 . only if @xmath29 can @xmath30 and @xmath31 take any value , i.e. 0 , 1 or 2 . it is beyond the scope of this work to present a full account of the dhcb model . instead , we shall try to uncover some of its physics , by means of a combination of two approaches , namely the density matrix renormalization group@xcite and the recurrence relation method ( rrm)@xcite . while the dmrg is a powerful numerical technique , which in many cases yields the exact answer , the rrm is essentially analytic , lacking the numerical precision of the dmrg , but sharing with it some features , as for example the wilsonian way of growing the system by the addition of sites at the boundary . in the rrm one begins with an assumption about the local configurations through which the system grows . then one may test whether the state that is generated gives results in agreement with the essentially exact dmrg results . the hamiltonian of the 2-leg , @xmath2 ladder is given by ,    @xmath32    where @xmath33 or @xmath34 , depending on whether the link @xmath35 is along the legs or the rungs respectively . @xmath36 is the gutzwiller projection operator which forbids double occupancy . the rest of the operators appearing in ( [ 1 ] ) are standard ( we use the conventions of reference @xcite ) . each site @xmath37 is labelled by the coordinates @xmath38 with @xmath39 and @xmath40 . we choose open boundary conditions along the legs of the ladder . the pair field operator which creates a pair of electrons , at the sites @xmath37 and @xmath41 , out of the vacuum is given by ,    @xmath42    as explained in the introduction , we want to built up an ansatz for the ground state based on the 5 local configurations of the dhcb model . the explicit realization of these configurations in terms of pair field operators are given by ( see fig.6 ) ,    @xmath43 \\,\\ , |0 \\rangle_{x , x+1 } \\end{array } \\label{3}\\ ] ]    where @xmath44 is the fock vacuum associated with the rung labelled by the coordinate @xmath45 ( @xmath46 ) . the states @xmath47 , involve @xmath48 rungs and @xmath49 pairs of holes . the variational parameter @xmath50 gives the amplitude of the resonance of a pair of bonds between vertical and horizontal positions @xcite , while @xmath51 and @xmath52 are the variational parameters associated with the diagonal and horizontal configurations of two holes respectively . in the strong coupling limit , @xmath8 , we expect to find @xmath53 and @xmath54 . let us call @xmath55 the ground state of a ladder with @xmath56 rungs and @xmath57 pairs of holes . of course we should be in a regime of the coupling constants where there is binding of two holes . the state @xmath55 will be in general a linear superposition of the dimer - hole states of fig.5 , which suggests that working with this sort of states could be a formidable task . fortunately , we can apply the method developed in @xcite to generate @xmath55 in a recursive manner , in terms of the states of the ladders with @xmath58 and @xmath59 rungs , and @xmath57 and @xmath60 pairs of holes . in @xcite it was shown that @xmath61 , which is in fact a dimer - rvb state @xcite , can be generated by a second order recursion relation . then by a simple procedure one can compute overlaps and expectation values of different operators using recursion formulas , whose thermodynamic limit can be studied analytically .    following the strategy of considering first the hcb states and then the dhcb ones , we shall give the rule that generates the former type of states . it is given by the first order recursion relation ,    @xmath62    supplemented with the initial conditions ,    @xmath63    calling @xmath64 the number of linearly independent states contained in @xmath65 , we deduce from eq.([4 ] ) the recursion relation ,    @xmath66    whose solution is given by the combinatorial number ,    @xmath67    eq . ( [ 7 ] ) is the dimension of the hilbert space of the hcb model with @xmath56 sites and @xmath57 pair of holes . we have not introduced variational parameters in eqs . ( [ 5 ] ) , but if we did , then all states of the hilbert space of the hcb model would be generated by the first order recursion relation . it may be worthwhile to recall that the hcb model is essentially equivalent to the spinless fermion model or the xxz model @xcite . turning now to the dhcb model , the key point is to realize that the dimer - hole states can be generated by the following second order recursion relation , involving the local configurations given by eq.([3 ] ) ,    @xmath68 ) . see fig.7 for a graphical representation of ( [ 8 ] ) . * counting dimer - hole states *    let @xmath69 denote the number of dimer - hole states of a 2-leg ladder with @xmath56 rungs containing @xmath57 pairs of holes . according to ( [ 8 ] ) they satisfy the recursion relation    @xmath70    with the initial conditions    @xmath71    from ( [ 9 ] ) and ( [ 10 ] ) we deduce that @xmath72 satisfies the well known fibonacci recursion formula @xcite , and that in the limit of very large @xmath56 it grows exponentially ,    @xmath73    where @xmath74 is the golden ratio . using generating function methods@xcite one can easily solved the recursion relation ( [ 9 ] ) , together with the initial condition ( [ 10 ] ) . the result is given by the contour integral ,    @xmath75    where the contour encircles the singularities of the integrand . for @xmath76 the integrand has two simple poles at the zeros of the polynomial @xmath77 , the largest of which is precisely the golden ratio @xmath78 . in this way one gets eq.([11 ] ) . for a finite number of holes the residue formula applied to ( [ 12 ] ) yields , to leading order in @xmath56    @xmath79    where the proportionality constant depends only on @xmath57 . let us finally consider the limit where both @xmath56 and @xmath57 go to infinity , while keeping their ratio fixed ,    @xmath80    here @xmath45 can be identified with the hole doping factor of the state @xmath65 . the saddle point method applied to ( [ 12 ] ) gives the asymptotic behaviour of the number of dimer - hole states for a finite density of holes ,    @xmath81    where @xmath82 is the highest root of the following equation    @xmath83    the function @xmath84 is depicted in fig . observe that @xmath85 . the effect of a finite density of holes is that of moving a singularity . this phenomena also occurs in the computation of the energy , and other observables . * ground state energy *    the parameters @xmath86 are found by the standard minimization of the mean value of the energy @xmath87 , where @xmath88 denotes the hamiltonian of the ladder with @xmath56 rungs . the usefulness of eq.([8 ] ) is that it implies that the wave function and energy overlaps also satisfy recursion relations . let us define the following quantities ,    @xmath89    where @xmath90 is the number operator acting on the rung @xmath56 . the off - diagonal overlaps arise from the cross terms when applying ( [ 8 ] ) to the ket and the bras in @xmath91 and @xmath92 . the recursion relations satisfied by ( [ 17 ] ) are given by ,    @xmath93    the initial conditions read ,    @xmath94    for finite values of @xmath56 and @xmath57 , and given choices of @xmath86 , one can iterate numerically the recursion relation ( [ 18 ] ) using the initial conditions ( [ 19 ] ) and look for the minimum of the ground state energy @xmath95 . we give below the results obtained using this variational method for a @xmath96 ladder and compare them with the corresponding results obtained with the dmrg . as explained in the introduction the dhcb model is the appropiate framework to study the strong coupling limit of the 2-leg ladder , if one wishes to take into account the local structure of the hole pairs . to check the validity of this asumption we have studied the cases where the coupling constants takes the following values , @xmath97 and @xmath98 and 5 . in this manner we go from the intermediate coupling regime , i.e. @xmath99 to the strong coupling regime @xmath100 . we are always working in a non - phase - separated region .    in figure 9 we show the ground state energy of the 2 x 32 ladder , for the previous choices of parameters , computed with the rrm for all dopings and the dmrg for @xmath101 and 7/8 . one sees that the results obtained with the rrm wave function agree reasonably well with those of the dmrg and their accuracy improves as @xmath6 increases . the kinetic energy of the ladder is shown in fig.10 . it has the pattern expected for a collective charge mode , as described by the hcb and the dhcb models . the similarity between this figure and fig.8 have a common origin . they both correspond to holes moving collectively through the spins in a complicated many body state . fig.10 shows the existence of an optimal doping for which the kinetic energy is a minimum . the existence and position of this optimal doping depends on the values of the coupling constants . the nature of this many body state is clarified by figures 11 , 12 and 13 where we show the values of the variational parameters @xmath102 and @xmath52 as functions of the doping @xmath45 for different coupling constants . the parameter @xmath50 starts from a positive value corresponding to the undoped ladder @xcite , and it decreases upon doping until a critical value @xmath103 , where it vanishes . for higher dopings @xmath50 becomes negative . for the undoped ladder the parameter @xmath50 can be interpreted as the square of the rvb amplitude @xmath104 for having a bond along the legs@xcite . the analogue amplitude for a bond along the rungs has been implicitly normalized to 1 . for low doping , i.e. @xmath105 , since @xmath106 , we can similarly define a doping dependent amplitude for a leg - bond as    @xmath107    in order to fulfill the marshall theorem for the undoped ladder one requires the rvb amplitude @xmath108 to be positive @xcite , which explains why @xmath109 is also positive . actually for the positivity of @xmath109 one just need @xmath108 to be a real number . at @xmath110 @xmath108 increases with @xmath13 due to the resonance between rung and leg singlets , according to the rvb scenario . upon doping , however , the holes give rise to destructive interference which degrades progressively the aforementioned resonance mechanism . this explains why @xmath111 and @xmath112 decrease with @xmath45 . for @xmath105 the ground state is dominated by the resonating valence bonds and the rvb picture remains qualitatively correct . for @xmath113 the interference due to the holes has driven @xmath50 negative and it is no longer appropiate to interpret @xmath111 as the square of @xmath114 . rather , the physical interpretation of the overdoped region comes from the solution of the cooper problem in the @xmath2 , 2-leg ladder , and its bcs extension . it can be shown analytically that two electrons in the latter system form a bound state only under certain conditions ( details will be given elsewhere ) . for @xmath115 one must have @xmath116 , ( note that the binding of two electrons in the @xmath2 chain requires @xmath117 @xcite ) . the exact solution for 4 or more electrons is difficult to construct , but we expect it to be given essentially by a gutzwiller projected bcs like wave function . a short range version of the latter type of wave function can be generated from the recursion relation ( [ 8 ] ) , with @xmath50 a negative parameter , which can be written as    @xmath118    where @xmath119 is the bcs amplitude for finding two electrons at distance 1 along the legs . of course this interpretation of @xmath50 as minus the square of a bcs amplitude requires it to be negative . as we put more electrons into the ladder the value of @xmath119 decreases and for electron densities larger than @xmath120 , we switch into the rvb regime . the difference between the underdoped and overdoped regimens can be attributed to two different internal structures of the pairs . in the low doping regime @xmath121 , holes doped into the spin - liquid rvb state form pairs with an internal @xmath4-like structure relative to the undoped system . however for @xmath113 one moves into the low density limit characterized by electrons doped into an internal @xmath122-wave like symmetry . this issue will be discussed in detail in a separate publication . let us now comment on figs . 12 and 13 . both are very similar and show that for @xmath123 , @xmath51 and @xmath52 reach their maximum . at @xmath124 there are as many electrons as holes , and in a certain sense the ground state of the ladder is a large scale reproduction of the microscopic ground state of the 2 x 2 cluster given in fig . 4 . indeed for @xmath125 the ratio @xmath126 of the parameters appearing in fig . 4 is given by 1.30 , which is very close to the value of @xmath51 at its maximum . for @xmath127 and @xmath128 the parameter @xmath51 is larger than 1 and it is always larger than @xmath52 for all dopings and couplings . this is in agreement with the dmrg results of @xcite , which show the importance of the diagonal frustrating bonds above the horizontal or vertical ones for @xmath129 . finally fig.14 is a @xmath130 diagram which shows the boundary of phase separation obtained by means of the dmrg and the rrm in the case where @xmath131 . observe that this is not the strong coupling case we have been discussing so far , and hence the validity of the rrm is more questionable . in any case , we see an overall agreement between both results ( see references @xcite for comparisons with other numerical results ) . in the two - leg @xmath0-@xmath1 model , phase separation is controlled by @xmath1 , rather than @xmath6 , so the strongest coupling we have considered above , @xmath132 , @xmath133 , does not phase separate . in this paper we have proposed an extension of the effective hard - core boson model ( hcb ) of the 2-leg ladder of reference @xcite , in order to include the local structure of the hole pairs . the extended effective model , called the dhcb model , contains both dimer bonds , hard core bosons and various combinations between bonds and holes , whose relevance have been studied previously with dmrg @xcite . generalizing the methods of reference @xcite to the case with holes , we study a variational ansatz for the ground state of the dhcb model , which depends only on three variational parameters . the resulting dimer - hole state is generated by a second order recursion formula , which also leads to recursion formulas for the overlaps necessary to compute the energy of the ansatz . we give the results of the energy minimization for the 2 x 32 ladder and compare them with those obtained with the dmrg method in the strong coupling region . the recursion relations we have derived for the ground state energy can be solved analytically in the thermodynamic limit and the minimization can be then done numerically . finally we give a physical interpretation of the behaviour of the variational parameters with doping . gs would like to thanks the organizers of the itp program quantum field theory in low dimensions : from condensed matter to particle physics \" for the warm hospitality . mamd thanks the organizers of the benasque center of physics 1997 for their support and hospitality . gs acknowledges support from the nsf under grant no . phy94 - 07194 and the direccin general de enseanza superior , mamd acknowledges support from the cicyt under contract aen93 - 0776 , jd acknowledges support from the digicyt under contract no . pb95/0123 , srw acknowledges support from the nsf under grant no . dmr-9509945 , and djs acknowledges support from the nsf under grant numbers phy-9407194 and dmr-9527304 . .26 in    e. dagotto , j. riera and d. j. scalapino , phys . b 45 , 5744 ( 1992 ) . t. barnes , e. dagotto , j. riera and e. s. swanson , phys . b 47 , 3196 ( 1993 ) . s. gopalan , t.m . rice and m. sigrist , phys . rev . b 49 , 8901 ( 1994 ) . white , r.m . noack and d.j . scalapino , phys . 73 , 886 ( 1994 ) . h. tsunetsugu , m. troyer , t. m. rice , phys . rev . b 49 , 16078 ( 1994 ) . m. troyer , h. tsunetsugu and t. m. rice , phys . b 53 , 251 ( 1996 ) . s. a. kivelson , d.s . rokhsar and j.p . sethna , phys . b 35 , 8865 ( 1987 ) . s. liang , b. doucot and p.w . anderson , phys . 61 , 365 ( 1988 ) . white and d.j . scalapino , phys . b 55 , 6504 ( 1997 ) .    g. sierra and m.a . martn - delgado ,  the short range rvb state of the even spin ladders : a recurrent variational approach \" , cond - mat/9704212 , phys . rev . b , to appear . y. fan and m. ma , phys . rev . b 37 , 1820 ( 1988 ) . r. baxter ,  exactly solved models in statistical mechanics \" , academic press , london , ( 1982 ) . white , phys . 69 , 2863 ( 1992 ) ; phys . rev . b 48 , 10345 ( 1993 ) . m. ogata , m.u . luchini , s. sorella and f.f . assaad , phys . 66 , 2388 ( 1991 ) . hayward and d. poilblanc , phys . b 53 , 11721 ( 1996 ) . k. sano , jour . 65 , 1146 ( 1996 ) . * figure 1:*the @xmath5 order picture of the hard core boson model : a ) the vertical bond , b ) the vertical hole - pair singlet , c ) a typical state of the hcb model . * figure 2 :* the two lowest order states in the strong coupling limit @xmath134 of the hcb model . they represent the first order contribution to the dhcb model . a ) the resonance of two vertical bonds , b ) bound state of two quasiparticles . * figure 3 :* higher order strong coupling states contributing to the dhcb model . a ) a higher order rvb state , b ) a bound state of two quasiparticles , c ) and d ) higher order corrections to the diagonal state 2(b ) ) . * figure 9 :* ground state energy per site of the 2 x 32 ladder with @xmath115 and @xmath138 . the remaining data given below in figures 10 - 13 also corresponds to these choices of couplings . the continuum curves are obtained with the rrm , while the special symbols are the dmrg data corresponding to @xmath139 and 7/8 respectively .", "tags": [], "output_text_a": "This paper explores the 2-leg Heisenberg ladder, a simple system that exhibits phenomena associated with high-temperature cuprate superconductivity. The undoped ladder is a spin liquid with a finite spin gap and exponentially decaying antiferromagnetic correlations. Upon doping, the spin gap persists, and power-law charge density wave (CDW) and singlet superconducting pairing correlations emerge. The pairing correlations exhibit an internal d-wave-like symmetry.\n\nThe study aims to extend the understanding of the ground state of the doped ladder by incorporating the internal structure of hole pairs into the effective model. The authors propose an extension of the hard-core boson (HCB) model, called the dimer hard-core boson (DHCB) model, which includes both dimer bonds and hole pairs. This model accounts for the local structure of hole pairs and their interactions, which are crucial for understanding the superconducting order parameter.\n\nThe paper employs a combination of numerical and analytical methods, including the density matrix renormalization group (DMRG) and the recurrence relation method (RRM), to study the variational ground state of the DHCB model. The authors derive recursion relations for generating the ground state and computing energy overlaps, allowing for the study of the model's thermodynamic limit.\n\nThe results show that the DHCB model provides a reasonable description of the ground state energy and kinetic energy of the ladder, especially in the strong coupling regime. The study also reveals the existence of an optimal doping level for minimizing kinetic energy and highlights the role of resonating valence bonds (RVB) in the low doping regime. The paper concludes with a discussion on the different internal structures of pairs in underdoped and overdoped regimes, suggesting a transition from RVB to BCS-like behavior as doping increases.\n\nOverall, this work provides a deeper understanding of the interplay between spin and charge degrees of freedom in the 2-leg ladder and offers insights into the nature of superconductivity in these systems.", "output_text_b": "This article discusses the 2-leg ladder system, a simple model exhibiting phenomena associated with high-temperature superconductivity. The ground state of the undoped system is a spin liquid with a finite spin gap and exponentially decaying antiferromagnetic spin-spin correlations. Upon doping, the spin gap remains, and power-law charge density wave (CDW) and singlet superconducting pairing correlations appear. The pairing correlations have an internal d-wave-like symmetry with a relative sign difference between leg and rung singlets forming a pair.\n\nThe authors use short-range resonating valence bonds (RVB) as a basis for representing the ground state of spin liquids. They build upon a 5th-order picture provided in the strong coupling limit, where the exchange coupling constant along the rungs (J') is much larger than any other scale in the problem. They construct an effective theory describing the motion and interactions of hole pairs using a hard-core boson model (HCB) with an effective hopping parameter (t') and interaction (V') of the hole pairs. The doped ladder is described as a Luther-Emery liquid, with gapped spin excitations and gapless charge collective modes, which are responsible for the CDW and superconducting (SC) power-law correlations.\n\nThe authors then consider fluctuations of the HCB model states and propose an extension of the HCB model to include the internal structure of hole pairs. They introduce additional states in the strong coupling expansion and consider the exact solution for two holes on the 4-site cluster, which requires a superposition of various states, including those in the proposed model.\n\nIn summary, the authors conjecture that in order to discuss the nature of the superconducting order parameter of the doped 2-leg ladder in the strong coupling regime, it is sufficient to consider states built up from 5 possible local configurations, given by rung-singlet-bonds, rung-hole-pairs, two-leg-bonds, hole-pairs with a singlet diagonal bond, and hole-pairs with a singlet leg bond. They propose an effective model, the Dimer Hard-Core Boson Model (DHCB), to govern the dynamics of these states and study its interplay between spin and charge degrees of freedom.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the exploration of the 2-leg Heisenberg ladder and the introduction of the DHCB model.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on understanding the ground state of the doped ladder and the internal structure of hole pairs.\n4. The methodology, including the use of the DHCB model and numerical methods like DMRG and RRM, is mentioned.\n5. Significant results, such as the description of ground state energy and kinetic energy, and the transition from RVB to BCS-like behavior, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"d-wave-like symmetry\" and \"RVB\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used, which is a requirement.\n10. The paper's significance in understanding superconductivity and the interplay between spin and charge degrees of freedom is reflected.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the 2-leg ladder system, the use of short-range resonating valence bonds, and the introduction of the Dimer Hard-Core Boson Model (DHCB).\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the ground state and superconducting order parameter of the doped 2-leg ladder system.\n4. **Methodology**: The summary mentions the methodology, including the use of short-range RVB and the construction of an effective theory using a hard-core boson model.\n5. **Significant Results**: The summary includes significant results, such as the description of the doped ladder as a Luther-Emery liquid and the proposal of the DHCB model.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"RVB\" and \"Luther-Emery liquid\" but provides context for understanding.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding high-temperature superconductivity phenomena."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "in recent years , much research has been dedicated to developing vision - based advanced driver assist systems ( adas ) . these systems help drivers in controlling their vehicle by , for instance , warning against lane departure , hazardous obstacles in the vehicle path or a too short distance to the preceding vehicle . as these systems evolve with more advanced technology and higher robustness , they are expected to increase traffic safety and comfort . a key component of adas is free - space detection , which provides information about the surrounding drivable space . in this work , we employ a fully convolutional network ( fcn ) for this task and explore _ online _ training in a _ self - supervised _ fashion , to increase the robustness of the free - space detection system . figure  [ fig : scheme ] provides a schematic overview of our proposed framework , which will be described in detail in the  __ section .        neural nets with deep learning are becoming increasingly successful and popular for image analysis . in the field of intelligent vehicles , many of the recent state - of - the - art algorithms rely on neural nets , mostly on convolutional neural nets ( cnns ) . they excel in a wide variety of adas applications , such as stereo disparity estimation  @xcite , object detection for cars and pedestrians  @xcite and road estimation  @xcite@xcite .    in literature , training a neural net typically requires many data samples for proper convergence of the large amount of parameters and proper generalization of the classifier . different strategies are adopted throughout the field to handle this . in image recognition and object detection problems in natural environments , a common method is to start with a net that is trained on a large and generic dataset , in either a supervised  @xcite or unsupervised manner  @xcite@xcite@xcite . to apply it to a new task , one can remove the last layer of the net , which provides class confidences , and train a new one for the problem at hand . this exploits the observation that these pre - trained nets are a compact and yet rich representation of the images in general , since they are trained extensively on a broad visual dataset  @xcite@xcite@xcite . an extension of this concept is not just retraining the last classification layer of a pre - trained net , but to also fine - tune a larger part or even the complete net with task - specific data  @xcite@xcite@xcite@xcite . scene labeling , in contrast to scene or object recognition , requires a per - pixel classification . several strategies have been developed to go from global object detection to fine - grained segmentation , such as classification of sliding windows  @xcite or image region proposals  @xcite , multi - scale cnns combined with superpixels  @xcite , or recurrent cnn architectures , which are a compact , efficient version of a multi - scale approach  @xcite . recently , fully convolutional networks ( fcns ) , have been employed for pixel - level segmentation  @xcite@xcite . fcns have several attractive properties in comparison to the aforementioned methods for scene parsing . for example , fcns have no constraints on the size of their input data and execute inference in a single pass efficiently per image , instead of a single pass per superpixel , window or region  @xcite . consequently , they do not require concepts like superpixel , region or multi - scale pre- or post - processing  @xcite . in the field of image segmentation , an additional interesting approach of training is weak supervision , where a limited set of related annotations are exploited for training . for example , the authors of  @xcite train cnns for pixel - level segmentation on image - level labels , since labels for the latter are more abundant than for the former . even though weakly- or unsupervised training methods of cnns are improving , they are currently still outperformed by fully supervised methods  @xcite@xcite . together with the fact that creating large amounts of pixel - accurate training labels is inherently much work , we propose a middle - way in this paper : self - supervised training . if training labels can be generated automatically , the amount of supervised training data available becomes practically unlimited . however , this leads to a paradox , since it requires an algorithm that can generate the labeling , which is exactly the issue that needs to be solved . therefore , we propose to rely on an algorithm based on traditional ( non - deep learning ) computer vision methods . this algorithm needs not to be perfect but at least sufficiently good to generate weak training labels . the goal is then that the fcn , trained with these weak labels , outperforms the traditional algorithm .    for next - generation adas , stereo cameras and multi - view cameras are an increasingly used sensor configuration . stereo cameras provide insight into the geometry of the scene by means of the stereo disparity signal , which is valuable information for free - space detection . a state - of - the - art algorithm to distinguish free space and obstacles is the disparity stixel world  @xcite . it performs very well under favourable lighting conditions where the stereo estimation works reliably , but the algorithm is shown to have trouble under adverse conditions such as dim or very bright light  @xcite@xcite@xcite . we will use this algorithm to generate free - space masks and exploit these as weak training labels . we will rely on the generalization power of fcns to deal with the errors in the weak labeling . in essence , we use a stixel - based disparity vision system to train a pixel - accurate free - space segmentation system , based on an fcn , and refer to this as self - supervised training .    as a further contribution , our proposed self - supervised training is enhanced by combining it with the aforementioned strategies of task - specific fine - tuning of neural nets . since traffic scenes come in a wide variety ( urban versus rural , highway versus city - center ) , with varying imaging conditions ( good versus bad weather , day versus night ) , adas have to be both flexible and robust . a potential strategy is to train many different classifiers and to select the one that is most relevant at the moment ( for instance , based on time and geographical location ) , or train a complex single classifier to handle all cases . in contrast , we show in this paper that it is feasible to fine - tune a relatively simple , single classifier in an online fashion . this is obtained by using the same self - supervised strategy as for offline learning , namely , based on generally correct segmentation by the disparity stixel world . this results in automatically improved robustness of the free - space detection , as the algorithm is adapted while driving . although our system does not yet operates in real - time , we deem this to be feasible in the near future , as the stixel world system can execute in real - time and our fcn is relatively small , which allows for both fast training and fast inference .    considering the overall approach , our work is also related to  @xcite , where automatically generated labels are exploited to train a cnn for road detection , which is applied as a sliding - window classifier . they also have an online component , which analyzes a small rectangular area at the bottom of the image ( assumed road ) and calculates a color transform to boost the uniformity of road appearance . the results of offline and online classifications are combined with bayesian fusion . our proposed work differs in several key points . firstly , we do not need to assume that the bottom part of a image is road in the online training step , which is often an invalid assumption in stop - and - go traffic , since we exploit the stereo disparity as an additional signal . secondly , their offline and online method is a hybrid combination of supervised and hand - crafted features , whereas our method can be trained and tuned in a fully end - to - end fashion , using a single fcn , while avoiding an additional fusion step . thirdly , we do not require a sliding window in our inference step , since we use an fcn and not a cnn . the remainder of this paper is structured as follows . our self - supervised and online training strategies are described in more detail in section  __. our validation procedures are provided in section  __ , with a corresponding __ section . finally , our research findings are briefly summarized in the __ section . in the following sections we will first explain the baseline fcn algorithm for image segmentation . after this , we will introduce our self - supervised and the corresponding online training strategies of the fcn in more detail .      the color - based segmentation algorithm used as a basis of our work is an fcn  @xcite . an fcn is a convolutional neural network , where all fully connected layers are replaced by their equivalent convolutional counterparts . this adaptation transforms the net into a deep filter that preserves spatial information , since it only consists of filtering layers that are invariant to translation . therefore , an fcn can process inputs of any size  @xcite . a challenge with this approach is that fcns also typically contain several subsampling layers , so that the final output is smaller or of coarser resolution than the input image . to address this issue , the authors of  @xcite introduce skip - layers that exploit early processing layers , which have a higher resolution , to refine the coarse results in the final layer . in this way , the output resolution matches that of the input for pixel - level labeling .    for our experimentation , we have relied on the cn24 framework as described in  @xcite . its extension to fully convolutional networks is shortly introduced in  @xcite . provided that the context ( road detection ) and data ( images captured from within a vehicle  @xcite ) are comparable to our research , we adopt their network architecture and their recommendations about the optimal training strategy . the network consists of several convolutional , max pooling and non - linear layers : conv ( @xmath3 ) ; maxp ( @xmath4 ) ; relu ; conv ( @xmath5 ) ; relu ; full ( @xmath6 ) ; relu ; full ( @xmath7 ) + spatial prior ; relu ; full ( @xmath8 ) + tanh . the fully connected layers are interpreted and executed as convolutional layers by the cn24 library . the special feature of this network is the spatial prior , which is trained in the learning process as an integral part of the net , using the normalized positions of training patches . this spatial prior exploits the spatial bias that is certainly present in road or free - space segmentation in traffic scenes . we employ the recommended settings for training , based on image patches and without using dropout . note that our current work is not meant to offer an exhaustive test on optimizing the network architecture or the hyper parameters of the training process . we acknowledge the fact that our results may be improved by investigating that more properly , but the focus in this paper is to show the feasibility of self - supervised training and the additional benefits of our proposed online tuning in the context of free - space segmentation . self - supervised training requires an algorithm that generates ( weak ) training labels . the training label generation algorithm is chosen to be an independent algorithm , which exploits an additional signal modality , namely stereo disparity . this disparity - based algorithm generates masks that indicate drivable surface . as these masks are estimates themselves and are not perfect , we say they represent _ weak _ training labels . the reason to use a different modality ( disparity ) as basis for the weak training labeling than the modality ( color ) that is analyzed by the fcn , is to increase the chance that the trained algorithm can correct unavoidable errors in the weak labels , instead of stepping into the same pitfalls in difficult situations . stereo disparity is an attractive modality , since it is computationally inexpensive and yet provides relevant information in the context of free - space detection . we propose to analyze the disparity signal with the disparity stixel world algorithm . this is a probabilistic framework that segments traffic scenes into vertically stacked , rectangular patches that are labeled as either ground or obstacle . the regularization within the stixel world algorithm is mostly a - priori designed , exploiting the fact that disparity measurements facilitate metric / real - world reasoning , such as metric margins and gravity assumptions . by simplifying the representation of a scene into piecewise planar segments ( flat for ground and fronto - parallel for obstacles ) , the segmentation can be formulated as a map estimation problem and can be solved efficiently using dynamic programming over columns with disparity measurements . the algorithm is highly parallel and can be executed in real - time  @xcite . in our system , we adopt the improvements to the disparity stixel world algorithm mentioned in  @xcite ( tuned transition probabilities , dynamic ground - plane expectation modeling and assuming a ground region below the image s field of view ) . the disparity - based ground and obstacle masks subsequently serve as the weak labels for the corresponding color image in our self - supervised training process . since this process can run automatically , we can generate ( weak ) labels for many frames . this facilitates training on images for which manual annotation is not available , so that we can enlarge the training set without much effort . since many related deep - learning experiments have shown that training on more data can be beneficial ( as discussed in the __ section ) , we also experiment with self - supervised training on on an increased amount of frames . the challenge is that the generated weak labels will contain errors , as illustrated in figure  [ fig : weaklabeling ] , potentially hampering the training process . we rely on the generalization power of the fcn training process to deal with these inconsistencies in the labeling , which we can validate by comparing the results of our self - supervised training with the results of training on manually annotated frames .      for online training , we adopt the training strategies as introduced in  @xcite . in that work , the stereo - disparity signal is analyzed for several frames , and the resulting segmentation labels are exploited to construct a color model of ground and obstacle regions . the color model is exploited to segment a new frame in the sequence with their color stixel world algorithm . the color model they apply is a simple histogram over the predominant colors in an optimized , compact color space . in the process of generating the histogram , pixels are weighted with their real - world surface to balance image regions nearby and far away from the camera . with the histograms , class posteriors are generated using bayes rule , which are subsequently applied in the map estimation of the color stixel world  @xcite . additional experiments over different color spaces showed that no single space is optimal for all frames  @xcite . in other words , their color representation can be potentially improved by adapting it better to the imaging circumstances . building further upon that observation , we propose to apply end - to - end learning in this work to exploit an fcn training algorithm for finding the representation of the image that is most relevant in the current situation .    a schematic overview of our experimental framework for free - space detection is shown in figure  [ fig : scheme ] . we train an fcn from scratch ( with random initialization ) , or start with one of the offline trained models and tune the entire model with online data . by comparing these online strategies with results from solely offline training , we show the importance and added value of adapting the classifier online to the changing environment . if this adaptation can be realized in a reliable and realistic way , our free - space detection system improves without putting extra effort and computational power into training and executing a larger , more advanced fcn . by limiting the complexity of our system , real - time execution in a driving car becomes feasible in the near future . we discuss our experimental setup and data in the following subsections ; firstly , the key experiment of comparing supervised and self - supervised learning of the fcn and secondly the comparison of online versus offline training . as a reference with general 3d modeling methods that do not rely on deep learning , we also compare against both the disparity and the color stixel world methods . to validate the feasibility of our self - supervised training method , we compare three fcns that have an equal architecture but are trained with different data . the first model , @xmath9 is trained offline on manually annotated labels , as a reference result for offline , supervised training . the second model , @xmath10 is trained offline on the same frames as @xmath9 , but now using automatically generated weak labels instead of the manual version . this model serves as a demonstration of offline , self - supervised training . thirdly , we train a model in a self - supervised fashion on _ all _ available frames in the dataset , including frames for which no manual labels are provided ( @xmath11 ) . this experiment tests the added value of training on additional data in our framework , which is realized efficiently because of the initial choice of fully self - supervised training . we perform two key experiments to test the benefits of online training for our fcn - based free - space detection and compare this to the offline experiments of section  __. similar to experiment  1 , we train on different data while the architecture of our fcn is kept identical . firstly , we train an fcn from scratch ( with random initialization ) on the weakly labeled preceding frames of each test frame , resulting in an @xmath12 for each test sequence . additionally , we validate the benefits of online tuning . to this end , we initialize the net of each training sequence with one of the offline trained models ( trained on either manual or self - supervised labels ) , resulting in an @xmath13 and @xmath14 for each test sequence . note that the labels for the online training itself are always self - supervised , since the preceding frames of each sequence are not manually annotated . additionally , we perform an experiment to further analyze our online training method . specifically , we show the power and benefit of _over - tuning_ for our framework . to this end , we test the online trained fcns on test frames of different sequences than on which they were trained . by doing so , we can investigate the extent to which the online trained fcns are tuned to their specific sequence . if the fcns are over - tuned , we expect them to perform well if the training sequence and the test frame are aligned , but simultaneously expect them to perform poorly when they are misaligned . to validate this , we conduct three different misalignment experiments : ( 1 ) shift one training sequence ahead , ( 2 ) shift one training sequence back , and ( 3 ) randomly permutate all training sequences . note that our data sequences are ordered in time , therefore , there can still be correlation between training sequences and test frames when shifting back or forth a single training sequence . we reduce this correlation as much as possible by randomly permutating all training sequences . we utilize the publicly available data from sanberg _ et al . _ @xcite@xcite as the training set for our offline training of the fcn . combined , the data consists of 188 frames with manual annotations of free space . additionally , the 10 preceding frames of each annotated frame are available , albeit without annotations . for our test set , we employ newly annotated data that is captured in a similar configuration and context as in  @xcite@xcite . the test set is released publicly with this work and consists of 265 hand - annotated frames of urban and highway traffic scenes , both under good and adverse imaging conditions . there is a large variety in scenes , covering crowded city centers , small streets , large road crossings , road - repair sites , parking lots , roundabouts , highway ramps / exits , and overpasses . to facilitate the online learning process , the 10 preceding frames of each annotated frame are provided as well ( without manual labeling ) . the rgb frames are captured with a bumblebee2 stereo camera from behind the windshield of a car . both raw and rectified frames are available , as are our disparity images . these were estimated using opencv s semi - global block - matcher algorithm with the same settings as used in  @xcite . to the best of our knowledge at the time of writing , these publicly available and annotated datasets are unique in the aspects that they ( 1 ) readily provide preceding frames that are required to perform and evaluate online learning , and ( 2 ) consist of color stereo frames that facilitate our self - supervised training methods . figure  [ fig : qual4h ] shows qualitative results of our experiments . the first column contains the input color image ( with free - space ground - truth annotation ) , and the second column the results of the disparity stixel world baseline . the third and fourth column show results of our offline and online fcn - based methods , respectively . in the top three images , the offline - trained fcn detects less false obstacles than the stixel world baseline . however , it performs worse in several important cases : it misses obstacles ( such as the poles in the fourth row , the cyclist in the fifth row ) and also classifies a canal as drivable ( sixth row ) . in contrast , all - but - one images show that our online trained fcn outperforms both the stixel world baseline and the offline training strategy . it segments the scene with raindrops on the car windscreen robustly , while the other results are also more accurate . the image in the fourth row shows an erroneous case : the online trained fcn does not detect the concrete poles , although they are present in the obstacle mask of the stixel world algorithm .                 for a more in - depth analysis , we also provide quantitative results . we adopt the pixel metrics as employed for the kitti dataset  @xcite , which are shortly described here for completeness . we calculate recall , precision and the f - measure ( the harmonic mean of recall and precision ) in a birds - eye - view projection ( bev ) of the image . additionally , since our fcns provide confidence maps , the maps need to be thresholded before they can be compared to the ground - truth annotation . to this end , we select the threshold that maximizes the f - measure , giving @xmath15 . the metric @xmath15 is an indication of the optimal performance of the algorithm . to provide a balanced view , we also calculate the average precision @xmath2 , which captures the precision score over the full range of recall . the recall - precision curves of our main experiments are shown in figure  [ fig : roc ] , where the left graph shows the full range and the right graph provides an enlarged view of the top - right region ( closest to the optimal point ) . for offline learning , the results of supervised ( manual labels ) and self - supervised ( disparity - based labels ) are nearly identical . this confirms the feasibility of self - supervised learning , as relying on weak labels does not hamper the performance of our system . self - supervised training on more data did not lead to a clear improvement of the results in our experiments , as illustrated by the graph . this may show that our network is too small to exploit the additional data , or that the correlation within the new samples is too high to be informative . considering our online training strategies , figure  [ fig : roc ] clearly shows that these outperform the offline training over the full range of recall , thereby confirming the qualitative results of figure  [ fig : qual4h ] . the trends of our quantitative results over the number of training iterations are shown in figure  [ fig : qoverep ] . the training converges after 5,000 to 10,000 iterations and the visible trends are consistent with the roc curves in figure  [ fig : roc ] : offline training is outperformed by online training and online tuning performs slightly but consistently better than online training from scratch . an important conclusion of the experiments is that the contribution of online - tuned training is most significant in the speed of convergence , and less relevant for the final result after convergence . more specifically , the models for which we apply tuning outperform offline methods and the baseline already after 100 iterations of training ( which takes less than half a second on a geforce gtx970 graphics card ) , whereas models trained from scratch need at least 500 iterations to match the offline fcn and more than 2000 to exceed the stixel world algorithm . figure  [ fig : confmasks ] illustrates how the confidence masks of these two methods converge . additionally , we have conducted two different experiments on the robustness of our online tuning strategy . firstly , we have tested the drop in performance as a function of the delay between the frames on which the online tuning is performed and the frame under analysis . the left graph in figure  [ fig : scoredrops ] shows that the score drops only about @xmath16 with a delay of 2.5 seconds . secondly , we validated the influence of the number of fcn layers that are tuned online on the free - space detection result . our net has 5 layers with parameters , so we compared tuning all layers ( regular online tuning ) to tuning only the last 4 , 3 , 2 or 1 layers . keeping all layers static is the offline training reference . the right graph in figure  [ fig : scoredrops ] shows that tuning only the final layer provides results within @xmath17 of the full tuning approach . both experiments provide tradeoffs between tuning time and performance quality . the results of the misalignment of the training sequences and the test frames with the online - trained fcns are provided in table  [ table : quantshuff ] . it is clear that the misalignment has a negative impact on the performance of the online training approach , as was to be expected . the scores drop even below that of the models that are trained offline , also for the fcns that were initialized with offline pre - trained nets . as the online fcns outperform all other methods when their training sequence and test frame are aligned , this validates our claim that the online training is giving the system flexibility to adapt to new circumstances , and that over - tuning can be exploited beneficially in the context of free - space detection for adas .    [ cols=\"<,^,^,^,^,^,^,^ \" , ] we have shown that fully convolutional networks can be trained end - to - end in a self - supervised fashion in the context of free - space segmentation for adas . the segmentation results are similar to a conventional supervised strategy that relies on manually annotated training samples . we expect that this result can be generalized to different end - to - end training algorithms , reducing the need for large amounts of manually labeled data . furthermore , we have extended this result to show that it facilitates _ online _ training of a segmentation algorithm . consequently , the free - space analysis is highly adaptive to any traffic scene that the vehicle encounters . experiments show that the online training boosts performance with @xmath0 when compared to offline training , both for @xmath1 and @xmath2 . in conclusion , we exploit the fact that our adaptive strategy is not required to generalize to a large amount of traffic scenes with a single detector . hence , the detector can -and should- be over - tuned on currently relevant data . in turn , this allows for a small fcn whose training converges fast enough to make real - time deployment feasible in the near future . we happily acknowledge the assistance of c .- a . brust with employing the cn24 library . brust , c.a . , sickert , s. , simon , m. , rodner , e. , denzler , j. : convolutional patch networks with spatial prior for road detection and urban scene understanding . int . conf . on computer vision theory and applications ( visigrapp ) ( 2015 ) 510 - 517    krizhevsky , a. , sutskever , i. , hinton , g.e . : imagenet classification with deep convolutional neural networks . in : advances in neural information processing systems 25 ( nips ) . curran associates , inc . ( 2012 ) 10971105        dosovitskiy , a. , springenberg , j.t . , riedmiller , m. , brox , t. : discriminative unsupervised feature learning with convolutional neural networks . in : advances in neural information processing systems 27 ( nips ) . curran associates , inc . ( 2014 ) 766774            girshick , r. , donahue , j. , darrell , t. , malik , j. : rich feature hierarchies for accurate object detection and semantic segmentation . in : conf . on computer vision and pattern recognition ( cvpr ) , ieee ( 2014 ) sermanet , p. , eigen , d. , zhang , x. , mathieu , m. , fergus , r. , lecun , y. : overfeat : integrated recognition , localization and detection using convolutional networks . in : int . conf . on learning representations ( iclr 2014 ) , cbls ( 2013 )  16        long , j. , shelhamer , e. , darrell , t. : fully convolutional networks for semantic segmentation . computer vision and pattern recognition ( cvpr ) , ( november 2015 ) , 3431 - 3440 brust , c.a . , sickert , s. , simon , m. , rodner , e. , denzler , j. : efficient convolutional patch networks for scene understanding . in : cvpr scene understanding workshop ( cvpr - sunw ) . ( 2015 )          sanberg , w.p . , dubbelman , g. , de  with , p.h . : extending the stixel world with online self - supervised color modeling for road - versus - obstacle segmentation . in : int . conf . on intelligent transportation systems ( itsc ) , ieee ( oct . 2014 ) 14001407    sanberg , w.p . , dubbelman , g. , de  with , p.h . : color - based free - space segmentation using online disparity - supervised learning . in : int . conf . on intelligent transportation systems ( itsc ) , ieee ( september 2015 ) 906912        sanberg , w.p . , dubbelman , g. , de  with , p.h . : free - space detection using online disparity - supervised color modeling . in : 7th iros workshop on planning , perception and navigation for intelligent vehicles ( iros - ppniv ) . 2015 ) 105110    willem sanberg received both his bsc . ( 2011 ) and his msc .- degree ( 2013 ) in electrical engineering and a certificate in technical management ( 2011 ) from eindhoven university of technology in the netherlands . his phd research is aimed at improving the semantic understanding of 3d modeled environments for intelligent vehicles by developing efficient yet robust methods that can adapt themselves to the dynamic environment of everyday traffic . he works in ( inter)national projects with both industrial and research partners . gijs dubbelman is an assistant professor with the eindhoven university of technology and focuses on signal processing technologies that allow mobile sensor platforms to perceive the world around them . he obtained his phd . research in 2011 on the topic of visual slam . in 2011 and 2012 he was a member of the field robotics center of carnegie mellon s robotics institute , where he performed research on 3-d computer vision systems for autonomous robots and vehicles . peter h. n. de with ( msc . ee ) received his phd degree from university of technology delft , the netherlands . after positions at philips research , university mannheim , logicacmg and cyclomedia , he became full professor at eindhoven university of technology . he is an ( inter-)national expert in surveillance for safety / security and was involved in multiple eu projects on video surveillance analysis with the harbor of rotterdam , dutch defense , bosch security , tkh - security , vinotion , etc . he is board member of ditss and r&d advisor to multiple companies . he is ieee fellow , has ( co-)authored over 300 papers on video analysis , systems and architectures , with multiple awards of the ieee , vcip , and eurasip .", "tags": [], "output_text_a": "This paper explores the development of vision-based Advanced Driver Assist Systems (ADAS) with a focus on free-space detection, which is crucial for identifying drivable areas around a vehicle. The authors employ a Fully Convolutional Network (FCN) for this task and introduce a self-supervised, online training approach to enhance the system's robustness. The paper highlights the advantages of using FCNs for pixel-level segmentation due to their efficiency and flexibility compared to traditional methods. The proposed self-supervised training leverages weak labels generated by a disparity-based algorithm, allowing the FCN to improve upon these initial labels. The study also demonstrates the benefits of online training, which adapts the FCN to changing environments in real-time, enhancing the system's performance without the need for extensive manual labeling. The results show that the self-supervised and online training strategies significantly improve free-space detection, making real-time deployment feasible for future ADAS applications. The research underscores the potential of adaptive, end-to-end learning systems in enhancing traffic safety and comfort.", "output_text_b": "This article presents a method for training a Fully Convolutional Network (FCN) for free-space detection in Advanced Driver Assistance Systems (ADAS) using a self-supervised, online approach. The authors use a stereo disparity-based algorithm to generate weak training labels for the FCN. These labels are then used to fine-tune the FCN, improving its robustness to real-world conditions. The proposed method is compared to traditional supervised training methods and is shown to perform well in a variety of traffic scenes.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the development of vision-based ADAS, the use of FCNs, and the introduction of self-supervised, online training.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is free-space detection for ADAS, is clearly highlighted.\n4. The methodology, including the use of FCNs and self-supervised training, is mentioned.\n5. Significant results, such as the improvement in free-space detection and the feasibility of real-time deployment, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"FCN\" and \"self-supervised training\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the use of weak labels and online training, are mentioned.\n10. The potential impact of the research in enhancing traffic safety and comfort is reflected.", "1. The summary accurately reflects the main findings and contributions of the paper by mentioning the use of a self-supervised, online approach for training a Fully Convolutional Network (FCN) for free-space detection in ADAS.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is improving free-space detection in ADAS, is highlighted.\n4. The methodology, including the use of a stereo disparity-based algorithm to generate weak training labels, is mentioned.\n5. Significant results, such as the improved robustness of the FCN in real-world conditions, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"stereo disparity-based algorithm\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments or data, such as the comparison to traditional supervised training methods, are mentioned.\n10. The potential impact of the research in improving ADAS is implied but not explicitly stated."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "eighteenth century europe is referred to as the age of enlightenment , a period when prominent thinkers began to question traditional forms of authority and power and the moral standards that supported these forms . one of the most significant and enduring contributions of the time was the notion that a government s existence should be predicated on protecting and supporting the natural , immutable rights of its citizens . among these rights are the right to self - governance , autonomy of thought , and equality . the inherent virtue of these ideas forced many european nations to relinquish time - honored aristocratic and monarchic systems . moreover , it was the philosophy of the enlightenment that inspired the formalization of a governing structure that would define a new nation : the united states of america . natural rights exposed during the enlightenment are immutable . that is , they are rights not granted by the government , but instead are rights inherent to man . however , the systems that maintain and support these rights merit no such permanence . while modern democratic governments strive to achieve the ideals of the enlightenment , it is put forth that governments can better serve them by making greater use of the technological advances of the present day information age . the technological infrastructure that now supports modern nations removes the physical restrictions that dictated many of the design choices of these early government architects . as such , many of today s government structures are remnants of the technological constraints of the eighteenth century . modern nations have an obligation to improve their systems so as to better ensure the fulfillment of the rights of man . inscribed at the jefferson memorial is this statement by thomas jefferson ( american : 17431826 ) , another thinker of the enlightenment :  [ ... ] institutions must go hand in hand with the progress of the human mind . as that becomes more developed , more enlightened [ ... ] institutions must advance also to keep pace with the times . \" to move in this direction , the principle of citizen representation as articulated by thomas paine ( english : 17371809 ) and the principle of competitive actors for the common good as articulated by adam smith ( scottish : 17231790 ) are considered from a techno - social , collective decision making systems perspective . moreover , the rationale for these principles can be understood within the mathematical formulations of marquis de condorcet s ( french : 17431794 ) requirements for optimal decision making . marquis de condorcet ( portrayed in figure [ fig : condorcet - portrait ] ) ardently supported equal rights and free and universal public education . these ideals were driven as much by his ethics as they were by his mathematical investigations into the requirements for optimal decision making .     a portrait of marquis de condorcet . this is a public domain photograph courtesy of wikimedia commons.,scaledwidth=25.0% ]    one of his most famous results is the condorcet statement and its associated theorem . in his 1785 _ essai sur lapplication de lanalyse aux probabilits des decisions prises  la pluralit des voix _ ( english translation : _ essay on the application of analysis to the probability of majority decisions _ ) , condorcet states that when a group of  enlightened \" decision makers chooses between two options under a majority rule , then as the size of the decision making population tends toward infinity , it becomes a certainty that the best choice is rendered @xcite . the first statistical proof of this statement is the condorcet jury theorem . the model is expressed as follows . imagine there exists @xmath0 independent decision makers and each decision maker has a probability @xmath1 $ ] of choosing the best of two options in a decision . if @xmath2 , meaning that each individual decision maker is enlightened , and as @xmath3 , the probability of a majority vote outcome rendering the best decision approaches certainty at @xmath4 . this is known as the  light side \" of the condorcet jury theorem . the  dark side \" of the theorem states that if @xmath5 and as @xmath3 , the probability of a majority vote outcome rendering the best decision approaches @xmath6 . figure [ fig : condorcet ] plots the relationship between @xmath7 and @xmath0 , where the gray scale values denote a range from 100% probability of the group rendering the best decision ( white ) to a 0% probability ( black ) . the relationship between @xmath1 $ ] and @xmath8 according to the condorcet jury theorem model . darker values represent a lower probability of a majority vote rendering the best decision and the lighter values represent a higher probability of a majority vote rendering the best decision.,scaledwidth=48.5% ]    the condorcet jury theorem is one of the original formal justifications for the application of democratic principles to government . while the theorem does not reveal any startling conditions for a successful democracy , it does distill the necessary conditions to two variables ( under simple assumptions ) . if a decision making group has a large @xmath0 and a @xmath2 , then the group is increasing its chances of optimal decision making . unfortunately , the theorem does not suggest a means to achieve these conditions , though in practice many mechanisms do exist that strive to meet them . for instance , democracies do not rely on a single decision maker , but instead use senates , parliaments , and referendums to increase the size of their voting population . moreover , for general elections , equal voting rights facilitate large citizen participation . furthermore , democratic nations tend to promote universal public education so as to ensure that competent leaders are chosen from and by an enlightened populace . it is noted that the practices employed by democratic nations to ensure competent decision making are implementation choices , and a society must not value the implementation of its government . tradition must be forgone if another implementation would serve better . implementations of government should be altered and amended so as to better realize the ideals of the nation . technology - enabled social algorithms may provide a means by which to reliably achieve the conditions of the  light \" side of the condorcet jury theorem , thus ensuring optimal decision making . furthermore , modern algorithms have the potential to do so in a manner that better honors the right of each citizen to participate in government decision making as such algorithms are not constrained by eighteenth century technology . present day social algorithms , in the form of information retrieval and recommendation services , already contribute significantly to the augmentation of human and social intelligence @xcite . in line with these developments , this article presents two social algorithms that show promise as mechanisms for governance - based collective decision making . one algorithm exaggerates thomas paine s citizen representation in order to accurately simulate the behavior of a large decision making population ( @xmath3 ) , and the other employs adam smith s market philosophy to induce participation by the enlightened within that population ( @xmath9 ) . both algorithms utilize the condorcet jury theorem to the society s advantage . an oil portrait of thomas paine painted by auguste millire in 1880 . this is a public domain photograph courtesy of wikimedia commons.,scaledwidth=25.0% ]    thomas paine ( portrayed in figure [ fig : paine - portrait ] ) was born in england , but in his middle years , he relocated to america on the recommendation of benjamin franklin . it was in america , in the time leading up to the american revolution , that his enlightened ideals were well received . in 1776 , the year in which the declaration of independence was written , thomas paine wrote a widely distributed pamphlet entitled _ common sense _ which outlined the values of a democratic society @xcite . this pamphlet discussed the equality of man and the necessity for all those at stake to partake in the decision making processes of the group . as a formal justification of this value , the condorcet jury theorem would hold that a direct democracy would be the most likely democracy to yield optimal decisions as the voting population is the largest it can possibly be for a nation . in practice , the desire for a direct democracy is tempered by the tremendous burden that constant voting would impinge on citizens ( not to mention the logistical problems such a model would incur within present day voting infrastructures ) . for this reason , representation is required . thomas paine states that when populations are small  some convenient tree will afford them a state house \" , but as the population increases it becomes a necessity for representatives to act on behalf of their constituents . moreover , the central tenet of political representation is that representatives  act in the same manner as the whole body would act were they present . \" the remainder of this section presents a social algorithm that simulates the manner in which the whole population would act without requiring pre - elected , long - standing representatives .    assuming a two - option majority rule , an individual citizen s judgement can be placed along a continuum between the two options such that the  political tendency \" of citizen @xmath10 is denoted @xmath11 $ ] . for example , given united states politics , a political tendency of @xmath12 represents a fully republican perspective , a tendency of @xmath13 represents a fully democratic perspective , and a tendency of @xmath14 denotes a moderate . given this definition , there are two ways to quantify the population as a whole . one way is to calculate the average tendency of all citizens . that is @xmath15 , where @xmath16 $ ] is the collective tendency of the population . given a uniform distribution of political tendency within @xmath17 , the collective tendency approaches @xmath14 as the size of the population increases toward infinity . the other way to quantify the group is to require that the citizen s tendency be reduced to a binary option ( i.e.  a two option vote ) . if a citizen has a political tendency that is less than @xmath14 , then they will vote @xmath12 . for a tendency greater than @xmath14 , they will vote @xmath13 . if they have a tendency equal to @xmath14 then a fair coin toss will determine their vote . this majority wins vote is denoted @xmath18 . imagine a direct democracy in the purest sense , where a raise of hands or a shout of voices is replaced by an internet architecture and a sophisticated error- and fraud - proof ballot system . all citizens have the potential to vote on any decisions they wish ; if they can not vote on a particular decision for whatever reason , they abstain from participating . in practice , not every decision will be voted on by all @xmath0 citizens . citizens will be constrained by time pressures to only participate in those votes in which they are most informed or most passionate . if we assume that all citizens have a tendency , whether they vote or not , how would the collective tendency and collective vote change as citizen participation waned ? let @xmath19 $ ] and @xmath20 denote the collective tendency and vote given by 100% participation . let @xmath21 $ ] and @xmath22 denote the collective tendency and vote if only @xmath23-percent of the population participates . the error in the collective tendency for @xmath23-percent participation is calculated as @xmath24 the further away the active voters collective tendency is from the full population s collective tendency , the higher the error . the gray line in figure [ fig : tendency ] plots the relationship between @xmath23 and @xmath25 . as citizen participation wanes , the ability for the remaining , active participants to reflect the tendency of the whole becomes more difficult . next , the error in the collective vote is calculated as the proportion of voting outcomes that are different than what a fully participating population would have voted and is denoted @xmath26 . the gray line in figure [ fig : vote ] plots the relationship between @xmath23 and @xmath26 . as participation wanes , the proportion of decisions that differ from what would have occurred given full participation decreases . as with collective tendency , a small active voter population is unable to replicate the voting behavior of the whole . the relationship between @xmath23 and @xmath25 for direct democracy ( gray line ) and dynamically distributed democracy ( black line ) . the plot provides the average error over a simulation that was run with 1000 artificially generated networks composed of 100 citizens each.,scaledwidth=48.5% ]     the relationship between @xmath23 and @xmath26 for direct democracy ( gray line ) and dynamically distributed democracy ( black line ) . the plot provides the proportion of identical , correct decisions over a simulation that was run with 1000 artificially generated networks composed of 100 citizens each.,scaledwidth=48.5% ]    dynamically distributed democracy is a social representation algorithm that provides a means by which any subset of the population can accurately simulate the decision making results of the whole population @xcite . as such , the algorithm reflects the primary tenet of representation as originally outlined by thomas paine . the argument for the use of the algorithm as a mechanism for representation goes as follows . not everyone in a population needs to vote as others in that same population more than likely have a nearly identical political tendency and thus , identical vote . what does need to be recorded is the frequency of that sentiment in the population . if an active , voting citizen is similar in tendency to @xmath27 non - active citizens , then the active citizen s ballot can be weighted by @xmath27 to reflect the tendencies of the non - participating citizens . dynamically distributed democracy accomplishes this weighting through a similarity- or trust - based social network that is used to propagate voting  power \" to active voters so as to mitigate the error incurred by waning citizen participation . as previously stated , let @xmath28^n$ ] denote the political tendency of each citizen in this population , where @xmath29 is the tendency of citizen @xmath10 and , for the purpose of simulation , is determined from a uniform distribution . assume that every citizen in a population of @xmath0 citizens uses some social network - based system to create links to those individuals that they believe reflect their tendency the best . in practice , these links may point to a close friend , a relative , or some public figure whose political tendencies resonate with the individual . in other words , representatives are any citizens , not political candidates that serve in public office . let @xmath30^{n \\times n}$ ] denote the link matrix representing the network , where the weight of an edge , for the purpose of simulation , is denoted @xmath31 in words , if two linked citizens are identical in their political tendency , then the strength of the link is @xmath4 . if their tendencies are completely opposing , then their trust ( and the strength of the link ) is @xmath6 . note that a preferential attachment network growth algorithm is used to generate a degree distribution that is reflective of typical social networks  in the wild \" ( i.e.  scale - free properties ) . moreover , an assortativity parameter is used to bias the connections in the network towards citizens with similar tendencies . the assumption here is that given a system of this nature , it is more likely for citizens to create links to similar - minded individuals than to those whose opinions are quite different . the resultant link matrix @xmath32 is then normalized to be row stochastic in order to generate a probability distribution over the weights of the outgoing edges of a citizen . figure [ fig : ddd - network ] presents an example of an @xmath33 artificially generated trust - based social network , where red denotes a tendency of @xmath6 , purple a tendency of @xmath14 , and blue a tendency of @xmath4 .     a visualization of a network of trust links between citizens . each citizen s color denotes their  political tendency \" , where full red is @xmath12 , full blue is @xmath13 , and purple is @xmath14 . the layout algorithm chosen is the fruchterman - reingold layout.,scaledwidth=40.0% ]    given this social network infrastructure , it is possible to better ensure that the collective tendency and vote is appropriately represented through a weighting of the active , participating population . every citizen , active or not , is initially provide with @xmath34  vote power \" and this is represented in the vector @xmath35 , such that the total amount of vote power in the population is @xmath13 . let @xmath36 denote the total amount of vote power that has flowed to each citizen over the course of the algorithm . finally , @xmath37 denotes whether citizen @xmath10 is participating ( @xmath38 ) in the current decision making process or not ( @xmath39 ) . the values of @xmath40 are biased by an unfair coin that has probability @xmath23 of making the citizen an active participant and @xmath41 of making the citizen inactive . the iterative algorithm is presented below , where @xmath42 denotes entry - wise multiplication and @xmath43 . @xmath44    in words , active citizens serve as vote power sinks \" in that once they receive vote power , from themselves or from a neighbor in the network , they do not pass it on . inactive citizens serve as vote power  sources \" in that they propagate their vote power over the network links to their neighbors iteratively until all ( or @xmath45 ) vote power has reached active citizens . at this point , the tendency in the active population is defined as @xmath46 . figure [ fig : tendency ] plots the error incurred using dynamically distributed democracy ( black line ) , where the error is defined as @xmath47 next , the collective vote @xmath48 is determined by a weighted majority as dictated by the vote power accumulated by active participants . figure [ fig : vote ] plots the proportion of votes that are different from what a fully participating population would have rendered ( black line ) . in essence , if a citizen , for any reason , is unable to participate in a decision making process , then they may abstain from participating knowing that the underlying social network will accurately distribute their vote power to their neighbor or neighbor s neighbor . in this way , representation is dynamic , distributed , and democratic . thomas paine outlines that representatives should maintain  fidelity to the public \" and believes this is accomplished through frequent elections @xcite . the utilization of an internet - based social network system affords repeated  elections \" in the form of citizens creating outgoing links to other citizens as they please , when they please , and to whom them please . that is , citizens can dynamically choose representatives who need not be picked from only a handful of candidates . moreover , if a selected representative falters in their ability to represent a citizen , incoming links can be immediately retracted from them . such an architecture turns the representative s status from that of elected public official to that of a self - intentioned citizen . while many countries have political institutions that are set up according to a left , right , and moderate agenda , the individual perspectives of a citizen may be more complex . in many cases , a citizen s political tendency may only be amenable to a multi - dimensional representation . in a multi - relational social network , the links are augmented with labels in order to denote the type of trust one citizen has for another . in this way , voting power propagates over the links in a manner that is biased to the domain of the decision . for example , citizen @xmath10 may trust citizen @xmath49 in the domain of  education \" but not in the domain of  health care \" . this design has been articulated in @xcite . supporting systems , including the means by which ballots are proposed and issues are discussed , is presented in @xcite .    with the internet , supporting web technologies , and dynamically distributed democracy , it is possible to dynamically determine a representative - layer of government that accurately reflects a full direct democracy . in this respect , the larger population helps to ensure , according to the condorcet jury theorem , that the decisions are either definitely right or definitely wrong . other technologies can be utilized to induce participation by only those that are more likely than not to choose the optimal decision . an etching of adam smith originally created by cadell and davies ( 1811 ) , john horsburgh ( 1828 ) , or r.c . bell ( 1872 ) . this is a public domain photograph courtesy of wikimedia commons.,scaledwidth=25.0% ]    adam smith ( portrayed in figure [ fig : smith - portrait ] ) was a scottish moral and economic philosopher who is best known for his two most famous works entitled _ the theory of moral sentiments _ ( 1759 ) and _ an inquiry into the nature and causes of the wealth of nations _ ( 1776 ) . in the latter work , adam smith outlines the economic benefits of a division of labor within a society . each citizen in the population serves a particular specialized function , and only in the dependency relationships amongst these specialists does an efficient , decentralized economy emerge . with many suppliers and consumers , the production requirements of a society as a whole is difficult to know . adam smith appreciated markets for their ability to expose these requirements through the  natural price \" of goods . moreover , he understood that competition within the market was a necessary driving force guaranteeing an accurate representation of commodity prices . adam smith states that when a citizen pursues his own interest he frequently promotes that of the society more effectually than when he really intends to promote it \" @xcite . market mechanisms are not only useful for determining commodity prices as they can be generally applied to information aggregation and ultimately , to collective decision making . such markets are called decision markets @xcite . similar to a division of labor , the knowledge required to make optimal decisions for a society is dispersed throughout the population . for difficult problems , it is nave to think that a single individual has the requisite knowledge to yield an optimal decision , much like it is nave to think a single merchant will offer the optimal price . a decision market functions because it guarantees a return on investment for quality information . in this respect , a decision market is a tool for attracting a population of knowledgeable citizens much like a commodity market is a tool for attracting knowledgeable speculators . in short , a decision market is a self - selection mechanism that incentivizes participation from those who have knowledge regarding the problem and are confident in their knowledge and discourages participation from others without forbidding it . decision markets reward individuals for buying low and selling high , thus encouraging those who believe they know which way the market will move to contribute their information in the form of the price at which they purchase and sell shares . a decision market differs from commodity markets ( such as the new york stock exchange ) in that stocks represent objective states about the world that can ultimately be determined , but are presently unknown . for example , given the market question  will decisions markets be used in u.s . government by the year 2013 ? \" , shares of stocks in a  yes \" outcome and in a  no \" outcome are purchased and sold on the market . a high market price for a stock indicates that the collective believes this outcome to be true with a high likelihood . the purpose of the market is to incentivize knowledgeable citizens to contribute to the decision by rewarding them for useful contributions and conversely to inflict a penalty for contributing poor information .    in order to demonstrate the benefits of incentives in decision making , a simulation is provided . suppose there exists @xmath0 citizens and a @xmath50-dimensional  knowledge space \" . each citizen is represented as a point in this space . that is , citizens have different degrees of knowledge in the various dimensions ( i.e.  domains ) of the space . a citizen s point in this space is generated by a normal distribution with a mean of @xmath1 $ ] and a variance of @xmath51 . next , there exists an objective truth in this spaced called the environment . for the purpose of simulation , the environment @xmath52 is the largest valued point in the knowledge space ( i.e.  @xmath53 ) . there also exists a market @xmath54 which denotes the collective s subjective understanding of the objective environment . for the purpose of simulation , the market starts as the smallest valued point in the knowledge space ( i.e.  @xmath55 ) . each citizen participates in the market , moving the market closer or further away from the environment . the closer the market is to the environment , the more accurate the collective decision . there are two markets in the simulation : an incentive - free market and an incentive market . the results of these two markets are compared in order to demonstrate the benefits of using incentives . the states of the incentive - free and incentive markets ( purple ) and the objective state of the environment ( green ) are diagrammed in a @xmath56-dimensional knowledge space . there exists two paths : the incentive - free market path ( red ) and the incentive market path ( blue ) . the dotted cubes denote the range of an incentive - free market ( red - @xmath14 ) and incentive market ( blue - @xmath57 ) for a @xmath58 . refer to the text for a description of the diagrammed market paths.,scaledwidth=35.0% ]    before presenting the results of a larger simulation , a small diagrammed example is provided to better elucidate the simulation rules . figure [ fig : market - cube ] diagrams a @xmath56-dimensional knowledge space with both markets ( bottom left purple point ) and an environment ( top right green point ) . the behavior of the citizens denotes the market paths ( red and blue arrows ) . also , there exists a @xmath58 population of @xmath56 citizens , where citizen @xmath59 $ ] , citizen @xmath60 $ ] , and citizen @xmath61 $ ] . at time step @xmath62 , both the incentive - free and incentive markets are at @xmath63 $ ] . at @xmath64 , citizen @xmath65 participates in both markets . in the incentive - free market , citizen @xmath65 has no incentive to contribute his best knowledge and thus , randomly chooses a dimension in which to move the market . according to the diagram , the citizen s random choice moves the market in the @xmath66 dimension by @xmath67 . in the incentivized market , citizen @xmath65 chooses the dimension in which he has the most knowledge ( i.e.  the dimension with the maximum value ) . moreover , a biased coin toss determines whether he participates or not , where @xmath65 has a @xmath68% chance of participating in the incentive market . assuming the coin toss permits it , @xmath65 moves the incentivized market in the @xmath69 dimension to @xmath70 . this process continues in sequence for citizens @xmath71 and @xmath72 . assuming that all citizens participate in both markets , at the end , the incentive - free market is located at point @xmath73 $ ] , while the incentive market is located at point @xmath74 $ ] . the market error is calculated as the normalized euclidean distance between the final market position and the environment for a given @xmath7 , @xmath75 the incentive - free market has an error of @xmath76 and the incentive market has an error of @xmath77 . thus , the incentive market is closest to the environment . there are two distinctions between the markets . in the incentive - free market , there is no benefit to producing an enlightened solution , so the citizen makes a contribution without comparing his knowledge against the environment . in the incentive market , there are two incentive structures . the first incentive is to participate along the dimension in which the citizen is most knowledgeable . the second incentive is to participate only if the citizen has a satisfactory degree of knowledge . this means that poor information is excluded from the market and that the most valuable knowledge of the citizen is included .    to demonstrate the effects of an incentive - free and incentive market on a larger population , over various values of @xmath7 , and in a @xmath78-dimensional knowledge space simulation results are provided . figure [ fig : market ] depicts the normalized euclidean distance error of the incentive - free market ( gray line ) and the incentive market ( black line ) for varying @xmath7 . next , figure [ fig : prediction ] provides the proportion of correct collective decisions . a decision is either correct or incorrect . while the market yields a point in @xmath79^d$ ] , rounding the dimension values of the point to either @xmath13 or @xmath12 provides the final decision made by the citizens . for a given @xmath7 , the proportion of times that the market rounds to the environment is the proportion of correct decisions and is denoted @xmath80 $ ] . the relationship between @xmath7 and @xmath81 for an incentive - free market ( gray line ) and an incentive market ( black line ) . the plot provides the average error over @xmath82 simulations with @xmath83 and @xmath84.,scaledwidth=48.5% ]     the relationship between @xmath7 and @xmath85 for an incentive - free market ( gray line ) and an incentive market ( black line ) . the plot provides the proportion of correct decisions over @xmath82 simulations with @xmath83 and @xmath84.,scaledwidth=48.5% ]    it is the principle of self - selection , and therefore citizen choice , that provides the mechanism by which knowledge is aggregated . choice is manifested in a number of ways . first , citizens choose whether or not to participate in the market at all . this reduces the amount of poor information that enters the market . second , citizens choose how often to participate . the market , therefore , induces citizens to become more knowledgeable so as to gain from the market . finally , citizens choose the extent of their participation . if a citizen has knowledge that is not well reflected in the market , suggesting that their knowledge is unique and therefore valuable , the citizen is incentivized to participate more so than if the market closely mimics their knowledge . in decision markets , it is the pricing mechanism of the market that serves the incentivizing role . however , the asset traded in the market need not be money . to maintain the egalitarian nature of self - selection , the market can be based in virtual money with rewards , reputation , or other social inducements as the backing . it has been demonstrated that virtual money is able to preserve the accuracy of decision markets @xcite .    as presented in the simulation the decisions of a society are multi - dimensional . it is likely that no single citizen has the requisite knowledge in all dimensions to make informed decisions . the ability to reach an optimal decision is dependent on the many dimensions such that ignorance of one dimension may lead to a suboptimal conclusion . the probability parameter of the condorcet jury theorem model is misleading . it is not through probability that one achieves an optimal decision , but through the careful application of knowledge to the decision . the use of a market is not a guarantee that decision makers have @xmath2 . the market is a guarantee that citizen knowledge has been thoughtfully applied to the decision . the purpose of a democratic government is to preserve and support the ideals of its population . the ideals established during the enlightenment are general in nature : life , liberty , and the pursuit of happiness . in articulating these values , the founders of modern democracies provided a moral heritage that remains highly regarded in societies today . however , it should be remembered that it is the ideals that are valuable , not the specific implementation of the systems that protect and support them . if there is another implementation of government that better realizes these ideals , then , by the rights of man , it must be enacted . it was the great thinkers of the eighteenth century enlightenment who provided the initial governance systems . it is the challenge and the mandate of the information age to redesign these governance systems in light of present day technologies . j.  h. watkins and m.  a. rodriguez , _ evolution of the web in artificial intelligence environments _ , ser . studies in computational intelligence . 1em plus 0.5em minus 0.4emberlin , de : springer - verlag , 2008 , ch . a survey of web - based collective decision making systems , pp . 245279 . [ online ] . available : http://repositories.cdlib.org/hcs/workingpapers2/jhw2007-1/      m.  a. rodriguez and d.  j. steinbock , `` a social network for societal - scale decision - making systems , '' in _ proceedingss of the north american association for computational social and organizational science conference _ , pittsburgh , pa , 2004 . [ online ] . available : http://arxiv.org/abs/cs.cy/0412047    m.  a. rodriguez , `` social decision making with multi - relational networks and grammar - based particle swarms , '' in _ proceedings of the hawaii international conference on systems science_.1em plus 0.5em minus 0.4emwaikoloa , hawaii : ieee computer society , january 2007 , pp [ online ] . available : http://arxiv.org/abs/cs.cy/0609034    m.  turrof , s.  r. hiltz , h .- k . cho , z.  li , and y.  wang , `` social decision support system ( sdss ) , '' in _ proceedings of the hawaii international conference on systems science hawaii international conference on systems science_.1em plus 0.5em minus 0.4em waikoloa , hawaii : ieee computer society , january 2002 , pp . 8190 .", "tags": [], "output_text_a": "The article discusses the influence of Enlightenment ideals on modern governance, emphasizing the need to adapt these principles using contemporary technology. The Enlightenment period in 18th-century Europe introduced the concept of natural rights, which are inherent and not granted by governments. These ideas led to the development of democratic systems, such as in the United States, which aim to protect citizens' rights to self-governance, autonomy, and equality.\n\nThe paper argues that while the ideals of the Enlightenment remain relevant, the systems supporting them should evolve with technological advancements. It highlights the Condorcet Jury Theorem, which suggests that larger, more informed decision-making groups are more likely to make optimal decisions. The article proposes using technology-enabled social algorithms to enhance democratic processes, ensuring better representation and decision-making.\n\nTwo social algorithms are presented: one simulates large decision-making populations, and the other uses market principles to encourage informed participation. These algorithms aim to dynamically distribute representation and incentivize knowledgeable contributions, aligning with Enlightenment ideals while leveraging modern technology.\n\nThe article concludes that while the foundational ideals of democracy are valuable, the systems implementing them should be flexible and updated to better serve society in the information age. It calls for a redesign of governance systems to incorporate present-day technologies, ensuring that democratic processes remain effective and inclusive.", "output_text_b": "The article discusses the importance of natural rights and their protection during the Age of Enlightenment and how these ideas influenced the formation of the United States of America. The authors argue that modern governments should make use of technological advances to better ensure the fulfillment of these rights. They propose two social algorithms for collective decision making based on the principles of citizen representation and competitive actors for the common good. These algorithms aim to improve decision making by utilizing the Condorcet Jury Theorem to better represent the will of the citizens.", "score": 0.5, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the influence of Enlightenment ideals on modern governance and the use of technology to enhance democratic processes.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of adapting Enlightenment principles using contemporary technology.\n4. **Methodology**: The summary mentions the use of technology-enabled social algorithms as the methodology.\n5. **Significant Results**: The summary includes significant conclusions about the need for flexible governance systems that incorporate modern technology.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like the Condorcet Jury Theorem.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in advocating for updated governance systems in the information age.", "1. **Accurate Reflection**: The summary captures the main ideas of the paper, such as the influence of Enlightenment ideas on modern governance and the proposal of social algorithms for decision making. However, it lacks specific details about the findings and contributions, such as the simulation results and the specific algorithms discussed.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary does not explicitly state the research problem or question addressed by the paper.\n4. **Methodology**: The summary briefly mentions the use of social algorithms and the Condorcet Jury Theorem but does not detail the methodology or approach used in the paper.\n5. **Significant Results**: The summary does not include specific results or conclusions drawn by the authors, such as the effectiveness of the proposed algorithms.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids technical jargon and does not explain terms like \"Condorcet Jury Theorem,\" which might be necessary for understanding.\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n9. **Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary does not reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "examining the earliest phases of low mass stellar evolution requires observations of protostars deeply embedded in the dense cores of nearby molecular clouds . these `` class i '' sources ( @xcite ) have blackbody - like spectral energy distributions that peak at wavelengths of 30100  and bolometric luminosities , @xmath1 0.1100  ( @xcite ; @xcite ; @xcite ; @xcite ; @xcite ) . despite many detailed studies of their circumstellar environments ( see , for example , @xcite , b ; @xcite ; @xcite ; @xcite , 1995 ; @xcite ; @xcite ; @xcite ; @xcite ) , understanding the stellar physics of these objects has proved elusive . comparisons of observed bolometric luminosity functions with models is straightforward but controversial ( @xcite ; @xcite ; @xcite , 1994b ) . the apparent lack of photospheric features in many objects has led several groups to abandon the hr diagram as a means for testing stellar evolutionary tracks of the youngest stars . these groups have proposed the bolometric temperature ( @xcite and references therein ) , the submillimeter flux ( @xcite ) , and the visual extinction ( @xcite ) to replace effective temperature and have developed models to place evolving pre main - sequence stars in their modified evolutionary diagrams . the accuracy of these techniques remains uncertain , because the methods are new and incompletely tested .    in this paper , we report an optical spectroscopic survey designed to detect photospheric absorption features from the central stars of class i sources in the taurus - auriga cloud . although the line - of - sight extinction to the central star is large , @xmath2 3060 mag ( @xcite ) , large ground - based telescopes can detect optical light scattered off cavities in the infalling envelopes of many objects . optical data also provide the best measure of spectral types for pre  main - sequence stars . in general , i - band and j - band data are least contaminated by emission from an accretion disc and its associated boundary layer or magnetic accretion column ( @xcite ) . however , the very large continuum veiling detected on near - ir spectra of some class i sources ( @xcite ; @xcite , 1996b ) favors i - band spectra , because the j - band veiling can be large if the disc extends to the stellar photosphere ( @xcite ; @xcite ) . finally , optical spectra of class i sources allow an unambiguous comparison with optically brighter t tauri stars , which have known spectral types in a well - calibrated system ( see , for example , kenyon & hartmann 1995 ; kh95 hereafter ) . our results provide the first optical detection of m - type absorption features in an embedded protostar . we identify tio absorption bands in three taurus - auriga class i sources ; one other star may have tio features and a fifth star may have k - type absorption features . we use optical spectra of t tauri stars to calibrate the spectral types of class i sources and then construct a complete hr diagram for the taurus - auriga cloud . these data , coupled with new evolutionary tracks for protostars accreting from discs and two spectral types derived from near - ir spectra ( @xcite ) , show that class i sources in taurus - auriga mingle with t tauri stars and lie below the birthline in the hr diagram . we also detect strong emission lines on the spectra of all protostars . forbidden emission from [ n  ii ] and [ s  ii ] is much more common among class i sources than older , optically brighter stars having the same bolometric luminosity . the fluxes of forbidden emission lines also seem stronger among class i sources than other pre  main - sequence stars in the cloud . we find no evidence that the permitted emission lines , such as h@xmath0 and he  i , are more common or stronger than in t tauri stars . these results extend and confirm previous conclusions that jet activity declines as a pre  main - sequence star contracts to the main - sequence . we describe our observations in sec . 2 , explain our results in sec . 3 , and conclude with a brief discussion in sec . we acquired optical spectra of faint taurus - auriga class i sources and other pre  main - sequence stars with the red channel spectrograph at the multiple mirror telescope ( mmt ; 1619 november 1995 ) and the double spectrograph at the palomar 5-m telescope ( 2930 november 1995 ) . at the mmt , we used the 270 g mm@xmath3 grating and a 1  slit to produce spectra covering 57009000   on a 1200 @xmath4 800 loral ccd . on - chip binning of the pixels , 2 @xmath4 2 , yielded a spectral resolution of 10.8   and a spatial resolution of 06 per pixel . at palomar , we used a 316 g mm@xmath3 grating , a 2  slit , and a 1024 @xmath4 1024 ccd . the palomar spectra cover 60008500   with a spectral resolution of 10   and a spatial resolution of 047  per pixel . we obtained low resolution spectra of brighter young stars in taurus - auriga during 19951996 with fast , a high throughput , slit spectrograph mounted at the fred l. whipple observatory 1.5-m telescope on mount hopkins , arizona ( @xcite ) . we used a 300 g mm@xmath3 grating blazed at 4750  , a 3  slit , and recorded the spectra on a thinned loral 512 @xmath4 2688 ccd . these spectra cover 38007500   at a resolution of @xmath5 6  . we derive final object spectra using standard tasks within noao iraf . after trimming the ccd frames at each end of the slit , we correct for the bias level , flat - field each frame , apply an illumination correction , and derive a full wavelength solution from calibration lamps acquired immediately after each exposure . the wavelength solution for each frame has a probable error of @xmath60.51.0  . we extract object and sky spectra using the optimal extraction algorithm within apextract . we vary the size of the object / sky aperture from source to source to include additional radiation from extended emission .    at both the mmt and palomar , we selected class i sources based on published vri photometry ( see kh95 ) , poss red plates , and red narrow band continuum images ( @xcite ) . our sample of 10 class i sources is complete to r @xmath5 20 : we detected all sources with optical counterparts on the poss and several sources with measured r @xmath5 1920 . we did not observe 14 other class i sources without known optical counterparts and can not estimate a reliable detection frequency for deeply embedded sources . the observed sample spans the observed range of class i luminosities in the taurus - auriga cloud , @xmath7 0.220 , but does not include the reddest systems that do not have optical counterparts ( see @xcite ) . we selected fast sources from the kh95 sample of @xmath5 150 known pre main - sequence stars in the taurus - auriga cloud . we observed essentially all targets with v @xmath8 1617 : 55 out of 65 weak emission t tauri stars , 69 out of 96 classical t tauri stars , and one class i source with a bright optical counterpart ( haro 6 - 28 ) . aside from their apparent brightness , these samples do not appear to be biased against any particular observational property of pre  main - sequence stars : the distributions of h@xmath0 equivalent widths , k l colors , and bolometric luminosities of stars in the fast sample are indistinguishable from the distributions for stars not included in the fast sample using data from cohen & kuhi ( 1979 ) and kh95 . we thus conclude that the fast objects are a representative sample of known pre main - sequence stars in the cloud . figure 1 shows fast spectra of t tauri stars with a range of emission characteristics . weak emission t tauri stars , such as lkca 3 , have absorption spectra similar to normal main - sequence stars with additional weak h@xmath0 emission lines ( @xcite ; @xcite ) . classical t tauri stars , such as bp tau , dg tau , and dp tau , have prominent emission lines and a variable blue continuum superimposed on a late - type absorption spectrum ( @xcite ; @xcite , 1991 ) . some t tauri stars have few emission lines other than h  i and he  i ; others have prominent [ o  i ] , [ s  ii ] , and [ fe  ii ] emission lines ( @xcite ) . in most interpretations , the h  i and he  i lines form in an accretion region or outflowing wind close to the central star ; the [ o  i ] and [ s  ii ] lines form in a jet or in the wind ( @xcite ; @xcite ; @xcite ; see also @xcite ) . figure 2 shows contour maps of mmt spectra for several sources centered on h@xmath0 and [ s  ii ] @xmath96717,6730 . we fit gaussian profiles to the continuum and a few emission lines along the spatial direction for each class i source and three point sources . several class i sources  such as l1489 irs ( 04016 + 2610 ) , hh31 irs2 ( 04248 + 2612 ) , and 04264 + 2433  are clearly extended along the slit , with @xmath10 510  compared to @xmath10 10@xmath602 for point sources . these sizes are comparable to sizes inferred from optical and near - infrared images of these sources ( @xcite ; @xcite , and references therein ) . the very deeply embedded sources l1527 irs ( 04368 + 2557 ) and l1551 irs5 ( 04287 + 1801 ) are much more extended than other class i sources . both have large optical reflection nebulae , @xmath11 30  across , with multiple emission knots ( see , for example , @xcite ; @xcite ; @xcite ; @xcite ) . our results indicate that the continuum and emission lines of all class i sources are equally extended within the errors of the fit . the mean difference in spatial extent between the emission lines and the continuum is @xmath12 = 04 @xmath6 03 for the 5 sources with strong continua ( l1489 irs , 04158 + 2805 , hh31 irs2 , 04264 + 2433 , and 04489 + 3042 ) . this difference is small compared to the typical spatial extent of each source , @xmath10 510 . our observations have insufficient spatial resolution to discriminate between sources with emission knots such as l1527 irs and those without emission knots such as 04489 + 3042 . figures 35 show mmt and palomar spectra for taurus class i sources . we detect a strong continuum in several objects ( figure 3 ) , including l1489 irs , hh31 irs2 , 04264 + 2433 , and 04489 + 3042 . three class i sources  04158 + 2805 , 04248 + 2612 and 04489 + 3042  have the deep tio absorption bands characteristic of m - type stars . the continua of l1489 irs and 04264 + 2433 appear featureless , although both have a prominent dip at 8100  . all of these class i sources have a strong h@xmath0 emission line , along with moderately strong emission from [ o  i ] , [ s  ii ] , and ca ii . several have he  i emission at @xmath95876 , 6678 , 7065 . these spectra are similar to the spectra of classical t tauri stars in figure 1 . the spectra of class i sources in figure 5 more closely resemble spectra of jets or herbig - haro ( hh ) objects ( e.g. , @xcite ; @xcite ; @xcite ; @xcite ; see also @xcite ) . we detect little , if any , continuum emission from 04239 + 2436 , 04295 + 2251 , and l1527 irs , but all of these objects have very strong emission lines ( figure 5 ) . the relative intensities of the emission lines in 04239 + 2436 and l1527 irs are similar to those for on - source emission in hh30 irs ( figure 4 ; right panel ) and l1551 irs5 ( figure 5 ; upper right panel ) . we detect [ o  i ] and [ s  ii ] emission in all class i sources except 04295 + 2251 ( figure 5 ; lower left panel ) , where we identify a prominent h@xmath0 emission line superimposed on a very weak continuum . to compare spectra of class i sources and t tauri stars in more detail , we measure the strengths of several prominent absorption and emission lines . we fit gaussian profiles to obvious emission lines using splot within noao iraf and use the deblend option for blended lines such as the [ s  ii ] doublet and the he  i @xmath135876 and na  i blend . in the absence of accurate de - reddened fluxes , the equivalent width , ew , provides a good relative measure of emission line strengths for strong continuum sources . we place upper limits of 100200   for equivalent widths of weak continuum sources depending on the continuum level . table 1 lists our results for class i sources ; table 2 summarizes measurements for fast spectra of t tauri stars . we include separate entries for the mmt and palomar spectra of two objects , l1489 irs and hh31 irs2 , and list the mmt results first in both cases . we estimate probable errors of @xmath610% for strong lines with ew @xmath14 10   and @xmath620% for weaker lines based on measurements of 23 separate spectra for each star in the fast sample and two stars in the mmt / palomar sample . we measure spectral types using tio absorption indices , defined as the depth of a tio band at a wavelength @xmath13 relative to an interpolated continuum point ( @xcite ) . the tio bands at @xmath136180 and @xmath137100 are temperature - sensitive for m dwarfs and giants ( @xcite ) . kenyon & fernndez - castro ( 1987 ) derive reliable spectral types for the red giant components in symbiotic stars  which also have strong emission lines and a variable blue continuum  with these features . we define :    @xmath15_1 = -2.5~log \\left ( \\frac{f_{6180}}{f_{6125 } + 0.225(f_{6370}~-~f_{6125 } ) } \\right ) \\ ] ]    and    @xmath15_2 = -2.5~log \\left ( \\frac{f_{7100}}{f_{7025 } + 0.2(f_{7400}~-~f_{7025 } ) }   \\right )   ~~ .\\ ] ]    each 30   bandpass used for these indices avoids contamination from strong emission lines and telluric absorption bands . the two tio indices increase from [ tio]@xmath16 @xmath17 [ tio]@xmath18 @xmath17 0 at k4k5 spectral types to [ tio]@xmath16 @xmath17 0.8 and [ tio]@xmath18 @xmath17 1.0 at m6 spectral types . figure 6 shows [ tio]@xmath18 as a function of [ tio]@xmath16 for normal main - sequence stars ( filled circles ) , t tauri stars with weak emission lines on fast spectra ( light triangles ) , and pre  main sequence stars with mmt or palomar spectra ( crosses and diamonds ) . the locus of t tauri stars generally follows the main - sequence stars except near [ tio]@xmath16 @xmath17 0.5 , where pre  main - sequence stars have larger [ tio]@xmath18 indices compared to main - sequence stars . main - sequence stars with mmt or palomar spectra lie on the t tauri star locus . both l1489 irs and 04303 + 2240 have featureless continua and negligible tio absorption on their spectra . other stars with strong optical continua have modest to strong tio absorption bands and must have m - type central stars . the measured tio indices indicate optical veiling in two sources with mmt or palomar spectra . the class i sources hh32 irs2 and 04158 + 2805 lie above the pre main - sequence locus in figure 6 . in both cases , the m - type absorption features for @xmath19 7400   are very strong , which suggests that the [ tio]@xmath16 index is ` weak ' compared to the [ tio]@xmath18 index . many t tauri stars with strong emission lines also have weak [ tio]@xmath16 indices . these t tauri stars have substantial emission from a blue continuum source which veils optical absorption lines ; this veiling increases towards short wavelengths in all cases ( see @xcite ) . optical veiling from a hot , @xmath20 k , continuum source probably causes the weak [ tio]@xmath16 index in hh32 irs2 and 04158 + 2805 , but our optical spectra have insufficient signal - to - noise to verify that absorption features at @xmath21 6000   are similarly weakened . we derive spectral types for class i sources and faint t tauri stars via comparison with t tauri stars of known spectral type . we adopt spectral types for bright t tauri stars from kh95 and use fast spectra to calibrate [ tio]@xmath16 and [ tio]@xmath18 as a function of spectral type . the measured tio indices for class i sources then yield the spectral types listed in table 1 . we estimate probable errors of @xmath612 subclasses for the spectral types based on measurement errors of the tio indices and the intrinsic uncertainty in assigning spectral types to bright t tauri stars .      as we noted in the introduction , powerful optical and molecular outflows distinguish class i sources from other pre  main - sequence stars in nearby dark clouds . practically all class i sources have molecular outflows ; very few optically visible t tauri stars are associated with molecular outflows ( e.g. , @xcite ) . in their complete survey of taurus class i sources , gmez ( 1997 ) show that the frequency of optical jets decreases from @xmath11 60% for class i sources to @xmath8 10% for t tauri stars . among t tauri stars , optical jet emission is almost always associated with classical t tauri stars ( ctts ) instead of weak - emission t tauri stars ( wtts ; see @xcite ; @xcite ) . near - infrared surveys also indicate more emission line activity among class i sources than ctts or wtts ( @xcite , 1996b ) . these results suggest that jet emission is correlated with disc accretion and that disc accretion somehow declines from class i sources to t tauri stars ( @xcite ; @xcite ; @xcite ) .    to examine these correlations with our spectroscopic data , we divide sources into classes based on the ratio of far - infrared to bolometric luminosity , @xmath22 ( kh95 ) . in this system , class i sources have @xmath23 , ctts have @xmath24 0.10.3 , and wtts sources have @xmath25 . we also select 14 sources in tables 12 with @xmath24 0.30.8 as flat - spectrum sources ( see also kh95 ; @xcite , 1997 ) . all of these sources have the same median luminosity , @xmath26 0.50.8 , except for the flat - spectrum which have @xmath1 1.5  ( kh95 ) . for each class , we compute the detection frequency for each of the emission lines listed in tables 12 . figure 7 shows our results for [ s  ii ] . the frequency of [ s  ii ] emission obviously increases with increasing @xmath22 . we find a similarly striking trend for [ n  ii ] emission : practically all class i sources have strong [ n  ii ] but only a few ctts or wtts have any [ n  ii ] emission . our detection frequencies for forbidden - line emission are lower limits , because we can not detect weak emission lines with ew @xmath8 0.20.4   ( see tables 12 ) . to estimate the importance of this uncertainty , we compare our results with hartigan ( 1995 ) who derive emission line equivalent widths from echelle spectra . at higher resolution , the detection frequency for [ s  ii ] emission increases to @xmath5 50% for ctts and remains unchanged at 0% for wtts . the [ n  ii ] emission shows a similar trend but is detected less often than [ s  ii ] . hartigan note , however , that the forbidden emission lines in ctts consist of high velocity material from the jet and low velocity gas near the disc . the weak , low velocity emission is responsible for the larger [ s  ii ] detection frequency among ctts in the hartigan sample . our low resolution spectra do not detect this emission and thus provide a proper estimate for the frequency of high velocity jet emission among ctts .    to check further the reality of the trend in figure 7 , we perform a simple test . we assume a parent population of @xmath27 sources with an intrinsic probability , @xmath28 , of [ s  ii ] emission . for @xmath29 observed sources , the probability of detecting [ s  ii ] emission in @xmath30 sources is given by the binomial distribution :    @xmath31    for @xmath32 . if we require @xmath33 , the allowed range in @xmath28 for a single class of pre  main - sequence star is large : @xmath34 0.13 for wtts , @xmath35 0.030.36 for ctts , @xmath35 0.240.93 for flat - spectrum sources , and @xmath35 0.331.00 for class i sources . however , the probability of realizing the observed frequency of [ s  ii ] detection for any two classes from a single parent population is extremely small . the probability that the wtts and ctts in our sample have the same parent distribution never exceeds @xmath36 ; it exceeds @xmath37 only for @xmath28 = 0.040.12 . we find no common intrinsic probability for the ctts and flat spectrum sources or for ctts and class i sources : @xmath38 is less than @xmath37 for any value of @xmath28 . the observed frequencies of [ s  ii ] emission in class i and flat spectrum sources , however , could be chosen from the same parent population for @xmath28 = 0.460.90 if @xmath39 . we derive similar results for the frequency of [ n ii ] emission . we detect the @xmath96548 , 6584 doublet in 82% of 11 class i sources , 36% of 14 flat spectrum sources , 4% of 46 ctts , and 0% of 54 wtts with reliable @xmath22 . the allowed ranges in the intrinsic probability of [ n  ii ] emission are then @xmath40 0.33 for class i sources , @xmath35 0.07 - 0.76 for flat - spectrum sources , @xmath34 0.21 for ctts , and @xmath34 0.12 for wtts . the observed detection frequencies allow a single intrinsic probability for [ n  ii ] emission between ctts and wtts for @xmath34 0.11 and between class i and flat spectrum sources for @xmath35 0.400.71 . our data do not allow a single [ n  ii ] emission probability for all sources . this result is not as strong as for the [ s  ii ] lines , because weak [ n  ii ] emission is more difficult to detect due to the strong h@xmath0 lines in many ctts .    we conclude that the increasing frequency of forbidden line emission as a function of @xmath22 is real . sources with large @xmath22 are much more likely to be associated with forbidden line emission than sources with small @xmath22 . in addition , our sample is large enough to detect a significant difference in the frequency of [ s  ii ] emission between ctts and wtts . previously published data had suggested this difference , but the data were too heterogeneous to make a firm statistical comparison . our sample is _ not _ large enough to detect a difference in the [ n  ii ] or [ s  ii ] emission frequency between class i and flat spectrum sources . adding sources to the optical sample and improved measurements of @xmath22 would allow a better discriminant between class i and flat spectrum sources . these improvements require larger ground - based telescopes and new far - ir data from either iso or sirtf . figure 8 shows an hr diagram for taurus - auriga pre main - sequence stars ( see kh95 ) . filled circles plot wtts and ctts from kh95 . crosses indicate the positions of 04158 + 2805 , hh31 irs2 , and 04489 + 3042 using our new spectral types . the triangle indicates haro 6 - 28 with a revised spectral type ( m2 ) based on fast spectra . the diamonds denote 04181 + 2655 and 04295 + 2251 using near - ir spectra from greene & lada ( 1996b ) . the relative positions of these two class i sources should be accepted with some caution , because near - ir spectral types for 04489 + 3042 ( k1-k2 ) and haro 6 - 28 ( k5-k6 ) are much earlier than our optical spectral types . although the class i sample is small , the positions of class i sources are not especially distinct from the distribution of wtts and ctts . three class i sources straddle the @xmath41 yr isochrone from the cma models of dantona & mazzitelli ( 1994 ) . two other class i sources fall midway between the @xmath42 yr and @xmath41 yr isochrones . all class i sources are within 2@xmath43 of the @xmath42 yr isochrone and the stellar `` birthline '' for spherical accretion ( @xcite , 1988 ; @xcite , 1993 ; see also kh95 ) . only haro 6 - 28 , however , lies _ on _ the stellar birthline    to compare our new data with an alternative to spherical protostellar accretion theory ( @xcite , 1988 ) , we consider the evolution of protostars accreting material from a disc . we construct a set of stellar models using the most recent version of the eggleton evolution program ( @xcite , 1972 , 1973 ) . our models assume an initially uniform composition with abundances of hydrogen @xmath44 , helium @xmath45 , deuterium @xmath46 , and metals @xmath47 appropriate for the meteoritic mixture determined by anders & grevesse ( 1989 ) . pols ( 1995 ) describe the equation of state , which includes molecular hydrogen , pressure ionization , and coulomb interactions . the nuclear reaction network includes the pp chain and the cno cycles . deuterium burning is explicitly included at temperatures too low for the pp chain . once the pp chain is active hydrogen burns to he@xmath48 with deuterium and he@xmath49 in equilibrium . the burning of he@xmath49 is not explicitly followed . we use the opacity tables of iglesias , rogers & wilson ( 1992 ) and alexander & ferguson ( 1994 ) . we adopt an eddington approximation ( @xcite ) for the surface boundary conditions at an optical depth of @xmath50 . low - temperature atmospheres , in which convection extends out as far as @xmath51 ( @xcite ) , are not modeled completely . however the effect on observable quantities is not significant ( see @xcite ) .    in these calculations , the initial protostar is a fully convective @xmath52 object with a radius of @xmath53 and an effective temperature of @xmath54 k. this starting point lies just off the right boundary of figure  8 . we add accreted material to the surface with the initial composition and with the same state ( entropy , temperature , etc . ) as the surface . in this approximation , most of the stellar surface is free to radiate normally with the boundary conditions described above . these boundary conditions are a compromise , because we are modeling a two dimensional process with a one dimensional evolution code . the solid lines in figure  8 indicate two accreting protostellar tracks using the eggleton code . the thinner line accretes at @xmath55 ; the thick line accretes at @xmath56 . initially , both stars contract at fairly constant luminosity and move to the left in the hr diagram . this contraction continues until deuterium ignites at their centers . the tracks then turn upwards to follow a deuterium burning sequence . both protostars are fully convective , so newly accreted material replenishes central deuterium . these protostars thus remain on the deuterium burning track until either accretion ceases or the rate of deuterium replenishment becomes insufficient for burning to continue to support the star . the latter occurs first , temporally , for the @xmath56 model at @xmath57k when it has reached a mass of @xmath58 . the @xmath55 model drops below the deuterium sequence at @xmath59k at a mass of @xmath60 . in both cases , we continue accretion until the total mass reaches @xmath61 . during the protostellar evolution , the stars lie close to the hayashi tracks appropriate to their instantaneous mass . if accretion ceases at any time , the star will shrink down to the main - sequence along a normal pre  main - sequence track and will ignite and burn deuterium on the way if it has not already done so .    in our accretion models , the deuterium burning sequence defines a stellar birthline in the hr diagram . previous calculations find similar results . stahler ( 1983 , 1988 ; see also @xcite , 1993 ) first identified the birthline for spherical accretion and showed that this locus provides a good upper envelope for observations of young stars in nearby molecular clouds . mercer - smith ( 1984 ) published the first hr diagram track for a disc - accreting protostar using a code similar in spirit to the eggleton code . hartmann ( 1997 ) later derived a birthline for disc accretion from semi - analytic calculations . our deuterium burning sequence lies close to stahler s ( 1983 , 1988 ) birthline for log @xmath62 3.55 and falls @xmath63 log @xmath64 0.10.2 below the birthline for log @xmath65 3.55 . the displacement reflects differences in the starting conditions and outer boundary condition . the birthlines converge at large @xmath66 , because the boundary conditions become less important as the stellar luminosity increases ( see also @xcite , 1993 ) . the location of the stellar birthline in our models is sensitive to the adopted deuterium abundance . this behavior follows from the explicit dependence of the stellar luminosity on the rate of deuterium burning ( see , for example , @xcite ; @xcite ) . our deuterium burning sequence shifts by @xmath63 log @xmath64 @xmath670.13 for a factor of two reduction in @xmath68 . our birthline then roughly coincides with that of hartmann ( 1997 ) for @xmath69 .    with only six class i sources in our hr diagram , it is difficult for the data to favor convincingly any theoretical calculation . the 2@xmath43 error bars are consistent with all of the tracks , even without considering uncertainties in the model input parameters . the data lie closer to the disc - accretion birthline of hartmann ( 1997 ) and our deuterium burning sequence than either the birthline for spherical accretion or the accretion track of mercer - smith ( 1984 ) . in all cases , changing model input parameters  such as the deuterium abundance would allow a better match between data and the models . more rigorous comparisons thus await observational estimates of unknown quantities such as the deuterium abundance and a larger sample of class i sources with reliable spectral types and luminosities . we conclude this section with several points about the comparison of observations with model tracks . first , the distribution of class i sources about _ any _ birthline should be uniform , if the range in initial conditions is small . this dispersion should be comparable to the observational errors . in our case , 5 out of 6 class i sources fall 12@xmath43 below the birthline for spherical accretion ( @xcite , 1988 ) and the mercer - smith ( 1984 ) accretion track . the data are somewhat more consistent with our deuterium burning sequence and the hartmann ( 1997 ) birthline for an accretion rate of @xmath70 . a larger sample of class i sources should distinguish between models . second , it is important to compare the _ stellar _ component of the protostellar luminosity with the predictions of model tracks . the observed class i luminosities are the _ total _ luminosity and have not been corrected for the unknown amount of accretion luminosity . in most of the ctts shown in figure 8 , the accretion luminosity is a small fraction 10% to 30%  of the stellar luminosity plotted in the figure ( see @xcite , 1995 ; @xcite ) . however , the accretion luminosity is roughly comparable to the stellar luminosity in the continuum + emission sources and is @xmath5 100 times the stellar luminosity in fu ori systems like l1551 irs5 ( @xcite ; @xcite ) . we expect a small accretion contribution for class i sources with optical spectra similar to most ctts , although the accretion luminosity in l1489 irs may be large ( see also @xcite ) . the arrow in fig . 8 indicates the displacement in log @xmath66 for a @xmath63 log @xmath71 = @xmath670.1 change in the bolometric luminosity . this change moves the data closer to both the birthline for spherical accretion and our deuterium sequence and illustrates the difficulty in comparing models with current data . third , knowledge of the deuterium abundance , and to a lesser extent the lithium abundance , is also necessary to compare observations with model predictions . the mean deuterium abundance for stars in a molecular cloud sets the location of the birthline in the hr diagram ; any star - to - star scatter in the abundance spreads the birthline vertically in the hr diagram . to our knowledge , the deuterium abundance has not been measured in any pre main - sequence star . recent measurements indicate a factor of 35 scatter in the lithium abundance among nearby molecular clouds ( e.g. , @xcite ; @xcite ; @xcite ) that could be due actual abundance differences between stars ( see @xcite ) or differences in the analysis procedures ( see @xcite and references therein ) . observations of older open clusters may also indicate considerable star - to - star differences in the rate of lithium depletion among stars with the same mass ( e.g. , @xcite and references therein ) . similar spreads in the deuterium burning rate , due perhaps to star - to - star variations in accretion rate , further complicates the comparison of observations with model tracks . the sample of protostars is not currently large enough to worry about abundance variations , but the uncertainties will become more important as sample sizes increase . in the previous sections , we have described the first optical spectroscopic survey of class i , embedded sources in a single molecular cloud . we supplemented these data with high quality optical spectra of a representative sample of older and optically brighter t tauri stars . the combined set of spectra show that the optical spectra of class i sources qualitatively resemble the optical spectra of t tauri stars . our analysis further reveals common physical properties and substantial differences between class i sources and t tauri stars , as summarized below . our data provide the first indication that the distribution of stellar spectral types among class i sources may not be very different from that of wtts and ctts . of the five class i sources with strong optical continua , one ( l1489 irs ) is a continuum + emission source , three are m - type stars , and another ( 04264 + 2433 ) may have an m - type central star . to the best of our knowledge , _ these are the first low mass protostars with measured optical spectral types . _ this sample is too small for a meaningful comparison with the distribution of spectral types among more evolved pre main - sequence stars in the cloud . we note , however , that the median spectral type for wtts and ctts is k7-m0 and that the frequency of continuum + emission sources is @xmath5 5%10% ( kh95 ) . published observations indicate other similarities between class i sources and older pre  main - sequence stars in taurus - auriga . first , class i sources have the same intrinsic near - ir colors as do ctts . whitney ( 1997 ) show that the observed near - ir colors of class i sources can be modeled as a ctts surrounded by an infalling envelope with an optical extinction , @xmath2 3060 mag . this analysis leads to the conclusion that the radiation from the star and inner disc of a class i source is similar to that of a t tauri star ( see also @xcite ; calvet 1997 reach a different conclusion ) . second , the bolometric luminosity distributions of class i sources , ctts , and wtts are indistinguishable ( kh95 ) . all three groups of pre  main - sequence stars have median luminosities of @xmath72 0.50.8 . this unexpected result is supported by the positions of class i sources in the hr diagram . our data show that class i sources have luminosities and effective temperatures very similar to those of ctts and wtts in the cloud . these conclusions are surprising , because a class i source should have a larger luminosity once it has accreted nearly all of its final mass , and this luminosity should decline with time as the star approaches the main sequence ( see , for example , @xcite , 1988 ; @xcite ; @xcite ; fig . 8) . the current sample , however , is too small to test stellar models in detail . the errors in luminosity and effective temperature are also too large . observations with the next generation of ground - based telescopes will undoubtedly expand the sample , reduce the errors , and provide better tests of protostellar accretion theory . one feature that distinguishes class i sources is their strong forbidden - line emission . as a group , class i sources are much more likely to have forbidden - line emission than ctts or wtts ( fig . 7 ) . this result confirms previous conclusions from imaging data ( e.g. , @xcite ) and indicates that class i sources are more likely to drive outflows than ctts or wtts ( see also @xcite ; @xcite , 1994 ) . the equivalent widths of the forbidden lines are also larger in class i sources than in ctts or wtts . although some large equivalent widths may be due to very weak optical continua , the [ s  ii ] equivalent widths in hh31 irs2  a class i source with a prominent tio absorption band  are larger than observed in _ any _ ctts in our sample ( see tables 12 ) . deeper optical spectra of our sample and other class i sources would clarify this point . our sample is not large enough to test whether class i sources also have more prominent _ permitted _ emission lines than ctts . the median h@xmath0 equivalent width for class i sources , @xmath5 90  , is much larger than the median equivalent width for ctts , @xmath5 3040  . this difference is roughly what we expect if class i sources have larger continuum veiling than ctts ( @xcite ; @xcite ) and if the h@xmath0 equivalent width correlates with veiling ( @xcite and references therein ) . however , the frequency of he  i @xmath95876 , 6678 emission among class i sources is roughly comparable to that among ctts . we measure a he  i emission frequency of 50% among 6 class i sources with reasonable signal - to - noise at 6000  , 57% among 14 flat - spectrum sources , and 65% among 46 class ii sources . for both emission lines , the class i sample is probably biased against small equivalent widths , because class i sources without emission lines are probably fainter than sources with emission lines . a deeper survey with a larger telescope could enlarge the sample of class i sources with high quality optical spectra . these data would provide a good test for differences in the distribution of h@xmath0 equivalent widths between class i sources and ctts . these results fit into the general picture of taurus - auriga class i sources developed in kh95 and in kenyon ( 1990 ) . in this picture , class i sources are envelopes of gas and dust falling into the central star - disc system at rates of a few @xmath73 ( see also @xcite ; @xcite , 1993b ; @xcite ) . bell & lin ( 1994 ) show that the stable accretion rate through the disc onto the central star is either very low @xmath8 a few @xmath74  or very high @xmath11 a few @xmath75  compared to the infall rate . the disc spends most of its time in the low accretion rate state ; the disc mass then slowly increases with time until it reaches a critical level and evolves to the high accretion rate state . this model explains the low observed luminosities of nearly all class i sources as well as the occasional high luminosity of a source such as l1551 irs5 . models with time - dependent disc accretion also qualitatively account for the evolution of forbidden and permitted emission lines in pre  main - sequence stars . we expect the time - averaged accretion rate through the disc to decline as the envelope disperses . if the h@xmath0 and other permitted emission lines of class i sources form in the accretion region of the inner disc as in ctts , then the median h@xmath0 equivalent width should decline as a pre  main sequence star evolves from a class i source into a ctts and then into a wtts . most models for jet formation link the mass loss rate in the jet to the mass accretion rate through the disc ( see , for example , @xcite ; @xcite ; @xcite , 1994b ) , so we expect forbidden emission to decline as well . explaining the observations of emission line equivalent widths with a quantitative model of a dispersing envelope and evolving disc , however , is currently beyond our reach . finally , our results further demonstrate the advantages of optical spectra . recent surveys of larger samples of class i sources using near - ir spectroscopy have yielded only two spectral types each in taurus - auriga ( @xcite ; @xcite ) and @xmath76 oph ( @xcite , 1997 ) . casali & eiroa ( 1996 ; see also @xcite ; @xcite , 1997 ) conclude that continuum emission from dust in a circumstellar disc or envelope veils photospheric absorption features on near - ir spectra of class i sources . preliminary results further suggest that this veiling is larger in class i sources than in ctts or wtts ( @xcite ; @xcite , 1997 ) . dust emission is much weaker relative to a normal stellar photosphere at shorter wavelengths , @xmath77 m , so optical spectra may yet provide the best measure of spectral types in class i sources . 6ex we thank the staffs of the mmt , palomar , and whipple observatories for assistance with our observations . fred chaffee kindly acquired several spectra of the class ii sources listed in table 1 . susan tokarz reduced the fast spectra and graciously assisted with the reduction of the mmt and palomar spectra . we also thank m. geller , m. gmez , c. lada , a. mahdavi , and b. whitney for advice and comments . the suggestions of an anonymous referee improved our presentation . observations at the palomar observatory were made as part of a continuing collaborative agreement between palomar observatory and the jet propulsion laboratory . portions of this research were supported by the national aeronautics and space administration through grant nagw-2919 and by the space telescope science institute through grant go-06132.01 - 94a . thanks the royal society and the hungarian academy of sciences for an exchange fellowship during the majority of his contribution to this project .", "tags": [], "output_text_a": "This paper presents an optical spectroscopic survey of Class I protostars in the Taurus-Auriga molecular cloud, aiming to detect photospheric absorption features from these deeply embedded objects. Class I sources are characterized by blackbody-like spectral energy distributions and significant bolometric luminosities. The study addresses the challenge of understanding the stellar physics of these young stars, which has been elusive due to the lack of photospheric features in many objects. The authors propose using bolometric temperature, submillimeter flux, and visual extinction as alternatives to effective temperature for placing pre-main-sequence stars in evolutionary diagrams.\n\nThe survey successfully detects M-type absorption features in several Class I sources, marking the first optical detection of such features in embedded protostars. The study finds that Class I sources in Taurus-Auriga share similarities with T Tauri stars, lying below the birthline in the HR diagram. The presence of strong emission lines, particularly forbidden lines like [N II] and [S II], is more common in Class I sources compared to older stars, suggesting a decline in jet activity as stars evolve towards the main sequence.\n\nThe paper also explores the correlation between forbidden line emission and the ratio of far-infrared to bolometric luminosity, finding that sources with higher ratios are more likely to exhibit such emissions. The authors compare their observations with theoretical models of protostellar evolution, including those involving accretion from discs, and discuss the implications for understanding the early stages of stellar evolution.\n\nOverall, the study highlights the potential of optical spectra in providing insights into the spectral types and evolutionary status of Class I protostars, despite the challenges posed by veiling from circumstellar material. The findings contribute to the broader understanding of the transition from protostars to T Tauri stars and the role of accretion and outflows in this process. The authors call for further observations with larger telescopes and improved data to refine these conclusions and better test theoretical models.", "output_text_b": "This arXiv paper reports an optical spectroscopic survey of Class I sources in the Taurus-Auriga cloud. The survey aimed to detect photospheric absorption features from the central stars of these objects, which are deeply embedded in dense cores of nearby molecular clouds. The authors identified TiO absorption bands in three Taurus-Auriga Class I sources and detected possible TiO features in another star, as well as potential K-type absorption features in a fifth star. These detections provide the first optical detection of M-type absorption features in an embedded protostar.\n\nThe authors used optical spectra of T Tauri stars to calibrate the spectral types of Class I sources and constructed a complete Hertzsprung-Russell (HR) diagram for the Taurus-Auriga cloud. The data, combined with new evolutionary tracks for protostars accreting from discs and spectral types derived from near-IR spectra, show that Class I sources in Taurus-Auriga mingle with T Tauri stars and lie below the birthline in the HR diagram.\n\nThe authors also detected strong emission lines on the spectra of all protostars. Forbidden emission from [N II] and [S II] is much more common among Class I sources than older, optically brighter stars having the same bolometric luminosity. The fluxes of forbidden emission lines also seem stronger among Class I sources than other pre-main-sequence stars in the cloud. These results support previous conclusions that jet activity declines as a pre-main-sequence star contracts to the main sequence.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the optical spectroscopic survey of Class I protostars, the detection of M-type absorption features, and the comparison with T Tauri stars.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of understanding the stellar physics of young stars and the lack of photospheric features.\n4. The methodology of using optical spectroscopic surveys is mentioned.\n5. Significant results, such as the detection of M-type absorption features and the correlation between forbidden line emission and luminosity ratios, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Class I sources\" and \"HR diagram\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the optical spectroscopic survey, are mentioned.\n10. The summary reflects the paper's significance in understanding the transition from protostars to T Tauri stars and the role of accretion and outflows.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, including the detection of TiO absorption bands and the construction of an HR diagram.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of detecting photospheric absorption features in Class I sources.\n4. **Methodology**: The summary mentions the use of optical spectroscopic surveys and the calibration of spectral types using T Tauri stars.\n5. **Significant Results**: The summary includes significant results, such as the detection of strong emission lines and the positioning of Class I sources in the HR diagram.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"TiO absorption bands\" and \"HR diagram.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions the key experiment of optical spectroscopic surveys and the data used for constructing the HR diagram.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding the evolution of protostars and their emission characteristics."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the idea that quantum mechanical systems can efficiently simulate physical systems @xcite is at the heart of the theory of quantum information and computation . deutsch @xcite constructed the first example of an algorithm which would require two queries to solve on a classical computer but that can be solved with only one quantum query . subsequently , deutsch and jozsa @xcite , bernstein and vazirani @xcite and simon @xcite demonstrated the striking difference between the classical and quantum query complexity . this culminated with grover s search algorithm @xcite achieving a quadratic speedup over any classical algorithm for the unstructured search problem along with shor s factoring algorithm @xcite that could factor integers efficiently and also calculate discrete logarithms . grover s algorithm gives an optimal solution to the unstructured search problem , the problem of deciding whether a black - box boolean function has any input that evaluates to 1 . it provides a quadratic temporal speedup over the best classical search algorithms , even when they both require the same spatial resources to perform the search task . zalka @xcite proved the optimality of the grover search algorithm . grover s algorithm was subsequently generalized to the framework of amplitude amplification and to counting the number of solutions by brassard _ grover s search algorithm has since been applied to a wide variety of similar problems @xcite@xcite@xcite . the usual paradigm of computation ( quantum or classical ) is defined in a discrete setting . however , adiabatic quantum computation @xcite provides a continuous time model for quantum computing by using the quantum adiabatic theorem . here , one begins by finding an appropriate hamiltonian whose ground state describes the solution to the problem of interest . next , a system with a simple hamiltonian is prepared and initialized to the ground state . finally , the simple hamiltonian is adiabatically evolved to the desired hamiltonian . by the quantum adiabatic theorem , the system remains in the ground state at all times during this adiabatic evolution , depending on the spectral properties of the hamiltonian @xcite@xcite . at the end , the final state of the system describes the solution to the problem . the time complexity for an adiabatic algorithm is simply defined as the time taken to complete the adiabatic evolution , which is known to depend on the spectral gap of the hamiltonian @xcite . the adiabatic model of quantum computing is universal and equivalent to standard quantum computation @xcite . farhi and gutmann were the first to construct an analog algorithm for solving the grover search problem @xcite referred to hereafter as the _ analog analogue of grover search algorithm _ or simply the _ analog grover search algorithm_.    it is understood that the speedup in quantum algorithms comes from quantum mechanical features like quantum coherence and quantum correlations like quantum entanglement , that exist amongst the qubits . quantum correlations , especially quantum entanglement , is one of the crucial resources in quantum information theory and has been studied extensively @xcite . the indispensable role of entanglement in quantum information processing tasks such as quantum teleportation @xcite , superdense coding @xcite and remote state preparation @xcite @xcite , etc . has been quantified and understood deeply . however , despite showing that quantum entanglement is _ necessary _ for the pure state implementation of grover search @xcite @xcite and shor s factoring algorithm @xcite , the innate role of entanglement is not clear for general quantum computing tasks . one of the fundamental attributes of quantum systems is their ability to exist in linear superpositions of different physical states . this physical phenomenon is called quantum superposition . quantum coherence arises from superposition and is at the heart of several quantum features like quantum interference , multiparticle entanglement @xcite , quantum biology @xcite @xcite @xcite , quantum thermodynamics @xcite @xcite @xcite @xcite , quantum game theory @xcite @xcite @xcite etc . , which in turn are some of the most important applications of quantum physics and quantum information science . inspired from the resource theory of entanglement @xcite @xcite , there has been a lot of effort recently to quantify coherence as a resource theory @xcite . the role of coherence in the deutsch - jozsa algorithm has also been explored recently @xcite . in a standard resource - theoretic treatment of coherence , the `` incoherent '' states are those that are diagonal in some fixed reference basis . the amount of coherence is then defined as the distance from these reference states . a ` coherence measure ' is a real - valued function over the quantum state - space , such that it vanishes for all the states that are deemed to be incoherent and can not increase under some class of operations that preserve incoherence .    in this paper , we quantitatively analyze the role of quantum coherence and monogamy of entanglement @xcite @xcite in the discrete analogue of the analog grover search algorithm . to quantify the dynamics of coherence in this analog grover search , we use two coherence monotones namely the @xmath1-norm and the relative entropy of coherence @xcite . we then discretize the analog grover search algorithm to study how the monogamy of quantum entanglement evolves parallel to the system s adiabatic evolution . we use an entanglement monotone called the concurrence  @xcite to study the same . we find that the amount of coherence ( as quantified by the coherence measures ) is non - zero at all times during the search . the only time this coherence goes to zero is when the search algorithm attains the maximum success probability equal to one . since we begin with a maximally coherent state , in a resource theoretic sense , @xmath0-maximal coherence is actually consumed during the quantum search . using coherence monotones , we relate the success probability of the search algorithm with the amount of coherence . further , during the analog search , the final state is a product state and so all entanglement monotones must go to zero at the end of the search algorithm . the bipartite entanglement entropy , concurrence and the monogamy score , all behave in accord with this , since for both qubit partitions , these measures of quantum correlations go to zero and mark the completion of the search algorithm . furthermore , the two qubit concurrence and the monogamy score peak simultaneously with the increasing rate of success probability , hence implying that entanglement monogamy is indeed satisfied for the discrete analogue of the analog analogue of grover search algorithm . the paper is organized as follows . in sec . [ sec : review ] , we review the analog grover search algorithm . in sec . [ sec : coherence ] , we use the two coherence monotones to calculate the dynamics of coherence and elucidate their behavior . we also define the mapping through which we discretize the analog grover search algorithm . in sec . [ sec : entanglement ] , we explore the entanglement entropy and the concurrence , and demonstrate the synonymous behavior between the rate of change of concurrence in the continuous and the discrete grover search . in the next section , we calculate the two - qubit concurrence and show its connection to the success probability of the search algorithm . we then use the monogamy inequality to bound the bipartite entanglement at all times during the search . we conclude our paper with the discussions in sec . [ sec : conclusion ] . adiabatic quantum computation can be described as a controlled hamiltonian evolution of a system obeying the schrdinger equation @xmath2 we briefly recapitulate the analog analogue of grover search algorithm  @xcite , where the problem is to use quantum evolution to find a marked state among @xmath3 orthonormal states . + imagine that we are given a hamiltonian in an @xmath3 dimensional hilbert space such that it has only one non - zero eigenvalue , @xmath4 . the task then is to find the corresponding eigenvector @xmath5 which has eigenvalue @xmath6 . the hamiltonian can be represented as @xmath7 with @xmath5 unknown and normalized , i.e. , @xmath8 . now we choose some normalized vector @xmath9 , which is independent of @xmath5 ( since we do not know what @xmath5 is yet ) . we then add to @xmath10 , the  driving \" hamiltonian @xcite @xmath11 so that the full hamiltonian is given by @xmath12 now , starting from the initial state @xmath9 at @xmath13 , we calculate the time evolution of the state @xmath14 . since the total hamiltonian is time - independent , we can simply write the time evolved state as @xmath15 we work in the units @xmath16 . it suffices to confine our attention to the two dimensional subspace spanned by @xmath9 and @xmath17 . the vectors @xmath9 and @xmath17 are not orthogonal ( in general ) and let us denote their inner product as @xmath18 , i.e. , @xmath19 , where @xmath18 can be taken to be real and positive since any phase in the inner product @xmath20 can be absorbed in @xmath9 . now the vectors @xmath21 and @xmath17 are orthonormal . in the \\{@xmath17 , @xmath22 } basis , the hamiltonian is given by @xmath23\\ ] ] and @xmath24.\\ ] ] now the state of the system at time @xmath25 is found to be @xmath26 .\\ ] ] thus , we can see that at time @xmath25 , the probability of finding the state @xmath17 is given by @xmath27 and the probability is one at time @xmath28 given by @xmath29 the inner product between the vectors @xmath17 and @xmath9 ( defined as _ x _ above ) , is assumed to be non - zero , else it will take infinite time for the quantum search to complete . this analog model has been generalized further . for example , the same algorithm was recast in the form of a spatial lattice search problem @xcite , where there is an @xmath3-dimensional lattice and the basis state @xmath30 is localized at the @xmath31th lattice site . the on - site potential energy , @xmath6 is zero everywhere except at @xmath32 , where it takes the value 1 . the objective is same as before , to reach the marked state @xmath32 starting from an equal superposition of all the @xmath33 s . the kinetic term is formulated through the laplacian of the lattice , which effectively introduces uniform hopping to all the nearest neighbors from any given lattice site , and is kept constant . our results will also hold in these generalized models . quantum coherence is one of the salient features of the quantum world . as this crucial feature drives several quantum technologies , it is very desirable to quantify the usefulness of coherence as a resource . this is done using the mathematical framework called a ` resource theory ' . to characterize something as a resource , we must first impose certain constraints on what specific physical operations are allowed ( e.g. the local operations and classical communication(locc ) framework for quantum entanglement @xcite restricts one from performing joint quantum operations between distant laboratories ) , which define the freely accessible operations . to be able to execute general quantum operations under such a constraint then requires some `` special '' quantum states that contain a relevant resource ( e.g. entangled states ) and can be consumed in the process . in fact , a quantitative resource theory for entanglement is already in place @xcite @xcite and has later expanded to encompass a wider range of operational phenomenon @xcite @xcite . however , for a long time there did not exist a resource theoretic framework to quantify the physical aspects of coherence . coherence was often defined in terms of functions of the off - diagonal entries of a density matrix , and the definition justified on the basis of physical intuition , which in turn also lead to the idea of decoherence developing along similar lines @xcite . eventually , in 2014 , baumgratz _ et al_. @xcite defined a resource theory of coherence and rigorously quantified the role of coherence in close analogy to the resource theory of entanglement . let us formally introduce the measures of coherence in the framework of a resource theory that is based on the set of incoherent operations and incoherent states @xcite . coherence is a basis dependent property and hence first , we must fix a _ reference basis_. the choice of the reference basis may be dictated by the underlying physics of the problem ( say the energy eigenbasis ) or the task to be performed ( wherever we wish to use quantum coherence ) . let \\{@xmath34 } be a basis for @xmath35 , a @xmath36-dimensional hilbert space . the set of all density matrices that are diaogonal in this chosen basis form the so called `` incoherent states '' . the set of all the states of the form @xmath37 , where @xmath38 and @xmath39 , forms the set @xmath40 of all incoherent states . any quantum state that does not belong to the set @xmath40 will be called a coherent state and will act as a resource . a maximally coherent state in this basis is then given by @xmath41 , as any other state can be created from @xmath42 using only the set of ` incoherent operations ' . et al_. @xcite define incoherent operations as the set of trace preserving completely positive maps @xmath43 admitting a set of kraus operators @xmath44 @xcite such that @xmath45 ( trace preservation ) and , for all @xmath0 and @xmath46 , @xmath47 } \\in \\mathcal{i}.\\ ] ] the definition of the set of incoherent operations is not unique and so we redirect the reader to a recent review for further discussions @xcite . we shall use two coherence monotones introduced in @xcite , namely , the @xmath1-norm of coherence and the relative entropy of coherence .    given a density matrix @xmath48 for the system , the @xmath1-norm of coherence is defined as @xmath49    for the analog grover search , the @xmath1-norm of coherence for the state given in eq . ( [ eqn : wavefunction ] ) is found to be    @xmath50    similarly , the relative entropy of coherence is given by @xmath51 which is found to be    & _ r ( ) = - ( 1 - x^2 ) ^2(e x t ) _ 2 ( ( 1- x^2 ) ^2(e x t ) ) & + & -(x^2 ^2(e x t)+^2(e x t ) ) _ 2 ( x^2 ^2(e x t)+^2(e x t ) ) . & -norm , the relative entropy of coherence and the probability of success as a function of time at parameter values @xmath52 and @xmath18 = 0.707 . ] the @xmath1-norm of coherence has a closed form expression in terms of the probability of success given by , @xmath53 where the form of @xmath54 is given in eq . ( [ eqn : successprobability ] ) . similarly , the relative entropy of coherence expressed in terms of the probability of success takes the form of a binary entropy function , i.e. , @xmath55    it can be observed analytically from eq . ( [ eqn : l1intermsofp ] ) and eq . ( [ eqn : relintermsofp ] ) and numerically from the fig . [ fig : relcoherence ] that both coherence measures go to zero _ iff _ the probability of success peaks to one , hence acting as a clear signature for the success of the search algorithm . even for other general initial states ( i.e. , with a different value of @xmath18 ) , after evolving under the analog grover search hamiltonian , the coherence attains a minima as the success probability peaks to 1 . note that although @xmath56 would also imply both coherence measures going to zero as can be observed from eq . ( [ eqn : l1intermsofp ] ) and eq . ( [ eqn : relintermsofp ] ) , the probability of success can not be zero since that would require @xmath18 to be zero ( which is excluded else the search would take infinite time to complete , see eq . ( [ eqn : time ] ) ) .      to quantify coherence in the analog grover search algorithm , we consider a mapping through which the @xmath3 eigenstates of the system are mapped to the logical states of @xmath0 qubits ( where @xmath57 ) . the hamiltonian initially acting on the state @xmath58 of the system now acts on the @xmath0 qubit system . throughout this paper , we refer to this mapping between the @xmath3 eigenstates and the @xmath0 qubits as the _ discrete analogue of analog grover search algorithm_. + now , consider the initial state to be an equal superposition of all the basis states , i.e. , + @xmath59 and the final state @xmath17 is one of the orthonormal basis states . the @xmath60 can be expressed in the \\{@xmath61 } basis as @xmath62 where @xmath63 , @xmath64 and @xmath65 . + therefore , the density matrix in the \\{@xmath61 } basis is @xmath66    after discretizing the analog grover search , the @xmath1-norm of coherence for the density matrix in eq . ( [ eqn : densitymatrix ] ) is analytically calculated to be    @xmath67    similarly the relative entropy of coherence is calculated to be    @xmath68    the @xmath1-norm and the relative entropy of coherence display a similar behavior as before , and it is important to note that the initial state for the analog grover search algorithm is an equal superposition of all orthonormal basis states , i.e. , @xmath69 which corresponds to a maximally coherent state in this eigenbasis . however , at time @xmath70 ( which is the time at which the search algorithm succeeds ) , the coherence is reduced to zero . this implies that maximally coherent states are actually consumed during the search algorithm . entanglement entropy is a measure of entanglement for many body quantum states . bipartite entanglement entropy is defined with respect to a bipartition of a state into two parts say @xmath71 and @xmath72 . for this , consider a quantum system whose hilbert space @xmath73 . the bipartite entanglement entropy @xmath74 of a state @xmath75 is defined as the von neumann entropy of either of its reduced states . that is , for a pure state @xmath76 , the entanglement entropy is given by + @xmath77 +   + where @xmath78 and @xmath79 are the reduced density matrices for each partition . the von neumann entanglement entropy in the eigenbasis is defined as @xmath80    it is easier to quantify the role of entanglement in the original grover search due to its discrete nature , however it is not so in the analog version . therefore , we use the discrete mapping to calculate the entanglement entropy for the analog grover search . we partition the @xmath0 qubit state into one qubit ( say @xmath81 ) vs the other @xmath82 qubits . the reduced density matrix for the @xmath81th qubit , @xmath83 is obtained by tracing out the other @xmath84 qubits and is given as    @xmath85    the eigenvalues of the matrix , @xmath86 are given by @xmath87 from which one can find the @xmath88 . concurrence is an entanglement measure , which for the special case of a pair of qubits is closely related to the entanglement of formation @xcite . for an arbitrary two qubit density matrix @xmath48 , concurrence is defined as follows : we first define a `` spin - flipped '' density matrix , @xmath89 as @xmath90 where @xmath91 is the pauli matrix @xmath92 . then we calculate the square root of the eigenvalues of the matrix ( @xmath93 ) and arrange them in decreasing order ( say @xmath94,@xmath95,@xmath96,@xmath97 ) . the concurrence is then defined as @xmath98 for pure states , the concurrence is also defined via another quantity known as the `` tangle '' , where @xmath99 and the @xmath100 = @xmath101 . concurrence for the pure state ( in eq.([eqn : wavefunction ] ) ) across the bipartition @xmath102 is found to be @xmath103    ) and the probability of success as a function of time at parameter values @xmath52 and @xmath104 . ] the entanglement entropy and concurrence across the system partition of @xmath102 are calculated analytically and their variation with time along with the probability of success is shown in fig . [ fig : entanglement ] . note that both entanglement measures go to zero as the success probability peaks to 1 . rate of change of the concurrence with time is found to be @xmath105    one can see that @xmath106 by neglecting o(@xmath107 ) terms for n @xmath108 1 . therefore , for a large database size ( n @xmath108 1 ) , the rate of concurrence goes to zero , hence implying that a very small amount of entanglement is generated during the search process . [ fig : dcbydt ] shows the analogous rate of change between the discrete and the continuous grover search and suggests that the mapping chosen in subsection [ sec : mapping ] preserves the properties of the original grover search algorithm . +      the amount of quantum correlations that can be shared amongst the subsystems of a multipartite quantum state is captured by the idea of monogamy . the central idea of monogamy is that entanglement can not be freely shared . precisely put , _ if two qubits a and b are maximally entangled then they can not be entangled at all with a third qubit c _ @xcite .    for the tripartite case , if @xmath109 is a bipartite quantum correlation measure , then this measure is said to be monogamous ( or satisfy monogamy ) for a tripartite quantum state @xmath110 , if the following condition holds @xmath111 here @xmath112 is the quantum correlation ( with respect to the correlation measure @xmath113 ) between subsystems @xmath71 and @xmath72 , @xmath114 is the quantum correlation between subsystems @xmath71 and @xmath115 , and @xmath116 is quantum correlation between subsystem @xmath71 and subsystems @xmath72 and @xmath115 taken together . for example , if we have a three - qubit pure state @xmath117 and a quantum correlation measure say concurrence then it is known that @xmath118 even though @xmath119 is a two qubit subsystem with a four dimensional subspace , it can be shown that the support of @xmath120 is spanned by the eigenvectors corresponding to _ at most _ two non - zero eigenvalues of the reduced density matrix @xmath120 , and hence it effectively becomes a two - dimensional space . this allows one to treat the bipartition of @xmath71 and @xmath119 as an effective two - qubit system whose concurrence , @xmath121 , is simply given by @xmath122 . substituting the value of @xmath121 above , we get the coffman , kundu , wootters ( ckw ) inequality @xcite @xmath123 which suggests that the concurrence is a monogamous entanglement measure . + this also leads to the concept of quantum monogamy score , which , for a given bipartite quantum correlation measure , is defined as @xmath124 if a tripartite state satisfies entanglement monogamy then its monogamy score is positive or else it is negative . + another measure of bipartite entanglement is the entanglement of formation ( eof)@xcite , which is closely related to two - qubit concurrence . consider a bipartite quantum state @xmath125 , and the ensemble @xmath126 denoting a possible pure state decomposition of @xmath125 , satisfying @xmath127 . the eof is defined as @xmath128 where @xmath129 is the von neumann entropy of the reduced density matrix corresponding to the @xmath71 subsystem of @xmath125 . for a two - qubit mixed state @xmath125 , @xmath130 , where @xmath131 is the binary entropy function . the eof , being a concave function of squared concurrence , does not obey the ckw inequality . however , the square of the eof does obey the same relation as the squared concurrence for tripartite systems @xcite . the discrete analogue of analog grover search algorithm satisfies the squared concurrence monogamy calculated as @xmath132    the reduced density matrix for two qubits is calculated by tracing out the @xmath133 qubits    @xmath134    the concurrence of an arbitrary two - qubit state is calculated according to the formula in subsection [ subsec : concurrence ] , using the spin flipped qubit . the eigenvalues for the density matrix @xmath93 ( i.e , the density matrix obtained after multiplying with the spin - flipped qubit for @xmath125 ) are +   + @xmath135 , @xmath136 , @xmath137 and @xmath138 . therefore , the two qubit concurrence is given by    @xmath139    this is the pairwise entanglement in the analog grover search . the evolution of the pairwise entanglement is calculated numerically and the result is shown in fig . [ fig : concurrenceandrate ] along with the rate of success probability in the search algorithm . the two peak simultaneously suggesting that entanglement is indeed necessary for the discrete analogue of analog grover search algorithm . for the multipartite system , in particular , the pairwise entanglement sharing and other pairwise correlations are monogamous ; when @xmath0 tends to infinity all of the pairwise entanglement vanishes as seen from eq . ( [ eqn : twoqubitconc ] ) .    ) and the rate of success probability as a function of time at parameter values @xmath52 and @xmath104 . ]    since in the analog grover search case , the concurrence between any two pair of qubits is the same , i.e. , @xmath140 ; as a result , the monogamy score between the @xmath0 qubits reduces to the following @xmath141    the monogamy score is , thus , given by @xmath142     and @xmath3 = 32 . ] similarly , the squared entanglement of formation satisfies a monogamy inequality . we do not provide the expression for this as it is simply too long . monogamy inequality bounds the amount of pairwise entanglement that can be shared between multiple qubits , and we can see that the discrete analog of grover search algorithm satisfies two monogamy inequalities for arbitrary times . to summarize , in this paper we have explored the role of quantum coherence and monogamy of entanglement in the discrete analogue of the analog analogue of grover search algorithm . using the @xmath1-norm and the relative entropy of coherence , it was shown that coherence acts as a signature for the success of the analog grover search algorithm . it was also shown that a maximally coherent state ends up into an incoherent state as the search algorithm evolves and hence @xmath0-maximal coherence is actually consumed during the search process . the variation of entanglement was also quantified and the analogous rate of change of concurrence between the discrete and analog grover search algorithms suggests that our mapping preserves the original behavior of the algorithm . the pairwise entanglement was shown to peak simultaneously with the rate of success probability as evidence that entanglement is indeed necessary , for the pure state implementation of analog grover search algorithm . the pairwise entanglement also suggested a monogamous behavior of quantum correlations in the analog grover search and it is then shown that the discrete analogue of analog grover search satisfies the entanglement monogamy inequality for both entanglement measures namely the concurrence and the squared entanglement of formation , for all times during the search algorithm . + note : after the completion of this work , the authors noticed the paper @xcite , where similar results about coherence have been obtained independently by hai - long shi , si - yuan liu , xiao - hui wang , wen - li yang , zhan - ying yang and heng fan . namit anand would like to acknowledge the hospitality of the harish - chandra research institute for allowing him to use their facilities during several visits made as a summer student over the last year during the preparation of this manuscript . 100 r. p. feynman , int . * 21 * , 467 ( 1982 ) . d. deutsch , proc . london a * 400 * , 97 ( 1985 ) . d. deutsch and r. jozsa , proc . london a * 439 * , 553 ( 1992 ) e. bernstein and u. vazirani , siam j. comput . * 26*(5 ) , 1411 ( 1997 ) . d. simon , siam j. comput . * 26*(5 ) , 1474 ( 1997 ) . l. grover , phys . lett . * 79 * , 325 ( 1997 ) . p. shor , siam j. comput . * 26*(5 ) , 1484 ( 1997 ) . c. zalka , phys . rev . a * 60 * , 2746 ( 1999 ) . g. brassard , p. hyer , m. mosca , and a. tapp , in _ quantum computation and information _ , ams contemporary mathematics series vol . * 305 * , 53 ( 2002 ) . g. brassard , p. hyer , and a. tapp , sigact news * 28 * , 14 ( 1997 ) . c. drr , m. heiligman , p. hoyer , and m. mhalla , siam j. comput . * 35 * , 1310 ( 2006 ) . a. ambainis and r. palek , symposium on theoretical aspects of computer science , lecture notes in computer science vol . * 3884 * ( springer , berlin ) , 172 ( 2006 ) . e. farhi , j. goldstone , s. gutmann , and m. sipser , https://arxiv.org/abs/quant-ph/0001106[arxiv:quant-ph/0001106 ] . m. born and v. fock , zeitschrift fr physik * 51 * , 165 ( 1928 ) . s. jansen , m. ruskai , and r. seiler , j. math . phys . * 48 * , 102111 ( 2007 ) . d. aharonov , w. dam , j. kempe , z. landau , s. lloyd , and o. regev , siam j. comput . * 37*(1 ) , 166 ( 2007 ) . e. farhi and s. gutmann , phys . a * 57 * , 2403 ( 1998 ) . r. horodecki , p. horodecki , m. horodecki , and k. horodecki , rev . * 81 * , 865 ( 2009 ) . c. bennett , g. brassard , c. crpeau , r. jozsa , a. peres , and w. wootters , phys . * 70 * , 1895 ( 1993 ) . c. bennett and s. wiesner , phys . lett . * 69 * , 2881 ( 1992 ) . a. k. pati , phys . a * 63 * , 014302 ( 2000 ) . c. bennett , d. divincenzo , p. shor , j. smolin , b. terhal , and w. wootters , phys . * 87 * , 077902 ( 2001 ) . s. l. braunstein and a. k. pati , quant . info . comput . * 2 * , 399 ( 2002 ) . a. k. pati and s. l. braunstein , j. of indian inst . of sci . , * 89 * , 295 ( 2009 ) . a. ekert and r. jozsa , rev . phys . * 68 * , 733 ( 1996 ) . d. meyer and n. wallach , j. math . phys . * 43 * , 4273 ( 2002 ) . n. lambert , y. chen , y. cheng , c. li , g. chen , and f. nori , nat . phys . * 9 * , 10 ( 2013 ) . d. abbott , p. davies , and a. k. pati , quantum aspects of life , imperial college press , london , ( 2008 ) . s. huelga and m. plenio , contemp . * 54 * , 181 ( 2013 ) . j. goold , m. huber , a. riera , l. rio , and p. skrzypczyk , j. phys . a : math . theor . * 49 * , 143001 ( 2016 ) . g. gour , m. mller , v. narasimhachar , r. spekkens , and n. yunger halpern , phys . , * 583 * , 1 ( 2015 ) . d. janzing , int . . phys . * 39 * , 2717 ( 2000 ) . e. ruch and a. mead , theor . acta * 41 * , 95 ( 1976 ) . d. meyer , phys . 82 * , 1052 ( 1999 ) . j. eisert , m. wilkens , and m. lewenstein , phys . lett . * 83 * , 3077 ( 1999 ) . n. anand and c. benjamin , quant . * 14 * , 4027 ( 2015 ) . plenio and s. virmani , quant . * 7 * , 1 ( 2007 ) . t. baumgratz , m. cramer , and m. plenio , phys . lett . * 113 * , 140401 ( 2014 ) . m. hillery , phys . a * 93 * , 012111 ( 2016 ) . b. terhal , ibm j. res * 48 * , 71 ( 2004 ) . h. s. dhar , a. k. pal , d. rakshit , a. sen de , and u. sen , https://arxiv.org/abs/1610.01069[arxiv:1610.01069 ] . w. wootters , phys . lett . * 80 * , 2245 ( 1998 ) . a. childs and j. goldstone , phys . a * 70 * , 022314 ( 2004 ) . m. nielsen and i. chuang , quantum computation and quantum information , cambridge university press , cambridge , ( 2004 ) . e. chitambar , d. leung , l. maninska , m. ozols , and a. winter , commun . * 328 * , 303 ( 2014 ) . b. coecke , t. fritz , and r. spekkens , inf . & comp . * 250 * , 59 ( 2016 ) . m. horodecki and j. oppenheim , int . b * 27 * , 1345019 ( 2013 ) . m. schlosshauer , rev . phys . * 76 * , 1267 ( 2005 ) . a. streltsov , g. adesso , and m. b. plenio , https://arxiv.org/abs/1609.02439[arxiv:1609.02439 ] . v. coffman , j. kundu , and w. k. wootters , phys . a * 61 * , 052306 ( 2000 ) . k . bai , y .- f . xu , and z. d.wang , phys . * 113 * , 100503 ( 2014 ) . shi , s .- y . liu , x .- h . wang , w .- l . yang , z .- y . yang , and h. fan ,  coherence depletion in the grover quantum search algorithm \" , https://arxiv.org/abs/1610.08656[arxiv:1610.08656 ] .", "tags": [], "output_text_a": "This paper explores the role of quantum coherence and entanglement monogamy in the discrete analogue of the analog Grover search algorithm. The study uses coherence monotones, specifically the \\( l_1 \\)-norm and the relative entropy of coherence, to analyze the dynamics of coherence during the search process. It finds that coherence is non-zero throughout the search and only vanishes when the algorithm achieves maximum success probability. This indicates that maximal coherence is consumed during the search. The paper also examines entanglement using measures like concurrence and entanglement entropy, showing that entanglement peaks with the success probability, suggesting its necessity for the algorithm's success. The study confirms that the discrete analogue satisfies entanglement monogamy inequalities, indicating limited sharing of entanglement among qubits. The findings highlight the importance of coherence and entanglement in quantum search algorithms and their potential as resources in quantum information processing. The paper concludes by noting that similar results on coherence have been independently obtained by other researchers.", "output_text_b": "The article discusses the role of quantum coherence and monogamy of entanglement in the discrete analogue of the analog grover search algorithm. The authors use two coherence monotones, the 1-norm of coherence and the relative entropy of coherence, to quantify the dynamics of coherence in the analog grover search. They discretize the analog grover search algorithm and study the evolution of monogamy of quantum entanglement using an entanglement monotone called the concurrence. They find that the amount of coherence is non-zero at all times during the search, and it goes to zero only when the search algorithm attains the maximum success probability equal to one. The paper also discusses the application of the grover search algorithm to various problems and the role of quantum coherence in the Deutsch-Jozsa algorithm.", "score": -0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, focusing on the role of quantum coherence and entanglement monogamy in the Grover search algorithm.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem, which is the exploration of quantum coherence and entanglement in the Grover search algorithm.\n4. **Methodology**: The summary mentions the use of coherence monotones and entanglement measures as the methodology.\n5. **Significant Results**: The summary includes significant results, such as the consumption of coherence and the necessity of entanglement for the algorithm's success.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses some technical terms like \"coherence monotones\" and \"entanglement monogamy\" but does not explain them, which might be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any specific experiments or data used in the research.\n10. **Significance**: The summary reflects the paper's significance in the field of quantum information processing.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the role of quantum coherence and monogamy of entanglement in the discrete analogue of the analog Grover search algorithm.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is mentioned, focusing on the dynamics of coherence and entanglement in the Grover search algorithm.\n4. The methodology or approach used in the paper is mentioned, including the use of coherence monotones and discretization of the algorithm.\n5. Significant results or conclusions drawn by the authors are included, such as the coherence being non-zero during the search and going to zero at maximum success probability.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like coherence monotones and entanglement monotone.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance in understanding quantum coherence and entanglement in quantum algorithms."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "even though the aim of mathematical modelling in epidemiology has always been to help predicting the patterns of spread of infectious diseases , the complexity of real populations has always constrained modellers to use strong assumptions . even though these do not always guarantee the existence of analytic solutions , at least the models become _ tractable_. on the other hand , the search for analitical simplicity , or beauty , has sometimes taken over more practical considerations . one of the strongest assumptions used in most epidemiological models is the law of mass action @xcite . first proposed by chemists , it postulates that in dynamical equilibrium the rate of a chemical reaction is proportional to the concentrations of the reactants , and can be derived from the probability of collision between reacting molecules . the analogy between the movements of molecules and living beings , drawn almost a century ago @xcite , leads to the epidemiological version of this postulate : the ` force of infection ' is proportional to the densities of infected and uninfected individuals ( called ` susceptibles ' in the epidemiological literature ) . it implies assuming that the population has no structure , i.e. that every person can be in contact with every other ( ` random mixing ' ) .    in general , however , members of a population interact only with a very small subset of it . thus , one way to go beyond the random mixing assumption is to consider that the members of the population form a social network . its definition depends strongly on the type of interaction necessary to transmit the disease whose spread is being modelled . the advantage of this over the random mixing approach is that models can be better adapted to specific populations . needless to say , this implies having more data about the social structure , as well as new concepts and tools to analyse them . fortunately , these are provided by social network analysis , a field that has developed rapidly in recent years @xcite . the mathematics are not as straightforward as in the analysis of mass - action models , but for some cases some interesting results can be obtained by using approximations ( some of them derived from statistical physics ) . one example is the simple relationship that exists for a disease with infectivity @xmath0 and an infectious period @xmath1 , between the relative epidemic threshold @xmath2 , and the topological properties of the network @xcite :    @xmath3    where @xmath4 is the mean of the degree distribution of the social network , and @xmath5 is its variance . network epidemiology seems particularly well suited for the analysis of the spread of sexually transmitted diseases , as the definition of the network in this case is more straightforward ( although not free of problems , see @xcite ) . the large number of surveys of sexual behaviour carried out in the last three decades has provided an invaluable resource for modellers . interestingly , one common feature of many sexual networks built from survey data is that their degree distribution has a very long tail : there exist a small number of individuals who have a very large number of sexual contacts . mathematically , this means that , even though @xmath4 is rather small ( typically less than 3 ) , @xmath5 can be very large . applying eq . ( [ statthres ] ) to such networks ( what , as explained below , is not altogether correct ) would lead to the conclusion that , for those populations , even diseases with very low infectivity can trigger an epidemic . it has even been argued that some sexual networks have power law degree distributions with infinite variance @xcite , which would imply a vanishing epidemic threshold , but there is some controversy about this @xcite . one aspect that is usually disregarded in the network approach is the dynamic nature of social interactions . it is reasonable to assume that this dynamics produces a steady - state , in which the distribution of contacts does not change , even though at all times individuals are free to end their existing relationships and create new ones . ( [ statthres ] ) is derived for a static network , and is sometimes used to estimate the epidemic threshold of populations whose structure is deduced from sexual behaviour surveys . respondents to these surveys , however , are usually asked about number of partners over a certain time period , and the distribution thus obtained is often used as a proxy for the steady state , or _ instantaneous _ distribution . but it is difficult to ascertain how close distributions of accumulated contacts can be to the instantaneous distribution @xcite . it is often suggested that if the time period asked about in the survey is similar to the infectivity period of the disease analysed , epidemic thresholds can be calculated by using the proxy network ( see for example @xcite ) . but in general this argument remains at a qualitative level . in principle , it should be possible to see whether the dynamics affects the spread of the disease only by generating a steady state distribution or there are other effects independent of this . models that take into account the dynamic nature of social network usually consider that the formation and dissolution of links between individuals are stochastic processes @xcite . more recently , such models have also been used to understand the spread of infectious diseases @xcite . but , in general , the additional complication of dealing with network dynamics has led either to models that have analytical solutions but that are too simple to be applied in a realistic setting , or to models that rely exclusively on numerical simulations , from which it is difficult to draw general conclusions . the model of network dynamics presented in the next section is an attempt at overcoming these limitations . it can be tailored to give similar accumulated degree distributions to those obtained in real surveys , as shown in the third section , but it also allows us to obtain some very general analytical results for the influence of network dynamics on the propagation of infectious diseases , using mean field techniques . we consider a population of @xmath6 individuals epidemiologically identical . as in this case it has been shown that static models with individuals placed on a bipartite network give identical predictions to models where the population is not divided into two groups @xcite , we have assumed that partnerships can be established between any two individuals . thus , even though our model applies strictly only to homosexual populations , its predictions should be qualitatively correct for heterosexual populations with similar epidemiological variables for both sexes . partnerhips can be established and dissolved with a rate that depends on features of the two individuals . as the only dynamic attribute we consider is the number of partners , we first assume that rates depend only on it . thus , the rate of partnership creation between individuals @xmath7 and @xmath8 is @xmath9 and the rate of partnership dissolution is @xmath10 , where @xmath11 and @xmath12 are the number of current sexual partners of @xmath7 and @xmath8 at time @xmath13 . as we only deal with steady states , hereafter the @xmath13 dependence is dropped from all quantities .    in equilibrium , the master equation for the steady state degree distribution @xmath14 becomes :    @xmath15    where @xmath16 is the average probability that an individual with @xmath17 partners gets a new partner and @xmath18 is the average probability that an individual breaks one of his existing relationships . in principle , the link creation probability should be averaged only over those individuals that are not current partners of the individual . however , as in real populations @xmath17 is much smaller than @xmath6 , this quantity is very well approximated by the average over the entire population :    @xmath19    for the link dissolution probability , the distribution that should be used to calculate the average is @xmath20 , the degree distribution of the individuals that are connected to an individual having @xmath17 partners . however , if we assume that the dynamics does not generate a significant assortative mixing by degree , @xmath20 can be written as @xmath21 . this is not a too stringent assumption , since there seems to be no definite tendency in mixing with respect to sexual activity : some sexual networks have been found to be weakly assortative @xcite , some neutral @xcite and some disassortative @xcite . the resulting average link dissolution is , then ,    @xmath22    solving eq . ( [ equil ] ) gives the steady state degree distribution :    @xmath23    for @xmath24 . @xmath25 is obtained by normalizing the distribution . @xmath14 can also be written as    @xmath26    where the @xmath6 parameters @xmath27 ( @xmath28 ) are obtained by solving the @xmath6 self - consistency equations    @xmath29    if a model is to be used for understanding the spread of a disease in a real population , its parameters should be adjusted by comparing with the available population data . for simpler models , it has been suggested that this could be done by using an empirical instantaneous distribution @xcite . in our model , however eqs . ( [ steady ] ) and  ( [ selfconsi ] ) show that rescaling the link creation and dissolution functions does not change the equilibrium distribution . this was to be expected , because changing the time scale can not change the nature of the steady state reached . thus , time scales should be obtained from other population measurements . an important problem of this approach is that , unfortunately , information about instantaneous degree distributions is usually _ not _ available . instead , almost all surveys ask respondents about the number of sexual contacts accumulated over a certain time period . thus , what we need to know from the model is the distribution of accumulated contacts ( i.e. the probability of having had @xmath17 contacts during a given time period ) , @xmath30 , which can be written as    @xmath31    where @xmath32 is the probability of having @xmath33 _ new _ contacts over a time period of length @xmath34 , conditional on having @xmath35 partners at the beginning of that period . the equations that these conditional probabilities satisfy are    @xmath36 + \\nonumber \\\\   & & n \\sigma_n \\ , [ p_t(m|n-1)-p_t(m|n ) ] \\label{cumu}\\end{aligned}\\ ] ]    for @xmath37 , with @xmath38 and @xmath39 . with the aid of some mathematical software , such as mathematica or matlab , this recursion can be solved exactly , for any desired value of @xmath34 ( see appendix ) . using this , the parameters @xmath40 and @xmath41 can be adjusted to fit the distributions obtained in any given survey . an example of this is given in the next section . the number of self consistency equations to be solved ( eqs .  [ selfconsi ] ) imposes a practical constraint on the models that can be effectively analized . one of the simplest ways to reduce the number of equations to only one is to consider functions of the form @xmath42 and @xmath43 . this choice has the added advantage of ensuring that there is no assortative mixing by degree . note that if @xmath44 is an increasing function of @xmath17 , individuals with many partners are more likely to attract new ones . this is usually known as preferential attachment in the network literature @xcite . interestingly it has been shown that this is likely to play a role in the formation of sexual networks @xcite . first we analyze two different models , called a and b , that generate almost the same instantaneous degree distribution . model a is defined by the functions @xmath45 ( for @xmath24 ) , @xmath46 , and @xmath47 , whereas model b is defined by @xmath48 ( for @xmath24 ) , @xmath46 , and @xmath49 . @xmath50 and @xmath51 are numerical constants . the instantaneous distribution is @xmath52 , where @xmath53 . @xmath54 is obtained by solving the self consistency equation for each model . the constants @xmath50 and @xmath51 are adjusted to obtain a degree distribution that has a mean value of order @xmath55 , and a variance large enough to mimic the long tails observed in sexual networks . we find that there is a critical value for @xmath50 and @xmath51 below which the network is sparsely connected , and above which the network becomes dense , in the sense that each individual is connected to a significant fraction of the population ( see appendix ) . this is usually called a phase transition . thus , to obtain a relatively wide degree distribution but keeping the network sparse , @xmath50 and @xmath51 were given values that are close to ( but below ) the critical value . 1 shows that the mean field approach is a very good approximation for the corresponding stochastic model , both for the instantaneous degree distribution as well as for the accumulated ones . it also shows that , even for models with the same instantaneous degree distribution , the distribution of the number of accumulated partners can be rather different . as a consequence , the usual approach of fitting the tail of these distributions with a power law function would not give the same exponent for models a and b. the accumulated distributions can be used to calculate epidemic thresholds , using eq . ( [ statthres ] ) , which can be considered as approximations to @xmath56 , the static threshold . the inset shows that these approximations can be very different from the actual value of @xmath56 .    [ ! h ]    , for models a and b ( see text ) . the full lines for @xmath57 are given by eq . ( [ steady ] ) , whereas the other lines are obtained by solving recursively eqs . ( [ cumu ] ) . symbols correspond to simulations for a system with @xmath58 individuals ( averaged over 100 runs ) . the symbols and lines falling on the left vertical axis represent the fraction of individuals having @xmath59 sexual partners . error bars are smaller then the symbols . the inset shows the static epidemic threshold calculated for the distribution of accumulated partners for different time periods , for both models . ]    to see whether these differences are relevant in a real setting , we have applied this model to data from the national survey of sexual attitudes and lifestyles ii ( natsal 2000 ) , carried out in britain in 2000 - 2001 @xcite . participants were asked about the number of male and female partners during several , overlapping , time periods previous to the survey : 1 month , 3 months , 1 year , and 5 years . from these data , one can build , for each time period , the distribution of the number of accumulated partners .    furthermore , we have only used the data related to homosexual men , since our model deals strictly with one - sex populations . however , as sexual orientation was not asked about to the participants of natsal , we have used a definition of msm ( men who have sex with men ) as those men having reported at least one male partner within the five years prior to interview @xcite . this leaves 166 out of 4762 male respondents . because of recall problems , the accuracy of the reports decreases as the time period asked about increases @xcite . this is already apparent in the data for 5 years ( not shown ) , where there is substantial heaping . in our case , this data set is further skewed because it has been used to define msm . thus , we have adjusted our model to fit only the degree distributions for 1 month , 3 months and 1 year ( see appendix ) . we have not used the data about lifetime number of partners , because the time periods involved were not the same for all participants ( whose ages ranged from 16 to 44 years ) , as assumed in our model . 2 shows the distribution of accumulated partners for the four time intervals analyzed . the fit is reasonably good for the three curves used . even though the data for the 5 years period are overestimated , the tendency seems to be correct . the inset shows the approximations to the static threshold , calculated using the model degree distributions for several time periods ( see appendix ) . as in the previous figure , the approximations get worse when calculated using longer time periods . in fact , already the 1 month distribution leads to an underestimation of @xmath60 of about 50 % .    to understand whether this underestimation is relevant , the spread of a disease should be analyzed taking into account the intrinsic dynamics of the network . the question is not only how close the real and static thresholds are , but even which one is larger , because it could happen that the real threshold was smaller than the static one , thus compensating for the underestimation of the approximations calculated with accumulated degree distributions . in the next section it is shown that this is not the case : real thresholds are always larger than static ones . we consider the propagation of a disease that can be cured , and that confers no immunity , i.e. individuals can be reinfected as soon as they become susceptible again . this type of models , called sis , are considered acceptable models of sexually transmitted diseases as gonorrhea and chlamydia @xcite . it is assumed that , in an existing relationship between a susceptible and an infected individual , infection can pass with a probability @xmath0 per unit time , and that infected individuals heal at a rate @xmath61 . we also assume that the social dynamics is not affected by the propagation of the disease . we need to calculate @xmath62 , the probability that at time @xmath13 an agent @xmath54 has @xmath17 simultaneous relationships and is infected . the master equation for this depends on the two point probabilities @xmath63 , which in turn depend on three - point probabilities , and so on . to get a closed system we choose the simplest ansatz : @xmath64 . using this , and averaging over all agents with the same number of partners , k , the master equation for @xmath65 becomes    @xmath66    where @xmath67 is a tridiagonal matrix defined by @xmath68 , @xmath69 and @xmath70 and the vectors @xmath71 and @xmath72 are given by @xmath73 and @xmath74 . @xmath75 is given by eq . ( [ steady ] ) . @xmath76 is the probability of having an infected partner @xcite , @xmath77 , and is obtained from the self consistency condition ,    @xmath78    the epidemic threshold can now be easily obtained by taking the limit @xmath79 :    @xmath80    the fraction of infected individuals is    @xmath81    where @xmath82 is the vector with all components set to @xmath55 . in the limit where the characteristic times of the disease are much shorter than the ones characterizing the social dynamics ( i.e. @xmath83 , @xmath84 , but keeping @xmath85 constant ) , the usual result for a static network is obtained ( eq . 1 ) : @xmath86 . intuitively one can think that the disease spreads so fast that it ` sees ' only the instantaneous network . the opposite limit can also be calculated ( see si text ) , giving @xmath87 . thus in this case , the social dynamics is so fast that , in terms of disease spread , the network is equivalent to an ` average ' network where all nodes have the same degree , @xmath88 . note that @xmath89 . it is interesting to note that the social dynamics influences disease spread only through the instantaneous network of contacts , in the limit cases . 3 shows that the relative epidemic threshold of the natsal model is larger for diseases with larger infectious periods , @xmath90 . note that for infectious periods of the order of a few months , as is the case of untreated gonorrhea , chlamydia and syphilis , the difference between the corresponding threshold and the static approximation , @xmath91 , can be significant . in terms of the nonnormalized epidemic threshold , the inset of fig . 3 shows that when the dynamics of the network is taken into account , @xmath92 decreases more slowly with @xmath93 . interestingly , it can be proved ( see appendix ) that the effect of the dynamics is the same for _ all _ possible choices of the link creation and dissolution functions , @xmath94 and @xmath95 : the relative epidemic threshold always grows monotonously with @xmath93 . even though the mean field approximation is not very good for sparse networks ( as should be the case of most instantaneous sexual networks ) , it can be conjectured that the picture is not qualitatively different . this is supported by simulations carried out for the stochastic analog of the natsal model . 4 shows that the qualitative behavior of the simulation curves is well predicted by the mean field approximation . note that the real epidemic threshold is even larger than the mean field value and therefore the underestimation mentioned before is even worse when compared with simulation values .    for large values of the infectivity , fig . 4 shows that @xmath96 , the fraction of infected individuals in the endemic state , grows with @xmath93 . this too is a general feature of this kind of models . interestingly , for very large @xmath0 , @xmath96 does not tend to @xmath55 :    @xmath97    in a static network ( i.e. @xmath98 ) , the disease can not reach isolated individuals . in the dynamic case , however , even momentarily isolated people get a partner after a time @xmath99 , on average . but there is a probability that isolated , infected people get cured before they get a partner . this ensures that there is always a fraction of the isolated individuals that is not infected , no matter how high the infectiousness of the disease is . the proportion of partners that are infected , @xmath76 , is also an increasing function of @xmath100 but it tends to @xmath55 for large infectivities , for all values of @xmath93 . it can also be proved that , for fixed values of @xmath100 , @xmath76 is a decreasing function of @xmath93 . individuals , using the same paramters as for the natsal model . symbols correspond to averages over @xmath101 runs . the lines joining the sysmbols are only guides to the eye . ] the model analyzed in the previous sections can be extended in many ways , in order to make it more realistic . one of them is to consider that the attraction between individuals can depend not only on the number of partners , which is a dynamical variable , but also on intrinsic features of each individual , called _ fitness _ in the network literature , that do not change over time ( or at least over the times relevant for the problem ) . many characteristics have been proposed to account for attraction , as beauty , talent , socioeconomical status , and even geographical location . the downside to this added realism is that such features are not easy to univocally define @xcite , let alone quantify . it is interesting , however , to see that some general properties can be derived for our model . we assume that the fitness @xmath102 takes a finite number of values , whose probability mass function is @xmath103 . the rates of partnership creation and dissolution depend now on the @xmath102 of each agent : @xmath104 and @xmath104 . the population can be divided in subpopulations with a common value of @xmath102 , with a degree distribution @xmath105 given by eq . ( [ steady ] ) . one important difference with the model analyzed in the previous sections is that the time average of the number of partners is not the same for all individuals , but depends on their fitness . the interaction between the subpopulations is encoded in the self consistency parameters @xmath106 , calculated from    @xmath107    it is also possible to obtain the distribution of accumulated contacts . in this case @xmath108 is the probability that an individual with fitness @xmath102 , having @xmath109 partners at the beginning of a given time period of duration @xmath34 , has had @xmath110 partners at the end of that period . there is now a set of equations for each @xmath102 , analog to eqs . ( [ cumu ] ) , that can be solved independently of each other . the degree distribution for the period @xmath34 is @xmath111 . the analysis of the spread of an infectious disease can be carried out much in the same way as in the previous section . the mean field approach leads to an equation analog to eq . ( [ infsinmat ] ) , for each subpopulation . the probability that a partner of an individual is infected , @xmath76 , is again assumed to be independent of the individual , and is obtained by solving :    @xmath112    where @xmath113 , @xmath114 denote an average over the distribution @xmath103 and @xmath115 denotes an average over both @xmath103 and @xmath116 . the epidemic threshold in this approximation is    @xmath117    it is instructive to compare the cases where different fitness distributions generate the same instantaneous network . as expected , the static limit ( @xmath118 ) does not depend on @xmath119 . but the opposite limit does depend on the fitness :    @xmath120    where @xmath121 is the average of @xmath17 over the individuals with the same value of @xmath102 . if there is a nontrivial fitness distribution , it can be shown that this value is strictly smaller than @xmath122 , the limit found in the previous section . in other words , the effect of the social dynamics on the spread of the disease is less pronounced if the instantaneous network is ( at least partly ) generated by the features of the individuals .    in std epidemiology it is often assumed that there is a small group of individuals , usually called _ core group _ , whose contribution to the spread of the disease is disproportionately large . even though there is some ambiguity in the exact characterization of it @xcite , this label is frequently applied to people with very many sexual contacts @xcite . our result suggests that , even having the same number of individuals at any time , dynamic core groups ( whose composition changes with time ) might be not as effective as static ones in driving an epidemic . one potential drawback of including intrinsic features is that the computational work needed to obtain the different predictions of the model is multiplied by the number of possible values of the fitness . it must be noted , however , that in sociological studies many features are quantified with a very small number of values . for example , income is usually quantified in quintiles or deciles , and physical attractiveness , because of its intrinsic ambiguity , has been quantified in many sociological studies in scales having between 5 and 10 values . another aspect of the model that can be criticized is that , at any given time , any two individuals in the population can become sexual partners . this is not only geographically but also ( and even more ) socially not realistic . one way to overcome this limitation is to assume that each individual can only become a sexual partner of a fixed set of individuals , which form his or her ` social neighbourhood ' . numerical simulations show that , for populations with neighbourhoods consisting of a few hundred individuals , results are almost indistinguishable from the ones presented in the previous sections . most models that take social dynamics into account seem to belong to two groups . one group consists of models that are analytically solvable but are too schematic to account for many important features of real populations . the other group consists of models that are much more complex , with many parameters that can be obtained from population data , but whose very complexity implies that their study can only be carried out by means of computational simulations . the model presented here is an attempt at bridging the gap between these two groups . on the one hand , it is sufficiently general to allow its parameters to be obtained by fitting data from population surveys . the example analyzed shows that the fits obtained can be very reasonable . on the other hand , the model can be studied analytically using mean field techniques , which allows us to obtain some general results . we have found that , because of the interplay between the social and the epidemic dynamics , the relative epidemic threshold , as a function of the average duration of infection , increases monotonically between the two limit cases , @xmath123 and @xmath124 . thus , approximating the epidemic threshold by the static network threshold , entails an underestimation . and the example analized shows that , in real cases , this underestimation can be significant for diseases having an infectious period of the order of months . but , even in the case when @xmath60 is a good approximation , the problem that remains is how to estimate its value from survey data . participants in surveys about sexual behaviour are usually asked about number of partners during one or several time periods . any properties of the instantaneous contact network must therefore be inferred from that information . usually , @xmath60 is estimated from the network built by considering the distribution of the number of accumulated partners as a degree distribution , for each time period . we have shown that , as is usually assumed , this approximation improves as shorter time periods are considered . unfortunately , we have also shown that , in real cases , even the values obtained for rather short time periods ( 1 month ) can be much smaller than @xmath60 . it is often assumed that to study the spread of diseases with short infectious periods the relevant information is encoded in the distribution of sexual partners for small time periods , whereas longer time periods ( of the order of years ) are more relevant for diseases with long infectious periods . the results of the previous sections show that this might not be the case , at least for the epidemic threshold . it is true that sometimes this threshold is well approximated by the static limit , whose estimation necessitates information about sexual partners in time periods as short as possible . but for diseases with long infectious periods , we find that the epidemic threshold obtained with distribution of partners for long time periods underestimates the static epidemic threshold , which in turn underestimates the real value . therefore , for this kind of diseases , the best would be to to build a good social dynamics model by fitting the empirical data for several time periods , and to calculate its corresponding epidemic threshold . dynamic models as the one presented here still need the addition of many features before being considered as reasonable representations of real populations , such as the possibility of having asymptomatic individuals , and the division of the population into groups with different epidemiological characteristics . there is also room for improvement in the approximations used for the analysis of the model . one possibility is to go one step further from the mean field theory and to consider a pair approximation . it is not clear , however , whether such modifications would lead to a model amenable to analytical solutions or approximations , which is one of the main advantages of the model presented in this paper . i wish to thank m.n . kuperman and d. h. zanette for a critical reading of the manuscript and useful suggestions . * appendix * by laplace transforming eqs . ( 9 ) , solving , and back transforming , it can be shown that the probabilities that an individual has had @xmath110 new contacts at the end of a time period of length @xmath34 , given that he had @xmath109 at the beginning of that period , are of the form :    @xmath125    the constants @xmath126 are obtained from the following recursions :    @xmath127 a_{i \\ , m+n - i}^{mn}(c_n - c_{m+n - i } ) & = & \\rho_n a_{i \\ , m+n - i}^{m-1 \\ , n+1 } \\,\\,\\,\\mbox{for $ i=1 , \\cdots , m-1 $ } \\nonumber \\\\[10pt ] a_{m j}^{mn}(c_n - c_j ) & = & n \\sigma_n a_{m \\ , j}^{m \\ , n-1 } \\,\\,\\,\\,\\mbox{for $ j=0 , \\cdots , n-1$}\\end{aligned}\\ ] ]    the remaining constants are obtained from the conditions @xmath128 if @xmath129 and @xmath130 : @xmath131 , @xmath132 , and @xmath133 . for models of the form @xmath42 and @xmath43 the self consistency parameters are @xmath134 . @xmath54 is obtained by solving    @xmath135    if now all the creation functions are multiplied by the same constant , @xmath136 , and the self consistency parameter is rescaled as @xmath137 , eq . [ selfconsap ] becomes    @xmath138    as mentioned in the text , models a and b are defined as follows . model a : @xmath45 ( for @xmath24 ) , @xmath46 , and @xmath47 . model b : @xmath48 ( for @xmath24 ) , @xmath46 , and @xmath49 . @xmath50 and @xmath51 are numerical constants . the instantaneous distribution is @xmath52 , where @xmath53 . fig.[figureap ] shows @xmath139 and @xmath140 , for different values of the constant @xmath136 , for @xmath141 . at @xmath142 there is a discontinuous phase transition from a network with @xmath143 to a network with @xmath144 . h ]     as a function of @xmath145 for model @xmath146 ( see text).,width=377 ] to obtain a model that fits the natsal data we have taken into account the fact that the number of respondents was rather small and , as a consequence , the sampling error for the number of repondents declaring having had more than two partners is likely to be rather large . we have chosen to adjust separately only the values of @xmath147 , @xmath148 , @xmath149 , and @xmath150 to fit the number of respondents that reported 0 or 1 partner . the rest of the data were fitted using the generic functions @xmath151 and @xmath152 . the fits were performed sequentially . in the first step we fitted @xmath147 , @xmath148 , @xmath149 , and @xmath150 using the analytic expressions for @xmath153 and @xmath154 . in the second step , a coarse sampling of parameter space was performed , in order to select a suitable region on which to focus . this selection was performed by calculating several different distributions @xmath155 for relatively small values of @xmath17 ( @xmath156 ) ( which takes only a few seconds of computation time ) and choosing the one that best fitted the data . in the third step , a fine tuning of the parameters found was performed by generating some ` full ' distributions ( up to @xmath157 ) ( which takes tipically a couple of days of computation time ) for small displacements from the parameters selected in the previous step . the values obtained for the different parameters are given in table [ tablenatsal ] .    to compensate for the heaping present in the number of partners reported ( i.e. the preference of respondents for round numbers , specially for large numbers ) , we have applied geometric binning to the data . nevertheless , the fits obtained are quite good for other presentations of the data , as the cumulative numbers of partners ( see fig . 2 in the main article ) the estimates of the static epidemic threshold shown in the inset of figs . 1 and 2 in the main text were calculated using the accumulated partners distributions found , i.e. up to @xmath157 . therefore the values are not exact , but it can be shown that they are upper bounds to the values calculated using the full distributions . this means that the difference between the exact estimations and the static threshold is even larger than what is shown in the insets . @lcr @xmath158&@xmath159@xmath160&@xmath161@xmath162&@xmath163@xmath164&@xmath165@xmath166&@xmath167@xmath168&@xmath55@xmath169&@xmath170@xmath171&@xmath172    [ tablenatsal ] using eq . 5 of the main text , the elements of matrix @xmath173 can be written as @xmath174 , @xmath175 , and @xmath176 . if we define a diagonal matrix @xmath177 such that @xmath178 , it is straightforward to see that @xmath173 can be written as @xmath179 , where @xmath180 is a symmetric , tridiagonal matrix , with vanishing row ( and column sums ) , defined by @xmath181 . therefore , gershgorin theorem implies that @xmath180 is positive - definite . that is , it has the property that          we can also show that the growth of @xmath92 is not unbounded , by calculating @xmath185 . for this , we need to calculate the limit of @xmath186 . note that it can be written as @xmath187 . the adjoint of a matrix @xmath188 is defined as @xmath189 , where @xmath190 are the minors of @xmath188 , i.e. @xmath190 is the determinant of the matrix obtained by deleting row @xmath7 and column @xmath8 from @xmath188 . the minors of @xmath191 can be written as @xmath192 , where @xmath193 are the minors of @xmath194 . but the fact that all row and column sums vanish implies that @xmath195 . it also implies that the determinant of @xmath196 can be calculated by replacing each element of its first row by @xmath61 . using the laplace expansion for the determinant , we then get            heesterbeek h ( 2005 ) the law of mass - action in epidemiology : a historical perspective , in ecological paradigms lost : routes of theory change , eds cuddington k , beisner b ( elsevier , amsterdam ) pp 81 - 105 . honekopp j ( 2006 ) once more : is beauty in the eye of the beholder ? relative contributions of private and shared taste to judgments of facial attractiveness , j exp psychol hum percept perform 32:199 209 .", "tags": [], "output_text_a": "The paper discusses the limitations and advancements in mathematical modeling of infectious disease spread, particularly focusing on the assumptions and complexities involved in epidemiological models. Traditional models often rely on the law of mass action, assuming random mixing within populations, which does not account for the structured interactions in real populations. The paper explores the use of social network analysis to better model these interactions, especially in the context of sexually transmitted diseases (STDs), where network topology can significantly influence disease dynamics.\n\nThe authors propose a dynamic network model that accounts for the formation and dissolution of partnerships, aiming to provide more realistic predictions of disease spread. This model can be tailored to fit real survey data, such as those from the National Survey of Sexual Attitudes and Lifestyles (NATSAL), and allows for analytical insights into how network dynamics affect epidemic thresholds.\n\nKey findings include the observation that static network models may underestimate the epidemic threshold, particularly for diseases with longer infectious periods. The paper suggests that dynamic models, which consider the changing nature of social interactions, provide a more accurate representation of disease spread. The authors also discuss the potential for incorporating individual attributes, or \"fitness,\" into the model to further refine predictions.\n\nOverall, the paper highlights the importance of considering social dynamics in epidemiological modeling and suggests that dynamic network models offer a promising approach to understanding and predicting the spread of infectious diseases.", "output_text_b": "This article discusses the limitations of traditional epidemiological models and the potential of network epidemiology to provide a more accurate representation of disease spread. It highlights the importance of considering the social structure and the dynamic nature of social interactions in epidemiological models. The article also presents a model of network dynamics that can be tailored to fit real-world survey data and provides analytical results for the influence of network dynamics on disease spread.\n\nThe key points of the article are:\n\n1. Traditional epidemiological models rely on strong assumptions, such as the law of mass action, which may not accurately reflect the complexity of real-world populations.\n2. Network epidemiology, which considers the social structure and interactions between individuals, can provide a more accurate representation of disease spread.\n3. The dynamic nature of social interactions is often disregarded in network epidemiology, but it can significantly affect disease spread.\n4. The article presents a model of network dynamics that can be tailored to fit real-world survey data and provides analytical results for the influence of network dynamics on disease spread.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the limitations of traditional models, the introduction of a dynamic network model, and the importance of considering social dynamics in epidemiological modeling.\n\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of accurately modeling infectious disease spread considering social network dynamics.\n\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of a dynamic network model and social network analysis.\n\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant conclusions, such as the underestimation of epidemic thresholds by static models and the benefits of dynamic models.\n\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like \"dynamic network model.\"\n\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically, with a clear introduction, body, and conclusion.\n\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of survey data from the National Survey of Sexual Attitudes and Lifestyles (NATSAL).\n\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by highlighting the potential impact of dynamic network models in epidemiological modeling.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the limitations of traditional epidemiological models and the potential of network epidemiology.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the limitations of traditional models and the need for considering social structures in epidemiology.\n4. The methodology or approach used in the paper is mentioned, specifically the model of network dynamics tailored to fit real-world survey data.\n5. Significant results or conclusions drawn by the authors are included, such as the influence of network dynamics on disease spread.\n6. The summary is written in clear and professional language.\n7. The summary avoids technical jargon and explains terms where necessary.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance or potential impact in its field by discussing the potential of network epidemiology."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the direct and precise measurement of the self - coupling between the electroweak gauge bosons in @xmath2-pair production will be a crucial step in testing the standard model of electroweak interactions and searching for physics beyond it . it will form an important part of the physics programme at lep2 and at a planned linear @xmath3-collider ( lc ) . as is well known there are three diagrams at tree level that contribute to the amplitude of @xmath4 in the standard model , one with @xmath5-channel neutrino exchange and the other two with a @xmath6 or @xmath7 in the @xmath8-channel , involving the vertices @xmath1 and @xmath0 . one can parametrise the corresponding vertex functions in order to quantify the couplings and to compare them with their form in the standard model . in the most general form respecting lorentz covariance each vertex involves seven complex form factors @xcite , three of which give couplings that violate @xmath9 symmetry .    without further physical assumptions one is thus left with 28 real parameters whose simultaneous extraction in one experiment looks quite hopeless . given the limited event statistics expected at both lep2 and the lc one will only obtain meaningful errors on a reduced number of coupling parameters at one time . this may be achieved by imposing certain constraints on the full set of coupling constants ; various suggestions for such constraints based on symmetry considerations have been made in the literature @xcite . one must however keep in mind that experimental values or bounds on couplings that have been obtained with particular constraints can not be converted into results without constraints or with different ones ; the information lost by assuming relations between couplings can not be retrieved . although imposing such constraints is certainly legitimate and can be useful we stress that a data analysis with independent couplings will be valuable , both from the point of view of model independence and the capability to compare results of different experiments . we remark that of course one can also give ( reasonably small ) errors on _ single or few _ couplings in a multi - parameter analysis . in this paper we propose a parametrisation of the couplings which is well adapted to this end , the statistical errors on the different measured parameters being approximately uncorrelated . we will work in the framework of optimal observables , a way to extract unknown coupling parameters introduced for the case of one parameter in @xcite that has since been used for various reactions @xcite . general aspects of this method , in particular its extension to an arbitrary number of parameters , as well as its application to @xmath10 production were discussed in @xcite . in this paper we investigate again the reaction @xmath11 . we concentrate here on the decay channels , where one @xmath2 decays hadronically and the other into an electron or muon and its neutrino . calculated with the born level cross section of the standard model the statistics of these channels is about 3000 events for a collision energy of @xmath12 and @xmath13 integrated luminosity , which are typical planned lep2 parameters , and about 22000 events with @xmath14 at @xmath15 , which might be achieved at the lc . a complementary source of information is the integrated cross section , which is a quadratic function of the triple gauge couplings . the combination of information from the total event rate and from observables that make use of the detailed distribution in the final state has for example been used in @xcite , where @xmath9 violation in the decay @xmath16 was investigated .    in sec . [ sec : method ] of this paper we will further develop some aspects of the method of optimal observables , in particular we will show how to apply it without the linear approximation in the coupling parameters that was used in @xcite . in sec .  [ sec : diagon ] we then propose a parametrisation of the couplings that simultaneously diagonalises certain matrices connected with our observables and with the integrated cross section . these parameters achieve two goals : their quadratic contribution to the total cross section is a simple sum of squares and the covariance matrix of the corresponding optimal observables is diagonal . the methods which we use for this purpose are borrowed from the theory of small oscillations of a system with @xmath17 degrees of freedom ( cf . e.g.  @xcite ) . our parameters correspond to `` normal coordinates '' and their use in an experimental analysis should in our view present several advantages . we give some numerical examples for @xmath2-pair production at lep2 and the lc in sec . [ sec : numeric ] and make some further remarks on how our proposal might be implemented in practice in sec . [ sec : practice ] . the last section of this paper gives a summary of our main points . the method of optimal observables has previously been presented in the approximation that the couplings to be extracted are sufficiently small to allow for a leading order taylor expansion of various expressions . here we show how to use it beyond this approximation . let us denote by @xmath18 the real and imaginary parts of the @xmath1 and @xmath0 form factors minus their values in the standard model at tree level . as the amplitude of our process is linear in these couplings we can write the differential cross section as @xmath19 where @xmath20 is a positive semidefinite symmetric matrix . @xmath21 collectively denotes the set of measured phase space variables . the integrated cross section is @xmath22 with the standard model cross section @xmath23 and coefficients @xmath24 the idea of using integrated observables is to define suitable functions @xmath25 of the phase space variables and to extract the unknown couplings from their measured mean values @xmath26 . let us give the details . from ( [ diffxsection ] ) and ( [ intxsection ] ) we obtain the expectation value @xmath27 $ ] of @xmath28 as @xmath29 - e_0[{{\\cal o}}_i ] = \\frac{\\displaystyle \\sum_{j } c_{ij } \\ , g_j      + \\sum_{jk } q_{ijk } \\ , g_j g_k}{\\displaystyle 1 + \\sum_{j }      { \\hat{\\sigma}_{1,j } } \\ , g_j + \\sum_{jk } { \\hat{\\sigma}_{2,jk } } \\ , g_j g_k}\\ ] ] with the standard model expectation value @xmath30 = ( \\int d\\phi \\ , { { \\cal o}}_i s_0 ) / \\sigma_0 $ ] and coefficients @xmath31 \\ , { \\hat{\\sigma}_{1,j } }   { \\hspace{6pt},}\\nonumber \\\\    q_{ijk } & = & \\frac{1}{\\sigma_0 } \\int d\\phi \\ , { { \\cal o}}_i s_{2,jk } -    e_0[{{\\cal o}}_i ] \\ , { \\hat{\\sigma}_{2,jk } } { \\hspace{6pt}.}\\end{aligned}\\ ] ] we remark in passing that the coefficients in ( [ expect ] ) can be written in a compact form as @xmath32 { \\hspace{6pt},}\\hspace{3em }    q_{ijk } { \\hspace{0.4em } = \\hspace{0.4em}}v_0[{{\\cal o}}_i \\ , , \\ ; s_{2,jk } /s_0 ] { \\hspace{6pt},}\\nonumber \\\\    { \\hat{\\sigma}_{1,j } } & = & e_0[s_{1,j } /s_0 ] { \\hspace{6pt},}\\hspace{4.4em }    { \\hat{\\sigma}_{2,jk } } { \\hspace{0.4em } = \\hspace{0.4em}}e_0[s_{2,jk } /s_0 ] { \\hspace{6pt},}\\end{aligned}\\ ] ] where @xmath33 = e_0[f g ] - e_0[f ] \\ , e_0[g]$ ] is the covariance of @xmath34 and @xmath35 in the standard model . note that @xmath36 is symmetric and positive definite , whereas @xmath37 as a matrix in @xmath38 and @xmath39 is symmetric but in general indefinite . an estimation of the couplings can now be obtained by solving the system ( [ expect ] ) with @xmath27 $ ] replaced by the mean values @xmath26 , @xmath40 = \\frac{\\displaystyle \\sum_{j } c_{ij } \\ , g_j      + \\sum_{jk } q_{ijk } \\ , g_j g_k}{\\displaystyle 1 + \\sum_{j }      { \\hat{\\sigma}_{1,j } } \\ , g_j + \\sum_{jk } { \\hat{\\sigma}_{2,jk } } \\ , g_j g_k }   { \\hspace{6pt},}\\ ] ] provided of course one has @xmath41 observables for @xmath41 unknown couplings . when the system ( [ mean ] ) is linearised in the @xmath18 it is easily solved by inversion of the matrix @xmath42 . one is however not constrained to do so and can instead solve the exact set of equations ( [ mean ] ) . by multiplication with the denominator it can be rearranged to a coupled set of quadratic equations in the @xmath18 and will in general have several solutions . some of these may be complex and thus ruled out , but from the information of the @xmath43 alone one can not tell which of the remaining real ones is the physical solution . we will come back to this point . the measured mean values @xmath43 are of course only equal to the @xmath27 $ ] up to systematic and statistical errors . we only consider the latter here , which are given by the covariance matrix @xmath44 of the observables @xmath28 divided by the number @xmath45 of events in the analysis . to convert the errors on the observables into errors on the extracted couplings we use the quantity @xmath46 \\right ) n    v({{\\cal o}})^{-1 } { } _ { ij } \\left ( { \\bar{{{\\cal o}}}}_j - e[{{\\cal o}}_j ] \\right ) { \\hspace{6pt},}\\ ] ] which depends on the @xmath18 through the @xmath27 $ ] given in ( [ expect ] ) . solving ( [ mean ] ) is tantamount to minimising @xmath47 with @xmath48 , and a confidence region on the couplings is as usual given by @xmath49 with the constant determined by the desired confidence level . there are several possible choices for the covariance matrix @xmath50 in ( [ chi ] ) . it can be    1 . determined from the measured distribution of the observables @xmath28 , 2 . calculated from the differential cross section ( [ diffxsection ] ) , taking for the @xmath18 the values extracted in the measurement , 3 . calculated for vanishing couplings @xmath18 , 4 . calculated as a function of the couplings . choices 1 .  and 2 . should lead to the same results in the limit of large @xmath45 where the statistical errors on the measured @xmath44 and @xmath18 become small . comparison of the covariance matrices obtained by these two methods might indeed be helpful to rule out unphysical solutions of ( [ mean ] ) . .  in turn will be a good approximation of 2 . if the couplings are small enough . we consider possibility 4 .  as the least practical one , except maybe for the case of one coupling . for several couplings the expression of @xmath44 as a function of the @xmath18 involves tensors of rank up to four and is even more complicated than the one for the expectation values ( [ expect ] ) , and the inverse matrix is yet more clumsy . for this reason we will discard choice 4 .  in the following .    in @xcite we considered an analysis at leading order in the @xmath18 , where one uses the linearised form of ( [ mean ] ) to estimate the couplings : @xmath51 \\right )   { \\hspace{6pt}.}\\ ] ] correspondingly the linear approximation of ( [ expect ] ) is used in the expression ( [ chi ] ) of @xmath47 which then reads @xmath52 where @xmath53 is the inverse covariance matrix of the estimated couplings @xcite . as one works to leading order in the @xmath18 one can approximate @xmath50 by its value for zero couplings , i.e.  choose possibility 3 .  above . the confidence regions @xmath54 for the measured couplings are then ellipsoids in the space of the @xmath18 with centre at @xmath55 . the optimal observables @xmath56 discussed in @xcite have the property that to leading order the statistical errors on the estimated couplings are the smallest possible ones that can be obtained with _ any _ method , including e.g.  a maximum likelihood fit to the full distribution of @xmath21 given by the differential cross section ( [ diffxsection ] ) . note that one can still use the linearised expressions ( [ linearestim ] ) and ( [ linearchi ] ) in an analysis beyond leading order . the error @xmath57 on the couplings will be given by an ellipsoid with defining matrix ( [ couplingscov ] ) , where @xmath50 is the covariance matrix at the actual values of the couplings . these errors will in general no longer be optimal , so that when the leading order approximation is not good one might obtain better errors with a different choice of observables . more importantly , however , the extracted values of the couplings are biased : averaged over a large number of experiments the measured couplings differ from the actual ones by terms quadratic in the @xmath18 . if instead one uses the full expressions ( [ expect ] ) , ( [ mean ] ) and ( [ chi ] ) one has no bias on the extracted coupling parameters , provided the number @xmath45 of events in the analysis is large enough . let us see if we can find optimal observables for this case . to this end we expand the differential cross section around some values @xmath58 of the couplings : @xmath59 the corresponding zeroth order cross sections and mean values are @xmath60 and @xmath61 = ( \\int d\\phi \\ , { { \\cal o}}_i \\widetilde{s}_0 ) / \\widetilde{\\sigma}_0 $ ] , respectively . we then can re - express @xmath27 $ ] in ( [ expect ] ) , replacing @xmath18 with @xmath62 , @xmath63 with @xmath64 , and using new coefficients @xmath65 etc . constructed as in ( [ xsectioncoeffs ] ) , ( [ obscoeffs ] ) . making the same replacements in ( [ mean ] ) we have an alternative set of equations to extract the coupling parameters . it can be shown that for sufficiently large @xmath45 the confidence regions obtained from ( [ chi ] ) , ( [ confidence ] ) in a nonlinear analysis are again ellipsoids given by @xmath66 one can then write @xmath67 as in ( [ linearchi ] ) , but with @xmath68 of ( [ couplingscov ] ) replaced by @xmath69 where @xmath70 corresponds to an expansion ( [ newdiffxsection ] ) of @xmath71 about the _ actual _ values of the couplings . the main point of the argument is that for large @xmath45 the statistical errors on the @xmath26 become small , so that the extracted couplings will be sufficiently close to the actual ones to allow for a linearisation of ( [ expect ] ) and ( [ mean ] ) , cf . @xcite , p.695 , and @xcite . finally one can construct new observables @xmath72 from ( [ newdiffxsection ] ) . they will be optimal , i.e.  have minimum statistical error if the @xmath58 are equal to the actual values of the @xmath18 . in the appendix we show that , up to linear reparametrisations given in ( [ reparam ] ) , this is the only set of @xmath41 integrated observables that measures the @xmath41 couplings with minimum error . there is hence no choice of observables that would be optimal for _ all _ values of the actual coupling parameters . as these are unknown one can in practice not write down the truly `` optimal '' observables , but our argument tells us how one can improve on the choice in ( [ optimal ] ) if one has some previous estimates @xmath58 of the couplings ( cf . also @xcite ) . one may then choose to perform a leading order analysis as described above , linearising about @xmath73 instead of @xmath74 . a practical way to proceed could be to estimate the parameters @xmath18 at first using the linearised method around @xmath75 . suppose this gives as best estimate some values @xmath76 . then in a second step one could set @xmath77 and use the linearised method around @xmath78 to improve the estimate etc .    at this point we wish to comment on the `` optimal technique '' for determining unknown parameters in the differential cross section that has been proposed in @xcite . the `` weighting functions '' @xmath79 there depend on the actual values of the parameters one wants to extract and are thus not `` observables '' . only if one sets the unknown parameters in the @xmath79 equal to some previous estimates of them can one use these functions to weight individual events ; the better these estimates are the more sensitive the functions will be . if one does this then the set @xmath79 is equivalent to our observables ( [ newoptimal ] ) defined for some estimates @xmath58 of the coupling parameters . we finally remark that if @xmath45 is not large enough the statistical errors on the mean values @xmath26 and thus on the measured couplings might be so large that they lead into a region where a linearisation of ( [ expect ] ) is not a good approximation . the covariance matrix @xmath80 is then no longer given by ( [ newcouplingscov ] ) . moreover the errors on the couplings might be asymmetric and the shape of the confidence region defined by ( [ chi ] ) , ( [ confidence ] ) very different from an ellipsoid , so that knowledge of @xmath80 is not sufficient to estimate the errors on the @xmath18 . in such a case we can not say on general grounds how sensitive our observables are . incidentally this also holds for other extraction methods such as maximum likelihood fits , whose optimal properties are realised in the limit @xmath81 . if one is rather far from this limit the sensitivity of a method will have to be determined by other means , e.g.  by detailed monte carlo simulations . the method we have outlined can of course also be applied if one chooses to reduce the number of unknown parameters by imposing certain linear constraints on the couplings . one may still use the observables ( [ optimal ] ) corresponding to the _ full _ set of couplings but minimise @xmath47 in ( [ chi ] ) for the _ reduced _ set ; in this case one can of course not take choice 2.for @xmath50 . in general @xmath82 is then different from zero and its value indicates to which extent the particular constraints on the couplings are compatible with the data . if @xmath45 is large enough @xmath82 follows in fact a @xmath47-distribution with @xmath83 degrees of freedom for @xmath41 observables and @xmath84 independent couplings so that its value can be converted into a confidence level @xcite . we conclude with a remark on the use of optimal observables in practice . a realistic data analysis will not be good enough if the born approximation of the differential cross section ( [ diffxsection ] ) is used . both higher - order theoretical corrections , such as initial state radiation and the finite @xmath2 width , and experimental effects like detection efficiency and resolution will modify the observed distribution of the phase space parameters @xmath21 . if they are taken into account in the determination of the coefficients in ( [ expect ] ) , ( [ mean ] ) and of the covariance matrix @xmath50 they will _ not _ lead to any bias in the extraction of the couplings and their errors . while this will presumably be done with sets of generated events and might be computationally intensive one still has to determine only a rather limited number of `` sensitivity '' constants . on the other hand one needs to know the observables @xmath25 of ( [ optimal ] ) as functions over the entire experimental phase space , so that the expressions of @xmath85 and @xmath86 used to construct them will in practice be taken from a less sophisticated approximation to the actual distribution of @xmath21 in order to keep them manageable . the observables are then no longer optimal , and it will depend on the individual case which approximations of @xmath85 , @xmath86 are good enough to obtain observables with a sensitivity close to the optimal one .      in @xcite it was shown how with a suitable combination of all semileptonic @xmath87 decay channels one can define observables that are either even or odd under the discrete transformations @xmath9 and @xmath88 , where @xmath89 denotes charge conjugation , @xmath90 the parity transformation , and @xmath91 the `` naive '' time reversal operation which flips particle momenta and spins but does not interchange initial and final state . under the conditions on the experimental setup and event selection spelt out in @xcite we have two important symmetry properties :    1 . a @xmath9 odd observable can only have a nonzero expectation value if @xmath9 symmetry is violated in the reaction . 2 .   if the expectation value of a @xmath88 odd observable is nonzero the transition amplitude must have an absorptive part whose phase must satisfy certain requirements in order to give an interference with the nonabsorptive part of the amplitude . we assume in this analysis that any nonstandard physics in the reaction is due to the triple gauge vertices . in the standard model one needs at least two loops to violate @xmath9 ; to a good accuracy the triple gauge couplings are therefore the only possible source of @xmath9 violation . for our process , i.e.  @xmath3 annihilation into four fermions , an absorptive part that satisfies the requirements mentioned in point 2 .  will appear in the standard model already at next - to - leading order in the electroweak fine structure constant , either through nonresonant diagrams or through loop corrections . to leading order , however , they are only due to the imaginary parts of triple gauge couplings .    in this approximation the optimal observables ( [ optimal ] ) are @xmath9 even ( odd ) if they correspond to @xmath9 conserving ( violating ) couplings , and @xmath88 even ( odd ) if they correspond to the real ( imaginary ) parts of form factors . the coefficient matrix @xmath92 is then block diagonal in four symmetry classes of observables and three - boson - couplings :    1 . @xmath9 and @xmath88 even 2 . @xmath9 even and @xmath88 odd 3 . @xmath9 odd and @xmath88 even 4 . @xmath9 and @xmath88 odd .    in the leading order analysis one thus can treat these four classes of couplings separately and benefit from a great reduction of unknown parameters . beyond leading order , however , form factors of any symmetry can contribute to @xmath27 $ ] :    * in the integrated cross section and thus in the denominator of @xmath27 - e_0[{{\\cal o}}_i]$ ] in ( [ expect ] ) couplings of all four classes enter quadratically , couplings of class @xmath93 also appear linearly ; * if @xmath28 belongs to class @xmath93 the numerator of @xmath27 -    e_0[{{\\cal o}}_i]$ ] has terms linear in the couplings of this class but couplings of all four classes enter quadratically through @xmath94 ; * if @xmath28 belongs to a @xmath9 ( @xmath88 ) odd coupling then the numerator in ( [ expect ] ) is only linear in @xmath9 ( @xmath88 ) odd couplings , but it contains also quadratic terms where a @xmath9 ( @xmath88 ) odd coupling is multiplied with a @xmath9 ( @xmath88 ) even one . we remark that this leads to different behaviours of @xmath27 $ ] as one or more couplings @xmath18 become large : whereas for observables in classes @xmath95 , @xmath96 and @xmath97 the expectation value goes to zero when a coupling of the same class goes to plus or minus infinity the corresponding limit of an observable in class @xmath93 can be a positive or negative constant or zero .    in a nonlinear analysis one will therefore in principle have to consider couplings with all symmetries at the same time . in practice one might choose simpler procedures if the linear approximation is expected to be not too bad and if one wants to calculate corrections to it . one might for instance first analyse the four symmetry classes separately , neglecting in each case the contributions of the three other classes at the r.h.s . of ( [ mean ] ) and then refine the analysis of a class by taking the values obtained in the first step for the couplings in the other classes as fixed in ( [ mean ] ) .    we emphasise that even beyond the leading order approximation it is still true that a nonzero mean value of a @xmath9 or a @xmath88 odd observable is an unambiguous sign of @xmath9 violation or the presence of absorptive parts in the process , respectively . the extraction of the values of the couplings , however , becomes more involved than in leading order . we shall now propose a method to analyse the data which presents several advantages in view of the basic problem posed by the large number of unknown three - boson couplings : with limited event statistics significant error bounds can only be obtained for subsets of the coupling parameters , but imposing constraints on the couplings to reduce their number entails a loss of information that can not be retrieved . in view of this it should be advantageous to use a parametrisation of the couplings which in a given process and at a given c.m . energy has the following properties :    1 . it allows to find observables which are only sensitive to one particular coupling parameter . 2 .   the induced errors on the couplings determined from these observables are statistically independent . with this we can on the one hand give single errors for each parameter , on the other hand we can recover from the single errors the multidimensional error of the full set of couplings , having avoided the loss of information incurred by imposing constraints . from the single errors we can also directly see which combinations of couplings in more conventional parametrisations can be measured with good accuracy and to which one is rather insensitive . let us remark that in the leading order analysis there is a set of observables satisfying point 1 .  in _ any _ parametrisation of the couplings . the linear combinations @xmath98 of our optimal observables ( [ optimal ] ) are only sensitive to @xmath18 for each @xmath99 ( cf .  also @xcite ) . the errors on the couplings determined from these observables are , however , in general not uncorrelated ; in fact their correlations are the same as those obtained with the original set @xmath28 . this can be seen as follows : going from the @xmath28 to the @xmath100 we must replace @xmath101 so that we have from ( [ couplingscov ] ) @xmath102 in such a case the single errors give an incomplete picture of the situation if correlations are large . this is illustrated in fig . [ fig : correlations ] @xmath93 , where the 1@xmath103 ellipsis for two parameters is shown . their single errors are given by its projection on the coordinate axes and in our example are both rather large . some linear combinations of them are however measurable with much better precision , which one can only recognise if both errors and their correlations are given . in fig . [ fig : correlations ] @xmath95 where a set of couplings leading to uncorrelated errors is used the situation is much simpler . note also that the number of correlations , i.e.  off - diagonals in @xmath80 , is yet modest for two couplings but increases rapidly with their number . ( 0,0 )    ( 5502,3031)(889,-4805 ) ( 1981,-2401)(0,0)[lb ] ( 5131,-2401)(0,0)[lb ] ( 6391,-3706)(0,0)[lb ] ( 3241,-3706)(0,0)[lb ] ( 1116,-2006)(0,0)[lb ] ( 4176,-2006)(0,0)[lb ]    we will now first see that a parametrisation of the couplings satisfying both points 1 .  and 2 . above can be found in idealised circumstances , and then mention the restrictions one will encounter under more realistic assumptions . if the leading order analysis is a sufficiently good approximation the solution to our problem is easily found . starting from a set of couplings @xmath18 and the corresponding optimal observables @xmath28 in ( [ optimal ] ) we can go to another set @xmath104 by @xmath105 where we use vector and matrix notation . the coefficients in the expansion of the differential cross section and the optimal observables transform as follows : @xmath106 let now @xmath28 be an arbitrary set of observables related to @xmath18 and define the corresponding @xmath107 related to @xmath104 as in ( [ obstransf ] ) . then we have for the matrices relevant for our analysis the following transformation properties : @xmath108 as shown in @xcite our optimal observables satisfy @xmath109 and @xmath110 so that for them one can choose a transformation @xmath111 which diagonalises all three matrices . this new set @xmath112 of parameters obviously has the properties 1 .  and 2 . we were looking for .    beyond the linear approximation of ( [ expect ] ) the expectation value of @xmath107 will still receive contributions from several couplings . in fact there is no set of observables for which the full nonlinear expression in ( [ expect ] ) satisfies point 1 . exactly , because the denominator involves quadratic terms in _ all _ couplings , and this can not be changed by any linear transformation of the couplings . if on the other hand the statistical errors are too large the covariance matrix @xmath80 will not give a good picture of the errors as we discussed in sec . [ sec : method ] , and its diagonalisation will not ensure point 2 . in the case however where nonlinear effects in the determination of the couplings and their errors are not too large , i.e.  where the leading order expressions are a good first approximation both points 1 .  and 2 . above will still be _ approximately _ satisfied in a full nonlinear analysis . we remark that if one has some previous estimates @xmath58 of the couplings that considerably deviate from zero one may reduce nonlinear effects in the determination of the @xmath18 by working with an expansion of @xmath113 around the @xmath58 as shown in sec . [ sec : method ] ; in our diagonalisation programme one will then use couplings @xmath114 instead of @xmath18 , the matrix @xmath70 instead of @xmath115 etc .    to the extent that the observables ( [ optimal ] ) are constructed from expressions of @xmath85 and @xmath116 which are only approximations of those that determine the experimentally observed kinematical distribution the matrices @xmath115 , @xmath50 and @xmath117 will not quite be the same and can not be diagonalised at the same time . one can then diagonalise either @xmath50 or @xmath68 because they are by definition symmetric and positive definite , whereas @xmath115 is not necessarily so . again , unless such effects are large one will end up with a matrix @xmath118 that is not diagonal but has relatively small off - diagonals .    it should also be borne in mind that the covariance matrix @xmath80 only gives the statistical errors on the couplings , so that even if it is exactly diagonal the final errors may be correlated due to systematics .      the choice of transformation in ( [ couplingstransf ] ) to ( [ matrixtransf ] ) is not unique if one does not require @xmath111 to be orthogonal . we see in fact no strong argument in favour of an orthogonal transformation and remark that the various parametrisations of the @xmath1 and @xmath0 couplings in the literature are related by non - orthogonal linear transformations . the freedom to choose @xmath111 can be used to impose additional conditions on the transformation , and the one we propose here is that the transformed quadratic coefficient @xmath119 in the integrated cross section be the unit matrix . in terms of the new couplings one then has @xmath120 where we choose the numbering such that @xmath121 to @xmath122 belong to symmetry class @xmath93 introduced in sec . [ sec : symmetries ] , i.e.   they are the @xmath9 and @xmath88 even couplings . only these appear linearly in the cross section , whereas all couplings give a quadratic contribution with coefficient one . having @xmath123 leads to a convenient simplification of ( [ expect ] ) , ( [ mean ] ) . moreover , the measurement of the total cross section gives complementary information on the unknown couplings . rewriting ( [ xsectransf ] ) as @xmath124 we see that measuring a cross section @xmath125 within an error @xmath126 constrains the couplings to be in a shell between two hyperspheres with centre at @xmath127 in the space of all couplings as shown in fig . [ fig : shell ] . their radii are given by @xmath128 here @xmath129\\ ] ] is the smallest value the cross section can attain ; that such a minimum exists has been pointed out in @xcite . if in ( [ radii ] ) @xmath130 is positive but @xmath131 negative the couplings are inside the hypersphere with radius @xmath132 , and if both @xmath130 and @xmath131 are negative the ansatz ( [ diffxsection ] ) for the cross section is inconsistent with the data within the error @xmath126 . ( 0,0 )    ( 4647,3843)(1339,-5473 ) ( 4231,-3391)(0,0)[lb ] ( 2611,-1726)(0,0)[lb ] ( 5986,-3661)(0,0)[lb ] ( 3401,-3796)(0,0)[lb ] ( 3601,-3166)(0,0)[lb ]    such constraints can be useful to find the physical set of couplings when the solution of ( [ mean ] ) from the measurement of the optimal observables is not unique . if they are strong enough they might even restrict the couplings to the region where ( [ mean ] ) can be linearised and thus simplify their extraction . one can of course use the information from the integrated cross section working with any set of couplings , but again the situation is particularly simple with the form ( [ xsectransf ] ) . we note that the information from the total rate is complementary to what is extracted from the mean values of our observables , which involve normalised kinematical distributions . from an experimental point of view their respective measurements will presumably have quite different systematic errors . let us also recall that the the measurement of the mean values @xmath26 times the number @xmath45 of events obtained with a fixed integrated luminosity combines the information of both @xcite . a nonlinear data analysis as presented in sec . [ sec : method ] can also be done in this case . we draw attention to the fact that unphysical solutions of equation  ( [ mean ] ) for @xmath26 and of its analogue for @xmath133 will in general be different . we shall however not elaborate on this point here . another aspect of the couplings with the property ( [ xsectransf ] ) is the following . it is well known that constant coupling parameters deviating from the standard model tree level values lead to amplitudes that violate unitarity @xcite . the coefficients @xmath134 and @xmath135 in the total cross section @xmath103 increase strongly with the @xmath3 c.m . energy @xmath136 and the couplings @xmath18 must vanish as @xmath8 becomes large to ensure a decent high - energy behaviour of @xmath103 . in our new parametrisation the quadratic coefficients in @xmath137 are energy independent , and in this sense the new couplings are at a `` natural scale '' at every energy .    to complete this section we show that a transformation with the properties we require always exists , i.e.  that we can find a matrix @xmath111 that diagonalises @xmath68 in ( [ matrixtransf ] ) and transforms @xmath138 in ( [ quadrattransf ] ) to the unit matrix . the argument is analogous if one replaces @xmath68 with @xmath50 . by construction both @xmath68 and @xmath138 are symmetric and positive definite , so our problem is the same as finding normal coordinates for a multidimensional harmonic oscillator in classical mechanics ( cf . e.g.  @xcite ) . to make this analogy transparent let us write @xmath139 and @xmath140 ; we then have to find @xmath111 so that @xmath141 with @xmath142 being diagonal . the elements @xmath143 of @xmath142 are generalised eigenvalues of @xmath144 satisfying @xmath145 where @xmath146 is the @xmath99-th column vector of @xmath111 . the solution is well known to be @xmath147 where @xmath148 is the orthogonal matrix that transforms @xmath149 to @xmath142 . of course one need not use ( [ solution ] ) in practice as there are convenient algorithms available to find @xmath111 and @xmath142 . in our numerical calculations we have used the routine ` eigenvals ` of the algebraic package maple . we will now give some numerical examples of our method described in the previous section . in this section we will stay within the framework of a leading order analysis of the observables . we start from the results in @xcite , where the sensitivity of optimal observables for semileptonic @xmath150-decays was calculated . we assume a full kinematical reconstruction of the final state , except for the ambiguity one is left with if the jet charge is not known . for the standard model cross section we use the born approximation and neglect effects of the finite @xmath2 width . to describe the triple boson couplings we take the form factors @xmath151 , @xmath152 ( @xmath153 ) of @xcite ; deviations from their standard model tree level values will be referred to as `` anomalous couplings '' . let us first look at a c.m . energy of @xmath12 , which will be attained at lep2 . the coefficient matrix @xmath115 can be found in table  4 of @xcite and in table  [ tab : coeff190 ] here we give the diagonal elements of the transformed matrix @xmath118 , ordered according to the symmetry of the corresponding observables . the one standard deviation ellipsoid is diagonal in the couplings @xmath104 , thus its intersections with the coordinate axes equal its projections on these axes . the errors @xmath154 setting all other @xmath155 to zero are then equal to the errors @xmath156 where all other @xmath155 are arbitrary . they are given by @xmath157 and are listed in table  [ tab : sens190 ] for an integrated luminosity of @xmath13 . we immediately remark that a negative diagonal element occurs in the transformed coefficient matrix , which is not allowed because @xmath158 is a covariance matrix and thus positive definite . we encounter here a problem of numerical instability : small errors in the calculation of the original matrices @xmath115 and @xmath138 can have a large effect on the smallest generalised eigenvalues @xmath159 and their eigenvectors , even to the point that eigenvalues come out with the wrong sign . this is not only a problem of our particular way of diagonalisation , but also occurs if one diagonalises @xmath115 with an orthogonal matrix ; we find that one of the usual eigenvalues of @xmath115 in the subspace of couplings with symmetry @xmath95 is negative . such instabilities can cause large errors in the matrix inversion of @xmath115 and @xmath50 . one needs @xmath160 to calculate the error on the extracted couplings as can be seen from ( [ chi ] ) and ( [ couplingscov ] ) , and large errors on @xmath161 can lead to large uncertainties in the extracted couplings , irrespective of whether @xmath161 is explicitly used to solve the system ( [ mean ] ) . one will of course aim to calculate @xmath115 and @xmath50 with best possible precision , but such an effort has limits , in particular if they are determined from simulated events and include for instance radiative corrections or detector effects . on a more fundamental level any calculation of these matrices will only be an approximation of the `` exact '' ones that correspond to the kinematical distributions seen in experiment . in this sense it seems quite inevitable that small eigenvalues ( the usual or our generalised ones ) of @xmath115 and @xmath50 and their eigenvectors are sensitive to imprecisions in the calculation and can lead to large errors or uncertainties in the data analysis . this holds of course even if one does not obtain eigenvalues with the wrong sign . we think that also in view of this a diagonalisation is useful , not because it solves the problem but because it makes it explicit ! it allows to easily identify those combinations of couplings which have small corresponding eigenvalues in @xmath115 and @xmath50 and will be the most unsafe ones in the analysis . from ( [ onesigma ] ) we see that they are those combinations for which the statistical errors will be largest . here the most unsafe coupling parameter is @xmath162 . one might thus choose to exclude it , and possibly other couplings , from the analysis and work in the remaining subspace of the @xmath104 where the numerics is more stable and where in any case the experiment is most sensitive . we will come back to this in sec . [ sec : practice ] . .[tab : lr190]diagonal elements @xmath159 of the coefficient matrix restricted to the left or right handed subspace of the couplings as explained in the text . the values in the left handed subspace differ from the corresponding ones in table 1 by at most 3% . [ cols=\"^ , > , > , > , > , > , > , > , > \" , ]     crrrrrrrrr & & & + @xmath93 & 1.4 & 1.1 & 0.72 & 0.63 & & 0.50 & 0.17 & 0.062 & 0.044 + @xmath95 & 1.3 & 1.0 & 0.79 & 0.26 & & 0.11 & 0.083 & 0.023 & @xmath163 + @xmath96 & 1.2 & 0.58 & 0.32 & & & 0.076 & 0.031 & 0.013 & + @xmath97 & 1.4 & 1.0 & 0.83 & & & 0.24 & 0.040 & 0.026 & +    finally we remark that like in the case for @xmath12 those couplings @xmath104 which give the largest statistical errors in the optimal observable analysis are predominantly related to right handed combinations of form factors as can be seen from the comparison of tables  [ tab : coeff500 ] and [ tab : lr500 ] . let us sketch how our method of simultaneous diagonalisation might be used in practice .    1 . one first has to choose which matrix to diagonalise simultaneously with @xmath138 . these matrices need not be the same ones to be used in the data analysis itself but may be calculated under further approximations . covariance matrices for the observables and extracted couplings can be evaluated for zero @xmath18 as our entire procedure will only have its desired properties if nonlinear effects are not too large . if one uses the same approximation of the differential cross section ( [ diffxsection ] ) for the construction of the optimal observables ( [ optimal ] ) and the calculation of @xmath115 , @xmath50 and @xmath117 then the latter are all equal and can be diagonalised at the same time . otherwise one has to choose a positive definite symmetric matrix for the diagonalisation , i.e.  one of the covariance matrices . the calculation of @xmath80 or of its inverse from ( [ couplingscov ] ) involves however a matrix inversion and might suffer from numerical instabilities , so presumably the best choice will be @xmath50 . 2 .   in the next step one carries out the simultaneous diagonalisation of the chosen matrix and @xmath138 as described in sec . [ sec : simultan ] and determines the transformation matrix @xmath111 in ( [ couplingstransf ] ) to ( [ matrixtransf ] ) . at this point it will be useful to test the numerical stability of the transformed matrices , for instance by re - calculating them in the new basis of couplings or by repeating the diagonalisation procedure with slightly modified initial matrices . one might choose to discard some of the new couplings @xmath104 and the corresponding observables from the analysis if the corresponding matrix elements are found to be instable . this does not mean that one has to set these couplings to zero . from the measurement of the total cross section one will obtain limits on them , which will also allow to control the contribution they can give to the mean values of those observables that are kept in the analysis because the matrix @xmath118 is not exactly diagonal and because of nonlinear terms in ( [ mean ] ) . 3 .   in the new parametrisation of the couplings one then carries out the analysis of the data . here @xmath164 , @xmath118 , @xmath165 and the other coefficients in ( [ expect ] ) will be determined under the most realistic assumptions and with the best precision one can afford . they will not be exactly diagonal in practice , but should have small off - diagonal elements if the approximations made in step 1 .  and in the construction of the optimal observables are sufficiently good . 4 .   one can then give both single and multidimensional errors on the measured coupling parameters @xmath104 . at this stage one can also present the results in other , more conventional parametrisations of the couplings and in particular compare with the measurements of other experiments , restricting oneself to whatever subspace of couplings might have been chosen there . in the first part of this paper we have shown how to extract coupling parameters from the measured mean values @xmath26 of appropriate observables without the approximation that the couplings are small . errors on the couplings can be obtained from a @xmath47-fit of the @xmath26 . if one puts constraints on the couplings in order to reduce their number the method also gives an indication of how compatible these constraints are with the data . the `` optimal observables '' discussed in @xcite have statistical errors equal to the smallest possible ones to leading order in the coupling parameters @xmath18 . beyond the leading order approximation one can obtain more sensitive observables if one has some previous estimate @xmath58 for the couplings , expanding the differential cross section around @xmath58 instead of zero and constructing observables from the corresponding expansion coefficients . in the appendix we show that up to linear reparametrisations the choice of optimal observables is unique : any other set of observables must give bigger ( statistical ) errors .    in a second part we have proposed to perform the data analysis using a particular parametrisation @xmath104 of the couplings , which is specific to the process and its c.m .  energy . it is obtained from the initial set @xmath18 by a linear transformation which diagonalises the covariance matrix @xmath50 of the observables and transforms the matrix @xmath138 of quadratic coefficients in the integrated cross section ( [ intxsection ] ) to unity . in an idealised framework each optimal observable @xmath107 for this parametrisation is only sensitive to one coupling , and the statistical errors on the extracted couplings are uncorrelated . under realistic circumstances both properties can be approximately satisfied provided that the analysis stays in a region of parameter space where the dependence of the mean values @xmath166 on the couplings is not far from linear . various matrices are then approximately diagonal which should generally facilitate the data analysis . in particular one can directly give errors on single or a small number of couplings , which will be necessary to obtain statistically significant results with a limited number of events . at the same time one can readily present multidimensional errors in parameter space , which is essential to compare with the results of measurements that impose various different constraints on the couplings . having approximately diagonal matrices also allows to easily identify those directions in parameter space which can be measured best and those for which the statistical errors will be large and which are likely to be associated with numerical instabilities , for example in matrix inversions . one can thus recognise and seek to remedy such problems in an early stage of the analysis . the measurement of the total cross section @xmath103 gives valuable complementary information on the coupling parameters . its dependence on the couplings is particularly simple in the parametrisation we propose since the quadratic contributions are @xmath167 times the standard model cross section @xmath168 , i.e.  they have the same form for all couplings . a measurement of @xmath103 will then restrict the @xmath104 to a shell between two hyperspheres in parameter space . we have given some numerical examples of our method applied to the semileptonic decay channels in @xmath4 . in particular we find that the couplings @xmath104 which can be measured best with unpolarised beams predominantly appear in the amplitude for left handed electrons ( or right handed positrons ) , and that the @xmath104 with the largest statistical errors mainly correspond to the opposite lepton helicity . comparing our results at lep2 and lc energies we see that the coefficients in the linear contributions of the couplings @xmath104 to our observables and to the integrated cross section change much less with energy than in usual parametrisations . this is because in the new parametrisation the quadratic coefficients in the normalised cross section @xmath169 are by construction energy independent . we would like to thank ch . hartmann and m.  kocian for their continued interest in optimal observables for triple gauge couplings . we gratefully acknowledge discussions with and remarks by j.  blmlein , p.  overmann , n.  wermes , , and p.  m.  zerwas . this work has in part been financially supported by the eu programme `` human capital and mobility '' , network `` physics at high energy colliders '' , contracts chrx - ct93 - 0357 ( dg 12 coma ) and erbchbi - ct94 - 1342 , and by bmbf , grant . it was started while one of us ( md ) was at the university of cambridge , and we acknowledge support by the arc programme of the british council and the german academic exchange service ( daad ) , grant 313-arc - viii - vo / scu , which made mutual visits of the cambridge and heidelberg groups possible . in this appendix we show that the set of observables ( [ newoptimal ] ) , obtained from expanding the differential cross section about the actual values of the couplings , is unique in the sense that up to the linear reparametrisations ( [ reparam ] ) it is the only set of @xmath41 integrated observables which in the limit of large @xmath45 leads to the minimum error on the @xmath41 extracted parameters .    to keep our notation simple we give the proof for the case that the actual values of the @xmath18 are zero . the expectation value and covariance of functions @xmath34 and @xmath35 are then given by @xmath170 = \\frac{\\int d\\phi \\ , f(\\phi )   s_0(\\phi)}{\\int d\\phi \\ , s_0(\\phi ) }   { \\hspace{6pt},}\\hspace{3em }    v_0[f , g ] = e_0[f g ] - e_0[f ] \\ , e_0[g ]   { \\hspace{6pt}.}\\ ] ] in the general case one has instead of @xmath85 the zeroth order coefficient @xmath171 ( [ newdiffxsection ] ) from the expansion about the appropriate values @xmath58 .    for large @xmath45 the covariance matrix for the extracted couplings is given by ( [ couplingscov ] ) . under a linear reparametrisation of observables , @xmath172 where @xmath173 and @xmath174 are constants and the matrix @xmath173 is nonsingular , the matrices @xmath115 from ( [ obscoeffcompact ] ) and @xmath50 transform according to @xmath175 from ( [ couplingscov ] ) we see that the covariance matrix @xmath80 is unchanged under such a transformation . for our proof we can hence restrict ourselves to observables with mean value @xmath176 = 0\\ ] ] and with a coefficient matrix @xmath177 . from ( [ obscoeffcompact ] ) we then have the condition @xmath178 = \\delta_{ij}\\ ] ] and the error on the extracted couplings is given by @xmath179   { \\hspace{6pt}.}\\ ] ]    from @xcite we know that the optimal observables ( [ optimal ] ) lead to the smallest possible error on the @xmath18 , given by the cramr - rao bound . to satisfy our conditions ( [ centred ] ) and ( [ normalised ] ) we take the linear combinations @xmath180    \\right)\\ ] ] with @xmath181   { \\hspace{6pt}.}\\ ] ] we assume that the functions @xmath86 are linearly independent . otherwise some of the parameters @xmath18 are superfluous and can be eliminated ; our assumption is thus that the @xmath18 are an independent set of parameters for the anomalous couplings . linear independence of the @xmath182 guarantees that @xmath183 is nonsingular , which has tacitly been used at several instances in our paper . the set @xmath184 is related to the optimal observables @xmath185 by a linear transformation ( [ reparam ] ) and thus gives the same optimal error matrix @xmath80 . the covariance @xmath186 $ ] defines a scalar product on the hilbert space @xmath187 of sufficiently smooth functions of @xmath21 with the property @xmath188 = 0 $ ] . the functions @xmath184 span a subspace @xmath189 of @xmath187 , and we define @xmath190 as the orthogonal complement of @xmath189 with respect to the scalar product @xmath33 $ ] . any set of @xmath41 observables satisfying ( [ centred ] ) can then be written as @xmath191 with @xmath192 , @xmath193 . further decomposing @xmath194 and using the constraint ( [ normalised ] ) we obtain @xmath195 , i.e.@xmath196 finally , we have from ( [ simplecov ] ) , ( [ decompose ] ) , ( [ first ] ) @xmath197 +                n^{-1 } v_0[{{\\cal o}}^{\\it ii}_i , { { \\cal o}}^{\\it ii}_j ]   { \\hspace{6pt}.}\\ ] ] the first term gives the error on the couplings for the optimal observables @xmath184 , which is minimal . if the observables @xmath28 have minimal error , too , the second term must be zero , so that for each @xmath99 we have @xmath198 = 0 $ ] and thus @xmath199 which completes our proof .    in sec . [ sec : simultan ] we mentioned that instead of @xmath26 one may use the product @xmath200 measured with fixed luminosity to extract the couplings @xcite . by an argument analogous to the one of this appendix one finds that up to linear reparametrisations our observables ( [ newoptimal ] ) are again the only optimal ones . in this case linear reparametrisations have to be homogeneous , i.e.  one must have @xmath201 in ( [ reparam ] ) , since adding constants to the observables can change the induced errors on the coupling parameters . g. gounaris et al . , `` triple gauge boson couplings '' , report of the `` triple gauge couplings '' working group during the lep2 workshop 19941995 , hep - ph/9601233 , in _ physics at lep2 _ , vol .  1 , g.  altarelli and f.  zwirner eds . , cern report 1996 , and references therein          p. overmann , dortmund preprint do - th 93/24 ; + w. bernreuther , g. w. botz , d. bru , p. haberl and o. nachtmann , z.  phys . c68 ( 1995 ) 73 ; + d. bru , o. nachtmann and p. overmann , `` cp violation in radiative @xmath7 decays '' , univ . heidelberg report hd  thep9702 ( 1997 ) r. akers et al . ( opal coll . ) , z.  phys . c66 ( 1995 ) 31 ; + a. stahl , nucl . b ( proc .  suppl . ) 40 ( 1995 ) 505 ; + aleph coll . , `` search for cp violation in the decay @xmath202 '' , paper contributed to the ichep96 conference , warsaw , 2531 july 1996 , report pa 08 - 030 ; + delphi coll . , `` improved test of cp - violation in @xmath203 using optimized observables '' , paper contributed to the ichep96 conference , warsaw , 2531 july 1996 , report pa 07 - 014 ( 1996 ) ; + n. wermes , `` cp tests and dipole moments in @xmath204-pair production experiments '' , talk given at tau96 workshop , estes park , colorado , usa , 1619 september 1996 , report bonn - he-96 - 10", "tags": [], "output_text_a": "This paper discusses the measurement of self-coupling between electroweak gauge bosons in W-pair production, which is crucial for testing the Standard Model and exploring new physics. The study focuses on the challenges of extracting coupling parameters due to the large number of potential parameters and limited event statistics at LEP2 and future linear colliders. The authors propose a parametrization of couplings that minimizes statistical errors and allows for independent extraction of parameters using optimal observables. They extend the method beyond the linear approximation and discuss the application of their approach to W-pair production, particularly in semileptonic decay channels. The paper also addresses the use of symmetry properties to reduce the number of parameters and the importance of considering both the total cross section and detailed final state distributions. Numerical examples are provided for LEP2 and linear collider scenarios, highlighting the advantages of the proposed method in achieving uncorrelated errors and identifying the most sensitive coupling combinations. The study emphasizes the need for a careful analysis to avoid biases and ensure accurate extraction of coupling parameters.", "output_text_b": "This arXiv paper discusses the measurement of self-coupling between electroweak gauge bosons in @xmath2-pair production, which is crucial for testing the Standard Model and searching for physics beyond it. The paper focuses on the physics program at LEP2 and a planned linear @xmath3-collider (LC). The authors propose a parametrization of the couplings for this process, which is well-adapted to the framework of optimal observables. They also investigate the reaction @xmath11, specifically the decay channels where one @xmath2 decays hadronically and the other into an electron or muon and its neutrino.\n\nThe authors propose a parametrization of the couplings that simultaneously diagonalizes certain matrices connected with their observables and the integrated cross section. These parameters achieve two goals: their quadratic contribution to the total cross section is a simple sum of squares, and the covariance matrix of the corresponding optimal observables is diagonal.\n\nThe paper also discusses the method of optimal observables, which is used to extract unknown coupling parameters. This method is presented beyond the approximation that the couplings are sufficiently small, which was used in previous work.", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the measurement of self-coupling between electroweak gauge bosons and the proposed parametrization method.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of extracting coupling parameters in W-pair production.\n4. **Methodology**: The summary mentions the methodology of using a parametrization of couplings and optimal observables.\n5. **Significant Results**: The summary includes significant results, such as minimizing statistical errors and achieving uncorrelated errors.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"optimal observables.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions the application to W-pair production and scenarios at LEP2 and linear colliders.\n10. **Significance**: The summary reflects the paper's significance in testing the Standard Model and exploring new physics.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the measurement of self-coupling between electroweak gauge bosons and the proposed parametrization of couplings.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of testing the Standard Model and searching for physics beyond it.\n4. The methodology of using optimal observables and parametrization of couplings is mentioned.\n5. Significant results, such as the diagonalization of matrices and the method of optimal observables, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"optimal observables\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research.\n10. The paper's significance in testing the Standard Model and its potential impact is implied but not explicitly stated."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "while atomic hydrogen ( hi ) , generally seen in emission , is certainly a pervasive component of the galaxy , our knowledge of its optical depth ( @xmath2 ) and spin temperature ( @xmath3 ) close to the galactic plane is sparse . the main reason for this is the difficulty inherent in disentangling the emission along most sight - lines ( kulkarni & heiles 1988 ) . use of absorption towards extragalactic sources has proved somewhat successful but has not been entirely satisfactory at low galactic latitudes . the plane is peppered with bright regions which could potentially be used . wendker & wrigge ( 1996 ) studied the absorption spectrum towards dr 7 as seen using the dominion radio astrophysical observatory s ( drao ) synthesis telescope ( st ) and argued for the usefulness of such observations for the determination of optical depth and spin temperature as a function of radial velocity ( or distance ) . the authors suggested that the careful study of many lines of sight will contribute to the quasi mapping of @xmath2 and @xmath3 , although for at velocities corresponding to gas in the proximity of the regions , it is important to bear in mind that some of the absorbing material may have been dissociated by the central stars , thus presenting local enhancements which are not typical of the general surroundings . this paper contributes a second line - of - sight towards a strong , extended continuum source within our galaxy : the w3 complex , shown in figure  [ fig : w3c21 ] . the w3 region has been studied in detail repeatedly and at many frequencies ( see e.g.  roberts , crutcher & troland 1997 for molecular line observations ; tieftrunk et al . 1997 for a multiwavelength radio continuum study ; roelfsema & goss 1991 for radio recombination lines ; campbell et al . 1995 for a far - infrared look at subcomponents ; and hofner & churchwell 1997 for x - ray ) . it houses active star formation and can be subdivided into multiple regions for which the nomenclature varies somewhat with the type of observations . table  [ tb : nomen ] defines the terminology used in this paper . studies of sight - lines towards w3 have concentrated on searching for atomic gas associated with the regions . while the limited spatial and spectral resolution of data presented by sullivan & downes ( 1973 ) precluded the detection of variations in opacities , observations with the nanay telescope led crovisier et al.(1975 ) to conclude that the absorption near 40  ( all velocities in this paper are with respect to the local standard of rest ) is due to atomic hydrogen related to w3 . read ( 1981 ) carried out a detailed study of the in this region in both emission and absorption ; his data had similar spatial resolution to the drao data presented here and somewhat poorer velocity resolution ( 4 ) . he suggested that photodissociation of molecular gas near the compact regions is responsible for several observed concentrations . goss et al .  ( 1983 ) and van der werf & goss ( 1990 ) used the westerbork synthesis radio telescope ( wsrt ) and so had better spatial resolution ( @xmath4 and @xmath5 ) than obtainable with the smaller drao array , as well as better velocity resolution ( 1.24  and 1.03 ) , but they do not provide full visibility plane coverage and so are not sensitive to emission on all angular scales . they also concluded that much of the at @xmath6 is due to dissociation and delineate shells associated with various compact regions . the above authors presented studies of the w3 complex itself and therefore concentrated on which may be related to it , i.e.  their focus was the absorption near 40 . the present paper uses sight lines towards w3 to probe the interstellar medium between us and this region , evaluating optical depths and spin temperatures , and placing it in a galactic perspective . section 2 briefly describes the data sets which were used in this analysis . section 3 gives an overview of the profiles towards w3 , placing their features in the context of rotation curves and spiral shocks , as well as outlining the method used to derive the optical depths and spin temperatures . the fourth section provides a more detailed discussion of optical depths and spin temperatures at different velocities . and finally , the last section summarises the findings . radio continuum data at both 408 mhz and 1420 mhz , as well as 21 cm spectral line data were obtained at the drao as part the canadian galactic plane survey ( cgps ) pilot project . the pilot project covered an @xmath7 area of the sky , encompassing all of the w3/w4/w5/hb3 galactic complex . observations were carried out in june , july , november and december of 1993 . the synthesis telescope is a 7-element interferometer with four fixed and three movable antennas , each with a diameter of @xmath09 m. in the course of twelve 12-hour periods , observations are taken for all baselines from 12.858 to 604.336 m by increments of 4.286 m. at 1420 mhz , the small dish size results in a field of view of 78 arcmin ( at 20% attenuation of the primary beam which is approximated by a gaussian ) , the longest spacing gives a spatial resolution of @xmath8 arcmin@xmath9 ( ew @xmath10 ns ) , and the shortest baseline means that the instrument is not sensitive to structures greater than 0.5  in extent . the spectral line data were collected by a 128-channel spectrometer with a channel width of 2.64  and a channel separation of 1.649 . the sensitivity at field centre for the st data is 3.0 k and degrades with distance from the centre as the inverse of the primary beam . for channels where the continuum emission from w3 is strongly absorbed there are processing artefacts from w3 . information about the lowest spatial frequencies ( i.e.  large angular sizes ) was provided by the drao s 26 m telescope , and as a result the images are sensitive to structures on all scales . relevant observational parameters are outlined in table  [ tb : obs_param ] . details of the observations and data reduction are described by normandeau et al . ( 1997 ) . continuum emission was subtracted from the images . while the drao synthesis telescope collects continuum data at 1420 mhz using four 7.5 mhz bands , two to each side of the line frequency , the resulting image was not used to subtract the continuum . instead an average was taken of channels where there was no apparent , the first and last twenty channels corresponding to velocities between + 55 and + 24  and between 137 and 154 . this allows for a more precise subtraction of the continuum emission for three reasons : 1 ) the drao spectrometers are equipped with automatic level control which adjusts the gain in order to minimise information loss due to quantization whereas the continuum system is not , and the uncertainty of the gain correction factor would decrease the reliability of images ; 2 ) the difference in bandwidth between a spectrometer channel and the continuum receiver results in differing amounts of bandwidth smearing in the images , making the subtraction of continuum sources progressively worse with distance from field centre ; 3 ) using the end channels insures that the visibility plane coverage is identical for all the maps involved in the operation , thus allowing a more accurate subtraction of any artefacts related to strong sources . however , the continuum brightness temperature values used in the optical depth calculations ( see below ) were from the true continuum image . the most prominent absorption features in the cgps pilot project data are those associated with w3 which can be seen out to @xmath11 . while the profiles towards different points within the w3 region differ significantly from each other , mostly for velocities near 40 , they all have the same global properties which are well illustrated in figure [ fig : w3_abs_em ] . this shows the average absorption profiles associated with w3-n and w3-w for all positions where the continuum brightness temperature is greater than 50 k. as well , an average emission spectrum from forty nearby positions ( see  [ sec : calc_w3 ] ) is plotted . spectra towards the source ( `` on '' ) , which show absorption , and towards nearby positions ( `` off '' ) , showing emission , can be combined to yield the optical depth and spin temperature . for the on - source spectrum , @xmath12 where @xmath13 is the continuum brightness temperature of the background source . the dependance on frequency and therefore radial velocity , @xmath14 , is indicated . the off - source spectrum is given by the first term of the above equation : @xmath15 assuming that the off - spectrum has been carefully chosen to be representative of what would be seen at the position of the source if no absorption were occurring , one can solve for the optical depth : @xmath16 once the optical depth has been obtained from the observed spectra and continuum brightness temperature , the spin temperature can be calculated using eq.2 . it should be noted that an over- or underestimate of @xmath17 will result in an over- or underestimate of @xmath2 .      as indicated above , the off - spectrum must be carefully chosen to be representative of the on - source emission . this proves difficult for sight - lines towards w3 as there is much variation . for forty positions within a few arcminutes of w3 , 20 near w3-n and 20 near w3-w as defined by their 50 k contours , being careful to avoid the image artefacts and the slight absorption associated with w3-e , for velocities ranging from + 8  to 91  which includes all of the galactic emission of note , the standard deviation was as high as 18 k , though the average deviation in both cases was @xmath07 k. the average spectra , for w3-n and w3-w , are shown in figure  [ fig : ave_em ] which also includes the average@xmath181@xmath19 profiles .    for areas where the absorption is almost total , the optical depth calculation depends very sensitively on @xmath20 . therefore , for the present purposes , whenever the value of @xmath21 came within @xmath22 of @xmath13 it was replaced by @xmath23 in the calculation , where @xmath24 is the standard deviation of the appropriate off - spectrum , and @xmath25 , the uncertainty at field centre for the continuum subtracted images adjusted for the effect of the primary beam correction . this provides a lower limit value for the optical depth . it affects approximately 36% of the values of @xmath2 for w3-w from 33.51  to 50.00 , and @xmath041% of those for w3-n in this same interval . away from this deep trough , none of the values for w3-n needed to be calculated in this manner , and less than @xmath02% of the values for w3-w at more positive velocities are affected . the spin temperature calculations are highly dependant on the value of @xmath26 which is the greatest source of uncertainty . therefore , in addition to indicating limits when only limits were calculated for @xmath2 , results for @xmath3 will be considered trustworthy only when @xmath27 . plots of @xmath28 and @xmath29 for sight lines towards w3-n and w3-w are presented in figures  [ fig : tau ] and [ fig : tspin ] . these were calculated using the average spectrum of all positions where the continuum emission is greater than 50 k ( i.e.  the on - source spectra shown in fig . [ fig : w3_abs_em ] ) and the average of 20 nearby spectra for the emission ( i.e.  the emission spectra shown in fig . [ fig : ave_em ] ) . calculations were also done on a pixel by pixel basis for each region . there are three main absorption troughs along this line - of - sight : one corresponding to local gas , one corresponding to the bulk of the perseus arm and an intermediate trough centred on @xmath30 . there is emission at velocities between the intermediate and perseus arm absorption troughs , at @xmath31 . three different scenarios are considered to explain this and are illustrated in figure  [ fig : diag ] . one possibility does not require that any of the gas be displaced relative to the standard rotation curve , nor that the emitting gas at 30  be behind w3 ( fig . [ fig : diag]a ) . if the opacity of the gas at 30  were low enough , there would be sufficiently little absorption for it to be noticeable . in this framework the values of @xmath2 calculated from the observed spectra would imply spin temperatures in excess of 10@xmath32 k for this interarm gas , higher than expected for the warm neutral medium ( @xmath33 k , kulkarni & heiles 1988 ; direct measurements towards cyg a by carilli et al . ( 1998 ) yielded @xmath34 k and @xmath35 k ) . this feature of the spectra extends approximately from 24  to 33 . assuming a flat rotation curve with an oort constant @xmath36 and r@xmath37 = 8.5 kpc , this implies a path length of 0.6 kpc within which there is no cold neutral hydrogen . this seems unlikely considering that the average off - source emission is approximately 55 k and that there is significant absorption at more positive velocities ( 20 ) which also correspond to the interarm region for the standard rotation curve .      in the most intuitive picture , the lack of absorption at 30 places the related gas behind the w3 region . it could be argued that the 30  gas has been displaced in velocity ( fig . [ fig : diag]b ) , that it is not following the rotation curve of the galaxy . in this case , the less negative velocity indicates that , while it is approaching us , it is receding relative to the general movement of the galactic at a velocity of at least 19 , as determined from the lower velocity edge of the 40  absorption trough and the upper velocity edge of the 30  trough .      for the perseus arm there are known to be large deviations from the circular motion normally assumed for the galaxy ( see roberts 1972 and references therein ) ; the location of the optical arm and that of the radio ( hi ) arm as determined using a standard galactic velocity curve do not coincide , with the radio arm being apparently further than the optical arm . roberts ( 1972 ) developed the `` two - armed spiral shock '' model ( tass ) to explain these discrepancies . according to this model a shock develops along the inner edge of the perseus arm where the gas encounters a minimum in the gravitational potential of the density wave . the shock has an amplitude of approximately 20 . in this framework the main ridge of perseus arm emission seen from 40  to 50 , depending on the longitude ( c.f . figure 6 of normandeau et al . 1997 ) , has been displaced from circular velocity by approximately 20 . in this context the absorption gap in the w3 spectrum at 30  would be due to the _ undisturbed _ gas behind w3 , the region itself being within or just past the layer of shocked gas at @xmath38  ( fig . [ fig : diag]c ) . this is reminiscent of the streaming motion seen in other spiral galaxies , e.g.  m83 ( lord & kenney 1991 ) and m51 ( rand 1993 and references therein ) . in m51 , the strong density wave has concentrated both the diffuse and dense gas along the inner edge of the spiral arm , coincident with the dust lane , in the collision front . the velocity shifts are quite large , as much as 6090  in the plane of the galaxy ( tilanus & allen 1991 ) . the density wave is much weaker in m83 , resulting in less pronounced streaming motions ( @xmath012 perpendicular to the spiral arm and @xmath00  parallel to it ; lord & kenney 1991 ) . the dust lane again lies along the inner edge of the spiral arm but in this case the molecular ridge is offset , some 300 pc downstream . lord & kenney speculate that the diffuse gas is compressed at the shock front , producing the dust lane , but that the molecular clouds pass through the front to form a broad distribution in the arm . the perseus arm lies somewhere between these two cases : the 20  offset is essentially perpendicular to the spiral arm , implying a stronger shock than in m83 but weaker than in m51 where the perpendicular component is approximately 64 ( lord & kenney 1991 ) . heyer & terebey ( 1998 ) studied the co and infrared emission in the w3/w4/w5 region and found the bulk of the co emission to be at velocities near 45 . they estimate that the minimum transit time for the interarm region requires an exceedingly long cloud lifetime ( 36 @xmath10 10@xmath39 yr ) , and , when combined with the arm - interarm contrast which they measure to be 28:1 for co , this implies that the gas which enters the spiral arms is in the atomic phase . all this is more akin to the situation in m51 than in m83 , with a pile - up of molecular material along the shock front , though the shock is weaker for the perseus arm than in m51 . it should be pointed out , however , that heyer & terebey discounted the possibility that the gas at 40  was in fact showing streaming motion . frail & hjellming ( 1991 ) presented an absorption spectrum towards lsi+61@xmath40303 , a perseus arm object located just east of w4 . it is very similar in appearance to the one presented here for w3 , and they also called upon the tass model to explain their observations . a large scale phenomenon such as a spiral density wave seems the most likely explanation for the similar velocity displacement of gas separated by some 78 pc ( assuming a distance of 2.3 kpc ) . frail & hjellming also show a spectrum toward an extragalactic source , bg 0237 + 61 which is 15 arcmin from lsi+61@xmath40303 , where there is absorption in the 20  to 40  velocity interval ; this argues against the possibility outlined in  [ sec : expl1 ] . for these reasons , the explanation involving the tass model is the one favoured here . of the studies towards w3 mentioned in the introduction , only the earlier ones cover a wide - enough velocity range to include the absorption by local gas . crovisier et al .  found that the optical depths and widths of the troughs for w3 n and w3``main '' were comparable . the present data show slight differences . the optical depth towards w3-w rises and falls smoothly , attaining at maximum of @xmath41 at @xmath42 , whereas towards w3-n there is a brief plateau , extending over some 8 , at a level of 0.60.7 . read also found a peak optical depth of @xmath00.6 . within the two subregion there is little variation . the spin temperature towards w3-n attains slightly lower values than towards w3-w and remains at this level over a wider velocity interval , corresponding to the 8 plateau mentioned above . both sight - lines show slightly lower @xmath3 ( as low as @xmath43 k towards w3-n and @xmath44 k towards w3-w ) than found by wendker & wrigge towards dr 7 ( generally around 140 k ) . considering the uncertainties , the discrepancy is not large . nonetheless a possible explanation for this could be that the presence of relatively small , colder `` clumps '' would have a much greater impact on the spin temperatures measured towards w3 than towards dr 7 . this is because for each channel only a mean brightness temperature is measured and , due to galactic rotation , the same channel width ( velocity width ) corresponds to a greater path length for the dr 7 case than for w3 . for dr7 sight - lines each channel would therefore include contributions from much warm gas as well as from the postulated small , cold clumps . as an illustration , for @xmath45 and assuming a flat rotation curve with an oort constant @xmath36 and r@xmath37 = 8.5 kpc , one finds d@xmath46 = 4.5 kpc for the longitude of dr 7 , but only 0.7 kpc for sight - lines towards w3 .      in the interval between the troughs at 0 and 20 , figure  [ fig : w3_abs_em ] indicates that there is some absorption , though not to the extent seen in the deep troughs . the optical depth calculations reach minima of @xmath47 towards w3-w and @xmath48 towards w3-n . it is reasonable to wonder if this is truly due to interarm absorption or if it is simply attributable to the overlap of wings from the distributions corresponding to the 0 and 20  troughs . fitting a gaussian to each of these shows that their wings can not account for the amount of absorption seen at intervening velocities . for both sight - lines , the spin temperature increases upon leaving the local arm . the rise and fall of @xmath3 in this interarm region is fairly smooth towards w3-w , reaching @xmath49 k when using the average absorption spectrum . towards w3-n the interarm spin temperature shows a double peak , though it is smooth within uncertainties . the above temperatures are , of course , weighted mean values for a given channel . they correspond to what kulkarni & heiles ( 1988 ) dubbed the _ naively derived spin temperature_. for a single , isothermal cloud , it is equal to that cloud s spin temperature , however for the more complicated and realistic case where there are contributions from two optically thin components , it becomes the column - density - weighted harmonic mean temperature . assuming the canonical values of 80 k and 8000 k for the cold neutral medium ( cnm ) and the warm neutral medium ( wnm ) respectively ( kulkarni & heiles 1988 ) and using 300 k as the value for the weighted harmonic mean spin temperature , one derives a column density that is three times as high for the wnm as for the cnm . from the measured values of the spin temperature and the optical depth in the 8.78  to 13.72  velocity interval , the total column density of the @xmath50 @xmath51 , implying a column density of @xmath52 @xmath51 for the cnm and @xmath53 @xmath51 for the wnm with the above assumptions . if one then uses as a path length the difference between the kinematic distances associated with the velocities given above ( 0.63 kpc and 0.96 kpc ) , one finds mean densities of 0.08 @xmath54 for the cnm and 0.24 @xmath54 for the wnm . the ism pressure in the plane is thought to be approximately @xmath55 @xmath54 k ( kulkarni & heiles 1988 ) , implying @xmath56 @xmath54 and @xmath57 @xmath54 . taking the ratio of the mean densities for the interarm velocities considered here and the expected densities in the plane , one finds volume filling factors @xmath050% for the wnm and @xmath58 for the cnm . the wnm filling factor is comparable to the value of @xmath040% which carilli et al . ( 1998 ) found for the average of two interarm regions along a line of sight towards cyg a , though using only their data for the interarm region between the local gas and the perseus arm results in a somewhat lower value , closer to 30% . the cnm and wnm filling factors calculated above are very uncertain , relying as they do on many assumptions . the temperatures adopted for the two components may be incorrect . carilli et al . measured temperatures for the wnm down to 4800@xmath181600 k. while using this lower value would not noticeably change the mean densities derived for the two components in the interarm region , it would greatly affect the expected density for the plane and would imply a filling factor of @xmath030% for the wnm . the cnm filling factor would , of course , be unaffected . the temperature chosen for the cnm has a greater impact on the implied relative column densities of the two phases ; for @xmath59 k , the filling factor of the wnm becomes @xmath060% , while for the cnm it is then below 0.1% . deriving path lengths from the kinematic distances can only give rough estimates . small differences in this number will result in widely differing estimates of the filling factor for the wnm ( @xmath030% for @xmath60 kpc and @xmath080% for @xmath61 kpc ) , though the cnm filling factor remains at the 0.10.2% level . clearly , the greatest uncertainty comes from the densities assumed for the two components in the plane . these are affected by the temperatures as noted above , but also depend on the assumption that the phases of the ism are in pressure equilibrium , as well as on the reliability of the equation . the quantitative results quoted in the preceeding paragraph are therefore not to be blindly trusted , particularly for the wnm , however the calculations clearly and reliably show that the cnm occupies a negligible fraction of the interarm region . nonetheless this small amount of cold gas dominates the absorption signal . crovisier et al .  interpreted their observations at these velocities as due to the presence of a large inhomogeneous cloud at a distance of approximately 1.5 kpc . in the context of the tass model favoured here , the difference between sight - lines towards w3-n and w3-w is due to inhomogeneities in the gas on the near side of the perseus arm .    towards w3-n the average optical depth rises and falls quickly , reaching only @xmath62 at 20.32 . for the w3-w line - of - sight , the rise is more gradual than the decline and the maximum attained is much greater , @xmath63 at 20.32 . read found a peak optical depth of @xmath01.4 for this trough , in agreement with the value above . accordingly , sight - lines towards w3-w reach lower spin temperatures ( @xmath64 k for the average profile ) than do those towards w3-n ( @xmath65 k for the average profile ) . the optical depth is fairly uniform over the individual regions . a few anomalously high values ( up to 2.6 ) do result from the calculations but these are correlated with steep gradients in the continuum image and are therefore likely to be artefacts . two factors which could have affected these pixels are : 1 ) slight misalignments of the continuum and spectral line images , which would have a great impact on calculations in these steep gradient regions , are not impossible as the continuum image was selfcalibrated ; 2 ) the gridding of the continuum image and of the spectral cube were done separately and both have been regridded , which procedure could have caused mismatches between the two data sets in steep gradient regions . because the affected region is very near the field centre , bandwidth smearing is not a likely cause of these errors .      as indicated in the introduction , the absorption at velocities near 40  has been studied with the wsrt at higher spatial and spectral resolutions ( goss et al . 1983 , and van der werf & goss 1990 ) . a new detailed analysis of the associated with the various compact regions using the drao data is therefore not warranted , but a few aspects shall be addressed and discussed .    for the w3-n region , the lower limit for the maximum value using the average spectrum is 1.6 . the optical depth varies little over the region ; for the pixel by pixel calculations , a lower limit of 2.9 on the maximum optical depth was found at a velocity of 40.11 .    for this region goss et al .  calculated values up to 2.5 whereas read found @xmath2 up to @xmath08 . the former are inconsistent with the present data . the latter may be overestimated due to poor continuum subtraction leading to an underestimate of @xmath66 ( read did not have channels perfectly devoid of continuum at his disposal for continuum subtraction and estimated that this may have resulted in a 10 k oversubtraction ) . it is possible that the westerbork results have underestimated the optical depth . the wsrt has a shortest baseline of 36 m and , as a result , the largest scale structure that can be imaged is @xmath010 arcmin in extent . this filtering property of the array highlights small scale knots , and therefore would not affect the absorption spectra because the structure of the absorbing sources is on scales smaller than 10 arcmin ( c.f . figure  [ fig : w3c21 ] ) . if all the emission was on scales greater than 10 arcmin then there would be no surrounding emission which would need to be accounted for through an off - source spectrum . however if the interferometer has not filtered out all of the emission , then neglecting it , as did goss et al . , will result in an underestimate of @xmath2 . the w3-n opacity images published by van der werf & goss show values of @xmath67 ; their calculations were done differently than those of goss et al . , circumventing the possible difficulty with @xmath26 ( see van der werf & goss 1989 for details of the method ) . it should also be noted that for these velocities , it is likely that the optical depths derived here are also underestimated . this is because there is probably local associated with the w3 region itself which will not be accounted for in the `` off '' spectrum . the latter will therefore contain less emission at these velocities than would a spectrum towards the source if there were no absorption . spatial variations are much more marked in w3-w which , contrary to w3-n , is made up of several distinct regions . in particular , the highest values are attained towards w3 core ( lower limit of 4.7 at 38.46  whereas the lower limit for the maximum from the average spectrum is 2.4 ) , and lesser but marked enhancements are seen towards w3 k and w3 j as well as in the southern section of ngc 896 . again goss et al .  obtained slightly lower values , with a maximum of 4.0 being detected towards w3-a and w3-b . however van der werf & goss found @xmath68 towards all continuum sources and explained the discrepancy in terms of beam dilution ; this reconciles the two westerbork data sets , though beam dilution should cause the optical depth evaluated with the drao data to be even lower . as for read , once again he quotes a higher value ( lower limit of 9.0 ) , but the same warning applies as for w3-n . the average spin temperature is fairly constant over the entire velocity range of the absorption trough , for both w3-n and w3-w , at somewhat less than 100 k. this temperature is consistent with expected values for cores of giant molecular clouds ( 20  100 k , turner 1988 ) . spectra towards w3-n and w3-w for velocities ranging from + 55  to 154  have been presented . these were combined with an average spectrum for nearby positions to calculate the optical depth and spin temperature for velocities where there was absorption of the continuum emission . there is a lack of absorption around 30  which may be indicative of temperatures in excess of @xmath69 k in the interarm region or which might correspond to gas behind the w3 region even though there is absorption out to 50 . in the latter case , it could be that the 30  gas has been displaced by @xmath70 from the standard rotation curve , or that it is the gas showing absorption near 40  that has been accelerated by a spiral shock in accordance with the two armed spiral shock model ( roberts 1972 ) . considering that frail & hjellming ( 1991 ) observe a very similar spectrum towards lsi+61@xmath40303 , a source east of w4 , the explanation wherein the 30  gas has been displaced seems the least probable . the explanation involving the tass model is favoured here because of the unlikely absence of cold over the velocity span of the 30  feature . for the local arm , the sight - lines presented here yield lower spin temperature values than reported by wendker & wrigge ( 1996 ) towards dr 7 . this discrepancy may be due to the longer path length corresponding to each channel width for the earlier study . additional investigations of this nature , towards other galactic plane regions seen in the cgps data , will clarify the matter . for the interarm region , values on the order of 300 k are found , from which one can estimate volume filling factors of @xmath050% for the wnm and @xmath71 for the cnm ; the calculations require many assumptions and the number quoted for the warm can not be said to be reliable , but the result for the cnm filling factor is quite robust . the 20 absorption trough which shows lower temperatures is part of the perseus arm in the tass model , not the interarm region . the study of this second line of sight towards a galactic plane region , following on work by wendker & wrigge towards dr7 , confirms the usefulness of such studies both in determining characteristics of the ism and in examining elements of galactic structure . the many regions within the 73  longitude span of the cgps should help us map the temperature and optical depth in the galaxy . the author is grateful to h.j . wendker and c.  heiles for useful comments on previous drafts , as well as to an anonymous referee for comments helpful in the preparation of the final manuscript . the dominion radio astrophysical observatory s synthesis telescope is operated by the national research council of canada as a national facility . the canadian galactic plane survey is a canadian project with international partners , and is supported by a grant from the natural sciences and engineering research council of canada . l c c l w3 north ( w3-n ) & ( 133.78 , + 1.42 ) & @xmath72 & evolved hii region w3``main '' & ( 133.79 , + 1.18 ) & @xmath73 & all the bright emission south of w3-n w3 east ( w3-e ) & ( 133.81 , + 1.18 ) & @xmath74 & part of w3``main '' . fan - shaped , lower + & & & intensity evolved hii region w3 west ( w3-w ) & ( 133.72 , + 1.17 ) & @xmath75 & part of w3``main '' . bright western emission w3 core & ( 133.71 , + 1.22 ) & @xmath76 & part of w3-w . bright northern sources w3 a+b & ( 133.72 , + 1.22 ) & @xmath77 & part of w3 core . unresolved hii regions w3 h+c+d & ( 133.69 , + 1.22 ) & @xmath77 & part of w3 core . unresolved hii regions w3 k & ( 133.73 , + 1.18 ) & @xmath77 & part of w3-w . compact hii region + & & & south of w3 core w3 j & ( 133.70 , + 1.17 ) & @xmath77 & part of w3-w . compact hii region + & & & south of w3 core ngc 896 & ( 133.70 , + 1.14 ) & @xmath78 & part of w3-w . large ring south of w3 core    l l l st primary beam & gaussian , fwhm = 103 arcmin st baselines & 12.858 m to 604.336 m , increment = 4.286 m spatial resolution & @xmath79 ( ew @xmath10 ns ) polarisation & rr bandwidth & 1 mhz central velocity ( lsr ) & 50.0 velocity coverage & 211 channel width & 2.64 channel separation & 1.65 st sensitivity at field centre & 3.0 k    carilli , c.l . , dwarakanath , k.s . , goss , w.m . 1998 , , 502 , l79 crovisier , j. , fillet , r. , kazs , i. , baudry , a. 1975 , , 45 , 97 campbell , m.f . , butner , h.m . , harvey , p.m. , evans , n.j . , ii , campbell , m.b . , sabbey , c.n . 1995 , , 454 , 831 frail , d.a . , hjellming , r.m . 1991 , , 101 , 2126 goss , w.m . , retallack , d.s . , felli , m. , shaver , p.a . 1983 , , 117 , 115 heyer , m.h . , terebey , s. 1998 , , 502 , 265 hofner , p , churchwell , e. 1997 , , 486 , l39 kulkarni , s.r . , heiles , c. 1988 , in _ galactic and extragalactic radio astronomy_. verschuur & kellermann , eds . springer - verlag . lloyd , s.d . , kenney , j.d.p . 1991 , , 381 , 130 normandeau , m. , taylor , a.r . , dewdney , p.e . 1997 , , 108 , 279 rand , r.j . 1993 , , 410 , 68 read , p.l . 1981 , , 194 , 863 roberts , d.a . , crutcher r.m . , troland t.h . 1997 , , 479 , 318 roberts , w.w . 1972 , , 173 , 259 roelfsema , p.r . , goss , w.m . 1991 , , 87 , 177 sullivan , w.t . , downes , d. 1973 , , 29 , 369 tieftrunk , a.r . , gaume , r.a . , claussen , m.j , wilson , t.l . , johnston , k.j . 1997 , , 318 , 931 tilanus , r.p.j . , allem , r.j . 1991 , , 244 , 8 turner , b. 1988 , in _ galactic and extragalactic radio astronomy_. verschuur & kellermann , eds . springer - verlag . van der werf , p.p . , goss , w.m . 1990 , , 238 , 296 van der werf , p.p . , goss , w.m . 1989 , , 224 , 209 wendker , h.j . , wrigge , m. 1996 , , 305 , 592", "tags": [], "output_text_a": "This paper investigates the optical depth and spin temperature of atomic hydrogen (HI) near the Galactic plane, focusing on the W3 complex. The study uses data from the Dominion Radio Astrophysical Observatory's Synthesis Telescope as part of the Canadian Galactic Plane Survey. The authors aim to disentangle the emission and absorption of HI to better understand its properties in the interstellar medium. The paper discusses the challenges of measuring these properties due to variations in emission along different sight lines and the presence of bright regions. The study finds that the optical depth and spin temperature vary significantly across different regions and velocities, with notable absorption features associated with the W3 complex. The authors explore different scenarios to explain these features, including the possibility of spiral shocks affecting the gas dynamics. The findings contribute to a better understanding of the structure and characteristics of the interstellar medium and the Galactic plane. The study highlights the importance of detailed observations across multiple sight lines to map the optical depth and spin temperature in the Galaxy. The paper concludes that the cold neutral medium occupies a negligible fraction of the interarm region, while the warm neutral medium has a significant volume filling factor. The research underscores the usefulness of such studies in examining Galactic structure and the interstellar medium.", "output_text_b": "This arXiv paper presents a study of atomic hydrogen (HI) in the galaxy, specifically focusing on determining the optical depth and spin temperature of HI close to the galactic plane. The authors use observations of absorption towards extragalactic sources, which have been somewhat successful but not entirely satisfactory at low galactic latitudes. They suggest that careful study of many lines of sight will contribute to the quasi-mapping of optical depth and spin temperature as a function of radial velocity or distance. The paper contributes a second line of sight towards a strong, extended continuum source within our galaxy: the W3 complex. The W3 region has been studied in detail repeatedly and at many frequencies, and it houses active star formation. The authors use sight lines towards W3 to probe the interstellar medium between us and this region, evaluating optical depths and spin temperatures, and placing it in a galactic perspective.", "score": 0.5, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, discussing the investigation of optical depth and spin temperature of atomic hydrogen near the Galactic plane, focusing on the W3 complex.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding the properties of atomic hydrogen in the interstellar medium near the Galactic plane.\n\n4. **Methodology or Approach**: The summary mentions the use of data from the Dominion Radio Astrophysical Observatory's Synthesis Telescope as part of the Canadian Galactic Plane Survey.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the variation of optical depth and spin temperature across different regions and velocities, and the conclusion about the cold and warm neutral medium.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"optical depth\" and \"spin temperature.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the key data used in the research, specifically the data from the Dominion Radio Astrophysical Observatory.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in understanding the structure and characteristics of the interstellar medium and the Galactic plane.", "1. **Accurate Reflection of Main Findings and Contributions**: The summary provides a general overview of the paper's focus on atomic hydrogen (HI) and its optical depth and spin temperature. However, it lacks specific details about the main findings and contributions, such as the specific results of the optical depth and spin temperature measurements or the implications of these findings.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary mentions the research problem of determining the optical depth and spin temperature of HI close to the galactic plane.\n\n4. **Methodology or Approach**: The summary briefly mentions the use of absorption observations towards extragalactic sources and sight lines towards the W3 complex, but it does not detail the specific methodologies or data analysis techniques used.\n\n5. **Significant Results or Conclusions**: The summary does not clearly state any significant results or conclusions drawn by the authors, such as specific measurements or insights gained from the study.\n\n6. **Clear and Professional Language**: The language used in the summary is clear and professional.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and does not explain terms like \"optical depth\" or \"spin temperature,\" which might be necessary for a broader audience.\n\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary does not mention specific experiments or data used in the research, such as the Canadian Galactic Plane Survey or the specific observations made.\n\n10. **Significance or Potential Impact**: The summary does not reflect the paper's significance or potential impact in its field, such as how the findings might contribute to the understanding of the interstellar medium or galactic structure."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "shell models are dynamical systems ( ordinary differential equations ) representing a simplified version of the spectral navier  stokes or mhd equations for turbulence . they were originally introduced and developed bydfg obukhov  @xcite , desnyansky and novikov @xcite and gledzer @xcite in hydrodynamic turbulence and constitute nowdays a consistent and relevant alternative approach to the analytical and numerical study of fully developed turbulence ( see  @xcite for a complete review ) . shell models are built up by dividing wave - vector space ( k  space ) in a discrete number of shells whose radii grow exponentially like @xmath0 , ( @xmath1 ) , @xmath2 . each shell is assigned a scalar dynamic variable , @xmath3 , ( real or complex ) which takes into account the averaged effects of velocity modes between @xmath4 and @xmath5 . the equation for @xmath3 is then written in the formex @xmath6 where @xmath7 , @xmath8 and @xmath9 are respectively quadratic nonlinear coupling terms ( involving nearest or next - nearest shell interactions ) , dissipation terms and forcing terms , the last generally restricted to the first shells . nonlinear terms are chosen to satisfy scale - invariance and conservation of ideal invariants . the main advantage shell models offer is that they can be investigated by means of rather easy numerical simulations at very high reynolds ( @xmath10 ) numbers . the degrees of freedom of a shell model are @xmath11 , to be compared with @xmath12 for a three dimensional hydrodynamic turbulence following the kolmogorov scaling . the paper is organized as follows . in section 2 shell models with nearest neighbour interactions are briefly reviewed . in section 3 equations for mhd models with nearest and next - nearest neighbour interactions are presented and conservations laws for the ideal case are discussed . section 4 is devoted to dynamo action in shell models and section 5 to spectral properties in forced stationary state and intermittency . in section 6 conclusions are drawn and a brief mention to astrophysical applications is made . the simplest hydrodynamic shell model is the obukhov  novikov model , which is a linear superposition of the obukhov equation @xcite and the novikov equation @xcite . the model involves real variables @xmath3 and conserves the energy @xmath13 in absence of forcing and dissipation . it does not conserve phase space volume nor other quadratic invariants exist . the extension of the obukhov - novikov model to mhd is due to gloaguen _ et al . _ we write down the equations for clarity ( @xmath14 and @xmath15 represent respectively the velocity and the magnetic field in dimensionless units ) @xmath16 -0.85 truecm @xmath17 here @xmath18 is the kinematic viscosity , @xmath19 is the magnetic diffusivity , @xmath20 and @xmath21 are two arbitrary coupling coefficients . the ideal invariants of the system are the total energy , @xmath22 and the cross - correlation , @xmath23 which are two ideal invariants of the mhd equations @xcite . when written in terms of the elssser variables @xmath24 , @xmath25 , the equations assume a simmetric form and the conservation of the two previous invariants is equivalently expressed as the conservation of the pseudo - energies @xmath26 . it is remarkable to note that , unlike the hydrodynamic model , the mhd version satisfies a liouville theorem @xmath27 , impling phase - space volume conservation . the mhd equations conserve a third ideal invariant which is the magnetic helicity in three dimensions ( 3d ) and the mean square potential in two dimensions ( 2d ) , but no further ideal quadratic invariant can be imposed to this shell model . a detailed bifurcation analysis for a three - mode system was performed in @xcite for different values of @xmath20 and @xmath21 . the low reynolds ( kinetic and magnetic ) numbers , used as control parameters , allowed to identify a great variety of regions in the parameter space . turbulence was investigated with a nine - mode system which produces an inertial range with spectra following approximately the kolmogorov scaling @xmath28 . temporal intermittency was also observed and then reconsidered in more details by carbone @xcite who calculated the scaling exponents of the structure functions for the elssser variables and for the pseudo - energy transfer rates , showing consistency with the usual multifractal theory . other interesting mhd phenomena were also observed in @xcite such as dynamo effect and the growth of correlation between velocity and magnetic field in an unforced simulation . these phenomena will be treated in more details in the next paragraphs .    the complex version of ( [ previousmodel1 ] ) and ( [ previousmodel2 ] ) was thoroughly investigated by biskamp @xcite . the complex model allows to include the alfvn effect @xcite , @xcite , @xcite , that is the interaction of a constant large scale magnetic field with small scale turbulent eddies . the main consequence of this effect should be a reduction of the spectral energy transfer rate and a consequent change of the spectra from the kolmogorov scaling , @xmath29 , to the iroshnikov - kraichnan one , @xmath30 . in this paper the alfvn effect will not be furtherly treated . the reader is referred to @xcite for a complete discussion concerning the inclusion of alfvnic terms in shell models . shell models with nearest and next - nearest neighbour interactions were introduced by gledzer @xcite . in particular the so called goy ( gledzer - yamada - ohkitani ) model has been extensively both numerically and analitically investigated @xcite , @xcite , @xcite . the goy model allows to conserve another quadratic invariant besides energy which was identified with the kinetic helicity @xcite . a generalization of the goy model to mhd can be found in biskamp @xcite . all the parameters of the model are now fixed by imposing the conservation of another quadratic invariant that can be chosen to distinguish between a 3d and a 2d model . a more refined version was then considered by frick and sokoloff @xcite to take into account the fact that the magnetic helicity is a quantity not positive definite . the situation can be summarized as follows @xcite . let us consider the following set of equations ( @xmath14 and @xmath15 are now complex variables representing the velocity and the magnetic field in dimensionless units ) @xmath31 @xmath32 or , in terms of the complex elssser variables @xmath33 , particularly useful in some solar  wind applications , @xmath34 where @xmath35 here @xmath36 , being @xmath18 the kinematic viscosity and @xmath19 the resistivity , @xmath37 , eq . ( [ nonlinearev ] ) , is a drag term specific to 2d cases ( see below ) , @xmath38 are external driving forces , @xmath39 and @xmath40 are real coupling coefficients to be determined . in the inviscid unforced limit , equations ( [ nonlineare ] ) conserve both pseudoenergies @xmath41 for any value of @xmath42 and @xmath43 ( the sum is extended to all the shells ) , which corresponds to the conservation of both the total energy @xmath44 and the cross - helicity @xmath45 . as far as the third ideal invariant is concerned , we can define a generalized quantity as @xmath46 whose conservation implies @xmath47 , @xmath48 for @xmath49 , @xmath50 and @xmath51 , @xmath52 for @xmath53 , @xmath54 , @xmath55 . thus two classes of mhd goy models can be defined with respect to the values of @xmath39 : 3d  like models for @xmath56 , where @xmath57 is not positive definite and represents a generalized magnetic helicity ; 2d  like models where @xmath58 and @xmath57 is positive definite . this situation strongly resembles what happens in the hydrodynamic case where 2d  like @xmath59 and 3d  like @xmath60 models are conventionally distinguished with respect to a second generalized conserved quantity @xmath61 here the 3d and 2d cases are recovered for @xmath62 where the ideal invariants are identified respectively with kinetic helicity and enstrophy . it should be noted that , although the hydrodynamic invariants are not conserved in the magnetic case , the equations which link @xmath20 and @xmath39 are exactly the same for hydrodynamic and mhd models . thus , once fixed @xmath20 and @xmath39 , it is a simple matter to find out which goy model the mhd goy one reduces to when @xmath63 @xcite . to summarize we have that ( with @xmath64 ) the model introduced in @xcite for the 3d case will be called , hence on , 3d mhd goy model or simply 3d model . it is recovered for @xmath65 , @xmath66 , @xmath67 and reduces to the usual 3d goy model for @xmath63 . the biskamp s 3d model @xcite is actually a 2d  like model and will be called pseudo 3d model . it is obtained for @xmath65 , @xmath68 , @xmath69 and reduces to a 2d  like goy model that conserves a quantity which has the same dimensions as kinetic helicity but is positive definite . the 2d models introduced in @xcite and in @xcite coincide , they are recovered for @xmath70 , @xmath71 , @xmath72 and reduce to the usual 2d goy model for @xmath63 . in the following the properties of the 3d model will be mainly investigated . the problem of magnetic dynamo , that is the amplification of a seed of magnetic field and its maintenance against the losses of dissipation in an electrically conducting flow , is of great interest by itself and for astrophysical applications ( see for example @xcite for an excellent introduction to the problem ) . shell models offer the opportunity to test with relative simplicity whether a small value of the magnetic field can grow in absence of forcing terms on the magnetic field . previous considerations about dynamo action in shell models can be found in @xcite . in that case numerical study of bifurcations in the three - mode system revealed instabilities of kinetic fixed points to magnetic ones or magnetic chaos . the existence of a sort of dynamo effect in mhd goy models was put forward by frick and sokoloff @xcite . the authors investigate the problem of the magnetic field generation in a free - decaying turbulence , thus showing that : @xmath73 in the @xmath74 case magnetic energy grows and reaches a value comparable with the kinetic one , in a way that the magnetic field growth is unbounded in the kinematic case ; @xmath75 in the @xmath76 case magnetic energy slowly decays in the nonlinear as well as in the kinematic case . these results have been interpreted as a 3d  turbulent dynamo effect \" and seem to be in agreement with well - known results by which dynamo effect is not possible in two dimensions @xcite . the problem was then reexamined in @xcite in a forced situation looking at a comparison between the 3d mhd goy model and the pseudo 3d model . starting from a well developed turbulent velocity field , a seed of magnetic field is injected and the growth of the magnetic spectra monitored . system is forced on the shell @xmath77 ( @xmath78 ) , setting @xmath79 , which corresponds to only inject kinetic energy at large scales . method of integration is a modified fourth order runge - kutta scheme . in fig . [ fseps ] we plot @xmath80 and @xmath81 versus @xmath82 for the 3d model . angular brackets @xmath83 stand for time averages . it can be seen that the magnetic energy grows rapidly in time and forms a spectrum where the amplitude of the various modes is , at small scale , of the same order as the kinetic energy spectrum . ( the subsequent evolution of magnetic and kinetic spectra will be considered in the next section ) . the spectral index is close to @xmath84 which is compatible with a kolmogorov scaling of the second order structure function . ( _ diamonds _ ) and @xmath85 ( _ lines _ ) versus @xmath82 . the averages of @xmath86 are made over intervals of 3 large scale turnover times . time proceeds upwards . the kinetic spectrum is averaged over 30 large scale turnover times . the straight line has slope @xmath87 . parameters used : n=24 , @xmath88 , @xmath89    for a comparison we integrated the pseudo 3d model and it can be seen ( fig . [ biskeps ] ) that a magnetic spectrum is formed , but it slowly decays in time . notice that , because of the smallness of @xmath15 , its back - reaction on the velocity field is negligible , thus the kinematic part of the model evolves independently from the magnetic one . now the scaling @xmath90 follows , as a cascade of generalized enstrophy is expected for 2d  like hydrodynamic goy models when @xmath91 ( see @xcite for details ) . ( _ diamonds _ ) and @xmath92 ( _ lines _ ) versus @xmath82 . averages are made over intervals of 100 large scale turnover times . time proceeds downwards . the kinetic spectrum is only shown for the last interval . the straight line has slope @xmath93 , see text for explanation . parameters used : n=33 , @xmath94 , @xmath95    the question now arises whether it is correct the interpretation of the growth of the magnetic field in the 3d model as the corresponding dynamo effect expected in the real 3d magnetohydrodynamics . first of all it should be noted that in the kinematic case an analogy with the vorticity equation predicts the following relations between velocity and magnetic energy spectra @xcite : @xmath96 , so that if @xmath97 it follows a magnetic energy spectrum growing with @xmath98 . the kinematic case corresponds to the first stage of growth of our simulation where this behaviour is sometimes visible , at least qualitatively . note however that the averages are made on very small time intervals because of the rapid growth of the magnetic energy . a similar , much more pronounced behaviour is found for the pseudo 3d model as well . let us stress that the sign of the third ideal invariant seems to play a crucial role as far as the growth of small magnetic fields is concerned . in effect this sort of dynamo effect can also be considered under a different point of view . let us consider the ideal evolution of the model @xmath99 . we can build up the phase space @xmath100 of dimension @xmath101 , by using the elssser variables as axes , so that a point in @xmath100 represents the system at a given time . a careful analysis of ( [ nonlineare ] ) shows that there exist some subspaces @xmath102 of dimension @xmath103 which remain invariant under the time evolution @xcite . more formally , let @xmath104 be a set of initial conditions such that @xmath105 , @xmath106 is time invariant if the flow @xmath107 , representing the time evolution operator in @xmath100 , leaves @xmath106 invariant , that is @xmath108 = y(t ) \\in i$ ] . the kinetic subspace @xmath109 , defined by @xmath110 is obviously the usual fluid goy model . further subspaces are the alfvnic subspaces @xmath111 defined by @xmath112 , say @xmath113 and @xmath114 ( or vice versa ) . each initial condition in these subspaces is actually a fixed point of the system . we studied the properties of stability of @xmath115 and @xmath111 . following @xcite , let us define for each @xmath106 the orthogonal complement @xmath116 , namely @xmath117 . let us then decompose the solution as @xmath118 where the subscripts refer to the @xmath106 and @xmath116 subspaces respectively . finally we can define the energies @xmath119 and @xmath120 . note that the distance of a point @xmath121 from the subspace @xmath106 is @xmath122 . then @xmath123 represents the square of the distance of the solution from the invariant subspace . at time @xmath124 , @xmath125 ( @xmath126 ) represents the energy of the perturbation . since the total energy is constant in the ideal case , two extreme situations can arise : @xmath73 the external energy remains of the same order of its initial value , that is the solution is trapped near @xmath106 which is then a stable subspace ; @xmath75 the external energy assumes values of the same order as the internal energy , that is the solution is repelled away from the subspace which is then unstable .        since the external and internal energies for the alfvnic subspaces are nothing but the pseudoenergies @xmath127 and @xmath128 , which are ideal invariants , the alfvnic subspaces are stable . as regards the kinetic subspace , @xmath129 and @xmath123 represent respectively the kinetic and magnetic energies . looking at the numerical solutions of the ideal model ( fig . [ eidealeps ] ) we can see the difference in the stability properties between the pseudo 3d model and the 3d one . in the first case the external energy remains approximately constant , while in the second case the system fills up immediately all the available phase space . this striking difference is entirely due to the nonlinear term , and in fact must be ascribed to the differences in sign of the third invariant . the effect of the unstable subspace , which pushes away the solutions , is what in ref . @xcite is called  turbulent dynamo effect \" . the main fundamental difference between hydrodynamic and mhd shell models lies in the fact that the behaviour of the former is not so sensitive to the type of forcing , at least as far as the main features are concerned . on the contrary in the magnetic case phase space is more complex because of the presence of invariant subspaces which can act as attractors of the dynamics of the system , hence the type of forcing becomes crucial in selecting the stationary state reached by the system . the spectral properties of the 3d model have been investigated by frick and sokolov in @xcite under different choices of the forcing terms . in their simulations they observe that the spectral indexes of kinetic and magnetic spectra depend on the level of cross helicity and magnetic helicity . in particular spectra with spectral index @xmath130 appear if the cross helicity vanishes . even in this case results may be deceptive . in fact , defining the reduced cross helicity @xmath131 as the cross helicity divided by the total energy , long runs @xcite show that , in case of constant forcing on the velocity variables , even from an initial value @xmath132 the system evolves inevitably towards a state in which the reduced cross helicity reaches either the value + 1 or -1 , corresponding to a complete correlation or anti - correlation between velocity and magnetic field . in terms of attractors the system is attracted towards one of the alfvnic subspaces where velocity and magnetic field are completely aligned or anti - aligned . due to the particular form of the nonlinear interactions in mhd ( [ nonlineare ] ) , the nonlinear transfer of energy towards the small scales is stopped . in this case kolmogorov - like spectra appear as a transient of the global evolution . this is shown in fig.[zmpeps ] where it is clearly seen a component ( @xmath133 ) which is completely vanishing while the @xmath134 spectrum becomes steeper and steeper as energy is not removed from large scales . if an exponentially correlated in time gaussian random forcing on the velocity field is adopted the system shows a very interesting behaviour . it spends long periods ( several large scale turnover times ) around one of the alfvnic attractors , jumping from one to the other rather irregularly ( fig . [ heleps ] ) . this behaviour assures the existence of a flux of energy to the small scales , modulates the level of nonlinear interactions and the consequent dissipation of energy at small scales , which is burstly distributed in time . what we want to stress is the fact that the alfvnic attractors play a relevant role in the dynamics of the system . this fact should be taken into account especially when a stationary state is investigated in order to determine the scaling exponents of the structure functions ( see below ) . two regimes , the kolmogorov transient and the completely aligned regime , could be mixed during the average procedure , thus leading to unreliable values of the scaling exponents .     versus @xmath135 at different times ( * a * ) black circles : the average of @xmath136 are made over the first @xmath137 large scale turnover times ( * b * ) white circles : the average is made after @xmath138 large scale turnover times ( * c * ) . the straight line has slope @xmath139 . _ right _ : the same for @xmath140 ] the  four - fifth \" relation @xmath141 , where @xmath142 is the mean rate of energy dissipation and @xmath143 the separation , derived by kolmogorov in @xcite , can be generalized to mhd flows @xcite,@xcite,@xcite . a corresponding relation exists in mhd shell models , which can be derived following the considerations in @xcite . assuming for simplicity @xmath144 , the scale  by  scale energy budget equation is : @xmath145 where the quantities @xmath146 are defined as @xmath147 assuming that i ) forcing terms only act at large scales ; ( ii ) the system tends to a statistically stationary state ; ( iii ) in the infinite reynolds numbers limit ( @xmath148 ) the mean energy dissipation tends to a finite positive limit @xmath149 , we obtain @xmath150 @xmath151 these are the equations that define the inertial range of the system and that can be easily checked and confirmed by numerical simulations ( fig . [ kolmeps ] ) . it is to be remarked that these are the appropriate combinations that are expected to scale exactly as @xmath152 . let us finally remind that , as far as cascade properties of shell models are concerned , the major drawback lies in the difficulty to reproduce cascades of quantities that are expected to flow inversely , such as energy in 2d hydrodynamic @xcite or magnetic helicity in mhd @xcite . a deep understanding of intermittency in turbulence is nowdays one of the most challenging tasks from a theoretical point of view ( see @xcite for review ) . a lot of papers have been dedicated in the last years to investigate temporal intermittency in shell models . deviations from the kolmogorov scaling @xmath153 of the scaling exponents in the structure functions , @xmath154 , have been observed and described in the context of a multifractal approach  @xcite . a precise calculation of the scaling exponents may have difficulties related to the presence of periodic oscillations superimposed to the power law . another source of uncertainty is linked to the exact identification of the inertial range where the fit should be performed . these problems are at lenght discussed and investigated in @xcite where a new shell model ( called sabra model ) has been introduced in the context of hydrodynamic turbulence . the sabra model is a slight modification of the standard goy model and allows to eliminate spurious oscillations in the spectra . the same problems are in principle encountered in magnetohydrodynamic models thus a generalization of the sabra model to mhd is required ( @xcite ) . an alternative approach to the determination of scaling exponents for the 3d mhd goy model can be found in @xcite where concepts and techniques related to ess and gess @xcite are used . we have determined the scaling exponents of the structure functions @xmath155 , @xmath156 , @xmath157 , @xmath158 adopting a random forcing on the velocity variables ( on shell n=1 and n=2 ) to assure the system does not  align \" . the forcing terms were calculated solving a langevin equation @xmath159 , where @xmath160 is a correlation time chosen equal to the large scale turnover time and @xmath161 is a gaussian delta - correlated noise . the total number of shells is @xmath162 and the values of viscosity and resistivity are @xmath163 , @xmath164 . in fig . [ mom123eps ] the first three structure functions are plotted for the magnetic field , together with the best fit lines . from a comparison with spectra obtained in the standard goy model @xcite , it should be remarked that the cross over region between the inertial range and the dissipative one is not so sharp as in the hydrodynamic case . we then decided to perform a least - square fit in the range , determined visually , between the shell numbers @xmath165 and @xmath166 .     versus @xmath167 for ( * a * ) @xmath168 ( _ black circles _ ) ( * b * ) @xmath169 ( _ large white circles _ ) ( * c * ) @xmath170 ( _ small white circles _ ) . the straight lines are the best fit in the range between @xmath165 and @xmath166 ]    the values of @xmath171 and @xmath172 are reported in table  [ tab1a ] together with the values of @xmath173 , extracted from @xcite , for the hydrodynamic goy model . the values of the scaling exponents of the other structure functions are compatible , within errors coming from the fit procedure , with those of the velocity variables . it can be seen that the values found are compatible with those obtained for the standard hydrodynamic goy model .    .scaling exponents @xmath173 ( goy model ) , @xmath171 , @xmath172 [ cols= \" < , < , < , < , < , < \" , ]     [ tab1a ] in this paper we have reported about the main properties concerning dynamical behaviour and intermittency of a shell model for mhd turbulence . the properties of the model reveal a complex structure of phase space in which invariant subspaces are present . the stability properties of the kinetic subspace are related to a dynamo action in the system while alfvnic subspaces act as strong attractors which cause the system to evolve towards a state in which no energy cascade is present . a careful choice of forcing terms seems to be crucial in determining the stationary state reached by the system . we want finally mention that shell models , as good candidates to reproduce the main features of mhd turbulence , can be used to check conjectures and ideas in astrophysical applications where very high reynolds numbers are often present . we briefly remind two examples of applications . in @xcite mhd shell models have been used to simulate magnetohydrodynamics in the early universe to investigate the effects of plasma viscosity on primordial magnetic fields . as second example , scaling laws found in the probability distribution functions of quantities connected with solar flares ( eruption events in the solar corona ) are at present matter of investigation by means of shell models . results on this subject can be found in @xcite .", "tags": [], "output_text_a": "This paper discusses the use of shell models as simplified dynamical systems to study turbulence, particularly in the context of hydrodynamic and magnetohydrodynamic (MHD) equations. Shell models divide wave-vector space into discrete shells, each associated with a dynamic variable representing averaged velocity modes. These models are advantageous for numerical simulations at high Reynolds numbers due to their reduced degrees of freedom compared to full three-dimensional turbulence models.\n\nThe paper reviews various shell models, including the Obukhov-Novikov model for hydrodynamics and its extension to MHD by Gloaguen et al. It also discusses the Gledzer-Yamada-Ohkitani (GOY) model and its MHD generalization, which conserve additional quadratic invariants like kinetic helicity. The study explores the dynamo effect, where a magnetic field is amplified in a conducting flow, and the spectral properties of forced stationary states, highlighting the role of invariant subspaces in the dynamics.\n\nThe authors emphasize the importance of choosing appropriate forcing terms to determine the system's stationary state and discuss the implications for astrophysical applications, such as the early universe's magnetohydrodynamics and solar flares. The paper concludes that shell models are valuable tools for investigating MHD turbulence and related phenomena.", "output_text_b": "Shell models are simplified versions of the Navier-Stokes or MHD equations used to study turbulence. They divide wave-vector space into discrete shells and assign each shell a dynamic variable that represents the averaged effects of velocity modes. The equations for these variables are written in the form of ordinary differential equations with nonlinear coupling terms, dissipation terms, and forcing terms. Shell models offer the advantage of being investigated by means of relatively easy numerical simulations at high Reynolds numbers.\n\nThe paper is organized into several sections, including a review of shell models with nearest neighbor interactions, equations for MHD models with nearest and next-nearest neighbor interactions, and discussions on dynamo action and spectral properties in forced stationary state and intermittency. The paper also includes a brief mention of astrophysical applications.\n\nThe simplest hydrodynamic shell model is the Obukhov-Novikov model, which is a linear superposition of the Obukhov equation and the Novikov equation. The model involves real variables and conserves energy in the absence of forcing and dissipation. The extension of this model to MHD is due to Gloaguen et al. and conserves the total energy and cross-correlation, which are ideal invariants of the MHD equations.\n\nA detailed bifurcation analysis has been performed for a three-mode system, and turbulence has been investigated with a nine-mode system. Temporal intermittency has also been observed. Other interesting MHD phenomena, such as dynamo effect and the growth of correlation between velocity and magnetic field in an unforced simulation, have been observed.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the use of shell models for studying turbulence and their applications in MHD.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of studying turbulence using shell models.\n4. **Methodology**: The summary mentions the methodology of using shell models and discusses specific models like the Obukhov-Novikov and GOY models.\n5. **Significant Results**: The summary includes significant results, such as the exploration of the dynamo effect and the importance of invariant subspaces.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"shell models\" and \"dynamo effect.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in its field, mentioning applications in astrophysics.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing shell models, their simplification of Navier-Stokes or MHD equations, and their application in studying turbulence. It also mentions the organization of the paper and some specific models and phenomena discussed.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the study of turbulence using shell models, is highlighted.\n4. The methodology or approach, involving the use of shell models and numerical simulations, is mentioned.\n5. Significant results, such as the observation of dynamo effects and intermittency, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like shell models and MHD.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance in the field of turbulence study and its potential impact."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "decoherence is a nearly universal effect in quantum systems , and one which plays a central role in the quantum to classical transition . however , the word `` decoherence '' is often used to denote several related , but distinct concepts . the first is dephasing , the loss of definite phase relations between different components in a superposition state . these phase relationships are essential for quantum interference , which can be regarded as the key phenomenon which distinguishes the quantum world from the classical world . in general , interaction of a quantum system with its environment can lead to dephasing . the second , closely related concept , is that of entanglement between the quantum system and its environment . entanglement by itself need not lead to decoherence , but often the variables of the environment are too numerous or complex to be readily measured . it is when one gives up on any attempt to keep track of the environmental degrees of freedom that decohenece arises . the third concept associated with decoherence is the revelation of `` which path '' information . any measurement in a double slit interference experiment which reveals the path taken by the particles will destroy the interference pattern .    here we will consider a specific example of a quantum system , coherent electrons coupled to the quantized electromagnetic field . an electron interference experiment , such as that illustrated in fig . [ fig : paths ] , deals with one of the simplest possible quantum systems , but also one in which many beautiful experiments have been performed in recent years@xcite . the coupling to the quantized electromagnetic field allows for photon emission by the electrons , leading to decoherence . this example illustrates all three of the versions of decoherence discussed above . as will be shown in sect . [ sec : ab ] , the coupling to the quantized electromagnetic field produces dephasing , or a loss of contrast in the interference pattern as a result of aharonov - bohm phase fluctuations . the emission of photons leads to entanglement between the quantum state of the electrons and that of the photons . finally , photon emission is capable of revealing `` which path '' information . if the wavelength of an emitted photon is less than the separation of the two electron paths in fig . [ fig : paths ] , then detection of that photon reveals the path taken by a given electron . in the cleanest version of the electron interference experiment , the flux of electrons may be made so low that only one electron is in the interferometer at any one time . consider a double slit interference experiment in which coherent electrons can take either one of two paths , as illustrated in fig . [ fig : paths ] . first consider the case of no field fluctuations . if the amplitudes for the electrons to take path @xmath0 and @xmath1 are @xmath2 and @xmath3 , respectively , to point @xmath4 , then the mean number of electrons at @xmath4 will be proportional to @xmath5 in the presence of a classical , non - fluctuating electromagnetic field described by vector potential @xmath6 , there will be an aharonov - bohm phase shift of the form@xcite . @xmath7 where the integral is taken around the closed path @xmath8 . here @xmath9 is the electron s charge . we will use lorentz - heaviside units with @xmath10 . the phase shift alters the locations of the interference minima and maxima , but does not alter their relative amplitudes , the contrast . if the electromagnetic field undergoes fluctuations , then the situation is different . in the case of gaussian fluctuations , the fluctuating aharonov - bohm phase causes a change in the contrast by a factor of @xmath11 where we define the _ coherence functional _ by @xmath12 with the angular brackets denoting averaging over the fluctuations . this functional can be expressed as @xmath13 where @xmath14 is the fine - structure constant and @xmath15 if the initial quantum state of the electromagnetic field is the vacuum , then @xmath16 is the vacuum hadamard function . note that the hadamard function itself is gauge dependent , but that @xmath17 is gauge invariant . in general , @xmath18 , leading to a reduction in contrast or dephasing . at the same time , the coherence functional reflects the effects of photon emission . if the electromagnetic field is initially in its vacuum state , @xmath19 , then after an electron traverses path @xmath20 , it will be in the state @xmath21 which is a superposition of photon number eigenstates . thus the descriptions in terms of a fluctuating aharonov - bohm phase or in terms of photon emission are complementary viewpoints . various aspects of decoherence associated with fluctuating or time - dependent electromagnetic fields have been discussed by numerous authors in recent years  @xcite . the connection between aharonov - bohm phase fluctuations and decoherence was discussed in by stern _ et al_@xcite . the effects of boundaries , such as a plane mirror , were considered by ford@xcite . some of these estimates for the magnitude of the effects were criticized by mazzitelli _ @xcite as being too large . the discrepancy is likely due to the sharp corners in the electron paths used@xcite ; when smooth paths are employed@xcite , the effects are much smaller . this can be understood because sharp boundaries cause large amounts of photon emission , which can in turn be modified by a perfectly reflecting boundary . a different effect was discussed by anglin _ et al_@xcite and machnikowski@xcite , who considered the effect of an imperfect conductor . here the motion of electrons over the conductor can cause excitations inside the metal , resulting in decoherence . this type of decoherence was recently observed by sonnentag and hasselbach@xcite . the initial quantum state of the electromagnetic field need not be the vacuum . the case of a thermal state , and the resulting increased decoherence , was discussed by breuer and petruccione@xcite . another possibility is a time - dependent classical electromagnetic field@xcite . here one really has aharonov - bohm phase variations rather than fluctuations . however in most experiments , one would average over the emission time of the electrons and effectively lose the information carried by this time - dependent phase , leading to decoherence . now we consider the situation when the initial state of the photon field is not the vacuum , but rather a squeezed state@xcite . such states have the property that they can temporarily suppress the quantum fluctuations in a given variable below the vacuum level . for example , the local energy density in such a state can be negative , although the total energy is always positive . the effects of squeezed states of photons on coherent electrons were recently analyzed by us@xcite . in this section , we will give a summary of the results found there . consider the special case where the quantized electromagnetic field is in a state in which one mode is excited to a squeezed vacuum state , and all other modes remain in the ground state . we take the excited mode to be a plane wave in a box with periodic boundary conditions , with wave vector @xmath22 and polarization @xmath23 , so the quantum state may be denoted by @xmath24 . this is a one complex parameter family of states , labeled by @xmath25 . take the plane wave to be travelling in the @xmath26-direction , with linear polarization in the @xmath27-direction . for electrons emitted at @xmath28 , we take the paths @xmath0 and @xmath1 to be given by @xmath29 ^ 2 \\,.\\ ] ] that is , the electrons start at @xmath30 at @xmath28 , reach their maximum separations where @xmath31 at @xmath32 , and finally return to @xmath30 at @xmath33 . here @xmath34 and @xmath35 can be thought of as the effective flight time and path separation , respectively . electrons which start from the source at different times will experience different fluctuations . we are interested in the change in the coherence functional due to the non - trivial state of the photon field , so define a renormalized coherence functional @xmath36 , where @xmath37 is the functional in the minkowski vacuum state . in our case , one finds that @xmath38 where @xmath14 is the fine structure constant , @xmath39 is the normalization volume , and @xmath40 is the frequency of the excited photon mode . in addition , @xmath41 ^ 2\\,,\\ ] ] which does not depend on the electron emission time @xmath42 and is always positive definite . thus the sign of @xmath43 is solely determined by the quantity @xmath44\\ , ,     \\label{eq : g}\\ ] ] where @xmath45 , @xmath46 , and @xmath47    the behavior of @xmath48 as a function of @xmath42 for fixed @xmath49 is illustrated in the left part of fig . [ fi : squeezed_state ] . the key feature is that @xmath50 for @xmath51 . this means that for electrons emitted during this interval , we have @xmath52 , an increase of contrast compared to the photon vacuum state . this is the phenomenon of _ recoherence_. the minimum value of @xmath53 in the interval @xmath51 is @xmath54 , plotted in the right part of fig . [ fi : squeezed_state ] , form which we see that @xmath55 . let @xmath56 and @xmath57 denote the averages of @xmath48 and of @xmath43 , respectively , over the interval @xmath51 . the dependence of @xmath56 upon @xmath49 is illustrated in fig . [ fi : squeezed_state1 ] , where we see that @xmath58 . this bound limits the degree of recoherence , and is analogous to the quantum inequalities which limit the magnitude and duration of negative energy densities in quantum field theory@xcite . marecki@xcite has recently derived variants of the quantum inequalities for limiting the amount of squeezing which might be observed in photodetection experiments in quantum optics . the bounds on @xmath56 and on @xmath59 are sufficient to ensure that unitarity is always preserved , so that @xmath18 . thus the recoherence effect can never be greater in magnitude that the decoherence in the vacuum state . the bound given above may be used to make estimates of the maximum recoherence . if we assume that @xmath59 attains its maximum value , then for a single mode in a box , we find @xmath60 where @xmath61 is the wavelength of the excited mode . this estimate was derived assuming non - relativistic motion and periodic boundary conditions . however , it should serve as a rough estimate for more realistic cavities . for a rough estimate , let us take @xmath62 and @xmath63 , corresponding to the lowest frequency mode in the cavity and a path separation of the order of the cavity size . this leads to @xmath64 non - relativistic motion requires @xmath65 . if , for example , we take @xmath66 , we would get the estimate @xmath67 . the case where a finite bandwidth of modes is excited is treated in our previous paper@xcite . if @xmath68 is the bandwidth of excited modes and @xmath69 is the solid angle within which they lie , then one finds the estimate @xmath70 all of the factors in the above expression , @xmath71 , @xmath72 , and @xmath69 , should be small compared to unity for our analysis to be strictly valid . if we take all three of these factors to be of order @xmath73 , then we would obtain @xmath74 . in this article , we have reviewed selected aspects of decoherence , using coherent electrons coupled to the quantized electromagnetic field as our model quantum system . this system exhibits all three forms of decoherence , dephasing , entanglement , and `` which - path '' information . the basic effect of the photon field can be described either as photon emission or as aharonov - bohm phase fluctuations . if the photon field is not in its vacuum state , then the decoherence is typically larger than in the vacuum . however , we have discussed how this can be reversed for selected quantum states , resulting in recoherence . the phenomenon of recoherence is a sub - vacuum phenomenon , similar to quantum violations of the weak energy condition . both effects are limited in magnitude by quantum inequalities . although the effect of recoherence is small , its eventual measurement is a possibility . we would like to thank c.i . kuo , d.s . lee , k.w . ng and c.h . wu for useful discussions . this work was supported in part by the national science foundation under grant phy-0555754 .", "tags": [], "output_text_a": "This paper explores the concept of decoherence in quantum systems, focusing on coherent electrons interacting with a quantized electromagnetic field. Decoherence is crucial in the transition from quantum to classical systems and involves three main aspects: dephasing, entanglement, and \"which-path\" information. The study uses an electron interference experiment to illustrate these concepts, showing how photon emission leads to dephasing and entanglement, and how it can reveal the path taken by electrons. The paper also examines the effects of different initial states of the electromagnetic field, such as vacuum, thermal, and squeezed states, on decoherence. Notably, it discusses the phenomenon of recoherence, where certain quantum states can temporarily reverse decoherence effects, although this is limited by quantum inequalities. The authors suggest that while recoherence is a small effect, it could potentially be measured in future experiments. The work is supported by the National Science Foundation and acknowledges contributions from several collaborators.", "output_text_b": "This arXiv paper discusses the concept of decoherence in quantum systems, specifically focusing on coherent electrons coupled to the quantized electromagnetic field. Decoherence is a process by which a quantum system interacts with its environment, leading to a loss of quantum coherence and a transition to classical behavior. The paper introduces three distinct concepts associated with decoherence: dephasing, entanglement, and the revelation of \"which path\" information.\n\nThe authors use the example of an electron interference experiment to illustrate these concepts. They show that the coupling between the electrons and the quantized electromagnetic field leads to dephasing, entanglement between the electrons and photons, and the revelation of \"which path\" information through photon emission.\n\nThe paper also explores the impact of fluctuating or time-dependent electromagnetic fields on decoherence. They discuss the connection between Aharonov-Bohm phase fluctuations and decoherence, as well as the effects of boundaries, imperfect conductors, and non-vacuum initial states of the electromagnetic field.\n\nIn the context of a specific quantum state, the authors introduce the phenomenon of recoherence, which is an increase in contrast compared to the photon vacuum state for electrons emitted during a specific interval. They derive bounds on the degree of recoherence, analogous to quantum inequalities in quantum field theory.\n\nThe authors conclude by summarizing the aspects of decoherence discussed in the paper and acknowledging support from the National Science Foundation.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, discussing decoherence, dephasing, entanglement, \"which-path\" information, and recoherence.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding decoherence in quantum systems.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of an electron interference experiment to illustrate the concepts.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the effects of different electromagnetic field states and the potential for measuring recoherence.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"decoherence\" and \"recoherence\" but explains them adequately.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the electron interference experiment as a key part of the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing the potential measurement of recoherence and its implications.", "1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, discussing decoherence, dephasing, entanglement, and \"which path\" information, as well as the phenomenon of recoherence.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding decoherence in quantum systems, specifically with coherent electrons and the quantized electromagnetic field.\n\n4. **Methodology or Approach**: The summary mentions the use of an electron interference experiment to illustrate the concepts of decoherence.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the introduction of recoherence and the derivation of bounds on its degree.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like decoherence, dephasing, and recoherence.\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the key experiment of electron interference used in the research.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in understanding quantum decoherence and its potential impact."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the dmrg algorithm was introduced by steven white @xcite , as an algorithm for calculating ground state properties of principally one - dimensional strongly correlated systems in condensed matter physics . the connection between dmrg and matrix product states @xcite ( also known as finitely correlated states ) was first made by rommer and stlund @xcite , who identified the thermodynamic limit of dmrg with a position - independent matrix product wavefunction . although dmrg had already proven itself to be useful empirically , this was an important step in rigorously establishing the physical basis of the algorithm due to the concrete and easy to manipulate form of matrix product states . work on the spectra of density matrices @xcite , later formulated as scaling of the von neumann entropy @xcite has placed the algorithm on a firm footing , showing that the required computational effort ( realized via the basis dimension @xmath0 ) is essentially a function of the entanglement of the wavefunction @xcite , which for one - dimensional ground - states scales at worst logarithmically with the system size @xcite . computationally , mps algorithms came to the fore with the assistance of a quantum information perspective , leading to algorithms for periodic boundary conditions @xcite , and finite temperature algorithms based on density operators @xcite . at around the same time , methods for simulation of real time evolution were developed in dmrg @xcite , which can also benefit from mps formulations @xcite . the common theme of mps approaches is to allow algorithms that operate on multiple , distinct wavefunctions at the same time . this is possible in the original formulation of dmrg only by constructing a mixed effective hilbert space that is weighted appropriately to represent all of the relevant states simultaneously . this is inefficient , as the algorithms typically scale as @xmath1 ( or up to @xmath2 for periodic boundary conditions @xcite ) in the number of basis states @xmath0 , so increasing @xmath0 so as to represent multiple states in the same basis is typically much slower than performing separate operations on each basis . in addition , the mixed basis approach lacks flexibility . while traditional dmrg programs calculate the wavefunction and a few ( often predetermined ) expectation values or correlation functions , if instead the wavefunction is calculated in the mps representation of eq . ( [ eq : mpwavefunction ] ) it can be saved for later use as an _ input _ for many purposes . perhaps the simplest such operation beyond the scope of traditional dmrg is to calculate the _ fidelity _ , or _ overlap _ between the wavefunctions obtained from separate calculations . in the mps formulation , this calculation is straightforward . nevertheless the determination of the scaling function for the fidelity of finite - size wavefunctions for different interaction strengths , provides a new tool for investigating phase transitions and crossover phenomena @xcite . indeed , due to the simplicity of the calculation the fidelity is likely in the coming years to be the first choice for quantitatively determining critical points . similar measures of entanglement , such as the concurrence and single- and two - site entropy @xcite , are also straightforward to calculate , hence the mps formalism allows us to apply directly the emerging tools of quantum information to the study of realistic systems in condensed matter physics . an alternative measure , the loschmidt echo @xcite is important because , unlike many of the quantum information theoretic measures , this is directly accessible in experiments while showing the rich behavior of the simpler measures . the loschmidt echo is more time - consuming to measure numerically as it requires a full time evolution simulation rather than a direct measurement , nevertheless it is well within the current state of the art @xcite .    in this paper , we focus on the case of open boundary condition matrix product states . this does not preclude calculation of periodic systems , however the entanglement of such periodic states is increased such that in the large @xmath3 limit ( where @xmath3 is the lattice size ) , the number of states kept tends to the square of that required for open boundary conditions @xcite . algorithms exist for periodic boundary conditions @xcite and infinite systems @xcite ( not to be confused with the ` infinite - size ' dmrg algorithm ) , and the basic formulas introduced here carry over to these cases , but we do not describe the specific algorithms here . in sec . [ sec : mps ] , we introduce the basic formulation of matrix product states , and formulas for the fidelity . [ sec : operators ] is devoted to a new approach , whereby we construct the hamiltonian operator itself as an mps , with many advantages . we cover some remaining details of the dmrg algorithm in sec . [ sec : dmrg ] , before discussing in detail the use of abelian and non - abelian quantum numbers in sec . [ sec : quantumnumbers ] . we finish with a few concluding remarks in sec .  [ sec : conclusions ] , including some observations on finite temperature states . we denote an mps on an @xmath3-site lattice by the form @xmath4 the local index @xmath5 represents an element of a local hilbert space at site @xmath6 . the two important cases we cover here are when @xmath5 runs over a @xmath7-dimensional local basis for a wavefunction @xmath8 , in which case we refer to this as a matrix product wavefunction ( mpw ) , or @xmath5 is a @xmath9-dimensional local basis for all operators acting on a local site , which we refer to as a matrix product operator ( mpo ) . in this paper , we use mps for a generic state irrespective of the form of the local space , and use mpw or mpo as necessary when the distinction between wavefunctions and operators is important . in general , the matrix product form can also represent periodic @xcite and infinite ( non - periodic ) states @xcite , but here we use only the open - boundary form equivalent to the wavefunction obtained by dmrg @xcite . to enforce this boundary condition , we require the left - most matrix @xmath10 to be @xmath11 dimensional , and the right - most matrix @xmath12 to be @xmath13 . here we have introduced @xmath0 as the basis size , or dimension of the _ matrix basis _ of the @xmath14-matrices . this quantity is often denoted @xmath15 , or sometimes @xmath16 , in the quantum information literature , but we emphasize it is exactly the same quantity in all cases . in general @xmath0 is position dependent , as we do not require the @xmath14-matrices to be square even away from the boundary . because of the 1-dimensional basis at the boundaries we can regard the mps wavefunction to be a sequence of operators attached to left and right ( or outgoing and incoming ) vacuum states . this makes the operator product in eq . ( [ eq : mpwavefunction ] ) an ordinary number , so the trace operation can be dropped .      in practice , a mps state with no particular constraints on the form of the @xmath14-matrices is numerically difficult to handle . we are always free to insert some product of a non - singular @xmath17 operator @xmath18 and its inverse @xmath19 in the middle of our mps , thus we can apply an arbitrary transformation to the matrix basis of an @xmath14-matrix , as long as we make the corresponding transformation to its neighbor . using this freedom , we can transform the @xmath14-matrices into a form where they are orthonormalized , that is , we prefer that they satisfy one of two possible constraints , @xmath20 states satisfying these conditions are orthonormalized in the sense that if all @xmath14-matrices to the left of some matrix @xmath21 are orthogonalized in the left - handed sense , then the basis on the left - hand side of @xmath21 is orthonormal ( _ ie _ the identity operator in the effective hilbert space is trivial ) . conversely , if all @xmath14-matrices to the right of @xmath21 are orthogonalized in the right - hand sense , then the basis on the right - hand side of @xmath21 is orthogonal . usually , we want both these conditions to be true simultaneously . note that it is not , in general , possible for _ all _ of the @xmath14-matrices ( including @xmath21 itself ) to be in orthonormal form at the same time . there are several ways of transforming an arbitrary mps into this normalized form . two ways that we consider here are the singular value decomposition ( svd ) , and the related reduced density matrix , as used in dmrg @xcite . the simplest , and in principle the fastest , is the svd , well - known from linear algebra @xcite . for example , for the left - handed orthogonality constraint on @xmath22 , where we have re - inserted the matrix indices @xmath23 , we consider @xmath24 to be a single index of dimension @xmath25 , giving an ordinary @xmath26 dimensional matrix , and carry out the singular value decomposition , @xmath27 where @xmath28 is column - orthogonal , @xmath29 , and @xmath30 is row - orthogonal , @xmath31 . @xmath15 is a non - negative diagonal matrix containing the singular values . this form coincides with the schmidt decomposition , where @xmath15 gives the coefficients of the wavefunction in the schmidt basis @xcite . the matrix @xmath28 therefore satisfies the left - handed orthogonality constraint , so we use this as the updated @xmath14-matrix , and multiply the @xmath14-matrix on the right by @xmath32 . this implies that the @xmath14-matrix on the right is no longer orthonormalized ( even if it was originally ) , but we can apply this procedure iteratively , to shift the non - orthogonal @xmath14-matrix to the boundary  or even beyond it  at which point the @xmath33 @xmath14-matrix coincides with the norm of the wavefunction . an important point here is that we can choose to discard some of the states , typically those that have the smallest singular value . this reduces the matrix dimension @xmath0 , at the expense of introducing an approximation to our wavefunction , such that the squared norm of the difference of our approximate and exact wavefunctions is equal to the sum of the squares of the discarded singular values . note however that the singular values only correspond to the coefficients of the schmidt decomposition if all of the remaining @xmath14-matrices are orthogonalized according to eq . ( [ eq : normalizationconstraint ] ) . if this is not the case , the singular values are not useful for determining which states can be safely discarded .    alternatively , we can construct the reduced density matrix , obtained by tracing over half of the system . this is achieved by @xmath34 which is a @xmath35 matrix , with @xmath0 eigenvalues coinciding with the values on the diagonal of @xmath36 , and the remaining eigenvalues are zero . again , the eigenvalues are only meaningful if the remaining @xmath14-matrices are appropriately orthogonalized . the utility of the density matrix approach over the svd , is that we can introduce mixing terms into the density matrix which can have the effect of stabilizing the algorithm and accelerating the convergence , which is further discussed in sec . [ sec : dmrg ] . the overlap of two mps is an operation that appears in many contexts . for wavefunctions this gives the fidelity of the two states , and for operators this is equivalent to the operator inner product @xmath37 which induces the frobenius norm . direct expansion of the mps form yields , @xmath38 due to the open boundary conditions , the direct product @xmath39 reduces to an ordinary @xmath17 matrix , after which can construct successive terms recursively , via @xmath40 with an analogous formula if we wish to start at the right hand side of the system and iterate towards the left boundary , @xmath41 for the purposes of numerical stability , it is advisable for the @xmath14- and @xmath42-matrices to be orthogonalized in the same pattern , that is , @xmath43-matrices are associated exclusively with the left - hand orthogonality constraint and @xmath44-matrices are associated with the right - hand orthogonality constraint . if we iterate all the way to the boundary , the @xmath43- ( or @xmath44- ) matrix ends up as a @xmath33 matrix that contains the final value of the fidelity . alternatively , we can iterate from both ends towards the middle and calculate the fidelity as @xmath45 . the key notion of the matrix product scheme is that of _ local updates _ ; that is , we modify , typically though some iterative optimization scheme , one ( or perhaps a few ) @xmath14-matrix while keeping the remainder fixed . a useful and flexible alternative is the _ center matrix formulation _ , where , instead of modifying an @xmath14-matrix directly , we introduce an additional matrix @xmath46 into the mps , @xmath47 this allows us to preserve orthogonality of the matrices at all times ; matrices @xmath48 for @xmath49 are normalized always according to the left - handed constraint , and matrices for @xmath50 are normalized according to the right - handed constraint . we directly modify only the matrix @xmath46 which simplifies the local optimization problem as @xmath46 is just an ordinary matrix . to introduce the local degrees of freedom , say for the @xmath51 states , we _ expand _ the basis for @xmath21 . that is , we replace the @xmath17 dimensional matrices @xmath21 with @xmath52 matrices @xmath53 , given by @xmath54 and introduce the @xmath26 dimensional center matrix @xmath55 with @xmath56 running over @xmath25 states . this does nt change the physical wavefunction , as @xmath57 . similarly , we can expand the basis for the @xmath14-matrix on the right side of @xmath46 , to give the effect of modifying either a single @xmath14-matrix , or two ( or more ) at once . in the center matrix formulation , the singular value decomposition required for truncating the basis is simply the ordinary svd on the matrix @xmath58 , and we multiply ( for a right - moving iteration ) @xmath59 , which preserves the left - handed orthogonality constraint , and @xmath60 which is not orthogonal , but becomes so when we again expand the basis to construct the new @xmath46 matrix . the density matrix in the center matrix formulation is simply @xmath61 or @xmath62 for left and right moving iterations respectively . for readers already familiar with dmrg , the center matrix corresponds exactly with the matrix form of the _ superblock wavefunction _ @xcite . the utility of the mps approach is realized immediately upon attempting manipulations on the wavefunction eq . ( [ eq : mpwavefunction ] ) . suppose we have two distinct mps , defined over the same local hilbert spaces , @xmath63 the superposition @xmath64 is formed by taking the sum of the matrix products , @xmath65 , which can be factorized into a new mps , @xmath66 , with @xmath67 to preserve the one - dimensional basis at the boundaries , the direct sum is replaced by a concatenation of columns or rows , for the left and right boundary respectively . this procedure results in an mps of increased dimension , @xmath68 . thus , after constructing these matrices we need to re - orthogonalize the state , and then we can , if necessary , truncate the basis size to a given truncation error , which is well defined here and measures the exact difference between the original and truncated wavefunctions . alternatively , the normalized and truncated mps @xmath69 can be constructed directly , by calculating the overlap matrices @xmath43 between @xmath70 and @xmath71 . from the @xmath43-matrices introduced in eq . ( [ eq : ematrix ] ) , we can construct directly the orthogonalized reduced density matrices of @xmath69 and truncate the basis as required , in a single step . this approach has better computational scaling than the two - step procedure of first orthogonalizing and then truncating , especially when the number of mps in the superposition is large . but in general , iterative optimization approaches , where we use a dmrg - like algorithm to optimize the overlap @xmath72 , have even better performance scaling with large @xmath0 or more states in the superposition . a useful generalization of the mps structure eq . ( [ eq : mpwavefunction ] ) is to use it to represent an operator ( an mpo ) instead of a wavefunction . this has been used before for calculating finite - temperature density matrices @xcite , but here we instead want to use this structure to represent the hamiltonian operator itself . all hamiltonian operators with finite - range interactions have an _ exact _ mps representation with a relatively small matrix dimension @xmath73 . for example , the ising model in a transverse field has a dimension @xmath74 , and the fermionic hubbard model has dimension @xmath75 . we use the capital letter to distinguish from the dimension of the wavefunction , @xmath0 . similarly , the local dimension of the upper index is denoted here by @xmath15 , which is usually just equal to @xmath9 , but slightly complicated in the case of non - abelian quantum numbers ( see sec .  [ sec : nonabelian ] ) . we denote an mpo by the form @xmath76 where again we require that the first and last dimensions are @xmath77 , for open boundary conditions . the orthogonality constraint used previously for the mps , eq . ( [ eq : normalizationconstraint ] ) , is not appropriate for hamiltonian operators . when applied to an operator , the usual orthogonality constraints utilize the ( frobenius ) operator norm , which scales exponentially with the dimension of the hilbert space . with this normalization , components of an mpo hamiltonian , such as the identity operator or some interaction term , tend to differ in magnitude by some factor that increases exponentially with the lattice size . arithmetic manipulations on such quantities is a recipe for catastrophic cancellation @xcite resulting in loss of precision . mixing operators with a unitary transformation ( for example @xmath78 ) , will lead to a disaster if @xmath79 and @xmath80 differ by a sufficiently large order of magnitude , @xmath81 for typical double - precision floating point arithmetic . but such rotations are inevitable in the orthogonalization procedure because in general the operator inner product @xmath82 will not be zero . instead we completely avoid mixing different rows / columns of the operator @xmath73-matrices , only collapsing a row or column if it is exactly parallel with another row or column . in this case , the actual norm of each component of the @xmath14-matrices is irrelevant , as they are never mixed with each other ( but see also the discussion of the single - site algorithm in sec .  [ sec : dmrg ] ) . for physical hamiltonian operators this remains essentially optimal , with the minimum possible matrix dimension @xmath73 . the only operators for which this orthogonalization scheme does not produce an optimal representation are operators that have a form analogous to an aklt @xcite state where the local basis states of the @xmath83 chain are replaced by local operators . the resulting operator contains an exponentially large number of @xmath84-body interactions for all @xmath85 . we know of no physical hamiltonians of this form .    given a hamiltonian as a sum of finite - range interactions , it is possible to construct the operator @xmath73-matrices such that they are entirely lower ( or upper ) triangular matrices , thus in principle we can ` normalize ' the matrices via some kind of generalized @xmath86 or @xmath87 decomposition . in practice we do nt need to do this , as the hamiltonian can easily be constructed in lower - triangular form from the beginning . imposing , again without loss of generality , that the top - left and bottom - right components of the operator @xmath73-matrices are equal to the identity operator @xmath88 , we can construct the sum of @xmath89-site local terms @xmath90 as a position - independent mps , @xmath91 which we regard as a @xmath92 matrix , the elements of which are @xmath93 dimensional local operators . for nearest - neighbor terms , @xmath94 , we have @xmath95 with the obvious generalization to @xmath84-body terms . the direct sum and direct product of lower triangular matrices is itself lower triangular , thus this form can be preserved throughout all operations . for open boundary conditions , the left ( right ) boundary @xmath96 ( or @xmath97 ) matrices are initialized to @xmath98 and @xmath99 respectively .    the principal advantage of formulating the hamiltonian operator ( and indeed , _ all _ operators needed in the calculation ) in this way that it can be manipulated extremely easily , amounting to a symbolic computation on the operators . this is in contrast to the ad hoc approach used in past dmrg and mps approaches where the block transformations required for each operator are encoded manually , with limited scope for arithmetic operations . in particular , the sum of operators is achieved via eq . ( [ eq : mpssum ] ) . products of operators are achieved by matrix direct product ; given mpo s @xmath14 and @xmath42 , the product @xmath100 is given by the matrices @xmath101 an implication of this is that the square of an mpo has a matrix dimension of at most @xmath102 , which , since @xmath73 is usually rather small , means that it is quite practical to calculate expectation values for higher - order moments , for example of the _ variance _ @xmath103 which has been mentioned previously @xcite as it gives a rigorous _ lower bound _ on the energy ( although with no guarantee that this corresponds to the ground - state ) . in practice this lower bound is too wide to be useful in all but the simplest cases , but of more interest is the property that the variance is , to first order , proportional to the squared norm of the difference between the exact and numerical wavefunctions , and therefore also proportional to the truncation error @xcite ( see sec .  [ sec : dmrg ] ) . thus , this quantity gives a quantitative estimate of the goodness of the wavefunction even for situations where the truncation error is not available . for our numerical mps algorithms the variance takes the role of the precision @xmath104 in numerical analysis @xcite via @xmath105 .    of a similar form to the product of two operators , the action of an operator @xmath73 on a wavefunction @xmath106 gives a wavefunction @xmath107 with matrix elements , @xmath108 the mpo formulation also gives a natural form for the evaluation of expectation values , similarly to the fidelity of eq . ( [ eq : overlap ] ) , @xmath109 where the @xmath43- and @xmath44-matrices now have an additional index @xmath110 that represents the terms in the mpo @xmath73 , with a recursive definition @xmath111 where again we can either iterate all the way to a boundary , at which point the @xmath110 index collapses down to one - dimensional and the @xmath112 or @xmath113 are @xmath33 dimensional matrices containing the expectation value , or we can iterate from both boundaries and meet at the middle , where our expectation value is given by the scalar product eq . ( [ eq : expectation ] ) . incidentally , given that the identity operators occur in a fixed location in the operator @xmath73-matrix ( ie . at the top - left and bottom - right of the @xmath73-matrix ) this fixes the index @xmath110 of the reduced hamiltonian and identity operators for the left and right partitions of the system . that is , in the application of the hamiltonian @xmath114 matrices to the wavefunction we are guaranteed that the @xmath115 component of @xmath116 corresponds precisely to @xmath117 , and the @xmath118 component corresponds to @xmath119 . thus , even after an arbitrary series of mpo computations we can still identify exactly which component of the @xmath120 matrices corresponds to the block hamiltonian . this is useful for eigensolver preconditioning schemes @xcite , for example to change to a basis where the block hamiltonian is diagonal .    . the @xmath121 symbols denote the impurity magnetization calculated via adaptive time dmrg , the dashed line is a guide to the eye . parameters of the calculation were ( in units of bandwidth ) , @xmath122 , on a log - discretized wilson chain with @xmath123 . at time @xmath124 , the hamiltonian was switched to @xmath125 and @xmath126 . , scaledwidth=80.0% ]    as an example of the utility of this approach , fig . [ fig : timeexample ] shows the time evolution of the magnetization of the impurity spin in the single impurity anderson model ( siam ) , where the ground - state is obtained with a small magnetic field which is then turned off at time @xmath124 . the mps operator approach readily allows the evaluation of the commutators required for a small @xmath127 expansion of the expectation value of an observable in the heisenberg picture , @xmath128 - \\frac{t^2}{2!\\hbar^2}[h,[h , a ] ] - \\frac{it^3}{3!\\hbar^3}[h,[h,[h , a ] ] ] + \\cdots \\ ; .\\ ] ] since the number of terms in the repeated commutator will , in general , increase exponentially the accessible time - scales from such an expansion are clearly limited . nevertheless this is a very fast and accurate way to obtain short - time - scale dynamics , and in this example @xmath129 order is easily enough to determine the @xmath130 relaxation rate . for this calculation , the terms up to @xmath131 took a few seconds to calculate , while the @xmath132 term took 6 minutes and the @xmath133 term took just over an hour , on a single processor 2ghz athlon64 . this time was divided between calculating the mpo matrix elements ( the dimension of which was just over 2500 at the impurity site ) , and calculating the expectation value itself . we now have all of the ingredients necessary to construct the dmrg algorithm for determining the ground - state . indeed , given the previous formulations , the dmrg itself is rather simple ; using the center matrix formulation , we iteratively improve the wavefunction locally by using the center matrix @xmath46 as input to an eigensolver for the ground - state of the hamiltonian . the details of this calculation are precisely as for dmrg , already covered elsewhere @xcite . an important component of dmrg , which has been neglected in some matrix product approaches , is the truncation error . if only a single site is modified at a time , the maximum number of non - zero singular values is bounded by the matrix dimension @xmath0 , thus the matrix dimension can not be incrementally increased as the calculation progresses . some way of avoiding this limitation is practically essential for a robust algorithm . the original dmrg formulation @xcite solved this problem by modifying two a - matrices simultaneously , equivalent to expanding the matrix dimension for both the left and right @xmath14-matrices in eq . ( [ eq : centermatrixmps ] ) so that the center matrix has dimension @xmath134 . a scheme for single - site algorithms that avoids the limit on the singular values was introduced by steven white @xcite , which uses a mixed density matrix constructed by a weighted sum of the usual reduced density matrix and a perturbed density matrix formed by applying the @xmath112-matrices ( on a right - moving sweep ) or @xmath113-matrices ( on a left - moving sweep ) of the hamiltonian , @xmath135 where @xmath136 is some small factor that fixes the magnitude of the fluctuations . this solves nicely the problem of the bound on the number of singular values and introduces fluctuations into the density matrix that give the algorithm good convergence properties , often better than the two - site algorithm . a minor problem is that the scaling of the @xmath112 matrices is not well defined , in that we can scale the @xmath112-matrices by an arbitrary @xmath137 non - singular matrix @xmath138 , while at the same time scaling the @xmath44-matrices by @xmath19 . for one- and two - site terms , there is an ` obvious ' scaling factor to use , whereby the scaling factors are chosen such that the ( frobenius ) operator norm of the @xmath43 and @xmath44-matrices are identical , but i do nt know how this would apply more generally . an alternative that appears interesting is to apply the full hamiltonian to a density operator for the full system , @xmath139 , constructed from the left ( right ) reduced density matrix and the right ( left ) identity operator , followed by a trace over the right ( left ) partition . in mps form , this operation is @xmath140 where @xmath141 is an @xmath137 coefficient matrix . however , this scheme often fails ; incorporating the @xmath142 matrix reduces the fluctuations such that @xmath143 differs little from @xmath144 itself and the algorithm typically fails to reach the ground - state . the single - site algorithm @xcite corresponds to choosing @xmath145 . a useful compromise appears to be using only the _ diagonal _ elements , such that @xmath146 , but this is surely not the last word on this approach . both the two - site and mixed single - site algorithm inevitably result in a reduction in the norm of the wavefunction by truncating the smallest non - zero eigenvalues of the density matrix . the sum of the discarded eigenvalues , summed over all iterations in one sweep , is equal to the truncation error @xmath147 , familiar from dmrg @xcite ( but note that it is common in the literature to quote an average or maximum truncation error _ per site _ ) . this quantity is useful in giving an estimate of the error in the wavefunction in this is , for a properly converged wavefunction , proportional to the norm of the difference between the exact ground - state and the numerical approximation . the presence of the truncation error explains why the bare single - site algorithm , despite having slightly better variational wavefunction than the two - site or mixed single - site algorithms @xcite , converges much slower ; the single site algorithm is a highly constrained optimization within an @xmath0-dimensional basis , whereas the two - site and mixed single - site algorithms are selecting the optimal @xmath0 basis states out of a pool of a much larger set of states , namely the discarded states at each iteration ( total @xmath148 states ) . while the notion of truncation error remains useful in mps algorithms , for the purposes of error analysis we much prefer the variance eq . ( [ eq : variance ] ) as being a direct measure of the accuracy of the wavefunction , independent of the details of a particular algorithm @xcite . low - lying excited states can be constructed using this algorithm . this has been done in the past in dmrg by targeting multiple eigenstates in the density matrix , but the mps formulation allows a substantial improvement . namely , it is easy to incorporate into the eigensolver a constraint that the obtained wavefunction is orthogonal to an arbitrary set of predetermined mps s . that is , after constructing the mps approximation to the ground - state , we can , as a separate calculation , determine the first excited state by running the algorithm again with the constraint that our obtained wavefunction is orthogonal to the ground - state . this is achieved by constructing the @xmath43-matrices that project the set of states to orthogonalize against onto the local hilbert space . these matrices are precisely those used in constructing the fidelity , eq . ( [ eq : overlap ] ) , thus given the center matrix of some state @xmath149 , we project this onto the current hilbert space @xmath150 , and as part of the eigensolver , orthogonalize our center matrix against this state . this is a very fast operation , much faster than even a single hamiltonian - wavefunction multiplication . so it is quite practical to orthogonalize against a rather large number of states , the practical limit is rather on numerical limitations in orthogonalizing the krylov subspace in the eigensolver . if this is combined with an eigensolver capable of converging to eigenvalues in the middle of the spectrum ( say , the lowest eigenvalue larger than some bound @xmath151 ) , then we need only a small number of states to orthogonalize against , say half a dozen states immediately above @xmath151 in energy . in our numerical tests it seems to be rather common to skip eigenvalues , which is why we can not simply orthogonalize against a single state . with a larger number of states to orthogonalize against , skipping eigenvalues is less of a problem as we are likely to recover the missing eigenstate on a later calculation . using this approach , quantities such as the level spacing statistics can be determined for system sizes far beyond exact diagonalization @xcite . an important feature of matrix product states is that they can easily be constrained by quantum numbers representing the global symmetries of the hamiltonian , as long as the symmetry is not broken by the spatial geometry of the mps . for example , internal rotational symmetries such as @xmath152 and @xmath153 @xcite can be maintained exactly , but for a real - space lattice we can not utilize the momentum in the same way because the representation itself violates this symmetry . to achieve this , we impose a symmetry constraint on the form of the @xmath14-matrices , so that they are _ irreducible tensor operators_. that is , under a symmetry rotation the matrix @xmath154 for each local degree of freedom @xmath155 transforms according to an irreducible representation @xmath156 of the global symmetry group . this is a very general procedure , that is applicable to essentially all mps approaches and generalizations thereof .      for abelian symmetries , the representations are one - dimensional therefore the set of quantum numbers labeling the irreducible representations also forms a group , which we can write as @xmath157 for two representations @xmath158 and @xmath159 , where @xmath160 denotes the group operation . thus to incorporate abelian symmetries into the algorithm we simply attach a quantum number to all of the labels appearing in the mps , with the constraint that each @xmath14-matrix transforms irreducibly , so that the only non - zero matrix elements are @xmath161 where @xmath162 are the quantum numbers attached to the local basis state and left and right matrix basis states respectively . we have suppressed here indices not associated with a quantum number , a convention which will be followed for the remainder of the paper .    by convention , for our open boundary condition mps we choose the right hand vacuum state to have quantum number zero . the symmetry constraint eq . ( [ eq : quantumnumbers ] ) then implies that the quantum number at the left hand vacuum will denote how the state as a whole transforms ( the _ target state _ , in dmrg terminology ) . this is the only real difference between dmrg and mps algorithms , in that the dmrg convention is to construct both blocks starting from a scalar ( quantum number zero ) vacuum state , so that the superblock wavefunction is a tensor product of two ket states , @xmath163 whereas for the mps formulation the superblock wavefunction is represented by a scalar operator with a tensor product basis @xmath164 with quantum numbers @xmath165 . this means that , in contrast to the usual formulation of dmrg , the target quantum number is not encoded in the superblock but rather in the left vacuum state . a consequence of this is that dmrg is capable of representing simultaneously states with different quantum numbers , but an mps is not . this is an important detail , for example in the calculation of dynamical correlations , as both the correction vector @xcite and the similar ddmrg @xcite algorithm require a basis optimized for both the ground - state @xmath166 and the so - called lanczos - vector @xmath167 , where @xmath14 is some operator that may not be scalar . however , the mps formulation allows significant optimizations to these algorithms whereby the the calculation of the ground - state is decoupled from that of the lanczos vector @xcite and the two need never appear in the same basis . if the symmetry group is large enough that some elements do not commute with each other , then it is no longer possible to construct a basis that simultaneously diagonalizes all of the generators hence the approach of the previous section needs some modification . instead , we label the basis states by quantum numbers that denote the representation , which is no longer simply related to the group elements themselves as the representations are in general no longer ordinary numbers , but instead are matrices of dimension @xmath168 , and eq .  ( [ eq : abeliangrouprep ] ) no longer applies . for @xmath153 , we choose to label the representations by the total spin @xmath155 , being related to the eigenvalue of of the spin operator , @xmath169 . assuming that all of the required operations can be formulated in terms of manipulations of these representations , we have a formulation that is _ manifestly _ @xmath153 invariant ; the rotational invariance is preserved at all steps and at no time in the calculation is it necessary to choose an axis of quantization @xcite . this supersedes the earlier approach based on the clebsch - gordan coefficients @xcite . the non - abelian formulation is an important optimization , because it increases the performance of the algorithm by an order of magnitude or more @xcite compared with the abelian case , while enabling more accurate and detailed information about the ground - state magnetization . the basic ingredient that enables this rotationally invariant construction is the wigner - eckart theorem @xcite , which we can state as : when written in an angular momentum basis , each matrix element of an irreducible tensor operator is a product of two factors , a purely angular momentum dependent factor ( the `` clebsch - gordan coefficient '' ) and a factor that is independent of the projection quantum numbers ( the `` reduced matrix element '' ) . we formulate the algorithm in such a way that we store and manipulate only the reduced matrix elements , factorizing out completely the clebsch - gordan coefficients . the efficiency improvement resulting from the non - abelian formulation is that the matrix dimensions @xmath0 and @xmath73 now refer to the number of irreducible representations in the basis , which is typically much smaller than the total degree of the representation . for a scalar state , this equivalence is precise : a single representation of degree @xmath84 in the non - abelian approach results in @xmath84 degenerate eigenstates when the symmetry is not used , with a corresponding improvement in efficiency . we do not give here a full introduction to the theory of quantum angular momentum , rather we present , in the style of a reference , the important formulas required to manipulate mps wavefunctions and operators . for a comprehensive introduction see for example references @xcite . using the normalization convention of biedenharn @xcite , we define the matrix elements of a tensor operator @xmath170}$ ] transforming as a rank @xmath171 tensor under @xmath153 rotations , as @xmath172}_m \\ , | \\ , jm \\ , \\rangle } = { \\langle \\ , j ' \\ , \\| \\ , { \\mbox{\\boldmath $ t$}}^{[k ] } \\ , \\| \\ , j \\ , \\rangle } \\ ; { \\mbox{$c { } ^{j}_{m } { } ^{k}_{m } { } ^{j'}_{m'}$ } } \\ ; , \\ ] ] where @xmath173 is the clebsch - gordan ( cg ) coefficient , @xmath174 label the representation of @xmath153 , and @xmath175 and @xmath176 label the projections of the total spin onto the @xmath177-axis . using the orthogonality of the clebsch - gordan coefficients , this defines the reduced matrix elements , @xmath178 } \\ , \\| \\ , j \\ , \\rangle } = \\sum_{mm } { \\mbox{$c { } ^{j}_{m } { } ^{k}_{m } { } ^{j'}_{m'}$ } } { \\langle \\ , j'm ' \\ , | \\ , t^{[k]}_m \\ , | \\ , jm \\ , \\rangle } \\ ; , \\ ] ] where @xmath179 is arbitrary . note that this normalization is _ not _ the same as that used by varshalovich _ et . al _ @xcite , whom instead use an additional factor @xmath180 in the reduced matrix elements . this is a tradeoff ; some formulas simplify slightly with this normalization , but the normalization used here has the advantage that the reduced matrix elements of scalar operators ( with @xmath181 ) coincide with the actual matrix elements as all of the relevant clebsch - gordan coefficients are equal to unity . given the definition of the reduced matrix elements , we formulate the remaining formulas without further reference to the axis of quantization , except as an intermediate step to relate the reduced matrix elements prior to factorizing out the clebsch - gordan coefficients . the coupling of two operators is just as for the coupling of ordinary spins ; @xmath182}$ } } \\times { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k ] } \\ ; , \\ ] ] which denotes the set of operators with components @xmath182}$ } } \\times { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k]}_{\\mu } = \\sum_{\\mu_1 \\mu_2 } { \\mbox{$c { } ^{k_1}_{\\mu_1 } { } ^{k_2}_{\\mu_2 } { } ^{k}_{\\mu}$ } } { \\hbox{${s}^{[k_1]}_{\\mu_1}$ } } { \\hbox{${t}^{[k_2]}_{\\mu_2}$ } } \\ ; .\\ ] ] applying the wigner - eckart theorem gives , after a few lines of algebra , @xmath183}$ } } \\times   { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\right]^{[k ] } \\ , \\| \\ , j \\ , \\rangle } \\\\ = ( -1)^{j+j'+k } \\sum_{j '' } \\sqrt{(2j''+1)(2k+1 ) }   { \\mbox{$\\left\\ { \\begin{array}{ccc } \\!{j'}\\ ! &                  \\!{k_1}\\ ! & \\!{j''}\\ ! \\\\ \\!{k_2}\\ ! & \\!{j}\\ ! &                  \\!{k}\\ ! \\end{array } \\right\\}$ } } \\\\ \\times { \\langle \\ , j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ s$}}^{[k_1]}$ } } \\ , \\| \\ , j '' \\ , \\rangle } { \\langle \\ , j '' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } \\ , \\| \\ , j \\ , \\rangle } \\ ; , \\end{array } \\label{eq : irredproduct}\\ ] ] where @xmath184 denotes the @xmath185 coefficient @xcite .    a special case of the coupling law eq .  ( [ eq : irredproduct ] ) that we will need is when the operators act on different spaces , such that they have a tensor product form @xmath186}_{\\mu_1}$ } } & = &   { \\hbox{${t}^{[k_1]}_{\\mu_1}$}}(1 ) \\otimes i(2 ) \\ ; , \\\\ { \\hbox{${t}^{[k_2]}_{\\mu_2}$ } } & = &   i(1 ) \\otimes { \\hbox{${t}^{[k_2]}_{\\mu_2}$}}(2 ) \\ ; . \\end{array}\\ ] ] here @xmath187 denotes the identity operator and @xmath188}$}}(i)$ ] is an irreducible tensor operator with respect to the angular momentum @xmath189 of part @xmath6 of a two - part physical system ( @xmath190 ) . the total angular momentum of the system is @xmath191 . in this case , we write the coupling as @xmath192}$ } } \\mathbf{\\times } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$ } } { \\big]}$}^{[k]}}$ ] @xmath193 @xmath194}$}}(1 ) \\mathbf{\\otimes } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) { \\big]}$}^{[k]}}$ ] . repeated application of the wigner - eckart theorem to these tensor operators gives , after some algebra , @xmath195}$}}(1 ) \\mathbf{\\otimes } { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) { \\big]}$}^{[k ] } } \\ , \\| \\ , j \\ , ( j_1j_2\\alpha_1\\alpha_2 ) \\ , \\rangle } \\vspace{0.25 cm } \\\\ = { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j_1}\\ ! &                                  \\!{j_2}\\ ! & \\!{j}\\ ! \\\\ \\!{k_1}\\ ! & \\!{k_2}\\ ! &                                  \\!{k}\\ ! \\\\ \\!{j'_1}\\ ! & \\!{j'_2}\\ ! & \\!{j'}\\ ! \\end{array } \\right]$ } }          { \\langle \\ , j'_1 \\ , ( \\alpha'_1 ) \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_1]}$}}(1 ) \\ , \\| \\ , j_1 \\ , ( \\alpha_1 ) \\ , \\rangle }          { \\langle \\ , j'_2 \\ , ( \\alpha'_2 ) \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k_2]}$}}(2 ) \\ , \\| \\ , j_2 \\ , ( \\alpha_2 ) \\ , \\rangle } \\ ; , \\end{array } \\label{eq : tensorproductcoupling}\\ ] ] where @xmath196 $ } } \\equiv           [ ( 2j'_1 + 1)(2j'_2 + 1)(2j+1)(2k+1)]^{\\frac{1}{2 } }           { \\mbox{$\\left\\ { \\begin{array}{ccc } \\!{j_1}\\ ! &                                  \\!{j_2}\\ ! & \\!{j}\\ ! \\\\ \\!{k_1}\\ ! & \\!{k_2}\\ ! &                                  \\!{k}\\ ! \\\\ \\!{j'_1}\\ ! & \\!{j'_2}\\ ! & \\!{j'}\\ ! \\end{array } \\right\\}$ } } \\ ; , \\ ] ] and the term in curly brackets is the wigner @xmath197 coefficient , which can be defined as a summation over @xmath185 coefficients @xcite , @xmath198    we can define an operator norm , corresponding to the usual frobenius norm , such that @xmath199}$}}||^2_{\\mbox{\\tiny frob } } = \\tr { \\hbox{${\\mbox{\\boldmath $ x$}}^{[k]}$ } } \\cdot   { \\hbox{${\\mbox{\\boldmath $ x$}}^{\\dagger[k]}$ } } =   \\tr { \\hbox{${\\mbox{\\boldmath $ x$}}^{\\dagger[k]}$ } } \\cdot { \\hbox{${\\mbox{\\boldmath $ x$}}^{[k]}$ } } \\ ; .\\ ] ] after some arithmetic , we see that @xmath199}$}}||^2_{\\mbox{\\tiny frob } } = \\sum_{j'j } ( 2j'+1 ) |{\\langle \\ , j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ t$}}^{[k]}$ } } \\ , \\| \\ , j \\ , \\rangle}|^2\\ ] ] for the center - matrix formalism , we need the transformation @xmath200}$}}_{ij } \\rightarrow \\sum_k \\ ; c_{ik } \\ ; { \\hbox{${\\mbox{\\boldmath $ a'$}}^{[s]}$}}_{kj}\\ ] ] where @xmath171 is a @xmath201 dimensional index that encapsulates both a @xmath202 and a @xmath203 index runs over the clebsch - gordan expansion of @xmath204 . ] : @xmath205 . requiring @xmath206}$}}_{kj}$ ] to satisfy the right orthogonality constraint , @xmath207 , this requires @xmath208}$}}_{kj } = \\delta_{j'j}\\delta_{s 's } \\quad \\left[\\mbox{with }   k \\simeq ( s',j')\\right]\\ ] ] with @xmath209}$}}_{ij'}\\ ] ] in the other direction , we need @xmath200}$}}_{ij } \\rightarrow \\sum_k \\ ; { \\hbox{${\\mbox{\\boldmath $ a'$}}^{[s]}$}}_{ik } \\ ; c_{kj}\\ ] ] where @xmath210 . requiring @xmath206}$}}_{ik}$ ] to satisfy the left orthogonality constraint , @xmath211 , this requires @xmath208}$}}_{ik } = \\delta_{s 's } \\delta_{i'i } \\sqrt{\\frac{2k+1}{2i+1 } }   \\quad \\left[\\mbox{with } k \\simeq ( s',i')\\right]\\ ] ] and @xmath212}$}}_{j'j } \\sqrt{\\frac{2i+1}{2k+1}}\\ ] ]    the most natural definition for a matrix product operator has two lower indices and three upper , @xmath213}_{s'i ' } { } ^{si}\\ ] ] which transforms as the product of two operators of rank @xmath214 $ ] , with matrix elements @xmath215}_{r}$ } } \\ , | \\ , sq ; jm \\ , \\rangle } = { \\langle \\ , s';j ' \\ , \\| \\ , { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$ } } \\ , \\| \\ , s;j \\ , \\rangle } \\ ; { \\mbox{$c { } ^{s}_{q } { } ^{k}_{r } { } ^{s'}_{q'}$ } } \\ ; { \\mbox{$c { } ^{j}_{m } { } ^{k}_{r } { } ^{j'}_{m'}$ } } \\ ; .\\ ] ] note that the product of an operator and a state requires a contraction of the index @xmath155 , which has the symmetry of over two _ lower _ indices , and then shifting the result index @xmath202 from upper to lower . for @xmath153 , the required phase factor is @xmath216 , giving the rule @xmath217}$ } } = { \\hbox{${\\mbox{\\boldmath $ ( ma)$}}^{[s']}$ } }   = \\sum_s ( -1)^{s+k - s ' } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s 's } \\otimes { \\hbox{${\\mbox{\\boldmath $ a$}}^{[s]}$ } } \\ ; . \\label{eq : operatorstateproduct}\\ ] ]    the action of a matrix - product operator on another matrix product operator is @xmath218}$ } } = { \\hbox{${\\mbox{\\boldmath $ m$}}^{[m]}$ } } { \\hbox{${\\mbox{\\boldmath $ n$}}^{[n]}$ } } \\ ; , \\ ] ] which corresponds to the ordinary ( contraction ) product in the local basis and the tensor product in the matrix basis , and therefore results in the product of a @xmath185 and a @xmath197 coefficient from equations eq . ( [ eq : irredproduct ] ) and eq . ( [ eq : tensorproductcoupling ] ) respectively .    for the evaluation of matrix elements , we need the operation @xmath219 on expanding out the reduced matrix elements , we see immediately that the coupling coefficient is @xmath220}$}}_{i'j ' } = \\sum_{a , i , j , k , s , s ' } { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j}\\ ! &                                  \\!{s}\\ ! & \\!{j'}\\ ! \\\\ \\!{a}\\ ! & \\!{k}\\ ! &                                  \\!{a'}\\ ! \\\\ \\!{i}\\ ! & \\!{s'}\\ ! & \\!{i'}\\ ! \\end{array } \\right]$ } } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s's}_{a'a } { \\hbox{${\\mbox{\\boldmath $ a$}}^{[s']}$}}^*_{i'i } { \\hbox{${\\mbox{\\boldmath $ b$}}^{[s]}$}}_{j'j }   { \\hbox{${\\mbox{\\boldmath $ f$}}^{[a]}$}}_{ij}\\ ] ] conversely , from the left hand side , @xmath221 is @xmath222}$}}_{ij } = \\sum_{a',i',j',k , s',s } \\frac{2i'+1}{2i+1 } { \\mbox{$\\left [ \\begin{array}{ccc } \\!{j}\\ ! &                                  \\!{s}\\ ! & \\!{j'}\\ ! \\\\ \\!{a}\\ ! & \\!{k}\\ ! &                                  \\!{a'}\\ ! \\\\ \\!{i}\\ ! & \\!{s'}\\ ! & \\!{i'}\\ ! \\end{array } \\right]$ } } { \\hbox{${\\mbox{\\boldmath $ e$}}^{[a']}$}}_{i'j ' } { \\hbox{${\\mbox{\\boldmath $ m$}}^{[k]}$}}^{s's}_{a'a } { \\hbox{${\\mbox{\\boldmath $ a$}}^{[s']}$}}^*_{i'i } { \\hbox{${\\mbox{\\boldmath $ b$}}^{[s]}$}}_{j'j}\\ ] ]    on interchanging @xmath223 , @xmath224 , this becomes the equation for a direct operator - matrix - product multiply . but using the center - matrix formalism , we want instead the operation @xmath225 where @xmath46 and @xmath226 transform as scalars , the quantum numbers impose @xmath227 , @xmath228 . this is essentially a scalar product @xmath229 , and the coupling coefficients drop out . in this paper , we have presented an introduction to the mps formulation of the dmrg algorithm for the calculation of ground- and excited states of one - dimensional lattice hamiltonians . the mps formulation is extremely flexible , allowing the possibility for algorithms that act on several distinct wavefunctions at once . the simplest such algorithms are for the fidelity and expectation values involving unrelated wavefunctions , @xmath230 and @xmath231 , which are difficult to extract from conventional dmrg . this gives access to new tools for the analysis of quantum phase transitions , by measuring the scaling function and exponents for the fidelity between ground - states as a function of the interaction strength . in addition , the mps formulation allow optimized versions of algorithms for dynamical correlations @xcite and time evolution @xcite , which remains a fertile area for continued algorithmic improvements . finally , we note that in the simulation of finite temperature states via a density operator or purification @xcite in the absence of dissipative terms that mix the particle numbers between the real and auxiliary systems , the symmetries of the system are _ doubled _ , such that the symmetries of the hamiltonian are preserved by the real and auxiliary parts independently . for simulations in a canonical ensemble , this leads to a significant efficiency improvement that , as far as we know , has not yet been taken into consideration . thanks to ulrich schollwck and thomas barthel for many stimulating conversations . while preparing this manuscript , we learned that a rotationally invariant formulation using the clebsch - gordan coefficients @xcite has been applied to the tebd algorithm for infinite systems @xcite .", "tags": [], "output_text_a": "This paper discusses the Density Matrix Renormalization Group (DMRG) algorithm, originally introduced by Steven White, and its connection to Matrix Product States (MPS). The authors explore the use of MPS in representing wavefunctions and operators, highlighting its advantages in computational efficiency and flexibility. The paper delves into the mathematical formulation of MPS, including orthonormalization and the calculation of overlaps and fidelities between states. It also introduces the concept of Matrix Product Operators (MPO) for representing Hamiltonians, which simplifies the manipulation of operators in numerical simulations.\n\nThe authors emphasize the utility of MPS in studying quantum phase transitions and dynamical correlations, offering new tools for analyzing critical points through fidelity scaling functions. They also discuss the application of MPS in time evolution simulations and the calculation of excited states, noting the potential for significant algorithmic improvements.\n\nAdditionally, the paper addresses the incorporation of quantum symmetries, both abelian and non-abelian, into the MPS framework, which enhances the efficiency and accuracy of simulations. The authors conclude by acknowledging the potential for further advancements in finite temperature simulations and the benefits of preserving system symmetries in such contexts.\n\nOverall, the paper provides a comprehensive overview of the MPS formulation of the DMRG algorithm, highlighting its strengths and potential for future research in condensed matter physics.", "output_text_b": "The article discusses the Density Matrix Renormalization Group (DMRG) algorithm and its connection to Matrix Product States (MPS), also known as Finitely Correlated States. The MPS formalism has played a crucial role in establishing the physical basis of the DMRG algorithm and has been used to analyze the spectra of density matrices and the von Neumann entropy. The computational effort required for DMRG algorithms is essentially a function of the entanglement of the wavefunction, which for one-dimensional ground states scales at worst logarithmically with the system size. MPS algorithms have been further developed with the assistance of a quantum information perspective, leading to algorithms for periodic boundary conditions and finite temperature algorithms based on density operators. Methods for simulation of real-time evolution have also been developed in DMRG, which can benefit from MPS formulations.\n\nThe article focuses on the case of open boundary condition matrix product states, which does not preclude calculation of periodic systems, but the entanglement of such periodic states is increased. Algorithms exist for periodic boundary conditions and infinite systems, but are not described in detail in the article. The paper introduces the basic formulation of matrix product states and formulas for the fidelity, and discusses the construction of the Hamiltonian operator itself as an MPS.\n\nThe DMRG algorithm is then covered, followed by a discussion of the use of Abelian and non-Abelian quantum numbers in the algorithm. The paper concludes with a few observations on finite temperature states.", "score": 0.30000000000000004, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the DMRG algorithm, its connection to MPS, and the advantages of using MPS in computational simulations.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of improving computational efficiency and flexibility in simulations of quantum systems.\n4. **Methodology**: The summary mentions the use of MPS and MPO in the paper's methodology.\n5. **Significant Results**: The summary includes significant results, such as the utility of MPS in studying quantum phase transitions and dynamical correlations.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids excessive technical jargon and explains terms like MPS and MPO.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data, which is a requirement.\n10. **Significance/Impact**: The summary reflects the paper's significance in the field of condensed matter physics.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the role of MPS in establishing the physical basis of the DMRG algorithm and the development of algorithms for periodic boundary conditions and finite temperature states.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary does not explicitly highlight the research problem or question addressed by the paper.\n4. **Methodology**: The summary mentions the use of MPS and DMRG algorithms, but does not detail the specific methodologies or approaches used in the paper.\n5. **Significant Results**: The summary includes significant results, such as the scaling of computational effort with entanglement and the development of real-time evolution simulation methods.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses some technical terms like \"MPS\" and \"DMRG\" but does not explain them, which might be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in advancing the understanding and application of DMRG and MPS in quantum physics."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "closed - orbit theory was first introduced by du and delos  @xcite and bogomolny  @xcite some twenty years ago to interpret the modulations observed in the photo - absorption spectra of hydrogenic rydberg atoms in a magnetic field close to the ionization threshold . since that time , it turned out to be a powerful and flexible tool for the semiclassical interpretation of a variety of spectra . it has been used to describe atoms in electric  @xcite as well as parallel  @xcite or crossed  @xcite electric and magnetic fields . in the case of non - hydrogenic atoms , the influence of the ionic core can be modelled either by means of an effective classical potential  @xcite or in terms of quantum defects  @xcite . recently , closed - orbit theory has even been shown to be applicable to the spectra of simple molecules in external fields  @xcite . a complete description of photo - absorption spectra requires the calculation of the energies @xmath2 of the excited atomic states and the strengths of the spectral lines , which is characterized by the dipole matrix elements @xmath3 between the initial state @xmath4 and the rydberg state @xmath5 , where @xmath6 is the component of the dipole operator describing the polarization of the exciting laser field . these quantities are neatly summarized in the response function @xmath7 where @xmath8 denotes the retarded green s function . closed - orbit theory provides a semiclassical approximation to the quantum response function  ( [ gdef ] ) , which splits into a smooth part and an oscillatory part of the form @xmath9 where the sum extends over all classical closed orbits starting from the nucleus and returning to it after having been deflected by the external fields , @xmath10 is the classical action of the closed orbit , and the amplitude @xmath11 describes its stability and its starting and returning directions . its precise form depends on the geometry of the external fields . in section  [ sec : smatrix ] , it will be specified for systems with and without a rotational symmetry . although the closed - orbit sum  ( [ resoscgen ] ) appears to provide a straightforward means of calculating the response function from the classical closed orbits , this is actually not the case because the sum usually diverges for real energies @xmath12 . thus , the quantal information can not be extracted directly from the semiclassical expansion . one particular and widely applicable method to overcome the convergence problems of the closed - orbit sum is semiclassical quantization by harmonic inversion @xcite . for the hydrogen atom in a magnetic field , this method has been shown @xcite to be capable of extracting semiclassical eigenenergies and transition matrix elements from a closed - orbit sum .    in the present paper we will investigate how these results can be generalized to the hydrogen atom in crossed electric and magnetic fields . this problem is considerably harder than the treatment of the diamagnetic hydrogen atom , which possesses a rotational symmetry around the field axis . due to that symmetry , in classical mechanics the angular momentum around the field axis is conserved . so is , in quantum mechanics , the magnetic quantum number @xmath13 . in crossed fields , the rotational symmetry is broken . as a consequence , the selection rules for the @xmath13-quantum number no longer hold , and a multitude of additional lines appears in the quantum spectrum . at the same time , the determination of classical closed orbits gets significantly more difficult because three non - separable degrees of freedom have to be dealt with . a detailed description of the intricate pattern of closed orbits and their bifurcations was given in an accompanying paper @xcite . that data forms the basis of the present work , where the semiclassical treatment of the crossed - fields hydrogen atom will be dealt with , and we will freely use the nomenclature introduced in @xcite .    after the essential properties of the crossed - fields hamiltonian have been summarized in section  [ sec : classham ] , we start , in section  [ sec : smatrix ] , with a derivation of the closed - orbit formula  ( [ resoscgen ] ) in the context of the @xmath0-matrix formulation of closed - orbit theory introduced recently by granger and greene @xcite . we show that the novel framework can be extended to the crossed - fields situation , and we clarify some misleading conclusions arrived at in @xcite . section  [ sec : xqm ] describes the quantum spectrum under study , and section  [ sec : scllo ] compares it to a semiclassical spectrum in low resolution . in section  [ sec : sclhi ] , the results of a high - resolution semiclassical quantization using the technique of harmonic inversion are presented . the semiclassical spectrum correctly identifies the strongest spectral lines , but it fails to describe finer details of the quantum spectrum . in section  [ sec : sclrec ] , we compare a quantum recurrence spectrum to the classical data to show that the principal source of this difficulty lies in the abundance of closed - orbit bifurcations . uniform approximations provide a tool to cope with the divergences introduced into semiclassical spectra by bifurcations of classical orbits . a general technique for their construction is described in section  [ sec : uniform ] , and uniform approximations for the two types of generic codimension - one bifurcations identified in @xcite are derived . finally , in section  [ ssec : unifrecur ] we demonstrate how uniform approximations can be incorporated into recurrence spectra , thus paving the way for their inclusion into the high - resolution semiclassical quantization by harmonic inversion . throughout this work , we will assume the magnetic field to be directed along the @xmath14-axis and the electric field to be directed along the @xmath15-axis . in atomic units , the hamiltonian describing the motion of the atomic electron then reads @xmath16 where @xmath17 and @xmath18 denote the magnetic and electric field strengths , respectively , @xmath19 , @xmath20 , and @xmath21 is the @xmath14-component of the angular momentum vector . by virtue of the scaling properties of the hamiltonian  ( [ specham ] ) , if all classical quantities are multiplied by suitable powers of the scaling parameter @xmath22 the dynamics can be shown not to depend on the energy @xmath12 and the field strengths @xmath17 and @xmath18 separately , but only on the scaled energy @xmath23 and the scaled electric field strength @xmath24 . in particular , classical actions scale according to @xmath25 . thus , the semiclassical limit of large classical actions corresponds to the limit of large @xmath26 . the way of recording a quantum spectrum which is best suited for semiclassical investigations is scaled - energy spectroscopy . a spectrum then consists of a list of the scaling parameters @xmath27 characterizing the quantum states for given scaled energy @xmath28 and scaled electric field strength @xmath29 . scaled - energy spectroscopy offers the advantage that the underlying classical dynamics does not change across the spectrum . it will be adopted throughout this work . the basic observation fundamental to all of closed - orbit theory is a partition of space into physically distinct regions . in the core region close to the nucleus , the rydberg electron interacts in a complicated manner with all electrons of the ionic core . this interaction is manifestly quantum mechanical in nature , it can not be described in the framework of semiclassical theories . on the other hand , the interaction of the rydberg electron with the external fields is much weaker in the core region than its interaction with the core , so that the fields can safely be neglected . therefore , a description of the core obtained in the field - free case can be used . in particular , the initial state of the photo - absorption process is assumed to be localized in the core region and not to be influenced by the external fields .    in the long - range region far away from the nucleus , on the other hand , the external fields play a dominant role , whereas there is no interaction with the ionic core except for the coulomb attraction of its residual charge . in this region , the dynamics of the rydberg electron is well - suited for a semiclassical description . it is independent of the details of the ionic core .    in order to establish a link between the dynamics in the core and long - range regions , a matching region is assumed to exist at intermediate distances from the nucleus where both the external fields and the interaction with the core are negligible . thus , in the matching region the simple physics of an electron subject to the residual coulomb field of the core is observed . recently , granger and greene  @xcite proposed a novel formulation of the theory based on ideas borrowed from quantum - defect theory . their formulation achieves a clear separation between properties of the external field configuration and the ionic core , which are encoded in separate @xmath0-matrices . suitable approximations to the core and the long - range @xmath0-matrices can be derived independently . therefore , the formalism can be expected to allow a generalization of closed - orbit theory to atoms with ionic cores exhibiting more complicated internal dynamics than have been treated so far . the derivation given by granger and greene treated the case of an atom in a magnetic field only . it will now be extended in such a way that it holds for combined electric and magnetic fields with arbitrary field configurations . to this end , the ansatz and basic formulae of granger and greene s theory will be summarized in this section . a more detailed treatment can be found in their paper  @xcite . in subsequent sections , we will then turn to a discussion of the long - range scattering matrices pertinent to different external field configurations .    to lay the foundation for a definition of the @xmath0-matrices , we pick a basis set @xmath30 and @xmath31 of wave functions of the rydberg electron valid in the core and long - range regions , respectively , and expand in terms of spherical harmonics @xmath32 the channel index @xmath33 is to be understood as a double index @xmath34 characterizing the spherical harmonics . when studying a complicated atom with more than one relevant state of the core , additional information can be included in the channel functions @xmath35 .    in the matching region , the radial function matrices @xmath36 and @xmath37 can both be expressed in terms of radial coulomb functions . we use the functions @xmath38 and @xmath39 satisfying outgoing and incoming wave boundary conditions , respectively , given by  @xcite and choose the radial functions to be of the form and @xmath40 used by granger and greene  @xcite differ from those used by robicheaux  @xcite in that they are energy - normalized in rydberg rather than in hartree units . the radial function matrices given here agree in normalization with those adopted by robicheaux , whereas the matrices used by granger and greene are inconsistent with their equation ( 12 ) . ] @xmath41\\;,\\ ] ] @xmath42\\;.\\ ] ] physically , these choices mean that the basis function @xmath30 is a superposition of a single incoming wave in channel @xmath33 and the outgoing waves in different channels produced from it by scattering off the core . similarly , @xmath31 consists of an outgoing wave in channel @xmath33 and the returning waves generated by scattering off the external fields . the scattering matrices @xmath43 and @xmath44 thus summarize the physical properties of the core and the external fields , respectively . they are determined by the condition that the radial functions obey suitable boundary conditions , i.e. @xmath36 is regular at the origin , whereas @xmath37 vanishes or satisfies outgoing - wave boundary conditions at infinity for bound and free states , respectively . for hydrogen , @xmath43 is the identity matrix .    following previous work by robicheaux  @xcite , granger and greene derive the following expression for the response function  ( [ gdef ] ) : @xmath45 where the vector @xmath46 comprises the energy - dependent dipole matrix elements @xmath47 between the initial state and the core - region channel wave functions . for hydrogen they can be computed explicitly ( see , e.g. , @xcite or @xcite ) . the terms of the series  ( [ resseries ] ) embody contributions from paths where the rydberg electron takes zero , one , two , etc .  trips out into the long - range region and back to the core before interfering with the initial outgoing wave . in the semiclassical approximation , @xmath44 will be given in terms of closed orbits . a returning wave is associated with each returning classical orbit . by a general ionic core , it is scattered into all directions . the parts of the wave scattered into the outgoing direction of a closed orbit will then follow this orbit until they return to the core again . thus , core scattering leads to a concatenation of different closed orbits  @xcite . in hydrogen , the coulomb center scatters the incoming wave back into its direction of incidence , so that there is no coupling of closed orbits . terms describing repeated scattering off the external fields are therefore absent from the sum , and the hydrogen response function can be decomposed into a smooth part @xmath48 which is the same as in the field - free case and contains `` direct '' contributions where the electron does not scatter off the external fields at all , and an oscillatory part @xmath49 generated by the electron going out into the long - range region and being scattered back to the nucleus . it is this part which describes the impact of the external fields . the basis for a semiclassical approximation is provided by the retarded green s function @xmath50 describing the propagation of the electron from @xmath51 to @xmath52 at the energy @xmath12 . it can be expanded in terms of the channel functions as @xmath53 with @xmath54 the long - range scattering matrix is related to the green s function matrix by @xcite @xmath55^{-1 }       \\underline{g}(r_0,r_0 ) [ \\underline{f}^-(r_0)]^{-1 } \\;,\\ ] ] where @xmath56 is the matching radius , @xmath57 is the diagonal matrix @xmath58 comprising the radial wave functions , and @xmath59 denotes the part of @xmath60 satisfying incoming - wave boundary conditions at the final radius @xmath61 . the latter condition ensures that only electron paths approaching the matching radius from the long - range region contribute to @xmath44 , whereas paths that traverse the core region are omitted .      to obtain a semiclassical approximation to the long - range scattering matrix , we make use of the semiclassical green s function derived by gutzwiller  @xcite @xmath62 where the sum extends over all classical trajectories leading from @xmath51 to @xmath52 at the energy @xmath12 , @xmath1 is the number of degrees of freedom , @xmath0 is the classical action along the trajectory , @xmath63 the number of caustics along the trajectory , and @xmath64          \\frac{\\partial^2 s}{\\partial e \\partial{\\boldsymbol}x ' } &          \\frac{\\partial^2 s}{\\partial e^2 }        \\end{array }      \\right)\\ ] ] is the amplitude for the contribution of the trajectory . by ( [ greenchannel ] ) , we obtain a semiclassical approximation to the green s function matrix @xmath65 as usual in semiclassics , the integrals will be evaluated in the stationary - phase approximation . it yields a sum over all classical trajectories leaving the matching sphere at a direction given by @xmath66 and returning to it at @xmath67 . the condition that @xmath68 obeys incoming - wave boundary conditions at the final radius translates into the condition that only orbits going out from the matching sphere into the long - range region and then returning to @xmath56 are to be included , whereas orbits passing through the core region are omitted . if all factors in the integrand except for the exponential are assumed to vary slowly , the stationary - phase approximation reads @xmath69 where @xmath70 is the number of negative eigenvalues of the hessian matrix of @xmath0 occurring in the prefactor . because the initial state is assumed to be well localized , it is clear that the outgoing waves generated by the photo - excitation originate in the immediate neighborhood of the nucleus . therefore , only trajectories leaving the matching sphere radially need to be included in ( [ sclgreensp ] ) . by the same token , the trajectories can be assumed to return to the matching radius radially . thus , they are parts of closed orbits starting precisely at the nucleus and returning there .    by transforming ( [ greenddef ] ) to spherical coordinates and making use of the relations @xmath71 the amplitude factor @xmath6 for radial trajectories can be simplified to @xmath72 the determinants occurring in ( [ sclgreensp ] ) combine to @xmath73    = & \\det\\frac{\\partial(p_\\vartheta',p_\\varphi',p_\\vartheta , p_\\varphi ) }               { \\partial(\\vartheta,\\varphi , p_\\vartheta , p_\\varphi ) } \\cdot      \\left(\\det\\frac{\\partial(-p_\\vartheta',-p_\\varphi',p_\\vartheta , p_\\varphi ) }                     { \\partial(\\vartheta',\\varphi',\\vartheta,\\varphi ) }      \\right)^{-1 } \\\\[.5ex ]    = & \\det\\frac{\\partial(\\vartheta',\\varphi ' ) }               { \\partial(p_\\vartheta , p_\\varphi ) } \\;. \\end{split}\\ ] ] with these results , the green s function matrix assumes the form @xmath74    the determinant in the denominator of ( [ sclgreenchannel2 ] ) measures the dependence of the final angular momenta of the trajectory upon the starting angles . as it stands , it suffers from the singularities of the spherical coordinate chart : at the poles , neither the angle @xmath75 nor the angular momenta @xmath76 and @xmath77 are well defined , so that close to the poles , the calculation of the determinant becomes numerically unstable . the determinant can be rewritten in the form @xcite @xmath78 with a @xmath79-determinant @xmath80 devoid of any singularities . the parameter @xmath80 was already used in @xcite to study the bifurcations of closed orbits . we showed there that a closed orbit bifurcates if and only if @xmath81 . with the form  ( [ mprime ] ) of the stability determinant , the semiclassical green s function matrix reads @xmath82 which is free of any singularities introduced by the spherical coordinates .    by virtue of ( [ sgreen ] ) , the semiclassical long - range scattering matrix reads @xmath83 this expression can be further simplified if , for excited states close to the ionization threshold , the radial wave functions @xmath84 are approximated by the zero - energy wave functions , and the hankel functions are replaced with their asymptotic forms for large arguments  @xcite @xmath85 this approximation has proven accurate in many cases of interest , but it was called into question by granger and greene @xcite . it will be discussed further in section [ sec : corot ] , where we will show that there is no reason to doubt its reliability . it leads to @xmath86 because , due to the conservation of energy , @xmath87 if @xmath88 . in equation  [ scrossed0 ] , the channel indices @xmath89 are finally written out explicitly .    for a radial trajectory in a hydrogen atom going out from the nucleus to @xmath90 at zero energy , the action is @xmath91 , so that @xmath92 is the action of a closed orbit , measured from its start at the nucleus to its return . the semiclassical long - range @xmath0-matrix finally reads @xmath93 both the action @xmath10 and the stability determinant @xmath80 are evaluated at the nucleus rather than on the matching sphere . the response function is given by @xmath94 where the maslov index @xmath95 was increased by 1 to absorb an additional phase , and the function @xmath96 with the core - region matrix elements @xmath97 given by  ( [ channelmat ] ) , characterizes the initial state and the exciting photon . through the @xmath97 , the function @xmath98 is energy - dependent . in accordance with the choice of zero - energy radial wave functions in the @xmath0-matrix elements , @xmath98 will be evaluated at zero energy . this approximation has proven accurate in all applications of closed - orbit theory considered in the literature so far . however , from the @xmath0-matrix theory derivation it is obvious that the energy - dependence of both the dipole matrix elements @xmath97 and the @xmath0-matrix elements can easily be included should the need arise . the semiclassical response function ( [ gcrossed ] ) has the anticipated form ( [ resoscgen ] ) with @xmath99      an atom in a single ( electric or magnetic ) external field possesses a rotational symmetry around the field axis , which must be taken into account in the derivation of the closed - orbit formulae . the symmetry gives rise to a conserved magnetic quantum number @xmath13 , so that the angular momentum quantum number @xmath100 remains the only relevant channel index . the semiclassical scattering matrix reads @xcite @xmath101 where @xmath102 @xmath103 is the number of poles of @xmath104 encountered along the trajectory , and the sum includes all classical trajectories with azimuthal angular momentum @xmath13 joining the circles given by polar angles @xmath105 and @xmath106 on the matching sphere . if the radius of the matching sphere is much larger than the extent of the initial state , the trajectories can again be assumed to leave the sphere and return to it radially . strictly speaking , this condition can only be met if @xmath107 , which we will assume in what follows . if @xmath108 , the initial angular velocity @xmath109 must be non - zero , but it will be small if the matching radius is large . in this case , the trajectory will not actually close at the nucleus , but swing by at a short distance .    using , as above , the radial wave functions at zero energy , we obtain the semiclassical scattering matrix @xmath110 and the response function @xmath111 with @xmath112 and @xmath113 this result has the form ( [ resoscgen ] ) with @xmath114 it differs from the result obtained previously by du and delos @xcite in that in their work the amplitude factor @xmath104 of ( [ agg ] ) is replaced with @xmath115 this discrepancy was noted and numerically investigated by granger and greene @xcite . they attribute it to the approximation of using zero - energy wave functions , which can easily be avoided in the @xmath0-matrix theory , but is an integral part of the derivation given by du and delos .    ) , solid line ) and after du and delos @xcite ( equation  ( [ add ] ) , dashed line ) for the closed orbit perpendicular to the magnetic field as a function of the scaled energy . the scaled matching radius is @xmath116 . ]    for the closed orbit perpendicular to the field in the diamagnetic kepler problem and a scaled matching radius of @xmath116 , the amplitudes ( [ agg ] ) and ( [ add ] ) are plotted in figure [ ampefig ] . this figure is similar to figure 1 in @xcite , although for the latter the matching radius is not given . the agreement is excellent at scaled energies close to zero , but becomes poor if the energy decreases . however , contrary to their conclusions , the lack of agreement is not due to the zero - energy approximation , but rather to the dependence of the amplitudes on the matching radius . this statement can be verified most conveniently if the motion is described in semiparabolic coordinates @xmath117 if the trajectory is recorded as a function of a parameter @xmath118 related to the time @xmath119 by @xmath120 and a prime denotes differentiation with respect to @xmath118 , for trajectories with vanishing azimuthal angular momentum the equations of motion in the coulomb region read @xmath121 these equations are devoid of any singularities , so that they can conveniently be used to discuss the motion close to the nucleus . the transformation inverse to ( [ sparcoord ] ) is given by @xmath122 the momenta transform according to @xmath123 note that the transformation from semiparabolic to cartesian coordinates is not one - to - one , but that @xmath124 and @xmath125 are fixed up to the choice of sign only .    to evaluate ( [ agg ] ) and ( [ add ] ) , the derivatives @xmath126 and @xmath127 , must be calculated and their dependence on the matching radius @xmath61 must be determined . as the radial trajectory specified by a starting angle @xmath105 is independent of the radius where the angle is measured , the @xmath61-dependence of the derivatives is determined by the returning trajectories only . it can be evaluated as follows :    we arbitrarily fix the returning time of a closed orbit at @xmath128 , so that @xmath129 . the solution to ( [ speqns ] ) describing a trajectory returning at an angle @xmath106 is given by @xmath130 where the coefficients were chosen to satisfy the conservation of energy and to give the correct returning angle after a transformation to cartesian coordinates . the second expression in each line follows from @xmath131 , whence for @xmath132 @xmath133    equations of motion for the derivatives @xmath134 and @xmath135 are obtained by linearizing ( [ speqns ] ) . since ( [ speqns ] ) is already linear , the derivatives satisfy the same equations of motion as the coordinates themselves as long as the electron moves in the coulomb region . there the solutions read @xmath136 and @xmath137 equation ( [ scr ] ) yields @xmath138 so that the coefficients @xmath139 can be identified with the values of the derivatives obtained at @xmath140 . analogous expressions hold for @xmath135 .    from ( [ spmomenta ] ) , the amplitude ( [ agg ] ) @xmath141 can be evaluated . it is independent of @xmath61 , as could have been anticipated from the fact that @xmath76 is a component of the total angular momentum and thus is conserved along the trajectory once the electron has entered the coulomb region . the amplitude @xmath142 can also , up to an immaterial choice of sign , be identified with the monodromy matrix element @xmath143 introduced by bogomolny  @xcite to describe the semiclassical amplitudes , so that the amplitudes derived by granger and greene from the @xmath0-matrix theory agree with bogomolny s . similarly , the amplitude ( [ add ] ) used by du and delos reads , by ( [ spinverse ] ) , @xmath144 \\\\      & = \\frac{1}{a } + { \\cal o}\\left(\\sqrt{r}\\right ) \\;.    \\end{split}\\ ] ] thus , the amplitudes @xmath104 and @xmath145 agree in the limit of vanishing matching radius , but the amplitude @xmath145 proposed by du and delos exhibits a strong dependence on @xmath61 , whereas the amplitude @xmath104 given by granger and greene does not . these findings can also be confirmed numerically . figure [ amprfig ] shows the two amplitudes for the closed orbit perpendicular to the magnetic field at a scaled energy of @xmath146 as a function of the scaled matching radius @xmath147 . the dependence of @xmath145 on @xmath147 is considerable .    ) , solid line ) and after du and delos @xcite ( equatiion  ( [ add ] ) , dashed line ) for the closed orbit perpendicular to the magnetic field as a function of the matching radius at @xmath146 . ] we have thus shown that , contrary to the conclusion reached by granger and greene , the discrepancy between their semiclassical amplitude and that obtained by du and delos is not due to the zero - energy approximation , but rather due to the choice of a finite matching radius . in addition , the amplitude derived by granger and greene is not specific to the @xmath0-matrix formulation , it agrees with the result derived earlier by bogomolny in the context of a semiclassical wave function formalism . nevertheless , as it eliminates the need to specify a finite matching radius and allows one to calculate all classical quantities at the nucleus , it seems more appropriate than the amplitude given by du and delos , which introduces a certain arbitrariness in the choice of a matching radius . if schrdinger s equation for the crossed - fields hydrogen atom is rewritten in terms of the scaled energy and the scaled electric field strength , a quadratic eigenvalue problem for the scaling parameter @xmath26 is obtained . an exact numerical method of solution for the quadratic eigenvalue problem has become available only recently @xcite . we resort to the method introduced by main @xcite , which relies on an approximate linearization of the eigenvalue problem to compute eigenvalues in a small spectral interval . the accuracy of the linearization can be verified by comparing results calculated using different overlapping intervals . the eigenvalues are obtained to a relative accuracy of at least @xmath148 , which is far beyond the typical accuracy of semiclassical approximations , so that the algorithm is well suited to this study .     and the scaled electric field strength @xmath149 . the initial state is @xmath150 , the light is polarized along the magnetic field axis . the plot shows the squared dipole matrix elements , which for graphical reasons are multiplied by @xmath26 . the strengths of the extraordinarily strong lines of the lowest @xmath1-manifolds at @xmath151 are scaled down by a factor of 0.2 . ]    in the following we will discuss quantum and semiclassical photo - absorption spectra obtained for the scaled energy @xmath152 and the scaled electric field strength @xmath149 with the initial state @xmath150 and light linearly polarized along the magnetic field axis . a quantum spectrum for these parameter values is shown in figure  [ quantumfig ] . as for a semiclassical analysis ( see section  [ sec : sclrec ] ) it is essential to have as many eigenvalues available as possible , the calculation was extended up to @xmath153 . the spectrum shown in figure  [ quantumfig ] contains nearly 30,000 lines , many of which are too weak to be discernible in the plot . the eigenenergies of the field - free hydrogen atom satisfy @xmath154 so that in the scaled spectrum the unperturbed @xmath1-manifolds appear equidistantly spaced at @xmath155 these spacings can clearly be recognized in figure  [ quantumfig ] . at low values of @xmath26 , neighboring @xmath1-manifolds are isolated . furthermore , in this region the magnetic quantum number @xmath13 is nearly conserved . this is apparent from the fact that each @xmath1-manifold contains a central group of strong levels corresponding to @xmath107 , which can be excited even at @xmath156 , and adjacent groups of considerably weaker levels with @xmath157 . levels with higher magnetic quantum numbers are too weak in this region to be seen in the figure . at higher values of @xmath26 , the conservation of @xmath13 is violated , and individual @xmath1-manifolds acquire strong side bands . at even higher @xmath26 , different @xmath1-manifolds strongly overlap . throughout the spectral range shown , groups of strong lines indicating the centers of different @xmath1-manifolds are clearly discernible . a semiclassical approximation to a scaled photo - absorption spectrum is obtained if the closed - orbit theory formulae of section  [ sec : cocrossed ] are rewritten in terms of scaled quantities , viz . @xmath158 with @xmath159    when low - resolution photo - absorption spectra are to be calculated from ( [ goscscal ] ) , a method of cut - off must be adopted to deal with the divergence of the semiclassical closed - orbit sum . for this section , we choose a gaussian cut - off , i.e. ( [ goscscal ] ) is replaced with @xmath160 so that orbits with scaled actions larger than the cut - off action @xmath63 are smoothly suppressed . this smoothing corresponds to a convolution of the quantum signal with a gaussian of width @xmath161 .     and ( b ) @xmath162 . ]    to facilitate the comparison of ( [ goscsmooth ] ) with the convoluted quantum spectrum , we added the smooth part of the spectrum to @xmath163 , which was calculated by convoluting the quantum spectrum with a gaussian of width @xmath164 . this function is broad enough to wipe out the distinction between neighboring principal quantum numbers . results obtained for @xmath165 and @xmath162 are shown in figure  [ xlofig ] . in both cases it is apparent that the large - scale structure of equidistant principal quantum numbers is well reproduced by the semiclassical approximation . in the quantum spectra , the substructure of the individual @xmath1-shells can be discerned to a certain degree , given by the smoothing width @xmath161 . in the case of @xmath165 , much of this fine structure is also present in the semiclassical spectrum , but often the agreement is not good quantitatively . in particular , the peaks corresponding to the lowest @xmath1-manifolds are considerably wider in the semiclassical than in the quantum spectrum . if the cut - off action is increased to @xmath162 , finer details are resolved in the quantum spectrum . at the same time , the semiclassical closed - orbit sum becomes more oscillatory to reproduce this fine structure . it appears , however , to be somewhat over - oscillatory , developing structures absent from the quantum spectrum . this type of behavior is typical of closed - orbit sums in non - integrable systems . thus , it can be questioned if the low - resolution closed - orbit sum can meaningfully be extended to even longer orbits . a high - resolution quantization based on the present semiclassical approximation will be presented in the following section . for the calculation of a scaled semiclassical spectrum , the method of semiclassical quantization by harmonic inversion of @xmath166 function signals @xcite can be applied . this technique requires the inclusion of closed orbits up to a maximum scaled action , i.e. it replaces the gaussian cut - off used for the low - resolution semiclassical spectra presented in the previous section with a rectangular cut - off . a rough estimate for the required cut - off action can be obtained by means of perturbation theory @xcite . @xmath167 for the case @xmath168 and @xmath169 , i.e. @xmath170 , this estimate yields @xmath171 .    according to ( [ smaxpert ] ) , to compute levels at high quantum numbers @xmath1 a long semiclassical signal is needed , which can be hard or even impossible to obtain . we calculated closed orbits up to @xmath172 , so that the orbital data is available for nearly 18,000 closed - orbit multiplets . however , for reasons to be described in section  [ sec : sclrec ] a useful semiclassical signal can be constructed up to @xmath173 only , so that , from the above estimate , the semiclassical calculation can not reach manifolds much higher than @xmath174 . on the other hand , the semiclassical approximation must be expected to yield more accurate results for higher quantum numbers . thus , when a high - resolution semiclassical spectrum is to be calculated , a compromise must be made between the contradictory requirements of describing a spectral region at sufficiently high quantum numbers and with a sufficiently low spectral density . @r|rrr@ @xmath1 & @xmath175 ( scl . ) & @xmath175 ( qm . ) & @xmath176 + & & 9.88321 & 1.3617 + & & 9.91431 & 3.1145 + & & 9.97747 & 1.7474 + & 10.05366 & 10.05912 & 51.0512 + 6 & 10.09551 & 10.09621 & 20.9313 + & 10.15461 & 10.15378 & 7.0060 + & & 10.24076 & 0.9608 + & & 10.26612 & 2.0777 + & & 10.31803 & 1.9385 +    & & 11.56497 & 2.5663 + & 11.60898 & 11.60820 & 2.5875 + & 11.66889 & 11.67341 & 2.3104 + & 11.72048 & 11.73128 & 32.8808 + 7 & & 11.75121 & 16.7278 + & & 11.78850 & 10.0092 + & & 11.84856 & 5.6249 + & & 11.92188 & 1.9229 + & & 11.95821 & 1.7923 + & & 12.01338 & 2.4821 +    & & 13.23441 & 1.3668 + & & 13.25629 & 2.5141 + & & 13.30255 & 1.9971 + & 13.36921 & 13.36913 & 2.8189 + & 13.40177 & 13.40568 & 30.8875 + 8 & 13.44313 & 13.43744 & 16.0829 + & 13.48737 & 13.48146 & 4.8263 + & & 13.54340 & 4.3111 + & & 13.59258 & 1.0747 + & & 13.61133 & 1.9475 + & & 13.65111 & 1.4081 + & & 13.70866 & 2.9676 +    & & 14.91192 & 2.1880 + & & 14.94654 & 2.9922 + & & 14.99711 & 1.4563 + 9 & [ 2ex]15.06960 & 15.06470 & 3.2226 + & & 15.07888 & 25.1866 + & & 15.10074 & 8.4317 +    [ cols=\">,>,>,>\",options=\"header \" , ]     for the harmonic analysis of the closed - orbit sum we applied the method of @xmath166 function decimated signal diagonalization @xcite , which yields not only semiclassical eigenvalues and amplitudes , but also an error parameter estimating the precision of the eigenvalues . results obtained for @xmath152 and @xmath149 with a signal length of @xmath177 are compiled in table  [ xscltab ] . the table contains the quantum eigenvalues of @xmath26 and their dipole matrix elements for levels satisfying @xmath178 . it is obvious at a glance that out of the multitude of spectral lines with intensities varying over many orders of magnitude ( most of which are not contained in the table ) only the strongest lines were detected in the semiclassical spectrum . the semiclassical eigenvalues given are characterized by having small imaginary parts , small error parameters and large amplitudes as well as being stable with respect to a variation of numerical parameters . the calculation operates at the edge of convergence , and in a few cases one can be in doubt whether a level should be included according to these fairly `` soft '' criteria , but in general a clear decision can be made . semiclassical values for the transition strengths are not given because they are not reasonably well converged and depend strongly on the numerical parameters . one might expect that in each @xmath1-manifold it is the strongest lines that are detected semiclassically , and in general this expectation is confirmed by the numerical data . this can clearly be seen , e.g. , in the manifold @xmath179 , which contains the most stably converged lines in the spectrum . there are , however , a few conspicuous exceptions , e.g. at @xmath180 , where strong lines are missing whereas comparatively weak lines are found . for @xmath181 , no lines at all can be computed from the given semiclassical signal . if the signal length is decreased to @xmath182 , the three strongest lines appear in the spectrum in this manifold .    at higher @xmath1 , the number of strong lines in the quantum spectrum increases . so does the number of lines in the semiclassical spectrum until @xmath183 , where only three semiclassical lines are found . they appear rather arbitrarily scattered across the quantum spectrum , and their convergence is notably worse than in lower manifolds . it is clear that in this @xmath1-shell the semiclassical quantization with the given signal is about to break down . at @xmath184 , no lines can be detected semiclassically . as , from the above discussion , this failure was to be expected because the required signal length becomes too large , the obvious way to improve convergence seems to be to use a longer signal . however , if the signal length is increased to @xmath185 , no reasonably converged semiclassical lines can be found in any @xmath1-manifold . neither are results improved if the technique of harmonic inversion of cross - correlated closed - orbit sums @xcite is applied . this method has proven powerful in reducing the signal length required in a semiclassical quantization . in the present case , however , because the cross - correlation increases the total number of frequencies obtained from the harmonic inversion , the true eigenvalues are hidden among a multitude of spurious frequencies , and no useful results can be obtained .    for the time being , therefore , the results given in table  [ xscltab ] represent what can be achieved in the semiclassical quantization of the crossed - fields hydrogen atom . they confirm the applicability of the closed - orbit theory approach in principle , but they also reveal a fundamental problem in its present formulation . from the analysis of the ideal test signal it is clear that the signal length available is sufficient for a stable signal analysis . thus , if the semiclassical results are not good , the semiclassical signal itself , rather than the signal analysis , must be to blame . this conclusion is confirmed by the observation that an increased signal length destroys the results rather than improves them . we therefore start searching for a flaw in the construction of the semiclassical photo - absorption spectrum . a conspicuous problem lies in the fact that the set of closed orbits available is incomplete . in no series of rotators or vibrators can arbitrarily long orbits be calculated . in the case of vanishing electric field there is a critical angle @xmath186 which the starting angles of both rotators and vibrators approach as the orbits get longer . this convergence indicates that the orbits approach a separatrix between two families of tori in phase space . if sufficiently long orbits are studied , there are many closed orbits with very similar initial conditions , so that the numerical search for closed orbits must eventually fail .    , @xmath149 . ]    the region of phase space where the unknown orbits are located is lying close to a separatrix , so that it is highly unstable . the orbits can therefore be expected not to contribute much to the semiclassical signal . the magnitude of an orbit s contribution to the closed - orbit sum ( [ gcrossed ] ) is determined mainly by its stability determinant @xmath80 . figure  [ stabmfig ] shows the stability determinants of the vibrator orbits for @xmath152 , @xmath149 as a function of the scaled action . different series of vibrators can clearly be discerned in the plot . it is indeed unstable orbits with large @xmath187 that are missing in the data set , but on the other hand the stability determinants of the missing orbits are not large enough to regard the corresponding semiclassical amplitudes as negligibly small . because a vast majority of orbits has small @xmath187 and was found , one can still hope that useful results can be obtained from the semiclassical signal , at least for quantum states not located in the separatrix region in phase space , but it is clear that the quality of the semiclassical signal is reduced by its incompleteness .    to assess in detail the detrimental effect of the missing orbits and of any other sources of error that may exist , we carry out a semiclassical analysis of the quantum spectrum . according to equation  ( [ goscscal ] ) , in a scaled photo - absorption spectrum every closed orbit contributes a purely sinusoidal modulation to @xmath188 . this contribution can be extracted from the spectrum either by a conventional fourier transform or by means of a high - resolution method . the spectral analysis yields information about classical orbits returning to the nucleus . for this reason , the transformed spectrum is referred to as a recurrence spectrum . high - resolution methods @xcite extract the scaled actions and scaled semiclassical amplitudes of individual orbits and thus yield more complete information about the semiclassical spectrum than the fourier transform , but they fail if the average density of closed orbits per unit of scaled action is too large . by contrast , due to its linearity the fourier transform can be applied to any part of the recurrence spectrum with equal ease and numerical stability , irrespective of the spectral density . in dense regions , it will not be able to identify individual closed orbits , but it will nevertheless yield a recurrence spectrum that can be compared to the classical data . in this section we will present results obtained by both the fourier transform and a high - resolution method . the semiclassical recurrence spectra will be compared to classical results in order to identify the reason why the semiclassical signal is only partially suitable to a semiclassical quantization .    using either method , it is essential to note that the semiclassical closed - orbit formula can not be expected to yield accurate results for the lowest levels . thus , the low @xmath1-manifolds must be excluded from the semiclassical analysis , i.e. the analysis is based on the quantum spectrum given in an interval @xmath189 $ ] instead of @xmath190 $ ] . furthermore , to minimize the impact of boundary effects due to the finite length of the semiclassical spectrum , a smooth gaussian cut - off with width @xmath70 centered at @xmath191 is introduced . the smoothing replaces the peaks of the semiclassical recurrence spectrum by gaussians of width @xmath192 . the recurrence spectra presented here were calculated from the quantum spectrum shown in figure  [ quantumfig ] , for @xmath152 and @xmath149 , with @xmath193 , @xmath194 , and @xmath195 . for the high - resolution recurrence spectra , the method of @xmath166 function decimated signal diagonalization was used .     and @xmath149 . sticks and squares : semiclassical closed - orbit amplitudes , stars : harmonic inversion of the quantum spectrum.,title=\"fig : \" ]   and @xmath149 . sticks and squares : semiclassical closed - orbit amplitudes , stars : harmonic inversion of the quantum spectrum.,title=\"fig : \" ]    for low scaled actions , where only few closed orbits exist , the high - resolution analysis can be applied . results are shown in figure  [ recurreimfig ] , which compares both the scaled actions and the real and imaginary parts of the semiclassical amplitudes extracted from the quantum spectrum to the classical results . for most closed orbits , the agreement is excellent . exceptions occur for the shortest orbits , where the actions of rotator and vibrator orbits are too similar to be resolved by the harmonic inversion . at somewhat larger actions , the three orbits in each group fall apart into two rotator orbits with similar actions and a vibrator orbit with a slightly larger action . these observations can be made even more clearly if the absolute values of the amplitudes are considered . they are shown in figure  [ recurabsfig ] , where the results of the high - resolution analysis are also compared to those of the fourier transform . notice that for the fourier transform the semiclassical amplitude is given by the area under a peak rather than the peak height , so that an immediate comparison to the high - resolution results is difficult . in figure [ recurabsfig ] , the fourier transform was arbitrarily scaled so that the peak heights roughly match the values of the high - resolution amplitudes . for isolated orbits identified both in the fourier transform and the high - resolution spectrum , the agreement between the two methods is excellent . where several peaks overlap in the semiclassical spectrum , no direct comparison is possible because the peak phases can not be determined from the figure . figure  [ recurabsfig ] also extends the results shown in figure  [ recurreimfig ] to higher actions . in this region the density of closed orbits starts to increase because , on the one hand , rotators of the first series exist and , on the other , bifurcations of closed orbits generate additional orbits . apart from the fact that many orbits can not be identified individually even by the high - resolution method , the most conspicuous feature of figure  [ recurabsfig ] is that for many orbits the semiclassical amplitudes calculated from the classical data are considerably larger than those extracted from the quantum spectrum . in some cases , this is obvious at a glance , but a closer inspection of the figure reveals that this phenomenon is rather common . some specific cases will be described in detail in section  [ sec : uniform ] . the occurrence of exceedingly large semiclassical amplitudes is a well - known problem of both closed - orbit and periodic - orbit theory . it is associated with bifurcations of classical orbits , where , in the case of closed orbits , the stability determinant @xmath80 vanishes and the closed - orbit amplitude ( [ acrossed ] ) diverges . close to the bifurcation , @xmath80 is small . the semiclassical amplitude of the bifurcating orbit is therefore large and exceeds the value determined from the quantum spectrum . in a classical context , we have shown previously @xcite that vanishing @xmath80 is both a necessary and sufficient condition for a bifurcation of closed orbits . in the context of semiclassical closed - orbit theory , it is necessary to overcome the divergence of the closed - orbit formula occurring close to a bifurcation . this problem will be addressed in section  [ sec : uniform ] , after the impact of the bifurcations on the semiclassical signal at hand has been investigated further . whereas , in figure  [ recurabsfig ] , the vibrator orbits are sufficiently isolated to be resolved by both the harmonic inversion and the fourier transform across the entire range of actions , the rotators occur in groups of several orbits having nearly identical actions . they are not resolved properly by either method . instead , the fourier transform produces peaks describing the collective contribution of the orbits in a group . the harmonic inversion fits this contribution with fewer actions and amplitudes than the actual number of orbits . although the results can be expected to reproduce the quantum spectrum fairly well , the principal virtue of the high - resolution analysis  that it is capable of giving individual rather than collective contributions  is lost . it is therefore pointless to extend the high - resolution analysis to higher actions unless a significantly longer quantum spectrum can be obtained , and only the fourier transform will be used henceforth .     of the recurrence spectrum with @xmath195 ( see text ) . upper part : fourier transform of the quantum spectrum , lower part ( inverted ) : smoothed semiclassical recurrence spectrum . ] figure  [ recurlongfig ] displays the fourier recurrence spectrum with smoothing @xmath195 for scaled actions up to @xmath196 and compares it to the semiclassical spectrum . these results extend the semiclassical analysis of quantum spectra to significantly longer orbits than investigated in previous studies . they allow a verification of closed - orbit theory all the way up to the long orbits . it is immediately apparent from the figure that the quantum recurrence spectrum retains its pronounced peak structure . this is to be expected from closed - orbit theory , and indeed the peak locations are given by the actions of closed orbits for long as well as for short orbits . the basic idea of closed - orbit theory that recurrence peaks are related to classical closed orbits is therefore confirmed in principle even for very long orbits .    even for the largest actions considered , the quantum and semiclassical recurrence spectra agree quantitatively for some peaks . for most peaks , however , the peak heights in the quantum and semiclassical spectra disagree . there are quantum peaks that are smaller in the semiclassical spectrum or even completely absent . they can be attributed to missing orbits . on the other hand , in many cases the semiclassical peaks are significantly higher than the quantum peaks , sometimes by several orders of magnitude . exceedingly high peaks can be traced back to bifurcations of closed orbits if the possibility is ignored that a quantum peak can be small because orbits missing in the semiclassical spectrum interfere destructively with the orbits present . this latter mechanism becomes the more implausible the larger the semiclassical peak is in comparison to the quantum peak . taken together , the effects of missing orbits and of bifurcating orbits distort the semiclassical recurrence spectrum to the point where it can no longer be expected to provide a suitable basis for a quantization . a close inspection of the recurrence spectrum suggests that the problem posed by bifurcating orbits is more severe . exceedingly high peaks do not only occur frequently , but in addition the very fact that they are high increases their detrimental effect on the semiclassical photo - absorption spectrum . unless a suitable scheme for dealing with bifurcating orbits can be devised , no improvement of the semiclassical signal can be expected . we therefore turn to a description of the semiclassical treatment of bifurcating orbits by means of uniform approximations . exceedingly large contributions of single orbits to a semiclassical spectrum arise when the orbits are too close to a bifurcation to be regarded as isolated , as is implicitly assumed by the stationary - phase approximation used in the derivation of the closed - orbit formula . uniform approximations furnish a collective contribution of all orbits involved in a bifurcation . this solution was first suggested by ozorio de almeida and hannay @xcite in the context of periodic - orbit theory . their original approach was extended by different authors @xcite , so that today uniform approximations are a well - established tool of semiclassical physics . in reference @xcite , we identified two types of generic closed - orbit bifurcations of codimension one . the pertinent uniform semiclassical approximations will be derived in what follows .    in most cases of interest , a bifurcation destroys real orbits and turns them into complex ghost orbits that exist in the complexified classical phase space . ghost orbits can yield palpable contributions to semiclassical spectra @xcite . in particular , their knowledge is essential for the construction of uniform approximation . for the generic closed - orbit bifurcations , the ghost orbits were described along with the real orbits in reference  @xcite .    of particular importance is the observation that bifurcations of codimension higher than one are relevant to semiclassics , although on a classical level they are not generically encountered . they appear as sequences of generic bifurcations , which , if the individual bifurcations are sufficiently close , must be described collectively by a single uniform approximation . several examples of uniform approximations for these complicated bifurcation scenarios have been described in the literature @xcite . the principal requirement a uniform approximation must satisfy is to asymptotically reproduce the known isolated - orbits approximation when the distance from the bifurcation grows large , because in this limit the stationary - phase approximation can be expected to be accurate . in the following , we will advocate a somewhat heuristic technique for the construction of a uniform approximation , which is easy to handle and yields a smooth interpolation between the asymptotic isolated - orbits approximations on either side of the bifurcation . it will first be described in general terms . subsequently , uniform approximations describing the generic types of codimension - one bifurcations of closed orbits will be derived . a bifurcation scenario is described by a normal form @xmath197 depending on @xmath198 variables  @xmath119 and @xmath199 parameters  @xmath200 such that for any fixed value of the parameters @xmath200 there are stationary points of @xmath197 corresponding to the closed orbits involved in the bifurcation . the parameters @xmath200 must then depend on the energy @xmath12 to reproduce the bifurcations of the closed orbits .    for the uniform approximation we make the ansatz @xmath201 with @xmath202 here , the functions @xmath203 and @xmath204 as well as the parameter values @xmath205 have to be determined . all of them must be smooth functions of @xmath12 .    to find the asymptotic behavior of the uniform approximation ( [ unifansatz ] ) far from the bifurcations , ( [ unifi ] ) is evaluated in the stationary - phase approximation , which yields @xmath206 where the sum extends over all stationary points @xmath207 of @xmath197 that are real at the given @xmath200 , @xmath208 is the hessian determinant of @xmath209 , and @xmath210 is the number of negative eigenvalues of @xmath211 . this expression is supposed to reproduce the isolated - orbits approximation @xmath212 in this case , the sum extends over all closed orbits involved in the bifurcation that are real at the given energy @xmath12 . if the normal form @xmath197 has been chosen suitably , there is a one - to - one correspondence between these orbits and the stationary points @xmath207 . a comparison of  ( [ unifsp ] ) to  ( [ unifisol ] ) yields the conditions @xmath213 and @xmath214 these equations must be valid for real orbits . in most bifurcation scenarios , all orbits are real at least at certain energies . in these cases , it appears natural to postulate ( [ unifamp ] ) also to hold for ghost orbits . the parameter values one obtains are then smooth functions of the energy even at the bifurcations where the orbits become ghosts . in some instances , bifurcations involving only ghost orbits occur @xcite . in these cases , the condition  ( [ unifamp ] ) still produces smoothly varying parameters and enforces the desired asymptotics . the numbers  @xmath210 of negative eigenvalues change discontinuously at a bifurcation . for orbits which are real on either side of the bifurcation , so do the maslov indices contained in the semiclassical amplitudes  @xmath215 . these changes must compensate each other if the values  @xmath216 are to be continuous across the bifurcation . for these orbits , therefore , the change of maslov index occurring in a bifurcation must be equal to the change in @xmath210 and can be determined from the normal form . for ghost orbits , maslov indices are not well defined classically . they must be chosen such as to make @xmath216 continuous . the normal form parameters  @xmath200 and the action @xmath203 can be determined from  ( [ unifaction ] ) . they usually turn out to be unique . the amplitude function  @xmath204 , on the contrary , is unknown . once the parameters  @xmath200 have been found , ( [ unifamp ] ) specifies its values @xmath216 at the stationary points of @xmath197 . these values , of course , do not suffice to identify @xmath204 uniquely , so that there is considerable freedom in the choice of @xmath204 . usually , if there are @xmath33  orbits participating in the bifurcation scenario , we will approximate @xmath204 by a polynomial of degree  @xmath217 . this choice is justified by the observation that the uniform approximation is needed only close to a bifurcation , where all orbits are close to @xmath218 . thus , in the spirit of the stationary - phase approximation , the dominant contributions to the integral  ( [ unifi ] ) stem from the neighborhood of  @xmath218 , whereas the regions of large  @xmath119 do not contribute . a suitable approximation to  @xmath204 must therefore be precise close to the origin . this is achieved by a taylor series expansion , which leads to the polynomial ansatz . simple as it might appear , however , this choice can bring about a mathematical difficulty : a polynomial  @xmath204 diverges as @xmath219 , so that there is no guarantee that the integral  ( [ unifi ] ) will converge . if it does not , its divergence is an artefact of the choice of @xmath204 , because by construction the regions of large @xmath119 should not significantly influence the value of the integral . in this case , a suitable regularization scheme must be applied . it can be justified by verifying that the regularized integral possesses the correct asymptotics . a slightly simpler form of the uniform approximation is obtained if the function @xmath204 is assumed to be a constant . this approximation does not exactly reproduce the desired asymptotics , but as the transition across the bifurcation mainly results in a change of the stationary points of @xmath197 rather than essential changes in @xmath204 , it can be expected to capture the principal features . it is clear from the above description that there is a certain arbitrariness in the procedure . this arbitrariness can be reduced to the choice of a suitable amplitude function  @xmath204 , because by the splitting lemma and the classification theorems of catastrophe theory @xcite the uniform approximation can always be brought into the form  ( [ unifansatz ] ) by a suitable coordinate transformation , provided a normal form @xmath197 equivalent to the actual action function is given .    in the following sections , uniform approximations for the two generic codimension - one bifurcations described in @xcite will be derived along the lines given here . they turn out to be analogous to those for isochronous and period - doubling bifurcations of periodic orbits given by schomerus and sieber @xcite . the simplest closed - orbit bifurcation is the creation of two orbits in a tangent bifurcation . it is described by the fold catastrophe @xmath220 this normal form has stationary points at @xmath221 , which are real if @xmath222 . its stationary values are  ( [ foldval ] ) @xmath223 by  ( [ unifaction ] ) , the actions @xmath224 and @xmath225 of the bifurcating orbits must satisfy @xmath226 for these equations to hold , one must assume @xmath227 if the orbits are real and @xmath228 , @xmath229 if they are ghosts . these conditions determine how the orbits are to be associated with the stationary points of @xmath197 . equation  ( [ foldaction ] ) can be solved for @xmath230 and @xmath231 the observation that the bifurcating orbits are real if @xmath222 and ghosts if @xmath232 fixes the sign of @xmath200 . both @xmath203 and @xmath200 have thus be determined .    for the semiclassical amplitudes , ( [ unifamp ] ) yields @xmath233 with the ansatz @xmath234 for the amplitude function @xmath204 , we can solve for the parameters @xmath235 and @xmath236 to obtain @xmath237 the uniform approximation thus takes the form @xmath238 with @xmath239 the integral @xmath240 can be evaluated in terms of the airy function @xcite as @xmath241 whereas @xmath242 is given by its derivative @xmath243 with these results , the uniform approximation ( [ uniffold ] ) can be computed once the classical quantities @xmath244 and @xmath245 are known . after some rearrangements , ( [ uniffold ] ) can be found to agree with the uniform approximation derived by schomerus and sieber @xcite for isochronous bifurcations of periodic orbits , although its present form is much simpler .      the normal form for the symmetrized cusp catastrophe is given by @xmath246 it has stationary points at @xmath218 and @xmath221 and describes a pitchfork bifurcation , where two asymmetric orbits bifurcate off an orbit invariant under a reflection . we denote their actions and amplitudes by @xmath247 and @xmath248 , respectively , where @xmath249 is understood to be the cumulative amplitude of both asymmetric orbits .    as @xmath250 , the reference action @xmath203 must be chosen equal to the action of the symmetric orbit . the action difference is given by the stationary value of @xmath197 , which is @xmath251 , so that @xmath252 and @xmath253 the parameter @xmath200 has to be chosen positive if the asymmetric orbits are real , and negative otherwise . here , @xmath254 was assumed to be positive . if it is not , the normal form @xmath197 must be replaced with @xmath255 , which changes the sign of the stationary values .    due to the reflection symmetry , the amplitude function must be an even function of @xmath119 . we make the ansatz @xmath256 and solve  ( [ unifamp ] ) for the coefficients @xmath257    the complete uniform approximation reads @xmath258 with @xmath259 the integral @xmath240 can be evaluated analytically in terms of bessel functions @xcite : @xmath260 \\;.    \\end{split}\\ ] ] although it is not apparent at first sight , @xmath240 is a smooth function of @xmath200 . this can be verified if the series expansion @xcite @xmath261 with @xmath262 a power series in @xmath263 is used . in terms of @xmath262 , @xmath264 \\ ; ,    \\end{split}\\ ] ] which is indeed smooth . the second integral @xmath265 can be evaluated from    @xmath266 \\\\             & \\phantom{{i}\\pi\\sqrt{|a|}{e}^{-{i}\\frac{a^2}8}\\bigg\\{}+                    \\frac a8 \\,{e}^{{i}\\pi/8 }                         \\left[j_{-5/4}\\left(\\frac{a^2}8\\right ) -                                j_{3/4}\\left(\\frac{a^2}8\\right ) \\right ] \\\\ & \\phantom{{i}\\pi\\sqrt{|a|}{e}^{-{i}\\frac{a^2}8}\\bigg\\ { }                    + \\operatorname{sign } a \\,\\frac a8 \\,{e}^{-{i}\\pi/8 }                         \\left[j_{-3/4}\\left(\\frac{a^2}8\\right ) -                                j_{5/4}\\left(\\frac{a^2}8\\right ) \\right ]              \\bigg\\ } \\;.    \\end{split}\\ ] ]    this derivation contains an interchange of differentiation and integration which achieves a regularization of the divergent integral @xmath265 . it can be justified by verifying that the asymptotic behavior of ( [ i2cusp ] ) for @xmath267 agrees with the stationary phase approximation to ( [ ikcusp ] ) . the formulae derived in the preceding sections give the uniform approximations directly in terms of the semiclassical actions and amplitudes . this circumstance makes them easy to apply to scaled spectra : we simply put @xmath25 and @xmath268 . as @xmath26 is varied , the bifurcation is not encountered because the classical mechanics does not change , so that the isolated - orbits approximation does not actually diverge . however , if @xmath26 is small , the action differences between the bifurcating orbits are also small , so that the presence of the bifurcation is felt and the isolated - orbits formula produces exceedingly large contributions . for large @xmath26 , the action differences also grow large , so that the isolated - orbits approximation should be recovered in the limit of large @xmath26 .    ) for the scaled spectrum at @xmath152 and @xmath269 . ] these findings are illustrated in figure  [ unifscalfig ] for a pitchfork bifurcation taking place in the first series of rotators at a repetition number @xmath270 . at @xmath152 , the bifurcation takes place at the scaled electric field strength @xmath271 . the data shown in figure  [ unifscalfig ] was calculated for @xmath152 and @xmath272 , which is sufficiently far away from the bifurcation for the asymptotic regieme to be reached within the range of @xmath26 shown . as anticipated , in the limit of @xmath273 the complete uniform approximation agrees with the isolated - orbits formula . the simple approximation also reproduces the beats correctly , but it has a smaller amplitude .    , @xmath274 and @xmath149 . ] the scaled uniform approximation can be used to improve the semiclassical recurrence spectrum , but this requires some effort : whereas the isolated - orbits approximation yields @xmath166 function peaks in the recurrence spectrum , which are replaced with gaussians due to the smoothing of the recurrence spectrum ( see section  [ sec : sclrec ] ) , the uniform approximation is a complicated function of @xmath26 . it must be subjected to a numerical fourier transform in the same was as the quantum spectrum if its contribution to the recurrence spectrum is to be evaluated . because a bifurcation involves orbits with roughly equal actions , the uniform approximation will produce a recurrence peak at the appropriate action . an example is shown in figure  [ unifrecfig ] . it was calculated for the bifurcation already described in figure  [ unifscalfig ] . the gaussian smoothing used in section  [ sec : sclrec ] was replaced with a rectangular window , so that a number of side peaks appear . in this case , the fourier transform of both the uniform approximation and the isolated - orbits approximation was taken over the rectangular window @xmath275 $ ] . the bifurcating orbits have the scaled action @xmath276 , which is where the fourier peaks are centered in both approximations . the peak produced by the uniform approximation is considerably smaller . if this uniformization procedure is carried out for all excessively high bifurcation peaks , it should be possible to bring the semiclassical recurrence spectrum in figure  [ recurlongfig ] into agreement with its quantum counterpart . in practice , however , several obstacles stand in the way . first of all , in many cases ghost orbits must be included in the uniform approximation . they must be found and identified as pertinent to a given bifurcation before the uniformization can be performed . furthermore , even if all relevant orbits are real , those orbits connected with each other in a bifurcation must be recognized in the data set . this is by no means an easy task . for example , if in a given series of rotators and for a given winding number a quartet of orbits appears , there are two different doublet orbits out of which they may have bifurcated , and it is not clear in general which of them must be taken for the uniform approximation . in a single case , this can be found out fairly comfortably by hand . if many orbits are to be classified , however , it is essential to do the grouping automatically . we have not yet been able to devise a practical algorithm for this task , so that an automatized uniformization of all bifurcation peaks is presently impossible . apart from these rather technical difficulties , there are also some obstacles of more fundamental importance . consider , e.g. , the two high semiclassical peaks at @xmath277 in figure  [ recurabsfig ] . they are notably too high , and they are well - isolated from neighboring recurrence peaks , so that they may appear to be the ideal testing ground for the uniformization procedure . these peaks are generated by vibrators with repetition numbers @xmath278 and @xmath279 , respectively . the pertinent bifurcation scenarios were described in figures 17 and 18 of @xcite . the `` simple '' scenario taking place at @xmath278 consists of two orbits being generated in the rotational symmetry - breaking at @xmath280 , followed by a tangent bifurcation destroying one of them and a third orbit . to smooth this bifurcation peak , a uniform approximation describing the complete scenario must be found , which requires the construction of a suitable normal form . although a uniform approximation for the symmetry - breaking is available @xcite , the derivation of the pertinent normal form relies on principles different from the catastrophe theory classification used here , and it is not clear how these two can be united into a single normal form . thus , the construction of a uniform approximation for this bifurcation scenario , and even more so for the more complicated scenario at @xmath279 , remains an open problem to be solved in the future . it can be solved within the framework of uniformization presented in section  [ ssec : unifconst ] , but will require a novel way of constructing normal forms . the approach to high - resolution semiclassical quantization relies on the harmonic inversion of a fourier transformed semiclassical spectrum , i.e. of a recurrence spectrum . the above method of uniformizing the bifurcation - induced excessively high recurrence peaks in a semiclassical spectrum would therefore , if it could be implemented systematically , also pave the way for the inclusion of uniform approximations into a high - resolution semiclassical quantization , which has not been possible so far . we were able to demonstrate the feasibility of our method by way of example for the hydrogen atom in an electric field @xcite , which is less demanding classically . its application to the crossed - fields hydrogen atom , however , remains open for future work . for the first time , a high - resolution semiclassical quantization of the hydrogen atom in crossed electric and magnetic fields has been presented . it achieved the identification of the strong spectral lines in different @xmath1-manifolds . by means of a detailed semiclassical analysis of the pertinent quantum spectrum , it was shown that bifurcations of closed orbits play a crucial role in the semiclassical spectrum and preclude the resolution of finer details in the semiclassical spectrum . they pose a particular challenge to the semiclassical quantization because they require a special treatment by uniform approximations . a simple heuristic scheme for the construction of uniform approximations has been proposed . its simplicity and efficacy was demonstrated by a derivation of the uniform approximations for the codimension - one generic bifurcations of closed orbits . we have devised a general method for the inclusion of uniform approximations in a high - resolution semiclassical quantization by harmonic inversion . in a recent publication @xcite it was successfully applied to the hydrogen atom in an electric field . in the case of the crossed - fields hydrogen atom , the diversity and complexity of the bifurcation scenarios encountered so far hinders the systematic implementation of the uniformization procedure . the treatment of all relevant bifurcations and the calculation of a detailed semiclassical spectrum thus remain challenging tasks for future studies .", "tags": [], "output_text_a": "This paper explores the application of closed-orbit theory to the hydrogen atom in crossed electric and magnetic fields, extending previous work on hydrogen atoms in magnetic fields. Closed-orbit theory, initially developed to interpret modulations in photo-absorption spectra of hydrogenic Rydberg atoms, has been a powerful tool for semiclassical interpretations of various spectra. The study addresses the challenges posed by the lack of rotational symmetry in crossed fields, which complicates the determination of classical closed orbits and the quantum spectrum.\n\nThe authors derive a closed-orbit formula using the S-matrix formulation and compare quantum and semiclassical spectra. They find that while the semiclassical spectrum identifies strong spectral lines, it struggles with finer details due to closed-orbit bifurcations. Uniform approximations are proposed to address divergences caused by these bifurcations, and the authors describe a method for constructing these approximations.\n\nThe paper highlights the importance of bifurcations in semiclassical spectra and suggests that a systematic inclusion of uniform approximations could improve high-resolution semiclassical quantization. However, the complexity of bifurcation scenarios in crossed fields presents challenges for future research. The study demonstrates the potential of closed-orbit theory in complex field configurations and sets the stage for further advancements in semiclassical quantization techniques.", "output_text_b": "This arXiv paper discusses the application and generalization of Closed-Orbit Theory to the hydrogen atom in crossed electric and magnetic fields. The theory was first introduced for interpreting the modulations observed in the photo-absorption spectra of hydrogenic Rydberg atoms in a magnetic field. It has since been a powerful tool for the semiclassical interpretation of various spectra, including atoms in electric and parallel electric and magnetic fields, non-hydrogenic atoms, and simple molecules in external fields.\n\nThe paper focuses on the semiclassical approximation to the quantum response function, which splits into a smooth part and an oscillatory part. The oscillatory part is given by the sum over all classical closed orbits starting from the nucleus and returning to it after being deflected by the external fields. The precise form of the amplitude depends on the geometry of the external fields.\n\nThe authors investigate the convergence problems of the closed-orbit sum and propose a method to overcome these issues using semiclassical quantization by harmonic inversion. They aim to generalize these results to the hydrogen atom in crossed electric and magnetic fields, which is more challenging due to the broken rotational symmetry and the absence of selection rules for the magnetic quantum number.\n\nThe paper also discusses the impact of bifurcations of classical orbits on semiclassical spectra and proposes a general technique for constructing uniform approximations to cope with divergences introduced by these bifurcations.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the application of closed-orbit theory to hydrogen atoms in crossed electric and magnetic fields and the challenges posed by bifurcations.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of applying closed-orbit theory to systems with broken rotational symmetry.\n4. The methodology, including the derivation of a closed-orbit formula and the use of uniform approximations, is mentioned.\n5. Significant results, such as the identification of strong spectral lines and the challenges posed by bifurcations, are included.\n6. The language is clear and professional.\n7. Technical terms like \"closed-orbit theory\" and \"bifurcations\" are used appropriately, with some explanation provided.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data, which is a requirement.\n10. The potential impact of the study in advancing semiclassical quantization techniques is mentioned.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the application and generalization of Closed-Orbit Theory to the hydrogen atom in crossed electric and magnetic fields.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of interpreting modulations in photo-absorption spectra and generalizing results to more complex field configurations.\n4. The methodology of using semiclassical approximation and harmonic inversion is mentioned.\n5. Significant results, such as addressing convergence problems and proposing uniform approximations for bifurcations, are included.\n6. The language is clear and professional.\n7. Technical terms like \"Closed-Orbit Theory\" and \"semiclassical approximation\" are used but are necessary for understanding the context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data, which is a requirement.\n10. The potential impact of the paper in advancing the understanding of semiclassical spectra in complex fields is implied but not explicitly stated."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "numerical simulations of galaxy interactions suggest that mergers of spiral galaxies can lead to the formation of elliptical galaxies ( e.g. toomre & toomre 1972 ; barnes 1988 , 1992 ; hernquist 1992 , 1993 ) . these expectations are supported by optical imaging observations which show that several elliptical galaxies exhibit shells , ripples , arcs , counter - rotating cores , or faint tidal tails ; structures which are interpreted as evidence for galaxy interactions or mergers ( e.g. schweizer 1990 ) . the availability of high spatial resolution x - ray data allows us to investigate these indications using x - ray binary populations as probes of the star - formation histories of galaxies : high - mass x - ray binaries ( hmxbs ) form much more efficiently than low mass x - ray binaries ( lmxbs ) ( kalogera & webbink , 1998 ; portegies zwart & verbunt , 1996 ) , leading to a higher number of x - ray sources per star in young stellar populations . thus , using number counts of discrete x - ray sources , we can identify regions of recent or enhanced star - formation within a galaxy . for example , the spatial distribution of lmxbs ( which trace the old stellar populations ) in early - type galaxies is expected to be smooth , generally following the distribution of optical star - light . on the other hand , if there are any sites of recent star - formation ( e.g. triggered by galaxy interactions ) they are expected to host hmxbs , the larger numbers of which ( compared to the lmxbs ) may result in an overall non - uniform x - ray source spatial distribution . in this paper we present evidence for a non - uniform spatial distribution of x - ray sources in ngc  4697 , an elliptical galaxy without any indication for merging activity from optical data , and we compare these results with similar observations of other early - type galaxies , finding a second example in ngc  4261 . a more detailed investigation of the x - ray source populations , their degree of non - uniformity and links to other merger activity diagnostics will be presented in a forthcoming paper . ngc  4261 is a nearby ( 35.1  mpc for @xmath0=75@xmath1 ) e2 type galaxy , belonging to a poor group of galaxies ( garcia , 1993 ) but without any evidence for interaction with other members of the group . optical observations show a 20(@xmath2  pc ) long dust lane along the north - south axis of the galaxy ( martel 2000 and references therein ) and a spectacular nuclear dust disk ( @xmath3 ; jaffe 1996 , ferrarese 1996 ) . its optical isophotes in larger scales have a very strong boxy morphology ( e.g. peletier 1990 ) . optical spectroscopy shows that its dominant stellar population has an age of @xmath4  gyr ( trager 2000 ) . this galaxy also features two prominent radio jets ( e.g. birkinshaw & davies 1985 , jones 2000 ) emanating from an active nucleus . the mass of the supermassive nuclear black - hole is estimated to be @xmath5 ( ferrarese 1996 ) . ngc4261 was observed for 35  ks ( obsid 834 ; pi m. birkinshaw ) with the acis - s3 ccd on - board the x - ray observatory . the spatial resolution of is 0.5@xmath6 ( van speybroeck 1997 ) corresponding to a physical resolution of @xmath7  pc at the distance on the galaxy . although the observation was performed in 1/2 subarray mode in order to mitigate pile - up on the nuclear source , the active field of view ( @xmath8 ) was large enough to cover the whole galaxy ( @xmath9 ; de vaucouleurs et al . , 1991 ) . the initial processing of the data and the results from the analysis of the nuclear spectrum are presented in zezas ( 2003 ) . in this paper we concentrate on the spatial distribution of the discrete sources . we used the _ wavdetect _ algorithm , within the ciao v2.2 data analysis suite in order to search for discrete sources in four different energy bands : full band ( 0.3 - 7.0  kev ) , soft band ( 0.3 - 2.0  kev ) and hard band ( 2.0 - 7.0  kev ) . the limit of 7.0  kev was set in order to minimize contamination by the particle background , while the boundary of 2.0  kev was chosen in order to limit the contribution of the diffuse emission ( which is mainly thermal with @xmath10 ) only in the soft band . the source detection was performed in scales of 1 , 2 , 8 and 16 pixels and a limiting probability of @xmath11 chance detection over this field . we found a total of 62 sources within the s3 ccd . of those , 45 sources are within the d25 radius of ngc  4261 , 40 of which have significance higher than 3@xmath12 above the local background . the absorption corrected luminosities of the latter are above the eddington limit for an 1.4neutron star , ranging from @xmath13   up to @xmath14   ( with two sources above @xmath15 ) assuming a power - law model with @xmath16 and galactic line - of - sight @xmath17 column density ( @xmath18  ; stark 1992 ) . figure 1a shows an adaptively smoothed image of ngc  4261 in the full band , together with the d25 ellipse of the galaxy and the active field of the s3 acis - ccd . for reference in figure 1b we present a dss2 r - band image of the galaxy in the same scale , with the discrete sources marked by the best fit @xmath19 ellipses to the spatial distribution of their photons . from the x - ray image is clear that the spatial distribution of the discrete sources does not follow the distribution of optical star - light , but shows instead a distinct asymmetric pattern . in the following discussion we focus on the sources within the d25 ellipse .    in order to assess the probability that the non - uniform distribution may be observed by chance , we performed a kolmogorov - smirnov ( ks ) test to compare the distribution of the position angles ( pa ) of the sources ( measured clockwise from the north - south direction ) , with ( a ) a uniform distribution and ( b ) the azimuthal profile of the optical light of the galaxy . for the latter we created a sample of `` optical sources '' based on the star - light distribution in the dss2 r - band image , by randomly drawing position angles in 2   sectors from a flat parent distribution ( equivalent to assuming constant surface brightness within each 2   sector ) . the number of draws in each sector was proportional to the fraction of the total galactic light included in it , after removing any strong point - like optical sources ( most probably associated with foreground stars or background galaxies / agns ) . we found that both comparison distributions are inconsistent with the observed x - ray source azimuthal distribution above the 99.9% confidence level ( fig . this result holds even for model distributions with as few as 10 sources .    a search for irregularities in the azimuthal distribution of the pa of the sources , using the bayesian blocks method ( scargle 1998 ; scargle 2003 , in prep ) also shows that there is an excess of sources between pa=140   and pa=190   at a confidence level greater than 99% ( estimated from the prior of @xmath20 used in the decomposition ; however see scargle 2003 , in prep , for a caveat on this interpretation of the value of the prior ) . therefore , we conclude that the spatial distribution of the x - ray sources is not the same as that of the optical light tracing the stellar population . indication for a different distribution of x - ray sources and optical star - light has been also seen in ngc  720 ( jeltema 2003 ) , which has relatively young stellar populations ( @xmath21  gyrs ; trager 2000 ) . the x - ray sources in ngc  720 appear to trace out spiral arms , but performing the same analysis as above we confirm that this result is not statistically significant ( jeltema 2003 ) . based on the ks test we find that the x - ray source distribution is different from the optical distribution or a constant at the 50% and 70% confidence levels respectively . similarly , the bayesian blocks method showed that any local enhancement of sources is significant only at the 63% confidence level . we searched the archive for deep observations of nearby early - type galaxies , which also did not show any evidence for fine structure ( schweizer & seitzer 1992 ) or recent merging activity , in order to construct a comparison sample . we obtained data for ngc3379 , ngc4636 and ngc4697 , the general properties of which are presented in table  1 . we analyzed the data for these three galaxies in the same way as for ngc  4261 (  2.1 ) . a ks test between the x - ray source distribution and the comparison distributions ( calculated as described in  2.2 ) showed that only in the case of ngc  4697 we can rule out at the 98% confidence level ( fig . 2b ) that they belong to the same population ( @xmath22 probability that there is a local enhancement of sources based on bayesian blocks ) . in the other two cases ( ngc  3379 and ngc  4636 ) these confidence levels are @xmath23% and @xmath24% respectively , not allowing us to draw any definitive conclusions . our results show evidence for a non - uniform spatial distribution of the x - ray source population in two nearby apparently normal elliptical galaxies . these galaxies have very low fine - structure parameters ( @xmath25 for ngc  4261 and @xmath26 ngc4697 ) indicating that if they are merger products the merger event took place at least a few gyrs ago . this is because merger simulations indicate that ripples , shells or strong tidal tails are not easily observable for much longer than @xmath27  yr after the relaxation of the merged system ( e.g. quinn 1984 ; hernquist & quinn 1988 , 1989 ) . moreover , faint traces of tidal tails surviving for much longer might not be easily detectable in optical observations because of their very low surface brightness ( mihos 1995 ) . in fact , optical observations indicate stellar populations as old as 9 and 15  gyrs in the nuclear regions of ngc  4697 and ngc  4261 respectively ( trager 2000 ) . we propose that one or more localized star - formation events which occurred at most a few hundred myr ago , are responsible for the discrepancy between the optical and x - ray morphology of these two galaxies . according to x - ray binary formation models , lmxbs are more susceptible to effects such as supernova kicks and common envelope phases ( kalogera & webbink , 1998 ) than hmxbs , leading to hmxb formation efficiencies 10 to 100 times higher than for lmxbs ( portegies - zwart & verbunt 1996 ) . in fig .  3 we plot the @xmath28 ratios of star - forming galaxies from the survey of shapley , fabbiano & eskridge ( 2002 ) together with the mean @xmath28 ratio for the discrete x - ray sources in elliptical galaxies ( @xmath29 is in , in the 0.35 - 10.0  kev band , @xmath30 is the total b band luminosity in erg / s ] ; athey 2003 ) . from this plot is clear that even after accounting for a 50% contribution from the diffuse emission in star - forming galaxies ( e.g. zezas 2001 ) , the latter have systematically higher @xmath28 ratios than the x - ray binary component of early type galaxies . this together with the fact that individual hmxbs have significantly lower x - ray to b - band flux ratios than lmxbs ( van paradijs & mcclintock 1995 ) supports the picture that hmxbs are forming much more efficiently than lmxbs . recently barnes ( 2003 ) suggested that shock - induced star - formation can explain the star - forming activity observed along the tidal tails of `` the mice''(stockton 1974 ; de grijs et al . according to this model shock waves developing along the tidal tails can compress the neutral gas and trigger star - formation . this picture is consistent with the tail - like distribution of the observed x - ray sources in ngc  4261 , if the tidal tails are projected against the body of the merger remnant . if the age of this young stellar population is less than a few hundred myr , it forms x - ray binaries much more efficiently than the populations in the relaxed merger remnant . on the other hand its optical emission is diluted by the optical light of the much stronger old population making its detection in the optical band very difficult . depending on the strength of the star - formation , this may result in an overall projected spatial distribution of x - ray sources which is inconsistent with that of the star - light . this star - formation event can be well - approximated by an instantaneous burst , in which case the young x - ray source populations are expected to decay in a few hundred myr after the passage of the shock . therefore , we estimate that the shock should propagate with a speed of @xmath31  in order to cover the length of the region we observe x - ray sources ( 20.5  kpc ) , within the timescale of hmxb formation ( @xmath32  myr ) . this speed is realistic for shock waves developing in the interstellar medium . alternatively , n - body simulations show that structures resembling dwarf galaxies can form in the tidal tails as a merger completes ( barnes & hernquist 1992 , 1996 ) . these structures remain bound to the body of the remnant , orbiting it . because the objects formed in this manner have a range of binding energies in the potential well of the remnant , the characteristic time for them to fall back onto the remnant can be much longer than the time for the body of the remnant to relax ( hernquist & spergel 1992 ; mihos & hernquist 1996 ) . thus , depending on the orbital distribution , the remnant will eventually lose evidence for a merger , while tidal dwarfs continue to orbit at large radii . the interaction between the body of the merger and the condensations in the tidal tails can trigger small scale star - formation events and locally enrich the galaxy with a young stellar population . as was mentioned earlier , a young stellar population can form x - ray binaries very efficiently , while it is very difficult to detect it against the much brighter stellar populations of the merger remnant . therefore , depending on the strength of the star - formation , this may result in an overall spatial distribution of x - ray sources which is inconsistent with that of the star - light . since fall - back is estimated to occur for several gyrs after relaxation , we expect that even elliptical galaxies with stellar populations of @xmath33  gyrs may exhibit non - uniform x - ray source distribution , if they are the end - points of galaxy mergers . although the spatial distribution of the sources in ngc  4261 indicates that they are associated with the tidal tails , probably both mechanisms can produce populations of numerous , young x - ray binaries in merger remnants . given the timescales of the orbits of dwarf galaxies ( up to   1 gyr ) or the velocities of the shocks along the tidal tails , and the lifetime of hmxbs ( up to @xmath31  myr ) , we would expect long periods during which these galaxies have uniform x - ray source distributions . these periods are expected to be longer in the more evolved systems since the dwarf companions with short orbits are accreted first , which is consistent with our finding that this phenomenon appears in only a few of the most evolved galaxies examined . studies of a more complete sample of elliptical galaxies and merging galaxies in their latest stages of merging will allow us to further investigate this hypothesis . we thank the referee ( j. rose ) for a very helpful report . we also thank j. barnes for providing results prior to publication , and e. osullivan and a. athey for useful discussions on the x - ray emission of x - ray binaries in elliptical galaxies . we thank p. ratzlaff and j. j. drake for making available their code for bayesian blocks analysis . this work has been partly supported by nasa grants g01 - 2116x , g01 - 3150x , and atp nag5 - 12140 and nsf grants aci 96 - 19019 , ast 98 - 02568 , ast 99 - 00877 , and ast 00 - 71019 . lcccc ngc 4261 & e2 & 32.5 & 1.0 & dust , quadrupole structure ( a ) + & & & & age @xmath4  gyrs ( b ) + ngc 3379 & e1 & 8.1 & 0.0 & + ngc 720 & e5 & 28.0 & - & in group , age 5  gyrs ( b ) + ngc 4636 & e0 & 15.0 & - & complex x - ray morphology ( c ) + ngc 4697 & e6 & 15.9 & 0.0 & age @xmath34  gyrs ( b ) +", "tags": [], "output_text_a": "This paper investigates the spatial distribution of X-ray sources in elliptical galaxies, focusing on NGC 4261 and NGC 4697, using high-resolution X-ray data. The study finds a non-uniform distribution of X-ray sources in these galaxies, which do not show signs of recent mergers in optical observations. The presence of high-mass X-ray binaries (HMXBs) suggests recent or enhanced star formation, possibly triggered by past interactions or mergers. The authors propose that localized star formation events, potentially induced by shock waves or interactions with tidal tails, could explain the observed X-ray distribution. These findings challenge the assumption that elliptical galaxies are uniformly old and highlight the potential for recent star formation in these systems. The study suggests that even elliptical galaxies with old stellar populations may exhibit non-uniform X-ray source distributions if they are remnants of past mergers. Further research on a broader sample of elliptical and merging galaxies is needed to explore this hypothesis. The work is supported by various NASA and NSF grants.", "output_text_b": "This article presents evidence for a non-uniform spatial distribution of X-ray sources in the elliptical galaxy NGC 4697 and compares it with similar observations in other early-type galaxies, finding a second example in NGC 426", "score": 0.7, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the non-uniform distribution of X-ray sources in elliptical galaxies and the implications for recent star formation.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the spatial distribution of X-ray sources in elliptical galaxies.\n4. The methodology, involving high-resolution X-ray data analysis, is mentioned.\n5. Significant results, such as the non-uniform distribution of X-ray sources and the potential for recent star formation, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"high-mass X-ray binaries\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments or data, such as the use of high-resolution X-ray data, are mentioned.\n10. The summary reflects the paper's significance by highlighting the challenge to the assumption that elliptical galaxies are uniformly old.", "1. **Accurate Reflection of Main Findings**: The summary mentions the main finding of non-uniform spatial distribution of X-ray sources in NGC 4697 and NGC 4261, but it does not fully capture the detailed analysis and comparison with other galaxies.\n2. **Conciseness**: The summary is concise, but it is too brief and lacks depth in covering the paper's content.\n3. **Research Problem or Question**: The summary does not explicitly state the research problem or question addressed by the paper.\n4. **Methodology or Approach**: The summary does not mention the methodology or approach used in the paper, such as the use of X-ray data and analysis techniques.\n5. **Significant Results or Conclusions**: The summary mentions the significant result of non-uniform distribution but lacks detail on the implications or conclusions drawn by the authors.\n6. **Clear and Professional Language**: The language is clear and professional.\n7. **Avoidance of Technical Jargon**: The summary avoids technical jargon but does not explain the context or significance of the findings.\n8. **Logical Structure**: The summary lacks a clear structure, with no distinct beginning, middle, or end.\n9. **Key Experiments or Data**: The summary does not mention any key experiments or data used in the research.\n10. **Significance or Potential Impact**: The summary does not reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, false], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "percolation is a simple phase transition that can occur in a great many systems that exhibit branched network structure@xcite . the basic idea is that one occupies , at random , either the components of the system ( often sites on a lattice ) or the links between the components ( bonds between sites ) . as the occupation probability per site ( or bond ) increases , clusters of connected elements form and grow . when the occupation probability exceeds a critical value @xmath0 , there is a cluster that spans the length of the system ( or wraps , in simulations with convenient periodic boundary conditions ) , from one side to the other . in the context of a lattice , one could envision the percolating cluster as being a continuous object that touches both sides of the system . percolation theory has applications in a great many contexts , ranging from materials science topics such as gelation or transport in porous media , to societally relevant contexts such as disease propagation and forest fires . the percolation threshold is only known exactly for special classes of lattices , all in 2d@xcite . for most systems one must use monte carlo simulations to compute @xmath0@xcite . one determines @xmath0 in simulations by occupying sites ( or bonds ) one - at - a - time in a random order , stopping when the occupation of one more site ( or bond ) results in the formation of a wrapping cluster . different random orders give percolation at different site occupation fractions , and after a large number of lattices have been simulated one obtains a sigmoidal plot of percolation probability ( _ i.e . _ probability of a wrapping cluster forming ) _ vs. _ site occupation probability ( figure [ fig : rlschematic ] ) . the percolation threshold is the point on the plot at which the wrapping probability rises rapidly from zero to one .        despite the paucity of exact results , analytical formulas have been proposed to provide approximate predictions ( of varying accuracy ) for @xmath0 on different lattices , _ e.g.  _ @xcite . one physically intuitive approximation for the percolation threshold is a power - law relation , noted by galam and mauger , between coordination number @xmath1 and percolation threshold @xmath0@xcite . power - law behavior is ubiquitous in critical phenomena , and the power - law relation is known to give reasonably accurate predictions of @xmath0 for many lattices with @xmath2 in 2 , 3 , and sometimes higher dimensions . recently , it has also been shown to give fairly accurate predictions of @xmath0 for @xmath1 as low as 3 in 3d@xcite . the power - law relation has been shown to be problematic in regards to its predictive power and accuracy@xcite . for instance , lattices are grouped by galam and mauger into 3 different universality classes , but the theory provides no criterion for determining which class a lattice should belong to . moreover , there are many situations in which two lattices have the same coordination number and dimensionality , but due to differences in higher - order aspects of structure their percolation thresholds differ , _ e.g.  _ the triangular and octagonal lattices in 2d ( which have the same site percolation threshold but different bond percolation thresholds ) @xcite , or the body - centered cubic and stacked triangular lattices in 3d@xcite . the power - law scaling formula also lacks a number of other properties that would be desirable in any accurate and widely - applicable predictor of percolation thresholds@xcite . despite these problems , the power - law formula of galam and mauger remains of some interest because it shows a common ( if not universal ) trend of approximately power - law behavior in a phase transition . it is natural to ask whether this power - law scaling of @xmath0 continues to hold for @xmath3 . while it is impossible to construct an interesting lattice in which _ all _ of the sites have @xmath3 ( it would just be a linear chain ) , one can still construct very interesting lattices in which _ some _ of the sites have @xmath4 , _ i.e.  _ some dangling atoms , analogous to the role of singly - bonded hydrogen in a macromolecule , but from a percolation standpoint such lattices are uninteresting . the occupation of a @xmath5 site can not connect two clusters to form a single cluster that wraps around the system , and thus it can be eliminated from the model without affecting any conclusions concerning connectivity and transport . ] , and others have @xmath6 . the @xmath4 sites can make the lattice analogous to some oxides , with 2-coordinated sites ( analogous to oxygen atoms ) joining together exactly 2 other sites . unfortunately , the conjectured power - law relation can not remain valid when the average coordination number gets sufficiently close to 2 . the power - law formula is : @xmath7 where @xmath8 and @xmath9 for site percolation on 2d kagom lattices and regular lattices in 3 or more dimensions , and @xmath10 and @xmath11 for simple 2d lattices ( _ e.g .  _ square , honeycomb , and triangular ) . for @xmath4 and @xmath12 it predicts @xmath13 , when it should obviously be @xmath14 for @xmath4 ( which corresponds to a 1d chain ) . given that this relationship can not remain valid for @xmath1 arbitrarily close to 2 , but that it does work ( to within @xmath15 ) for @xmath16@xcite , it is reasonable to explore other low-@xmath1 cases to determine the accuracy of the power - law scaling relation . the introduction of 2-coordinated sites along the bonds of a lattice is equivalent to introducing a mixed site - bond problem , in which sites are occupied with probability @xmath17 and bonds are occupied with probability @xmath18@xcite . if we place a single oxygen atom ( 2-coordinated site ) along each bond , and treat the 2-coordinated sites the same as the other sites ( _ i.e .  _ occupy them with the same probability as other sites ) , we have a site - bond problem with @xmath19 . physically , one could visualize this problem as corresponding to an oxide , in which the two - coordinated sites correspond to oxygen atoms and the higher - coordinated sites correspond to atoms of higher valence . alternately , if one wished to visualize these problems in terms of communications networks or similar phenomena , the 2-coordinated sites would correspond to possible points of failure in connections between network nodes . if we introduce additional 2-coordinated sites ( _ i.e . _ more than one per bond ) and continue to treat them on an even footing with the other sites we have a problem with @xmath20 . this equivalence between a problem with low coordination number and a site - bond percolation problem enables us to use existing results for site - bond percolation to probe site percolation on lattices with @xmath3 . however , setting up a lattice with average coordination number less than 3 and finding its percolation threshold is not sufficient for understanding the behavior of @xmath0 at low @xmath1 . we also need a proper quantitative measure of average coordination number on that lattice . there are a number of plausible approaches that one could take . intuitively , one could compute the average number of atoms per site , an approach based on the structure of the lattice . alternately , one could compute the average number of available bonds between high - coordinated sites , an approach based on the connectivity of the lattice at a particular occupation fraction , and one that we will show to be useful in this work .    to illustrate the difference between these measures , consider the lattice in figure [ fig : zeff ] . it is a square oxide structure , with a 3-atom basis outlined in red . the average coordination number per site is easy to compute . there are 2 atoms with 2 neighbors apiece , and there is 1 atom with 4 neighbors . the average coordination number is thus @xmath21 . however , forming a cluster that wraps around the system requires linking 4-coordinated sites to one another . if we occupy sites with probability @xmath22 , and treat the 4-coordinated sites on the same basis as 2-coordinated sites ( _ i.e . _ occupy each type of site with the same probability ) then the average number of sites occupied between the 4-coordinated sites is @xmath23 , and thus each 4-coordinated site has connections to ( on average ) @xmath23 other sites ( which may or may not be occupied ) . more generally , if we start with a lattice on which each site has coordination number @xmath24 , introduce ( possibly multiple ) 2-coordinated sites along some or all of the bonds , and occupy those sites in such a way that there is a probability @xmath18 of having an unbroken bond between the @xmath25-coordinated sites , the average number of accessible neighbors per @xmath25-coordinated site will be @xmath26 . we will show here that choosing the later measure ( number of bonds between high - coordinated sites ) leads to a more robust scaling between percolation threshold and coordination number for lattices with mixed coordination numbers . in what follows we will study lattices with low coordination number in two different ways : first , we will use monte carlo simulations to compute site percolation thresholds on three oxide - type lattices with average coordination number less than 3 : the sio@xmath27 lattice ( a diamond lattice with 2-coordinated oxygen atoms along the bonds ) and two 3-coordinated lattices ( ( 10,3)-a and ( 10,3)-b@xcite ) with 2-coordinated oxygen atoms introduced along their bonds . as a check on the scaling behavior of @xmath0 at low coordination number we will also study a  cubic oxide \" with average coordination number 3 . we will show that the percolation thresholds of these lattices are consistent ( to better than @xmath28 , and in 2 cases to better than @xmath29 ) with the power law conjectured by galam and mauger if average coordination number is defined in terms of the average number of bonds between high - coordinated sites rather than the average number of neighbors per site . second , using existing data on site - bond percolation problems@xcite , we will map mixed site - bond problems onto pure site percolation problems with low coordination numbers and show that power - law scaling of @xmath0 with @xmath1 again holds if the average coordination number is measured by the average number of bonds per high - coordinated site . based on these results , we conjecture that power - law scaling between @xmath0 and @xmath1 holds if one defines @xmath1 in terms of available links between higher - coordinated sites , leading to an implicit formula for @xmath0 that incorporates aspects of lattice structure beyond dimensionality and average coordination number . we begin by briefly describing the four lattices that we are studying here : silicon dioxide , ( 10,3)-a oxide , ( 10,3)-b oxide , and cubic oxide . we will describe the structure of these lattices in their most symmetric forms , so that the reader can visualize them in plausible physical realizations . however , as in our previous work@xcite , for computational purposes we deformed the bond orientations so that the lattices could be mapped onto cubic grids , albeit with fewer than six bonds to each site . percolation thresholds are governed only by the presence of the bonds , not their orientations . deforming the lattice in a way that preserves the connections between sites does not change its percolation threshold , but leads to greater convenience in enumerating sites . the process of this deformation for ( 10,3)-a and ( 10,3)-b can be seen in greater detail in our previous work . the silicon dioxide lattice is based on the diamond lattice , which is a face centered cubic lattice whose primitive cell consists of two lattice points . each site is connected to four others in a tetrahedral pattern@xcite . the silicon dioxide lattice is a diamond lattice in which each bond between tetrahedrally coordinated sites has been replaced by a 2-coordinated site . the average coordination number per site on this lattice is @xmath30 .      the ( 10,3)-a lattice is part of a larger family of 3-coordinated lattices . the lattices in this family go by a number of names , but perhaps the most exhaustive exploration of this family of lattices was by wells , who coined the name ( 10,3)@xcite . the 3 reflects the 3-fold coordination of the sites . the number 10 reflects the fact that if one were to make a circuit on the lattice , traveling site - by - site and visiting no site more than once before the return to the starting point , the shortest path would be a 10-gon . the -a reflects the fact that there are 7 lattices in this family , named alphabetically : ( 10,3)-a , ( 10,3)-b , _ etc . _  in its most symmetric realization , the ( 10,3)-a lattice is a bcc lattice with a 4-atom basis , each site having three neighbors . this lattice is of interest for a number of reasons , including the fact that there are real materials with this structure ( _ e.g .  _ block copolymers@xcite , molecular magnets@xcite , and even butterfly wings@xcite ) . additionally , it has unusually high symmetry , possessing a property known as  strong isotropy\"@xcite , shared with only one other 3d lattice ( diamond ) . the structure of ( 10,3)-a is illustrated in our previous paper on this subject@xcite .    the oxide form that we will study for this lattice is one in which a 2-coordinated site is inserted between each 3-coordinated site . if we denote the 2-coordinated sites as o ( for oxygen ) and the 3-coordinated sites as x , the stoichiometric formula of this structure is x@xmath27o@xmath31 , but it is important to note that this is _ not _ the typical structure of a group iii oxide ( _ e.g .  _ the most common form of aluminum oxide has a coordination number higher than 3@xcite ) . for our purposes here , ( 10,3)-a oxide is of interest for being a convenient lattice with a low coordination number . for each pair of 3-coordinated sites there are 3 2-coordinated sites , giving an average coordination number of @xmath32 . we illustrate it figure [ fig:103aox ] , with bond orientations deformed to fit the lattice onto a cubic grid for convenience in enumerating sites .          the ( 10,3)-b lattice is similar to ( 10,3)-a , in that the shortest circuit that returns to a site is a 10-gon , and that the primitive cell has four atoms . the effective coordination number of the oxide is again 2.4 . however , the lattice contains an extra structural degree of freedom . even if all bond angles are 120 degrees , and all bonds are equal length ( _ i.e .  _ a highly symmetric realization of the lattice ) , we can continuously deform the lattice in a manner that uniformly changes the spacing between planes without altering any bond lengths or angles . in the maximally symmetric case , the lattice is body - centered tetragonal with a four - atom basis . if , however , we compress the lattice to decrease the spacing between planes , it begins to look like a 3d generalization of a honeycomb lattice , being a stacking of interwoven honeycomb planes . for this reason , the ( 10,3)-b lattice has been referred to as the  hyper honeycomb \" lattice , and has attracted some interest in the study of spin systems@xcite . we will consider an oxide form which , again , has a 2-coordinated site along each bond . we illustrate it figure [ fig:103box ] , with bond orientations deformed to fit the lattice onto a cubic grid for convenience in enumerating sites . cubic oxide is a simple cubic lattice ( 6-coordinated sites ) with 2-coordinated oxygen sites along the bonds between the 6-coordinated sites . there are 6 oxygen sites bonded to each 6-coordinated site . the oxygen sites are shared between 2 neighbors , so the stoichiometric formula is xo@xmath31 and the average coordination number is @xmath33 . while we have studied the case of @xmath16 in our previous work on 3-coordinated lattices , this case was included to see if there are significant differences between a homogeneous lattice ( all sites the same coordination number ) and an oxide with a different underlying structure but the same average coordination number . we determined @xmath0 with the algorithm of newman and ziff@xcite . we described our implementation in previous work@xcite . in brief , the newman - ziff algorithm occupies sites or bonds on a lattice in a random order . when a new site ( or bond ) is occupied , the program checks to see if it borders an existing cluster of sites ( or bonds ) . if so , it joins that cluster . if the new site ( or bond ) bridges two existing clusters , the clusters are merged . finally , if the occupation of a new site ( or bond ) joins two parts of an existing cluster and causes them to wrap completely around , then percolation has occurred , and the program moves on to randomly occupy sites or bonds on a new , fresh lattice . by repeating this process @xmath34 times , one can get the fraction @xmath35 of lattices of linear dimension @xmath36 ( _ i.e . _ number of unit cells in the system is @xmath37 ) that wrap when a given number @xmath38 of the sites are occupied .    in order to obtain wrapping probability @xmath35 as a function of site occupation _ probability _ @xmath22 , one convolves @xmath39 with the binomial distribution : @xmath40 the convolution amounts to a weighted sum over all possible realizations of a lattice in which sites are occupied with probability @xmath22 . for each possible occupation number we multiply the probability of that occupation number occurring ( from the binomial distribution ) by the wrapping probability for that occupation number . the plot of @xmath41 has a steep rise at the percolation threshold @xmath0 , and one could obtain a reasonable estimate of @xmath0 simply by looking for the point on the graph with the steepest slope . however , one can obtain a higher precision estimate by comparing plots of @xmath41 for several different values of the linear dimension @xmath36 . the percolation threshold is the point at which the wrapping probability crosses over from 0 to 1 , and the width of this cross - over region gets smaller as @xmath36 increases . consequently , above @xmath0 the wrapping probability increases as @xmath36 increases , and below @xmath0 the wrapping probability decreases as @xmath36 increases . if we make a plot of @xmath35 _ vs. _ @xmath36 for different site occupation probabilities , this plot will be flattest at @xmath42 . this method has been used to determine @xmath0 by us and others in previous work@xcite . there is a straightforward way to determine the uncertainty in an estimate of @xmath0 . if one repeatedly generates @xmath34 lattices with the same fraction of occupied sites , one would expect the standard deviation of the fraction that wraps to be given by the binomial distribution : @xmath43 . this is the magnitude of vertical fluctuations in the @xmath35 _ vs. _ @xmath22 graph , approximately @xmath44 for simulations of @xmath45 lattices wrapping with probability @xmath46 ( the numbers used here ) . the figures below do indeed exhibit vertical fluctuations of that order .    to go from vertical fluctuations to horizontal fluctuations ( _ i.e . _ the effect on the estimate of @xmath0 ) , one must divide by the slope of the @xmath35 _ vs. _  @xmath22 graph , giving : @xmath47 by way of comparison , when we generated @xmath45 lattices of size @xmath48 unit cells , typically with 4 or more sites ( depending on the lattice ) per unit cell , this amounted to producing of order @xmath49 random numbers , which should give uncertainties of order @xmath50 or larger . for the cases shown below , uncertainties were estimated to be between @xmath51 and @xmath52 , consistent with the number of random numbers generated . we convolved our @xmath39 data with the binomial distribution twice . on the first pass , we worked with a coarse - grained distribution , varying the site occupation probability @xmath22 in steps of @xmath53(smallest lattice size ) . we looked for the approximate intersection of the @xmath35 _ vs. _ @xmath22 curves to get an approximate @xmath0 , and used the values of @xmath35 and @xmath54 to get an approximate uncertainty in @xmath0 . after that , we again convolved @xmath39 with the binomial distribution , this time varying @xmath22 in steps of the estimated uncertainty . after the second convolution , we looked for the value of @xmath22 that made @xmath41 flattest ( _ i.e . _ smallest slope in a least squares fit ) as a function of @xmath36 , to get a better estimate of @xmath0 and its uncertainty .    using this method for determining @xmath0 and the uncertainty in @xmath0 , we previously@xcite determined the site percolation threshold of the 3d simple cubic lattice to be in close agreement with the literature value@xcite . as a further check on our work , before computing the percolation threshold of silicon dioxide we used simulations to determine the site and bond percolation thresholds of the diamond lattice , getting results in good agreement with the most precise available literature values@xcite . besides confirming the reliability of our implementation of the newman - ziff algorithm , this also gives us confidence that our code correctly represents the silicon dioxide lattice , as the code for silicon dioxide was based on the test code for the diamond lattice ( due to the close relationship between the lattices ) . figures [ fig : rlsio2 ] through [ fig : rl103b ] show @xmath35 _ vs._@xmath36 for silicon dioxide , cubic oxide , ( 10,3)-a oxide , and ( 10,3)-b oxide . for each type of lattice we generated @xmath45 cases . each figure shows plots for selected values of @xmath22 , spaced by intervals of the uncertainty ( as computed from eq . ( [ eq : uncert ] ) ) . there are fluctuations in the graphs of @xmath35 _ vs. _ @xmath36 , but they are of order @xmath43 as discussed above , and the mean values ( @xmath55 ) of the wrapping probability @xmath35 at the percolation threshold are very close to values found at @xmath0 in other investigations of 3d site percolation@xcite . for a given value of @xmath36 , all values of @xmath35 fluctuate in the same direction and by approximately the same amount ( irrespective of the value of @xmath22 ) because they are derived from the same set of simulated lattices . the percolation thresholds of these oxides are summarized in table  [ tab : table1 ] .     _ vs. _  @xmath36 for site percolation on the silicon dioxide lattice , for different occupation probabilities @xmath22 . the @xmath22 that produces the flattest overall trend ( dashed red line ) is taken to be the percolation threshold @xmath0 . ] _ vs. _  @xmath36 for site percolation on the cubic oxide lattice , for different occupation probabilities @xmath22 . the @xmath22 that produces the flattest overall trend ( dashed red line ) is taken to be the percolation threshold @xmath0 . ] _ vs. _  @xmath36 for site percolation on the ( 10,3)-a oxide lattice , for different occupation probabilities @xmath22 . the @xmath22 that produces the flattest overall trend ( dashed red line ) is taken to be the percolation threshold @xmath0 . ] _ vs. _  @xmath36 for site percolation on the ( 10,3)-b oxide lattice , for different occupation probabilities @xmath22 . the @xmath22 that produces the flattest overall trend ( dashed red line ) is taken to be the percolation threshold @xmath0 . ] ccll lattice & average neighbors per site & @xmath56 & @xmath0 ( site ) + ( 10,3)-a oxide & @xmath57 & @xmath58 & @xmath59 + ( 10,3)-b oxide & @xmath57 & @xmath60 & @xmath61 + silicon dioxide & @xmath62 & @xmath63 & @xmath64 + cubic oxide & 3 & @xmath65 & @xmath66 +    , and cubic oxide . the six regular lattices are ( _ from left to right _ ) 2d kagom  @xcite , ( 10,3)-a@xcite , diamond@xcite , simple cubic@xcite , body - centered cubic@xcite , and face - centered cubic@xcite . the factor of @xmath67 is included in the horizontal axis to enable comparisons between 3d lattices and the 2d kagom  lattice . ]    with these numbers in hand , we can compare the computed percolation thresholds with the predictions of power - law scaling . as discussed above , we have at least two plausible methods for quantifying the average coordination number on a lattice , and each measure , when used in the power - law , will give a different prediction for the site percolation threshold . in figure [ fig : error ] , we show the errors produced by each method for the four oxides studied , as well as the octagonal lattice ( which has mixed coordination number and is discussed below in section [ sec : discussion ] ) . for comparison , we also show the errors for several well - known uniform lattices ( all sites with same coordination number ) . quantifying average coordination number according to the average number of bonds available to a high - coordinated site improves the predictions by at least an an order of magnitude for each oxide . when we then plot @xmath0 as a function of @xmath68 we see that all of the oxides are very close to the same line as other lattices in figure [ fig : sitescaling ] . interestingly , the errors for the oxides are actually comparable to or smaller than the errors for most of the regular , higher - coordinated lattices . the errors for cubic oxide and silicon dioxide are @xmath69 and @xmath70 respectively , smaller than the errors that galam and mauger obtained when they tried to derive effective coordination numbers for uniform 3d lattices@xcite . the results are less impressive for the ( 10,3 ) oxides , but are still a definite improvement ( order of magnitude reduction in error ) over the results obtained by using an arithmetic average coordination number . even for the lowest-@xmath1 oxide , errors are of the same order of magnitude as the errors obtained by galam and mauger for uniform 3d lattices of higher coordination number . the fact that the formula of galam and mauger happens to be accurate for some lattices is not surprising ; what is more interesting is that the formula remains reasonably accurate when one applies it to site - bond problems . the good agreement with power - law scaling for an effective @xmath1 as low as 2.246 is especially significant in light of the fact that for the higher - coordinated uniform lattices the coordination number is unambiguously defined , whereas there are multiple plausible definitions for the average coordination number of an oxide .    ) . the black line shows the power - law scaling relation from eq . ( [ eq : powerlaw ] ) , with @xmath71 and @xmath72 from the second universality class identified by galam and mauger . the horizontal scale includes a factor of @xmath67 to enable comparisons between 3d lattices and the 2d kagom  and octagonal lattices . for lattices with variable numbers of nearest neighbors , @xmath1 is the average number of connections between high - coordinated sites at @xmath0 . ] we do not have to restrict our attention to oxides if we want to study low coordination numbers . we can also study site - bond percolation problems , in which ( as discussed above ) sites are occupied with probability @xmath17 and bonds with probability @xmath18 . one can hold the bond occupation probability fixed and vary the site occupation probability ( or vice - versa ) to see when a wrapping cluster forms , and thereby determine the site percolation threshold as a function of bond occupation probability @xmath18 ( or vice - versa ) . removing some of the bonds reduces the average coordination number from @xmath25 ( the coordination number of the underlying lattice ) to @xmath26 .    in figure [ fig:3dzeff ] we show plots of @xmath0 _ vs. _ @xmath26 , using data from tarasevich and van der marck@xcite . we considered several lattices that galam and mauger conjectured to fall into the same universality class . the right end of each data series lies close to the line representing the power law of galam and mauger , as well as the 2d octagonal lattice ( discussed below ) . the agreement ultimately breaks down at sufficiently small effective coordination numbers , because eventually the problem of constructing a wrapping cluster is dominated by the low number of occupied bonds , and scaling relations valid for site percolation no longer apply . nonetheless , for each lattice considered , the site percolation threshold initially follows the power - law scaling relation as some of the bonds are removed . quantitative agreement is confirmed by examining the errors in figure [ fig : sitebonderrors ] . the mere fact that the formula of galam and mauger works in these cases ( which have been conjectured to belong to a universality class ) is less interesting than the fact that the formula continues to work for those same cases when we generalize from site percolation to site - bond percolation .     and dimension @xmath73 for the universality class of 3d lattices ( and also 2d kagom lattices ) identified by galam and mauger . we include the dimension on the horizontal axis because the formula depends on @xmath74 and the kagom lattice is 2d . results for the diamond , octagonal , and kagom  lattices are in blue to highlight lattices with low coordination number . the black line shows the power - law scaling relation from eq . ( [ eq : powerlaw ] ) , with @xmath71 and @xmath72 from the second universality class identified by galam and mauger . ]        however , when we performed the same analysis for the universality class of 2d lattices identified by galam and mauger ( honeycomb , triangular , and square)@xcite , the results are not well - approximated ( even for @xmath75 ) by the power - law scaling of site percolation threshold . we have no good explanation for this phenomenon . it can not be a consequence of dimensionality , as the 2d kagom  lattice results follow the power - law scaling behavior of regular lattices . while the concept of 2 distinct universality classes at low dimension has been met with important objections@xcite , the differences between figure [ fig:3dzeff ] and figure [ fig:2d ] show that lattices that ( approximately ) follow a common scaling law for pure site and bond percolation also ( approximately ) also follow the same scaling law for mixed site - bond percolation . while the universality classes proposed by galam and mauger have significant defects ( _ e.g .  _ no criterion to predict which lattices should belong to which class ) , this difference in scaling behavior suggests that there may be some underlying phenomenon meriting further study . it is worth noting that ziff and gu have developed a useful and reasonably accurate ( better than @xmath44 ) approximate formula for site - bond percolation on the honeycomb lattice@xcite , but we are not aware of any generalization that we can use for other 2d lattices .     and dimension @xmath73 for the universality class of 2d honeycomb , square , and triangular lattices identified by galam and mauger . the black line shows the power - law scaling relation from eq . ( [ eq : powerlaw ] ) , with @xmath71 and @xmath72 from the first universality class identified by galam and mauger . ] the measures we considered here for average coordination number are not the only possible approaches . galam and mauger proposed that one could define an effective coordination number as the value of @xmath1 that minimizes the sum of the errors in the site and bond percolation thresholds ( with errors defined as the difference between the actual percolation threshold and the predictions of power - law scaling ) . however , this is an after - the - fact definition of effective coordination number , requiring knowledge of the true percolation threshold . one can not derive this effective coordination number from a direct examination of lattice geometry , but only from already knowing the percolation threshold . our approach , in which we define @xmath76 as the effective coordination number at the percolation threshold , can be used to obtain a prediction of @xmath0 without _ a priori _ knowledge of the percolation threshold . if one uses power - law scaling , one gets an implicit formula for an oxide s site percolation threshold @xmath0 : @xmath77 this equation can be solved for @xmath0 , as long as one knows @xmath25 , @xmath73 , @xmath71 , and @xmath72 . we can generalize this procedure . consider a more complicated lattice , such as the octagonal lattice ( figure [ fig : octagonal ] ) with site percolation threshold @xmath78 ( because it is fully triangulated ) @xcite . we consider the octagonal lattice because ( 1 ) its combination of site and bond@xcite percolation thresholds make it a plausible candidate for being in the same universality class as the kagom  lattice@xcite and ( 2 ) its structure of mixed coordination numbers is more complex than the oxides considered above , but is nonetheless simple to study . let us assume that formation of a percolating cluster is dominated by the 8-coordinated sites , and that the 4-coordinated sites primarily serve to facilitate links between 8-coordinated sites . each 8-coordinated site has direct bonds to 4 other 8-coordinated sites , as well as 4 4-coordinated sites . occupation of these other 4-coordinated sites is not the only way to reach other 8-coordinated sites , but we can begin by trying to  average out \" the 4-coordinated sites , modeling this in a manner analogous a site - problem .    in our approximation , where we replace 4-coordinated sites with bonds , at the percolation threshold @xmath79 of the 4-coordinated neighbors will be occupied and permit access to 8-coordinated neighbors . additionally , there are direct bonds to 4 other 8-coordinated sites . the average coordination number is thus @xmath80 . if we assume the power - law scaling relation to hold , we get : @xmath81 this is an implicit equation for @xmath0 . more importantly , it was derived by taking into account features of the lattice beyond nearest neighbors , addressing one of the common criticisms of the galam - mauger power law . if we solve eq . ( [ eq : octagonal ] ) numerically we get that the site percolation threshold is @xmath82 . this is reasonably close to the exact site percolation threshold of @xmath83 , but still not resounding agreement . however , when we use this prediction of the site percolation threshold to compute an effective coordination number ( @xmath84 ) and then use that in galam and mauger s formula for the bond percolation threshold , we get the prediction @xmath85 , which agrees with the bond percolation threshold determined from monte carlo simulations ( @xmath86 ) to @xmath87 . while our inclusion of the octagonal lattice in the same universality class as kagom  is just conjecture , the site bond results for octagonal in figure [ fig:3dzeff ] follow the same trend as kagome and the 3d lattices , suggesting that its inclusion in this conjectured universality class is a hypothesis worthy of further study . of course , our approach to  averaging out \" lower - coordinated sites is _ ad hoc _ and gives no obvious prescription for more general lattices . we only present it as the beginning of an idea that might be generalized to more complicated lattices : treating the higher - coordinated sites as the key players in the formation of a percolating cluster , and the lower - coordinated sites as providing an average number of bonds between the higher - coordinated sites . by removing the lower - coordinated sites from explicit consideration , one is removing the shortest length scales from the analysis , bringing in ideas analogous to renormalization group calculations . however , renormalization treatments of percolation do not assume compliance with an empirical power law derived from monte carlo simulation results , unlike our use of the galam mauger formula . nonetheless , power laws are closely related to the idea of scale invariance , raising the question of whether our approach to oxides and the octagonal lattice might have connections to renormalization ideas . however , given that there are demonstrated examples of lattices for which our approach does _ not _ support a power - law relationship between site percolation threshold and average coordination number , a more rigorous exploration of these ideas would have to provide some criterion for identifying the lattices that can be treated by this approach . criteria that relate lattice topology to properties of percolating clusters seem especially promising for further insight@xcite . in conclusion , we have shown that a conjectured power - law relationship between site percolation threshold and average coordination number holds for a number of lattices with average coordination number less than 3 . these lattices are closely analogous to oxide materials . the quantitative accuracy of the power - law scaling relationship depends on how the average coordination number is defined and measured , with better agreement when we define average coordination number as the average number of available bonds between higher - coordinated sites . when we apply that definition of average coordination number to site - bond percolation problems , we find that existing simulation results are roughly consistent with the power - law scaling conjecture for site percolation . more interestingly , this approach turns the power - law scaling formula into an implicit formula for @xmath0 , one that can ( in some cases ) take into account next - nearest neighbors . finally , although there are some key cases in which our approach fails to give good agreement between simulation results and the conjectured power - law scaling behavior , the relevant lattices are those that had previously been conjectured to fall into a distinct universality class . while there are still significant problems with the power - law scaling formula and the conjectured universality classes , our results suggest that a re - examination is merited , to see if there are ways to refine these conjectures to take into account additional features of the lattice structure and refine estimates of percolation thresholds . this work was supported in part by the citrus college race to stem program , funded by the us department of education . shane stahlheber was also supported by the kellogg university scholars program . the writing of this paper was completed on a sabbatical in the laboratory for fluorescence dynamics at uc irvine . we thank robert ziff for many useful discussions . 10                                                cai - ming liu , song gao , de - qing zhang , yong - hong huang , ren - gen xiong , zhi - liang liu , feng - chi jiang , and dao - ben zhu . a unique 3d alternating ferro- and antiferromagnetic manganese azide system with threefold interpenetrating ( 10,3 ) nets . , 43(8):990994 , 2004 . beatriz gil - hernandez , pedro gili , jana  k. vieth , christoph janiak , and joaquin sanchiz . magnetic ordering in two molecule - based ( 10 , 3)-a nets prepared from a copper ( ii ) trinuclear secondary building unit . , 49(16):74787490 , 2010 . matthias saba , michael thiel , mark  d. turner , s.t . hyde , min gu , karsten grosse - brauckmann , dragomir  n. neshev , klaus mecke , and gerd  e. schrder - turk . circular dichroism in biological photonic crystals and cubic chiral nets . , 106(10):103902 , 2011 .", "tags": [], "output_text_a": "The paper discusses the concept of percolation, a phase transition phenomenon in systems with branched network structures, such as lattices. Percolation occurs when the occupation probability of sites or bonds in a lattice exceeds a critical threshold, leading to the formation of a spanning cluster. The percolation threshold is known exactly for some 2D lattices, but for most systems, it is determined through Monte Carlo simulations. The paper explores the power-law relationship between coordination number and percolation threshold, originally proposed by Galam and Mauger, and its applicability to lattices with low coordination numbers, particularly those analogous to oxide materials.\n\nThe study uses Monte Carlo simulations to compute site percolation thresholds for various oxide-type lattices with average coordination numbers less than 3. It finds that defining the average coordination number in terms of the number of bonds between high-coordinated sites leads to more accurate predictions of percolation thresholds. The paper also examines site-bond percolation problems, showing that the power-law scaling holds when the average coordination number is measured by the average number of bonds per high-coordinated site.\n\nThe results suggest that the power-law scaling between percolation threshold and coordination number can be extended to include aspects of lattice structure beyond dimensionality and average coordination number. The study concludes that while the power-law scaling formula has limitations, it remains a useful tool for predicting percolation thresholds in certain classes of lattices, and further refinement of these predictions could be achieved by considering additional lattice features. The work was supported by the Citrus College Race to STEM program and the Kellogg University Scholars Program.", "output_text_b": "Percolation theory is a simple phase transition that occurs in branched network structures. It has applications in various fields, including materials science and societally relevant contexts. The percolation threshold, which is the critical occupation probability at which a spanning cluster forms, is only known exactly for special classes of lattices in 2D. For most systems, Monte Carlo simulations are used to compute the percolation threshold. A power-law relation between coordination number and percolation threshold has been proposed, but it has limitations and does not provide a criterion for determining the universality class of a lattice. The power-law relation has been shown to give reasonably accurate predictions for the percolation threshold in lattices with coordination number as low as 3 in 3D.", "score": 0.5, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the concept of percolation, the power-law relationship, and the study's focus on oxide-type lattices.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of determining percolation thresholds and the applicability of the power-law relationship.\n4. The methodology of using Monte Carlo simulations is mentioned.\n5. Significant results, such as the accuracy of predictions when defining average coordination number in terms of bonds, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"percolation\" and \"coordination number\" are explained.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as Monte Carlo simulations, are mentioned.\n10. The summary reflects the paper's significance in predicting percolation thresholds and suggests potential impact.", "1. **Accurate Reflection**: The summary captures the essence of percolation theory and its applications, but it lacks specific details about the main findings and contributions of the paper, such as the exploration of low coordination numbers and the introduction of mixed site-bond problems.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary mentions the research problem related to the percolation threshold and its computation.\n4. **Methodology**: The summary briefly mentions Monte Carlo simulations but does not detail the specific methodologies or approaches used in the paper, such as the study of oxide-type lattices.\n5. **Significant Results**: The summary mentions the power-law relation and its limitations but does not include specific results or conclusions drawn by the authors, such as the findings on low coordination numbers.\n6. **Language**: The language is clear and professional.\n7. **Technical Jargon**: The summary avoids excessive technical jargon but does not explain terms like \"universality class.\"\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention key experiments or data used in the research, such as the specific lattices studied.\n10. **Significance/Impact**: The summary does not adequately reflect the paper's significance or potential impact, such as the implications for understanding percolation in complex systems."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "ultracold atoms provide a unique toolbox to study many - particle physics under very clean and well - defined conditions . the precise control over their interactions and their trapping potentials allows to study the dynamics of phase transitions as well as the preparation of strongly correlated quantum states @xcite . while so far the majority of experiments is carried out with ground state atoms , exploiting the unique properties of highly excited states is gradually moving into the focus of experimental and theoretical efforts . atoms in highly excited states can interact strongly , i.e. , the interaction strength can be of the order of several tens of mhz at a distance of several micrometers . the corresponding quantum dynamics takes place on a microsecond timescale and thus is orders of magnitude faster than the atoms external dynamics . such scenario is usually referred to as frozen gas @xcite . a number of experimental groups have studied the excitation dynamics of such system using rydberg states of alkali metal atoms @xcite which were excited from an ultracold gas . here a dramatic reduction of the fraction of excited atoms was observed once the atomic density was too high or the interaction between excited states was too strong @xcite . this is a manifestation of the so - called rydberg blockade @xcite effect that is responsible for the collective character @xcite of rydberg excitations in dense gases . very recently the power of rydberg states to establish a controlled interaction of single atoms trapped in distant traps has been demonstrated in a series of impressive experiments @xcite . strongly supported by these results , highly excited atoms nowadays are believed to have a manifold of applications ranging far beyond traditional atomic physics . indeed , exploiting the properties of atoms in rydberg states permits the study of spin systems at criticality @xcite , the quantum simulation of complex spin models @xcite , the investigation of the thermalization of strongly interacting many - particle systems @xcite and also the implementation of quantum information protocols @xcite .    in a recent work ( ref . @xcite ) we showed that the unique properties of rydberg atoms allow the creation of entangled many - particle states on a one - dimensional ring lattice on a short time scale . finding simple ways for creating entangled many - particle states is of importance , since such states have a number of applications , e.g , they serve as resource for the creation of single - photon light sources @xcite , for improving precision quantum measurements @xcite and for measurement based quantum information processing .    in this paper we will go into depth and largely expand on our previous study . we show that excited many - particle states of a laser - driven gas of rydberg atoms on a ring lattice can be obtained analytically in the limit of strong laser driving . we give a detailed derivation of the system s hamiltonian in sec . [ sec : system ] . the construction of the many - body excitations , their eigenenergies and their correlation properties are analyzed in sec . [ sec : states ] . in sec . [ sec : how_address ] we discuss thoroughly how these states can be excited in an experiment . we conclude with a summary and outlook in sec . [ sec : conclusion ] . we study a gas of bosonic ground - state atoms confined to a deep large spacing optical or magnetic @xcite ring lattice with periodicity @xmath0 ( see fig . [ fig : lattice ] ) . the wannier functions @xmath1 are localized at the @xmath2-th site with a width @xmath3 . we assume the external dynamics of the atoms to be frozen , i.e. , no hopping and hence no particle exchange between the lattice sites is present . this is well justified as the internal ( electronic ) dynamics - in which we are interested here - takes place on a much shorter timescale , of the order of hundred nanoseconds . we consider two electronic levels which are denoted by @xmath4 and @xmath5 . here @xmath5 is a rydberg @xmath6s - state which - due to its quantum defect - is well isolated from any other electronic level . it is coupled to the ground state @xmath4 via a laser with rabi frequency @xmath7 and detuning @xmath8 . within the rotating wave approximation , the hamiltonian describing the coupling of the atoms to the laser field reads ( with @xmath9 ) @xmath10 where @xmath11 and @xmath12 ( @xmath13 and @xmath14 ) represent the creation ( annihilation ) of a ground and a rydberg state , respectively , and @xmath15 stands for the number of atoms in state @xmath5 at the @xmath2-th site .     being much larger than the extension @xmath16 of the wannier functions ( deep lattice ) . the internal atomic degrees of freedom at each site are described by the ( collective ) states @xmath17 and @xmath18 , coupled by @xmath19.,width=264 ]    we will consider throughout this paper the case where each lattice site is occupied by the same number of atoms , @xmath20 . this is achieved , for example , if the system is initialized in a mott - insulator state . the interaction between the rydberg atoms is given by the van - der - waals potential @xmath21 , that is quickly decaying with the distance @xmath22 between atoms . nevertheless , as @xmath23 scales with the eleventh power of the principal quantum number @xmath6 , the interaction can strongly affect the excitation dynamics of atoms that are separated by several micrometers . this strong interaction gives rise to the so - called blockade effect @xcite . we consider a scenario in which the simultaneous excitation of two or more atoms to the rydberg state on a single lattice site is blockaded . thus , on each lattice site @xmath2 , only the two states @xmath24_1\\otimes\\dots\\left[\\left|g\\right>_k\\right]_{n_0}\\\\ \\left|r\\right>_k&=&\\frac{1}{\\sqrt{n_0}}{\\cal s } \\left\\{\\left[\\left|r\\right>_k\\right]_1\\otimes\\left[\\left|g\\right>_k\\right]_2\\otimes\\dots\\left[\\left|g\\right>_k\\right]_{n_0}\\right\\},\\end{aligned}\\ ] ] are accessible , where @xmath25 is the symmetrization operator . the effective rabi frequency for the laser coupling between these so - called ( super)atom states ( see fig . [ fig : lattice ] ) is given by @xmath26 . taking all this into account , in eq . ( [ eqn : laser_ham ] ) we can replace @xmath27 $ ] , where @xmath28 and @xmath29 are the pauli spin matrices . since @xmath3 ( see fig . [ fig : lattice ] ) we can rewrite the van - der - waals potential between two ( super)atoms in the state @xmath30 located @xmath31 sites apart as @xmath32 , where @xmath33 is the separation between those sites . as already pointed out , @xmath34 is quickly decaying with the distance . in particular , the next - nearest neighbor interaction is a factor of @xmath35 smaller than the nearest neighbor one ( @xmath36 ) . we will thus only focus on the nearest neighbor interaction which is well - justified for large enough lattices . the interaction hamiltonian for the entire atomic ensemble , with @xmath37 , then reads @xmath38 with the rydberg number operator @xmath39/2 $ ] and the boundary condition @xmath40 .    in summary , the complete hamiltonian that drives the dynamics of our system can be written as @xmath41.\\ ] ] the system can be described as a periodic arrangement of spin-@xmath42 particles , where the two spin states , corresponding to the two internal states of the ( super)atoms , @xmath17 and @xmath18 , interact via an ising - type potential . in this picture , the rabi frequency @xmath19 and the combination of @xmath43 can be effectively interpreted as perpendicular magnetic fields . hence , the relevant parameters in our system will be : a ) the ones related to the laser , i.e. , the single - atom rabi frequency @xmath7 and detuning @xmath8 , which can be time - dependent and b ) the interaction between rydberg atoms represented by @xmath44 .      throughout this paper , we consider the regime where the detuning is much smaller than both the collective rabi frequency ( laser driving ) and the interaction strength , i.e. , @xmath45 . as a consequence , the behavior of the system will be determined by the ratio of the latter two parameters . here we focus on the limit @xmath46 , i.e. , the laser coupling is much stronger than the interaction between atoms . in this regime the first term of the hamiltonian ( [ eqn : working_hamiltonian ] ) is the dominant one and it is convenient to make it diagonal by means of a rotation of the basis . this is achieved by the unitary transformation @xmath47 which brings @xmath48 and @xmath49 . when applied to our hamiltonian ( [ eqn : working_hamiltonian ] ) , it yields @xmath50 with @xmath51\\label{eqn : h_xy}\\\\ h_1&=&\\frac{\\delta}{2}\\sum_{k=1}^l\\left(1-\\sigma_{x}^{(k)}\\right)\\label{eqn : h_1}\\\\ h_2&=&\\frac{\\beta}{4}\\sum_{k=1}^l \\left[\\left(\\sigma_{+}^{(k)}\\sigma_{+}^{(k+1)}+\\sigma_{-}^{(k)}\\sigma_{-}^{(k+1)}\\right)-2\\sigma_x^{(k)}\\right]\\label{eqn : h_2},\\end{aligned}\\ ] ] where @xmath52 is the famous @xmath53-model of a spin chain with a transverse magnetic field . let us now analyze the importance of the individual contributions of @xmath54 . as we can see in fig . [ fig : spectrum ] , the spectrum of @xmath54 decays into manifolds of states which are separated by gaps whose width is approximately @xmath55 . this is caused by the dominant first term of @xmath52 , i.e. , @xmath56 . the eigenstates of @xmath57 are - in terms of the ( super)atom states - given by @xmath58\\ ] ] with @xmath59 . thus , each of the manifolds that determine the coarse structure of the spectrum is spanned by a set of product states that have the same number of ( super)atoms in the state @xmath60 . in fig . [ fig : spectrum ] , these manifolds are denoted by @xmath61 , which is the eigenvalue of the states with respect to the operator @xmath62 . the second term of @xmath52 conserves the total number of @xmath60 ( super)atoms . in other words , it couples only states that belong to the same @xmath61-manifold and that are nearly degenerate . as a consequence , the strength of these intra - manifold couplings due to @xmath63 is proportional to @xmath44 . conversely , @xmath64 and @xmath65 couple states that belong to manifolds with different number of ( super)atoms in the state @xmath60 . in particular , @xmath64 and the last term of @xmath65 flip one of the ( super)atoms from @xmath60 to @xmath66 or viceversa . thus , the coupled states belong to different manifolds with @xmath67 , energetically separated by @xmath55 . the two first terms of @xmath65 drive a similar process , flipping always two contiguous ( super)atoms in the same state simultaneously , i.e. , @xmath68 or @xmath69 . as a result , these terms connect states with eigenvalue @xmath61 to those with @xmath70 , which are separated roughly by @xmath71 . these features are reflected in fig . [ fig : spectrum ] .     and @xmath72 . the spectrum splits into manifolds which can be labeled by the quantum number @xmath61 of the operator @xmath73 . for sufficiently large @xmath19 , the coupling between manifolds that is established only by @xmath64 and @xmath65 can be neglected . the ( constrained ) dynamics inside the @xmath61-subspaces is then determined by @xmath52.,width=188 ]    the transition rates between @xmath61-manifolds corresponding to @xmath64 and @xmath65 can be estimated by second order perturbation theory to be of the order @xmath74 and @xmath75 , respectively . hence , for sufficiently strong driving @xmath46 , their contribution can be neglected and the system s dynamics is constrained to the @xmath61-manifolds . as a consequence , the hamiltonian that drives the intra - manifold dynamics , @xmath52 , _ effectively drives the dynamics of the entire system in this parameter regime_. this hamiltonian is analytically solvable , and we thus have access to the actual spectrum and eigenstates of the system . the diagonalization of this hamiltonian relies on the so - called jordan - wigner transformation and a fourier transform that we explain thoroughly in the following paragraph @xcite . the pauli matrices in the hamiltonian ( [ eqn : h_xy ] ) obey anti - commutation and commutation relations when they belong to the same and different sites , respectively . thus , the algebra is neither bosonic nor fermionic . this difficulty can be overcome by the jordan - wigner transformation , @xmath76 which introduces the operators @xmath77 and @xmath78 that obey the canonical fermionic algebra @xmath79 after this transformation , the hamiltonian ( [ eqn : h_xy ] ) takes on the form @xmath80\\\\ & -&\\frac{\\beta}{4}\\left(c_l^\\dagger c_1+c_1^\\dagger c_l\\right)\\left(e^{i\\pi n_+}+1\\right).\\end{aligned}\\ ] ] thus , the hamiltonian has been transformed into one which describes a chain of spinless fermions with nearest neighbor hopping . the last term of hamiltonian ( [ eqn : h_jw ] ) appears due to the periodic boundary conditions . it depends on the operator @xmath81 which counts the total number of fermions , which is also equivalent to the number of ( super)atoms in the state @xmath60 . thus , depending on the parity of the number of fermions of the state , @xmath52 reads @xmath82 for even ( e ) or odd ( o ) parity , respectively . these two cases can be accounted for simultaneously in a convenient way by introducing a matrix representation for the fermionic operators . they are projected onto the subspaces with even and odd eigenvalue of @xmath83 by means of the projectors @xmath84/2 $ ] , with @xmath85 . since the hamiltonian @xmath52 conserves the number of fermions , i.e. , @xmath86=0 $ ] , it is diagonal in this representation and can be decomposed as @xmath87 we now introduce new matrix - valued creation and annihilation operators of the form @xmath88 which obey the fermionic algebra provided @xmath78 and @xmath89 are fermionic operators . the hamiltonian can now be conveniently written as @xmath90 with @xmath91    the diagonalization of the hamiltonian ( [ eqn : h_matrix_gamma ] ) is achieved by performing the following fourier transform @xmath92 with the fourier coefficients @xmath93 the operators @xmath94 and @xmath95 are matrix - valued @xmath96 with @xmath97 and @xmath98 being fermionic creation and annihilation operators , respectively . defining the eigenvalue matrix @xmath99 as @xmath100 } & 0\\\\ 0 & \\cos{\\left[\\frac{2\\pi}{l}n\\right ] } \\end{array}\\right),\\end{aligned}\\ ] ] the diagonalized hamiltonian ( [ eqn : h_matrix_gamma ] ) reads @xmath101 as we will see in the next section , the introduction of the matrix - valued fermionic operators has the advantage that excited states can be constructed by applying products of @xmath94 to the ground state . as a consequence , this matrix notation allows us to automatically distinguish between the odd and even fermion cases , which otherwise has to be done manually . the symmetry properties of our system impose certain selection rules for the excitation of the many - particle states . in order to understand this , let us start our analysis of the excited states by studying the symmetries of the hamiltonian . because of the special arrangement of the sites , the hamiltonian ( [ eqn : working_hamiltonian ] ) and also ( [ eqn : h_matrix_lambda ] ) are invariant under cyclic shifts and reversal of the lattice sites . this can be formally seen by representing these two symmetries through the operators @xmath102 and @xmath103 , respectively . their action on the spin ladder operators are @xmath104 and @xmath105 , from where follows that @xmath106=\\left[h_\\mathrm{spin},{\\cal r}\\right]=0 $ ] , i.e. , both of them correspond to conserved quantities . thus , if the system is initialized in an eigenstate with respect to @xmath107 and @xmath108 , the time evolution will not take place in the entire hilbert space , but merely in the subspace spanned by the states with the same quantum number with respect to @xmath102 and @xmath103 . this observation is highly relevant for our system . in practise , the natural initial situation will be that in which all atoms are in the ground state , i.e. , @xmath109 . this state has the above - mentioned properties , i.e. , it is invariant under cyclic shifts and the reversal of the sites : @xmath110 and @xmath111 . we will refer to such a state that has eigenvalue @xmath112 with respect to @xmath107 and @xmath108 as being fully - symmetric . hence , only the states from this fully - symmetric subspace can be actually accessed in the course of the system s time evolution under hamiltonian ( [ eqn : working_hamiltonian ] ) . in the following we will thus focus on constructing excited states that belong to this subset . the ground state of hamiltonian ( [ eqn : h_matrix_lambda ] ) is given by @xmath113 and it is fully - symmetric . excited states that contain @xmath114 fermions are in general formed by successive application of the creation operator , i.e. , @xmath115 . however , not all combinations will give rise to states that belong to the fully - symmetric subset . let us start considering the possible cases of a single - fermion excitation . for a fully - symmetric state we require @xmath116 , i.e. , @xmath117 with @xmath118 being a placeholder for @xmath102 and @xmath103 . after some algebra one finds that @xmath119 since @xmath120 and @xmath121 , only the single excitation with @xmath122 is symmetric under cyclic shifts and reversal . hence , the only one - fermion state that can be reached by the time - evolution reads @xmath123 to have a better physical understanding of this state , it is convenient to write it in terms of the atomic operators , @xmath124 thus , @xmath125 is a spin wave or , in other words , a superatom that extends over the entire lattice . these states are of interest since they can be used as a resource for single photon generation . for the two - fermion states , we follow the same procedure and demand @xmath126 one finds that @xmath127c_1^\\dagger\\left(e^{i\\pi n_+}-1\\right).\\end{aligned}\\ ] ] from this , one sees that the condition @xmath128 has to be accomplished . as a result , the fully - symmetric states are @xmath129 with @xmath130 . these are entangled states formed by superpositions of two - atom excitations in the ring with opposite momentum . this is more clearly seen by writing everything in terms of the pauli matrices @xmath131 these states are potentially interesting for the production of photon pairs . how they can be actually accessed will be discussed in sec . [ sec : how_address ] . finally , let us illustrate how the three - fermion excitations are formed . we have @xmath132 and thus fully symmetric three - fermion states are of the form @xmath133 with @xmath134 . writing these eigenexcitations back in terms of the spin operators yields @xmath135}\\sigma_+^{(k)}\\sigma_+^{(k')}\\sigma_+^{(k'')}\\left|g\\right>,\\end{aligned}\\ ] ] where @xmath136 is the levi - civita symbol . in a similar way , states with higher number of fermions are obtained . now that we have analyzed the eigenstates of the system we will focus on the corresponding eigenenergies . in the course of this investigation we will also perform a comparison of the analytic results to the ones obtained from a numerical diagonalization of the hamiltonian ( [ eqn : working_hamiltonian ] ) . this will allow us to assess the accuracy of our analytical approach . let us begin with the ground state energy . from eq . ( [ eqn : h_matrix_lambda ] ) we can read off the value @xmath137 where we have included the general energy - offset @xmath138 ( see eq . ( [ eqn : uhu ] ) ) . for @xmath139 , @xmath140 , @xmath141 and @xmath142 , the result is @xmath143 . this is to be compared with the numerical value of @xmath144 which is obtained by diagonalizing the hamiltonian ( [ eqn : working_hamiltonian ] ) . we find both results to be in good agreement . for the first excited state we obtain @xmath145 using the same set of parameters , the energy of the single - fermion state is @xmath146 , which is very close to the numerically exact value @xmath147 . the energies of higher eigenexcitations are given by @xmath148},\\end{aligned}\\ ] ] with @xmath130 , for the two - fermion case and @xmath149,\\end{aligned}\\ ] ] with @xmath134 , for the three - fermion one . for @xmath142 , we obtain five and eight different eigenenergies for the two- and three - fermion states , respectively ( see insets in fig . [ fig : spectrum_real ] ) . in the tables [ tab:2n ] and [ tab:3lmn ] we perform a comparison between the analytical and the numerical results . a difference of less than a @xmath150 is observed in all cases . ( [ eqn : uhu ] ) for a lattice of @xmath142 sites versus the laser driving @xmath19 in units of @xmath44 . in the right insets , the energies of the two- and three - fermion states are shown for @xmath140 . five two - fermion and eight three - fermion eigenenergies arise as it is analytically predicted for this lattice size.,width=340 ]    .energies of the five two - fermion states @xmath151 for @xmath142 , @xmath139 , @xmath140 and @xmath141 and comparison with the numerically exact values . [ cols=\"^,^,^\",options=\"header \" , ]     the discrepancies between analytical and numerical values are mainly caused by second order energy shifts due to @xmath64 and @xmath65 ( eqs . ( [ eqn : h_1 ] ) and ( [ eqn : h_2 ] ) ) . these contributions vanish only in the limits @xmath152 and @xmath153 . here , we will calculate them for a finite ratio . there is a constant term in @xmath64 which is proportional to @xmath8 that gives rise to a global energy shift @xmath154 . being aware of this shift facilitates the comparison between the numerically exact and the approximate analytical eigenvalues for @xmath155 . let us focus first on the ground state . @xmath64 and @xmath65 only couple states whose number of fermions differ by one or two ( fig . [ fig : spectrum ] ) . as a consequence , only the states @xmath125 and @xmath151 contribute to the second order correction of the energy of the ground state . it yields @xmath156}}{4\\omega+\\beta\\cos{\\left[\\frac{2\\pi}{l}(p-1/2)\\right]}}.\\end{aligned}\\ ] ]    analogously , we calculate the energy shift of the first excited state , @xmath125 , due to @xmath64 and @xmath65 . in this case , we have to compute the effect of the states @xmath157 , @xmath151 and @xmath158 . the resulting energy correction is given by @xmath159}}{2\\omega+\\frac{\\beta}{2}\\left(2 \\cos{\\left[\\frac{2\\pi}{l}(p-1/2)\\right]}-1\\right)}.\\end{aligned}\\ ] ]    for the parameters @xmath139 , @xmath140 , @xmath141 and @xmath142 , these shifts yield @xmath160 and @xmath161 . the corrected energies of the ground and the single - fermion state are now @xmath162 and @xmath163 , much closer to the numerically exact ones of @xmath144 and @xmath147 , respectively . we will later see that these energy corrections can be useful for the selective excitation of many - particle states in the lattice .      in this subsection we are going to study the density - density correlation function of the many - particle states . this quantity measures the conditional probability of finding two simultaneously excited atoms at a distance @xmath22 from each other normalized to the probability of uncorrelated excitation . it is defined - for a fully - symmetric state @xmath164 - as @xmath165 where we have used @xmath166 for all sites . the correlation function will give @xmath167 when two sites separated by a distance @xmath22 are completely uncorrelated , and @xmath168 for correlation ( anticorrelation ) between the sites . in particular , for the case @xmath169 , @xmath170 can be analytically calculated . in terms of the expectation values of the spin operators , the correlation function reads @xmath171 . for @xmath172 we have @xmath173 and for @xmath174 the calculation yields @xmath175}\\right.\\\\ & & \\left.+2\\sin{\\left[\\frac{2\\pi}{l}(p-1/2)x\\right]}\\cot{\\left[\\frac{2\\pi}{l}(p-1/2)\\right]}\\right].\\end{aligned}\\ ] ] by inspecting this expression for the allowed values @xmath176 , some general statements can be made :    \\a ) independently of the total number of sites @xmath177 , there are always two extremal cases ( see fig . [ fig : correlations]a ) which correspond to @xmath178 and @xmath179 : for @xmath178 , the correlation function shows a positive maximum at @xmath180 , i.e. , nearest neighbor , and then decreases monotonically and smoothly with the distance , staying always positive ; for @xmath179 , the nearest neighbor is pronouncedly anticorrelated , the next - nearest neighbor is correlated and this pattern of correlation - anticorrelation persists with increasing distance . \\b ) for @xmath179 , the oscillations of @xmath170 are more pronounced for @xmath177 than for odd @xmath177 , see fig . [ fig : correlations]a . the ratio of the amplitudes of the correlations for @xmath180 and @xmath181 is , @xmath182 in the even and odd cases , respectively . also , for an even number of sites , the correlation functions of the two extreme cases accomplish @xmath183 , i.e. , the envelope of the oscillating function @xmath184 is given by the smoothly decreasing @xmath185 . \\c ) for a fixed value of @xmath186 , the amplitude of the correlations decreases with increasing number of sites as @xmath187 , as can be seen in fig . [ fig : correlations]b . numerically , we have observed agreement to the analytical results shown in fig . [ fig : correlations ] . as expected , this agreement improves with a decreasing ratio @xmath188 . states . * a * : for @xmath178 and @xmath179 , the correlations show completely different behavior , i.e. , smoothly decreasing and strongly oscillating , respectively . these oscillations are much more pronounced for the even value of @xmath189 than for the odd , @xmath190 . * b * : the magnitude of the correlations decreases as the number of sites @xmath177 is enhanced , as can be seen for @xmath191.,width=340 ]    the correlations could be directly monitored experimentally provided that a site - resolved detection of atoms in the @xmath60-state is possible . the next section will deal with the open question of how these correlated states can be experimentally accessed . our aim is to selectively excite correlated many - body states by a temporal variation of the laser parameters . initially the atoms shall be in the product state @xmath192 and the laser shall be turned off , i.e. , @xmath193 and @xmath194 . starting from these initial conditions , the goal is to vary @xmath195 and @xmath196 such that at the end of the sequence , i.e. , at @xmath197 , the detuning is zero and the laser driving is much larger than the interaction ( @xmath198 and @xmath199 ) . this final situation corresponds to the right - hand side of the spectrum presented in fig . [ fig : spectrum_real ] . once a desired many - particle state has been populated , and due to the limited lifetime of the highly excited levels which is in the order of several @xmath200 ( e.g. , 66 @xmath200 for rb in the 60s state ) , we want to map it to an stable configuration . to do so , we first turn off the laser ( @xmath201 ) and then switch on a second one whose action can be described by the hamiltonian @xmath202 in this expression , @xmath203 and @xmath204 stand for the creation and annihilation operators of an single - atom stable storage state @xmath205 on site @xmath2 , respectively . in the limit where the interaction is much smaller than the rabi frequency of this transition , i.e. , @xmath206 , we can neglect the second term of this hamiltonian . thus , performing a global @xmath207-pulse to the considered many - particle state means to perform the mapping @xmath208 , such that a stable configuration is achieved . hence , the difficulty lies in finding a trajectory or sequence @xmath209 for which at @xmath197 only a single many - particle state is occupied . we propose two different methods in the following .      in certain cases , one can guess a trajectory @xmath210 like the ones shown in fig . [ fig : address ] that eventually connects @xmath211 with a desired eigenstate of @xmath52 @xcite , but this is not always possible . the general appearance of the laser sequence strongly depends on the sign of the initial detuning @xmath212 . in fig . [ fig : address ] the two possible scenarios ( taking @xmath213 ) are depicted . for @xmath214 , the initial state is not the ground state of the system when the laser is turned off ( @xmath201 ) . as a consequence , this initial state suffers several avoided crossings with other levels when @xmath19 is increased . thus , it is not easy to find a path through the spectrum that connects it to a single desired eigenstate of @xmath52 , as the one shown in fig . [ fig : address]a . a more general framework for finding a proper trajectory is provided by optimal control theory @xcite . here , the desired fidelity with which the final state is achieved can be set and certain constraints on the trajectory can be imposed . this method is successfully applied to quantum information processing @xcite , molecular state preparation @xcite and optimization of number squeezing of an atomic gas confined to a double well potential @xcite . the case of @xmath215 will be treated in the next subsection .    ) through the spectrum of @xmath54 with @xmath216 ( units of @xmath44 ) . * a * : when @xmath214 , the ground state at @xmath201 does not coincide with the initial state , @xmath211 , and the energy of the initial state goes through a number of avoided crossings . a possible path through them to reach the state @xmath217 is shown . * b * : if @xmath215 , the initial state @xmath211 is adiabatically connected to the ground state @xmath157.,width=340 ]      we present in this work a different route to populate single many - particle states . this is accomplished in two steps : first , one has to prepare the ground state @xmath157 of hamiltonian ( [ eqn : h_xy ] ) in the limit @xmath46 ; once the ground state is populated , the single - fermion and two - fermion many - particle states can be accessed by means of an oscillating detuning , that gives rise to a time - dependent @xmath64 .    _ step 1 : _ let us start by explaining how to vary the laser parameters to prepare the ground state @xmath157 . in particular , when setting @xmath215 , the ground state of the system at @xmath201 coincides with the initial state @xmath211 . with increasing @xmath19 , it is adiabatically connected to the ground state @xmath157 of @xmath63 ( see fig . [ fig : address]b ) . the problem that we can encounter here is that non - adiabatic transitions to other energy levels occur when increasing @xmath19 , so that we do not populate only @xmath157 but also other states . to avoid this , we choose a large enough value of @xmath212 when the laser is still turned off ( @xmath201 ) . this increases the energy gap between @xmath211 and other energy levels , and , as a consequence , suppresses non - adiabatic transitions . this initial detuning can be decreased as @xmath19 increases so that in the desired regime , i.e. , @xmath218 , it is set to zero . as an example , we propose the following shapes of @xmath219 and @xmath196 @xmath220\\label{eqn : detuning}.\\end{aligned}\\ ] ] the obtained fidelity @xmath221 for different values of the initial detuning @xmath212 and time intervals @xmath222 is given in fig . [ fig:0togs ] , where @xmath223 stands for the wavefunction of the final state . it is actually possible to populate the desired state with high fidelity , e.g. , over @xmath224 is achieved for all considered lattice sizes with @xmath225 and @xmath226 . we find that : i ) the fidelity depends only weakly on the lattice size although the dimension of the hilbert space grows exponentially with @xmath177 , and ii ) as expected , for a fixed value of the initial detuning , the fidelity increases with the increasing length of the time interval . note that the timescale of this whole process is limited by the lifetime of the rydberg state .     when populating the ground state of @xmath52 from the initial state via variation of the parameters of the laser @xmath219 and @xmath196 in the form given by ( @xmath227 ) and ( [ eqn : detuning ] ) , respectively . several initial values of the detuning and time intervals , as well as different lattice sizes , are considered . for a fixed value of @xmath212 ( units of @xmath44 ) , better fidelities are obtained for larger time intervals ( units of @xmath228 ) . for a fixed time interval , there is an optimal value of @xmath212 for each size of the lattice , around @xmath229.,width=340 ]    if there is only one atom per site , and based on the fact that @xmath230 is a product state , an alternative procedure to this adiabatic passage can be envisaged . starting from the vacuum @xmath211 ( also a product state with every atom in @xmath4 ) , we perform a global @xmath231-pulse to the single - atom transition @xmath232 . as a result , we obtain a product state where every atom is in a superposition @xmath233/\\sqrt{2}$ ] . in a second step , the @xmath207-pulse with the mapping laser described by the hamiltonian ( [ eqn : h_map ] ) and with @xmath206 , transfers every atom to the state @xmath234/\\sqrt{2}$ ] , i.e. , we have prepared the ground state @xmath157 . it is worth remarking that this method eliminates the lifetime limitation in this first stage . _ step 2 : _ let us show now how to address the single - fermion and two - fermion states from this ground state @xmath157 . as we explained in section [ sec : constrained ] , the hamiltonian @xmath64 , associated with the detuning , drives transitions between neighboring manifolds , i.e. @xmath235 , ( see fig . [ fig : spectrum ] ) . we exploit this fact and introduce an oscillating detuning of the form @xmath236 . if we tune @xmath237 to coincide with the gap between two given states , this detuning acts effectively as a laser that couples them resonantly with a rabi frequency that is proportional to @xmath238 .    using this oscillating detuning , we want to transfer the population from the ground to the first excited state ( fig . [ fig : excitation]a ) . to do so , @xmath237 is tuned to be on resonance with the corresponding energy gap , i.e. , @xmath239 , and by a @xmath207-pulse we populate @xmath125 . one has to take into account that in the limit of @xmath46 the energy gap between any two neighboring manifolds is equal , i.e. , also higher lying excitations are populated . to avoid this effect and address only the @xmath125 state , we can choose a not too large value of @xmath19 . in this regime , the second order level shifts caused by @xmath64 and @xmath65 , that are roughly given by @xmath74 and @xmath75 , respectively ( see section [ sec : energy ] ) , become increasingly important . in particular , as it is sketched in fig . [ fig : excitation]a , the gap between @xmath240 and any of the @xmath151 levels becomes more and more different from @xmath241 and , as a consequence , the unwanted transitions fall out of resonance . analogously , the same procedure could be used to address the two - fermion many - particle states ( see fig . [ fig : excitation]b ) . the first @xmath207-pulse resonant with the @xmath242 transition , is followed by another @xmath207-pulse with @xmath237 tuned to coincide with the energy gap of the specific @xmath243 transition , @xmath244 . the separation between neighboring @xmath151 states is of the order of @xmath44 and the rabi frequency of the transition is proportional to @xmath238 . as a consequence , to populate only a single level of the two - fermion manifold , the parameters have to accomplish that @xmath245 and , at the same time , @xmath238 has to be large enough in order to perform the transfer at a time interval that is much shorter than the lifetime of the rydberg state .    . * a : * in a first step , the population is transferred by a @xmath207-pulse to the single - fermion state by tuning the frequency of the detuning on resonance with the gap @xmath246 . * b : * a second @xmath207-pulse with @xmath237 tuned to match @xmath247 addresses the corresponding @xmath151 state , bearing in mind that @xmath245 in this step.,width=321 ] in this work we have studied the collective excitation of a laser - driven rydberg gas confined to a ring lattice . we have focused on the regime in which the interaction between the highly excited states is much weaker than the laser field . we found that the corresponding system can be described as a chain of spinless fermions whose dynamics is driven by the @xmath53-model . this hamiltonian can be analytically solved and , by exploiting the symmetries of the system , we were able to completely characterize the many - particle states arising . in particular , we have shown that the first excited state of the hamiltonian corresponds to a spin wave or to an excitation which is completely delocalized all over the lattice . the two - fermion states could be expressed as a superposition of excitation pairs and an investigation of their density - density correlation function has been performed . we have demonstrated that the qualitative behavior of these correlations differs substantially from one state to another of the same two - fermion manifold , going from a smoothly decaying function to a pronounced correlation - anticorrelation pattern . the analytical eigenenergies of the @xmath53-hamiltonian were compared to the numerical exact ones of the complete hamiltonian , and excellent agreement between both results has been found . finally , we have investigated several paths for the selective excitation of the many - particle states . one of them relies on the variation of the laser parameters with time , finding trajectories from the initial to a given final many - body state . the other possibility we have presented makes use of an oscillating detuning which allows to access excitations starting from the ground state of the hamiltonian . in each step , a @xmath207-pulse is performed with the frequency of the oscillation matching the energy gap between the involved states .    throughout this work we have considered an homogeneous occupation of the sites of the ring lattice . the situation of having a randomly fluctuating number of atoms per site would effectively lead to a disorder potential for the fermions , as outlined in ref . this would imply as well a change in the symmetry properties of the system , so that more states become accessible by a time - evolution ( e.g. , @xmath177 possible single - fermion states instead of only the fully - symmetric one ) . in addition , we have assumed that the atoms are strongly localized , @xmath248 ( fig . [ fig : lattice ] ) . taking into consideration the finite width of the wave packet would lead to another kind of disorder , this time associated to the interaction parameter @xmath44 .    as we have pointed out , the main problem one has to face in this system is the limited lifetime of the rydberg states , which is in the order of several microseconds . one could think of preparing a parallel system to the one described in this work but using polar molecules @xcite , to overcome this lifetime limitation . an interesting extension is also the investigation of the system in two - dimensional geometries , e.g. , triangular or square lattices , as well as several rings disposed in concentric or cylindric configurations . in all these cases , the symmetries of the particular arrangement of the sites might give rise to new interesting many - particle states .", "tags": [], "output_text_a": "This paper explores the collective excitation of a laser-driven Rydberg gas confined to a ring lattice, focusing on the regime where the interaction between highly excited states is weaker than the laser field. The study reveals that the system can be described as a chain of spinless fermions driven by the XY-model Hamiltonian, which is analytically solvable. The authors characterize the many-particle states, showing that the first excited state corresponds to a spin wave or a delocalized excitation across the lattice. Two-fermion states are expressed as superpositions of excitation pairs, with their density-density correlation functions exhibiting varying patterns from smooth decay to pronounced correlation-anticorrelation oscillations. The paper compares analytical eigenenergies with numerical results, finding excellent agreement. It also discusses methods for selectively exciting many-particle states, including varying laser parameters and using oscillating detuning to access excitations from the ground state. The study considers homogeneous site occupation but notes that random fluctuations could introduce disorder, affecting symmetry and state accessibility. The limited lifetime of Rydberg states is acknowledged as a challenge, with potential solutions including using polar molecules or exploring two-dimensional geometries for new many-particle states.", "output_text_b": "This arXiv paper discusses the use of ultracold atoms to study many-body physics under well-controlled conditions. The interactions and trapping potentials of these atoms can be precisely controlled, allowing for the study of phase transition dynamics and the preparation of strongly correlated quantum states. While most experiments have been conducted with ground state atoms, there is growing interest in using highly excited states due to their strong interactions and fast quantum dynamics. The paper describes experiments using Rydberg states of alkali metal atoms, which exhibit a blockade effect that gives rise to collective behavior in dense gases. The power of Rydberg states to establish controlled interactions between single atoms trapped in distant traps has also been demonstrated. The authors believe that highly excited atoms have a wide range of applications beyond traditional atomic physics, including the study of spin systems at criticality, quantum simulation of complex spin models, investigation of the thermalization of strongly interacting many-body systems, and implementation of quantum information protocols.\n\nThe paper also describes a recent work in which the authors demonstrated the creation of entangled many-body states on a one-dimensional ring lattice using Rydberg atoms. These states have a number of applications, such as serving as a resource for single-photon light sources, improving precision quantum measurements, and enabling measurement-based quantum information processing. The authors expand on their previous study and show that excited many-body states of a laser-driven gas of Rydberg atoms on a ring lattice can be obtained analytically in the limit of strong laser driving. They derive the system's Hamiltonian and analyze the construction of many-body excitations, their eigenenergies, and their correlation properties. They also discuss how these states can be excited in an experiment.\n\nThe system studied in the paper is a gas of bosonic ground-state atoms confined to a deep large-spacing optical or magnetic ring lattice with periodicity. The authors assume that the external dynamics of the atoms are frozen, and consider two electronic levels that are coupled by a laser. The internal (electronic) dynamics of the system take place on a much shorter timescale than the external dynamics, and the interaction between Rydberg atoms is given by the van der Waals potential, which quickly decays with distance. The authors consider a scenario in which the simultaneous excitation of two or more atoms to the Rydberg state on a single lattice site is blockaded, and show that the effective Rabi frequency for the laser coupling between these so-called (super)atom states is given by a particular expression.\n\nThe authors then rewrite the van der Waals potential between two (super)atoms in terms of the separation between those sites, and show that the next-nearest neighbor interaction is a factor of 1/32 smaller than the nearest neighbor one. They focus on the nearest neighbor interaction, which is well-justified for large enough lattices. The interaction Hamiltonian for the entire atomic ensemble is then derived, and the complete Hamiltonian that drives the dynamics of the system is obtained.\n\nThe system is described as a periodic arrangement of spin-1/2 particles, where the two spin states interact via an Ising-type potential. The Rabi frequency and the combination of certain parameters can be effectively interpreted as perpendicular magnetic fields. The relevant parameters in the system are the laser parameters (single-atom Rabi frequency and detuning, which can be time-dependent) and the interaction between Rydberg atoms.\n\nThe authors consider the regime where the detuning is much smaller than both the collective Rabi frequency (laser driving) and the interaction strength, and focus on the limit where the laser coupling is much stronger than the interaction between atoms. In this regime, the first term of the Hamiltonian is the dominant one, and it is convenient to diagonalize it by means of a rotation of the basis. This is achieved by the unitary transformation, which brings the Hamiltonian into a diagonal form.\n\nThe authors then analyze the importance of the individual contributions of the terms in the Hamiltonian, and show that the spectrum of the system decays into manifolds of states that are separated by gaps whose width is approximately equal to the Rabi frequency. The eigenstates of the system are given by product states that have the same number of Rydberg atoms, and the second term of the Hamiltonian conserves the total number of Rydberg atoms. The third term couples states that belong to manifolds with different numbers of Rydberg atoms, and the two first terms of this term flip one of the Rydberg atoms to the ground state or vice versa.\n\nThe authors also discuss the transition rates between the manifolds corresponding to these terms, and show that for sufficiently strong driving, their contribution can be neglected and the system", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the collective excitation of a laser-driven Rydberg gas and the characterization of many-particle states. \n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the interaction between highly excited states and the laser field.\n4. The methodology or approach used in the paper is mentioned, including the use of the XY-model Hamiltonian and analytical solutions.\n5. Significant results and conclusions, such as the characterization of many-particle states and the comparison of analytical and numerical results, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"spin wave\" and \"XY-model Hamiltonian\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The paper's significance and potential impact are reflected by discussing the challenges and potential solutions, such as using polar molecules or exploring new geometries.", "1. **Accurate Reflection of Main Findings and Contributions**: The summary captures the main findings and contributions of the paper, such as the use of ultracold atoms to study many-body physics, the use of Rydberg states, and the creation of entangled many-body states on a ring lattice.\n\n2. **Conciseness**: The summary exceeds the 250-word limit, making it less concise than required.\n\n3. **Research Problem or Question**: The summary highlights the research problem of studying many-body physics using ultracold atoms and Rydberg states.\n\n4. **Methodology or Approach**: The summary mentions the use of Rydberg states and the analytical derivation of the system's Hamiltonian.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the creation of entangled states and the potential applications of Rydberg atoms.\n\n6. **Clear and Professional Language**: The language used in the summary is clear and professional.\n\n7. **Avoidance of Technical Jargon**: The summary uses some technical terms but does not explain them, which might be necessary for clarity.\n\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions key experiments involving Rydberg states and their applications.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in advancing the study of many-body physics and potential applications in quantum information processing."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "there are many famous theorems about periodic points of annulus maps . the poincar - birkhoff theorem asserts that any area - preserving homeomorphism of the annulus isotopic to the identity has periodic orbits with rational rotation numbers in the rotation interval of the homeomorphism ( see and @xcite ) . with the additional twist hypothesis , aubry and mather proved the existence of periodic orbits whose radial order is preserved by the map . such orbits are called birkhoff orbits ( see @xcite ) or monotone orbits . this notion of monotone periodic orbits inspired the definition of topologically monotone orbits in @xcite , where boyland proved that any homeomorphism of the annulus , isotopic to the identity , that has a periodic orbit with a non - zero rotation number @xmath3 also has a topologically monotone periodic orbit with the same rotation number . a topologically monotone periodic orbit has the property that the isotopy class of the map , keeping the periodic orbit fixed as a set , is of finite order . then the existence of topologically monotone periodic orbits was established on the torus for smooth maps in @xcite and for homeomorphisms in @xcite . it is natural to ask if a similar theorem can be proved on other surfaces . the main goal of this paper is to describe an analogous theorem on general orientable surfaces with negative euler characteristic . section 1 introduces rotation vectors and braids for periodic orbits on orientable surfaces . section 2 shows that topologically monotone periodic orbits ( trivial braids ) are quite `` rare '' on surfaces with negative euler characteristic . this motivates the definition of simple braids ( which are not that rare ) in section 3 where the main theorem about the existence of simple braids , instead of topologically monotone orbits , is proved on surfaces of negative euler characteristic . so simple braids should be considered as an alternative to trivial braids on surfaces with negative euler characteristic . also , the main theorem of this paper can be viewed as a sharkovskii - type forcing result  non - simple braids force the existence of simple braids . throughout this paper , @xmath0 will represent a compact , oriented surface , with or without boundary , and @xmath1 will be a homeomorphism isotopic to the identity . in this situation , the _ rotation vector _ for a periodic point is easy to define . let @xmath4  be a periodic point of least period @xmath5 . there s an isotopy from the identityto @xmath6 and so we get an arc from @xmath4  to @xmath7denoted @xmath8by following the isotopy . concatenate the arcs @xmath9, ... ,@xmath10  to obtain a loop @xmath11 . take the homology class @xmath12 $ ] of this loop in the surface and divide it by @xmath5 . the _ rotation vector _  of the periodic point @xmath4  is @xmath13}{n}$ ] . in fact , the rotation vector of every point in the orbit of @xmath4 is the same , and so , we can associate the rotation vector @xmath13}{n}$ ] to the entire periodic orbit .    in the example below ( figure 1 ) , the rotation vector is @xmath14 . the generators chosen are the inner boundary circles endowed with the orientations given to the boundary . in general , the rotation vector depends on the choice of generators . we could also depict the vector as a 3-tuple like @xmath15 . in general , we write @xmath2 , where @xmath16 is the _ homology vector _ and @xmath17 is the period . every orientation preserving homeomorphism of an orientable surface with negative euler characteristic is isotopic to a homeomorphism @xmath18 such that either    \\a ) @xmath18 is finite order , or    \\b ) @xmath18 is pseudoanosov ( @xmath19 ) , or    \\c ) @xmath18 is reducible . a map @xmath18 is said to be _ reducible _ if there is a disjoint collection @xmath20 of non - parallel , non - peripheral simple disjoint curves such that @xmath18 leaves invariant the union of disjoint regular neighborhoods of curves in @xmath20 , and the first return map on each complementary component is either of finite order or @xmath19 . this classification theorem was first announced in @xcite and the proofs appeared later in @xcite and @xcite .    on any surface , with zero or negative euler characteristic , we follow handel as in @xcite and examine the isotopy class relative to a periodic orbit ; this will introduce punctures and insure the negative euler characteristic required to apply the nielsen - thurston classification theorem . when the isotopy class relative to a given periodic orbit is of finite order , the periodic orbit is called a _ finite order periodic orbit _ , and _ reducible _ and @xmath19 _ periodic orbits _ are defined similarly . the isotopy class relative to a periodic orbit is also referred to as the _ braid _ of the periodic orbit . let @xmath4  and @xmath21  be two distinct periodic points of least period @xmath5  for homeomorphisms @xmath6 and @xmath18 respectively of the same orientable surface @xmath0 . then the orbit of @xmath4  ( @xmath22 ) and the orbit of @xmath21  ( @xmath23 ) have the same _ braid _ if there exists an orientation - preserving homeomorphism @xmath24of @xmath0 with the property that @xmath24  maps @xmath22  onto @xmath23 and the isotopy class of @xmath25  relative to the orbit of @xmath21  is the same as the isotopy class of @xmath18  relative to the orbit of @xmath21 , that is , @xmath26_{o(y)}=[f]_{o(y)}$ ] . a braid is considered * trivial * if its isotopy class , relative to the periodic orbit corresponding to the braid , is of finite order , that is , there exists a homeomorphism @xmath18 isotopic to @xmath6 , relative to the periodic orbit , such that @xmath27 , for some @xmath5 . and a braid is * non - trivial * if the isotopy class is not of finite order . by definition , topologically monotone periodic orbits are finite order periodic orbits and trivial braids , and non - trivial braids are the @xmath19 and the reducible periodic orbits . boyland defined a natural partial order @xmath28 on these braids . if @xmath29 and @xmath30 are two braids of periodic orbits , then @xmath31 if and only if the existence of @xmath29 in any surface homeomorphism @xmath6 implies the existence of @xmath30 for the same @xmath6 . the proof of the fact that this is an actual partial order is not easy and is in @xcite . the existence of topologically monotone periodic orbits on the annulus in @xcite is established by showing that non - trivial braids of periodic orbits force the existence of trivial braids of periodic orbits with the same rotation number ( non - trivial @xmath32 trivial ) . let f be a homeomorphism of the annulus isotopic to the identity . then if there exists a periodic orbit with rotation number @xmath3 , there exists a trivial braid with the same rotation number . then a similar theorem was proved on the torus in @xcite . let f be a homeomorphism of the torus isotopic to the identity . then if there exists a periodic orbit with rotation vector @xmath33 , there exists a trivial braid with the same rotation vector . the proofs of both theorems rely heavily on the fact that the fundamental groups of the annulus and the torus are abelian . however , this is not the case for surfaces with negative euler characteristic and the situation is completely different . section 2 shows that the existence of trivial braids or finite order periodic orbits can not always be established . this then motivates the definition of simple braids in section 3 . we consider compact , oriented surfaces and homeomorphisms isotopic to the identity . the main theorem of this section says that , under these conditions , the isotopy class of any homeomorphism , relative to a periodic orbit of least period greater than 1 , can never be of finite order . this is why trivial braids can not exist for periodic orbits with period greater than 1 . the theorem will be proved by a series of simple lemmas . first , some notation . let @xmath1 be a homeomorphism of an oriented surface that is isotopic to the identity and let @xmath4 be a periodic point of least period @xmath5 , @xmath34 . suppose the isotopy class relative to this periodic orbit , @xmath22 , is of finite order . let @xmath18 represent this finite order class . there exists a hyperbolic metric on this surface for which @xmath18 is an isometry ( see @xcite ) .    for an orientation - preserving isometry g on any connected oriented surface , if a geodesic segment is fixed ( pointwise ) by g , then all points are fixed by g.    let @xmath11 be this geodesic segment that is fixed by @xmath18 . assume that @xmath11 is small , that is , it is contained in a ball with radius less than the injectivity radius . in this small ball , pick any point @xmath4 and construct a geodesic triangle by picking any two points on @xmath11 and drawing geodesics from these points to @xmath4 . the two endpoints on @xmath35 are fixed , by assumption , and the orientation preserving isometry sends geodesics to geodesics and preserves angles and lengths . so the whole geodesic triangle is fixed , and hence , @xmath4 is fixed . the point was arbitrary and so every point is this ball is fixed . since the surface is connected , this can be extended to other neighboring balls and eventually to the whole surface . for an orientation - preserving isometry g on any connected oriented surface , either the fixed points are isolated or g fixes every point .    suppose a fixed point @xmath4 is not isolated . then there exists a fixed point @xmath21 , close enough to @xmath4 , such that there is a unique geodesic connecting @xmath4 to @xmath21 . then the isometry sends this geodesic to itself it fixes every point on this geodesic . by the lemma above , @xmath18 fixes every point .    for an orientation - preserving isometry @xmath18 on any connected oriented surface , all the isolated fixed points have index 1 . the derivative map at the isolated fixed point must preserve angles and lengths . it is either the identity or some rotation . if it is the identity , then an entire neighborhood is fixed by @xmath18 and so every point on the surface is also fixed . since we are assuming that the fixed point is isolated , it must be some rotation . this means that the index is one . let @xmath1  be a homeomorphism of a compact , oriented surface , with negative euler characteristic , that is isotopic to the identity and let @xmath4  be a periodic point of least period @xmath5 , @xmath34 . then @xmath36  is not isotopic to the identity relative to the orbit of @xmath4 . suppose @xmath36 is isotopic to the identity relative to the orbit of @xmath4 . let @xmath18 represent this finite order class of @xmath6 . there exists a hyperbolic metric on this surface for which @xmath18 is an isometry ( see @xcite ) . clearly @xmath18 is not the identity as it contains a periodic orbit of period greater than one , but @xmath18 is isotopic to the identity because @xmath6 is . this means that the indices of the fixed points must add up to the euler characteristic , which is negative . but by the above lemma , all the fixed points have index one . so @xmath6 can not be isotopic to the identity relative to the orbit of @xmath4 .    here we have established that there are no trivial braids for periodic orbits with period greater than 1 , but what about trivial braids for fixed points ? does there always exist a finite order fixed point ? we will use the following extremely useful description of finite order fixed points which is probably well known . since the author could not find a reference , a simple proof is provided . first recall that if @xmath6 is a homeomorphism of surface @xmath0 isotopic to the identity and if @xmath0 has negative euler characteristic , then there exists a unique lift  called the identity lift  of @xmath6 to the universal cover of @xmath0 such that the lift commutes with all covering translations . let @xmath6 be a homeomorphism isotopic to the identity of a surface @xmath0 with negative euler characteristic , and let @xmath4 be a fixed point for @xmath6 . then @xmath4 is a finite order fixed point if and only if the identity lift of the map @xmath6 to the universal cover of @xmath0 fixes all the lifts of @xmath4 . first assume that @xmath0 has no boundary and consider the following well known exact sequence ( see @xcite ) . @xmath37    here @xmath38 stands for the mapping class group of @xmath0 and @xmath39 is the mapping class group of @xmath0 relative to @xmath4 . the homomorphism from @xmath39 to @xmath38 is the forgetful homomorphism one simply removes the restriction that the point @xmath4 needs to be fixed during the isotopy . the homomorphism from @xmath40 to @xmath39 is called the push homomorphism  given a closed loop based at @xmath4 , we obtain an element in @xmath39 by pushing @xmath4 along the loop .    now if we restrict our attention to maps which are isotopic to the identity on @xmath0 , then the mapping class group of these homeomorphisms relative to @xmath4 is isomorphic to @xmath41 . this isomorphism is easily described . pick a representative of the element in @xmath39 which maps to the identity under the forgetful homomorphism and consider an isotopy of the representative to the identity . then the loop formed by following @xmath4 gives an element in @xmath41 . equivalently , we may consider the identity lift of the representative and then the covering translation that moves a particular lift of @xmath4 provides an element in the fundamental group of @xmath0 . it now follows that @xmath6 is isotopic to the identity relative to @xmath4 if and only if the identity lift of @xmath6 fixes all lifts of the point @xmath4 . now suppose that @xmath0 has boundary . if @xmath4 lies in the interior of @xmath0 , the argument above goes through without any change ; here we assume that the mapping class groups are the sets of isotopy classes that fix the boundary of @xmath0 setwise and not pointwise . if @xmath4 lies on a boundary circle , @xmath40 needs to be replaced by the group @xmath42 . in other words , @xmath6 relative to @xmath4 is isotopic to possibly non - trivial dehn twists around the boundary circle associated to @xmath4 . the rest of the argument is identical . we answer the question , raised earlier , regarding the existence of finite order fixed points by appealing to a recent result due to le calvez ( see @xcite ) . let @xmath43 be a fixed point free homeomorphism of the plane . suppose that @xmath43 commutes with the elements of a discrete group @xmath44 of orientation - preserving homeomorphisms that act freely and properly on the plane . then there exists a topological foliation of the plane by brouwer lines that is invariant under the action of the elements in the group @xmath44 . this allows us to prove the following . let @xmath6 be a homeomorphism , isotopic to the identity , of a compact and oriented surface @xmath0 with negative euler characteristic . then there always exists a finite order fixed point . first suppose that @xmath0 has no boundary . let @xmath43 be the unique lift of @xmath6 to the universal cover that commutes with all the elements of the fundamental group of @xmath0 . such a lift does exist since @xmath6 is isotopic to the identity . it suffices to show that there exists a fixed point for @xmath43 because this would imply that @xmath6 is isotopic to the identity relative to the fixed point obtained by projecting the fixed point in the universal cover down to the surface @xmath0 . suppose that @xmath43 is fixed point free . then use le calvez s result above to obtain a topological foliation of the universal cover , which is homeomorphic to the plane . since @xmath43 commutes with all the elements of the fundamental group of @xmath0 , the foliation is invariant under the action of the fundamental group . this means that we obtain a topological foliation of the surface @xmath0 , which is impossible since @xmath0 has negative euler characteristic . so @xmath43 must have a fixed point . now suppose @xmath0 is with boundary . let @xmath45 be another copy of @xmath0 with the same map @xmath6 on it and let @xmath46 ( the double ) be the surface formed by identifying the corresponding boundary components of @xmath0 and @xmath45 . more precisely , every point @xmath4 in @xmath0 has a counterpart in @xmath45 called @xmath47 and @xmath46 is the surface formed under the identifications @xmath48 , for all @xmath4 on the boundary of @xmath0 . then a map @xmath18 on @xmath46 is defined by @xmath49 for @xmath50 and @xmath51 for @xmath52 . note that @xmath46 has no boundary and the map @xmath18 on @xmath46 is isotopic to the identity . now the arguments above show that there exists a finite order fixed point for @xmath18 in @xmath46call this point @xmath21 . without loss of generality , assume that @xmath21 lies in @xmath0 and consider the identity lift of @xmath18 to the universal cover of @xmath46 . this lift fixes all lifts of @xmath21 and it also leaves invariant all lifts of the subsurface @xmath0 . the restriction of the lift of @xmath18 to any lift of the subsurface @xmath0 is the identity lift of @xmath6 to its universal cover since the covering translations associated to a lift of @xmath0 are a subset of the covering translations on the universal cover of @xmath46 . then by theorem 2.5 , it follows that @xmath6 is isotopic to the identity relative to @xmath21 , and so , @xmath21 is a finite order fixed point . note that this finite order fixed point must have a zero rotation vector . if its rotation vector were non - zero , the isotopy loop obtained in the calculation of the rotation vector would have to be essential . then the lift of this isotopy loop would not be a loop in the universal cover , implying that @xmath43 moved the fixed point by some covering translation . but the finite order fixed point is fixed in the universal cover , and hence , it must have rotation vector equal to zero . so the above theorem establishes the existence of a fixed point with a zero rotation vector for any homeomorphism isotopic to the identity on any surface with negative euler characteristic . this is a variation on a theorem by john franks who in @xcite proved the existence of a fixed point of positive index and a zero rotation vector under stronger hypotheses . if 0 is in the interior of the convex hull of the recurrent rotation vectors for an area - preserving diffeomorphism @xmath6 isotopic to the identity and if the fixed points are isolated , then @xmath6 has a fixed point of positive index and a zero rotation vector . also note that since all finite order fixed points have to also be fixed when lifted to the universal cover , no fixed point with a non - zero rotation vector can be of finite order . so trivial braids can only exist for fixed points with a zero rotation vector . the next section concentrates on the case of periodic orbits with non - zero rotation vectors . let @xmath0 be a compact , oriented surface with negative euler characteristic and let @xmath53 be a homeomorphism isotopic to the identity . we can always lift this map to the universal covering space , which in the poincar disc model can be identified with the interior of the unit disc if @xmath0 has no boundary . if @xmath0 has boundary , its boundary components lift to geodesic arcs . in either case , the covering space can be compactified and any lift can be considered as a homeomorphism of closed disc @xmath54 . we will focus on the identity lift @xmath43 which is the unique lift of @xmath6 that commutes with all covering translations . first consider the lift of any periodic point in the interior of @xmath0 with rotation vector @xmath55 to @xmath54 ; assume that @xmath16 is not zero . if @xmath4 lies on the lifted orbit , then @xmath56 , for some covering translation @xmath57 . @xmath58 is homeomorphic to the closed annulus ( @xmath59 ) and since @xmath43 commutes with @xmath57 , a homeomorphism @xmath60 is induced on @xmath61 . the lift of the periodic orbit on @xmath54 projects down to a periodic orbit on @xmath59 , and since @xmath56 , it has rotation number @xmath62 . define a _ simple braid _ as the periodic orbit that can be lifted , in the manner described above , to a finite order periodic orbit on the annulus . so simple braids are trivial when lifted to the annulus . any periodic orbit on a boundary circle is considered to be a simple braid . in fact , any periodic orbit on a circle trivially has its radial order on the circle preserved under the action of the map , and so we may even call these orbits birkhoff orbits . let @xmath0  be a compact , oriented surface with negative euler characteristic and let @xmath1  be a homeomorphism isotopic to the identity . if there exists a periodic orbit with non - zero rotation vector @xmath2 , then there exists a simple braid with the same rotation vector . if the periodic orbit is already a simple braid , there is nothing to prove . so assume that the orbit lies in the interior of @xmath0 and then lift the periodic orbit to a periodic orbit with rotation number @xmath62 on the annulus as described above . boyland s theorem ( theorem 1.2 ) asserts that there exists a trivial braid with the same rotation vector . if two periodic points on the annulus have the same rotation vector , then their isotopy loops , the loops constructed by concatenating isotopy arcs between successive iterates in order to calculate their rotation numbers , have to be homotopic ( freely ) . if two loops are homotopic in some covering space , their projections are also homotopic . so the isotopy loops are homotopic even on @xmath0 . if the isotopy loops are homotopic , they are homologous and the two periodic points have the same rotation vectors . figure 3 depicts a period 6 orbit going around a handle of a genus 2 surface . one is tempted to call this a trivial braid , but by the discussion in section 2 we know that the periodic orbit can not be a finite order periodic orbit . the second handle poses an obstruction to isotoping the map , around the periodic orbit , into a finite order map . of course , there is no obstruction to doing this on the torus where trivial braids can exist for all periods ( see @xcite ) . simple braids are the best we can hope for in general . even on finite covers of the surface that one begins with , which have all negative euler characteristic , there can be no trivial braids for periodic orbits with period greater than one . it is only on the compactified , infinite cover , the annulus , a surface with zero euler characteristic , where there is some hope for trivial braids , and that is exactly what happens . can this theory of topologically complicated orbits forcing topologically simpler orbits be generalized to the case in which the orbits are not periodic ? this question remains open even on the annulus . the author would like to thank john franks for several useful conversations . this work was supported in part by nsf grant dms0244529 .", "tags": [], "output_text_a": "This paper explores the existence of periodic orbits on orientable surfaces with negative Euler characteristic, extending the concepts of periodic points and braids from annulus maps to more general surfaces. The Poincar\u00e9-Birkhoff theorem and its extensions by Aubry, Mather, and Boyland are foundational, asserting the existence of periodic orbits with specific properties on the annulus and torus. The paper introduces the notion of \"simple braids\" as an alternative to \"trivial braids\" on surfaces with negative Euler characteristic, where trivial braids are rare. The main theorem demonstrates that non-simple braids force the existence of simple braids, akin to a Sharkovskii-type forcing result. The study involves defining rotation vectors and braids for periodic orbits, and proving that trivial braids cannot exist for periodic orbits with periods greater than one on these surfaces. The paper also establishes the existence of finite order fixed points with zero rotation vectors, drawing on results by Le Calvez and Franks. The work suggests that simple braids are the best achievable outcome for periodic orbits on surfaces with negative Euler characteristic, and raises open questions about extending these results to non-periodic orbits. The research is supported by NSF grant DMS0244529.", "output_text_b": "This paper discusses theorems about periodic points of annulus maps and generalizes them to orientable surfaces with negative Euler characteristic. The authors introduce rotation vectors and braids for periodic orbits on orientable surfaces and show that topologically monotone periodic orbits (trivial braids) are rare on surfaces with negative Euler characteristic. They then define simple braids, which are not as rare, and prove the existence of simple braids on surfaces with negative Euler characteristic. The main theorem can be viewed as a Sharkovskii-type forcing result, where non-simple braids force the existence of simple braids.", "score": -0.10000000000000009, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the introduction of \"simple braids\" and the extension of periodic orbits concepts to surfaces with negative Euler characteristic.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of extending periodic orbits concepts to surfaces with negative Euler characteristic.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary does not explicitly mention the methodology or approach used in the paper.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the existence of simple braids and finite order fixed points.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"simple braids\" and \"trivial braids\" but does not explain them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any key experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing the extension of concepts to more general surfaces and raising open questions.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the generalization of theorems about periodic points of annulus maps to orientable surfaces with negative Euler characteristic and the introduction of rotation vectors and braids.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the generalization of theorems to surfaces with negative Euler characteristic.\n4. The methodology or approach used in the paper is not explicitly mentioned in the summary.\n5. Significant results or conclusions, such as the existence of simple braids and the Sharkovskii-type forcing result, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids technical jargon and explains terms like \"simple braids\" and \"Sharkovskii-type forcing result.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research.\n10. The summary reflects the paper's significance by discussing the potential impact of the findings on the understanding of periodic orbits on surfaces with negative Euler characteristic."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [false, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the bacteria _ l. monocytogenes _ , _ s. flexneri _ , the spotted fever group of _ rickettsiae _ , and the _ vaccinia _ virus are intracellular pathogens that move through the continual polymerization of actin @xcite in distinctively curved `` comet - tails '' of actin filaments behind the motile particles . while fascinating on its own , the actin comet - tail is functionally similar to the actin mesh in the lamellipodia of a locomoting eukaryotic cell , and the bacterial surface is analogous to the leading edge of the cell . identification of the biochemical components involved has thus provided insight into the active regulation of actin polymerization by the cell @xcite  an essential cellular process @xcite .    for polymerization - based motility , the force generated by actin polymerization at the moving object s surface drives the object forward against the viscous drag of the cytoplasm @xcite . the necessary and sufficient bacterial contribution to motility is a single surface protein that orchestrates cellular cytoplasmic proteins to locally promote the nucleation , elongation , and cross - linking of actin filaments . in _ l. monocytogenes _ , this process is driven by the bacterial protein acta @xcite , while _ s. flexneri _ expresses the protein icsa for the same purpose @xcite . candidates for similar proteins have been proposed for spotted - fever _ rickettsiae _ @xcite and for the _ vaccinia _ virus @xcite . simplified systems that have been developed for the study of polymerization - based motility include _ escherichia coli _ expressing icsa on their surfaces @xcite and microspheres coated with purified acta @xcite . similar motility mechanisms appear to be at work in endosomal rocketing @xcite , and in non - actin polymerization - based motility systems derived from nematode sperm @xcite . actin polymerization - based motility may even play an important role in vesicle trafficking within the cell @xcite .    as the bacterium or particle is driven forward , a curved comet - like tail of actin filaments remains behind . photobleaching experiments in _ l. monocytogenes _ @xcite and qualitative observation of _ s. flexneri _ @xcite and of spotted - fever _ rickettsiae _ @xcite demonstrate that the tail is stationary with respect to the surrounding environment , probably due to steric or functional connections with the cellular cytoskeleton , so that the shape of the tail represents the path of the bacterium . the curvature of this path varies from bacterium to bacterium , and changes over time for individual bacteria . it is not known what determines the bacterial path , and hence the tail curvature , though no active control or chemotactic behavior has been proposed for these systems . bacteria are functioning micromachines , but can not be fully exploited without being fully understood . the _ l. monocytogenes _ motility system is well enough understood biochemically that acta coated microspheres @xcite should reconstitute polymerization - based motility in solutions of purified proteins @xcite , i.e. with total experimental control . however , we do not yet _ quantitatively _ understand the motility enough to be able to use the bacterial or microsphere motion as a probe of the bacterial or cellular conditions , or conversely to attempt to tailor those conditions to affect the bacterial motion .    in this paper , we propose that the curvature results from the random location of actin filaments pushing against the bacterium . we show how the curvature of the bacterial path can be used to predict static and dynamic structure at the bacterial surface . the average curvature is determined by the number of active filaments pushing the bacterium . information about filament lifetime and surface diffusion rates may be obtained from curvature autocorrelations , since curvature depends on the location of active filaments with respect to the bacterial surface . if filaments are closely localized to specific bacterial surface proteins , then lifetimes and diffusivities of those proteins can be inferred . we focus on the most common experimental geometry of a thin quasi - two - dimensional system constrained between a glass slide and cover - slip , however we also discuss what would be expected for bulk geometries . in both cases , we discuss the apparent curvature appropriate to video microscopy . curvature is defined as the rate of rotation of direction , @xmath0 , or the rotation per unit path length , where @xmath1 is the polar angle in the current plane of motion ( see fig . [ fig : angles ] ) and @xmath2 is distance measured along the particle path . the radius of curvature , @xmath3 , equals the radius of the circle that locally best fits the path . either @xmath4 or @xmath5 _ locally _ characterize the path , i.e. both may vary along the bacterial path . = 3.25truein    curved trajectories imply a torque @xmath6 is acting on the bacterium to balance viscous drag proportional to the angular rate of rotation , @xmath7 , where @xmath8 $ ] is a rotational drag coefficient for turning in @xmath1 , and @xmath9 is the fluid viscosity , @xmath10 and @xmath11 are bacterial dimensions ( see fig . [ fig : angles ] ) , and @xmath12 $ ] @xcite . the viscous drag force @xmath13 due to linear motion at speed @xmath14 also carries a factor of the viscosity , where @xmath15 and @xmath16 $ ] @xcite . since the curvature of the path , @xmath17 , we can use the drag coefficients to obtain a remarkably simple result , @xmath18 independent of the viscosity . this is fortunate since the effective viscosity of the cellular cytoplasm is strongly scale - dependent , ranging from @xmath19 poise ( @xmath20 ) for small loops on dye molecules @xcite to @xmath21 poise ( @xmath22 ) for @xmath23 diameter spheres @xcite . we find that the curvature directly probes the ratio of force and torque applied to the bacterium , with an easily determined geometrical prefactor . the force , @xmath24 , is proportional to the number of actively pushing filaments @xmath25 , while the force per filament @xmath26 depends on the specific details of the motility mechanism  as seen explicitly in thermal - ratchet models of polymerization - based motility @xcite . a complementary coarse - grained elastic analysis of polymerization - based bacterial motion @xcite exists , however it is not convenient for determining curvatures . we take @xmath26 as constant in time , which amounts to considering only times much greater than the mean - time between actin monomer addition or equivalently distances much greater than the monomer size @xmath27 . this is appropriate , since observed radii of curvature are larger than the bacterial scale ( which is @xmath28 microns ) .    to calculate the torque @xmath6 , we must consider the torque due to each filament . these individual torques depend on exactly where the filament pushes on the bacterium . we assume that the @xmath25 actively pushing filaments are each randomly placed on the trailing end of the bacterium , so that each one will produce a random vectorial torque on the bacterium . the sum of many of these random torques will have a gaussian distribution with zero mean . we can calculate the root - mean - square ( rms ) torque , @xmath29 , from the local filament density . we take the growing filament barbed - ends as uniformly distributed over the hemispherical cap at the end of the bacterium . in cross - section , this leads to enhanced filament density at the edges of the tail , similar to that seen in thin - section electron micrographs of _ l. monocytogenes _ @xcite . this distribution also follows naturally if the filament density follows a uniform acta surface density . in cross - sectional coordinates , where the cylindrical radius @xmath30 ranges from @xmath31 to @xmath11 , the filament density distribution is @xmath32 where @xmath33 is the average number of filaments in the interval @xmath34 and @xmath35 . here , @xmath36 is the uniform surface filament density on the hemispherical end of the bacterium , and @xmath11 is the bacterial radius . the mean - square torque perpendicular to the direction of motion is easily found @xmath37                       p_f(r,\\phi),\\ ] ] where @xmath38 and @xmath39 are the two components of the torque , so that they add in quadrature . this leads to an rms torque @xmath40 . taking the ratio @xmath41 to calculate the rms curvature from eq . [ eqn : curvature ] , we have @xmath42 for a hemispherical distribution of filaments . bacterial size and shape contribute to the curvature , as does the average distribution of filaments eq . [ eqn : distrib ] . other surface distributions of filament densities are also possible , and would affect the geometric prefactors in eq . [ eqn : rmsk ] though not the functional dependence on the number of filaments @xmath25 . remarkably , the average force per filament @xmath26 does not appear in our expression for the curvature , so that our results appear _ independent _ of the details of the force generation mechanism . however within polymerization ratchet models @xcite thermal fluctuations of semi - flexible actin filaments transverse to their length @xcite could generate transverse forces , which would lead to an increased torque and greater curvature than predicted a bove in eqn . [ eqn : rmsk ] . this transverse contribution would depend on the biomechanics of the coupling between the actin filament and the bacterial surface , which would also depend on the bacterial shape . unfortunately it also depends on the effective and anisotropic elastic constants of the actin filaments @xcite , which in turn sensitively depends on how actively pushing actin filaments are cross - linked into the bacterial tail and the cytoskeleton  as can be seen by contrasting the elastic constants given by @xcite and @xcite . our simplified treatment corresponds to no coupling of forces transverse to the direction of bacterial motion . we hope that sensitive experiments can uncover the effects of these transverse forces and hence yield more insight into polymerization - based force generation , though we expect the effects to show up predominately in the geometrical prefactor or amplitude of the curvature in eqn . [ eqn : rmsk ] and not in the @xmath43 dependence . we expect our subsequent analysis , on distributions and autocorrelations of the curvature , to be unaffected .    the vectorial torque perpendicular to the bacterial direction of motion is gaussian distributed , and the curvature is proportional to the _ magnitude _ of the torque . within a bulk ( @xmath44 ) geometry the curvature has distribution @xmath45 where @xmath46 and @xmath47 .      the curvature of the bacterial path , characterized by eq . [ eqn : rmsk ] and eq . [ eqn : intrinsic ] , is _ intrinsic _ to a given random placement of @xmath25 filaments pushing against the bacterium . this intrinsic curvature is constant for fixed filament locations on the bacterial surface . at any given time , the intrinsic curvature represents circular motion around the curvature axis . however , the instantaneous curvature axis is not necessarily parallel to the line of sight , so the apparent path would appear elliptical and have a non - uniform curvature . we must also consider dynamical effects which change the direction of the curvature axis , both through rotation of the bacterium and through motion of the filaments on the bacterial surface . most experimental work to date has been done with restricted geometries , such as the typical gap of several microns @xcite between a glass slide and its cover slip . for thin enough samples , curvature out of the plane will be restricted . if the axial angle @xmath48 measures the angle between the vectorial torque and the normal to the sample plane in the line of sight , then the apparent curvature as measured from a microscope or video image will be @xmath49 positive and negative curvatures correspond to clockwise and counterclockwise curved paths in the microscope image , respectively . a single bacterium with a fixed intrinsic curvature , @xmath4 , would eventually uniformly explore @xmath50 $ ] through rotational diffusion @xcite . as it does , the apparent curvature will change . for a fixed intrinsic curvature , sampling at uniform time intervals , we would measure a distribution of apparent curvatures given by @xmath51 where @xmath52 $ ] . if an individual bacterium changes its intrinsic curvature in time , then over sufficient time @xmath4 will explore the entire intrinsic distribution , eq . [ eqn : intrinsic ] . the ensemble distribution @xmath53 of apparent curvatures will then be given by eq . [ eqn : apparent ] convoluted with eq . [ eqn : intrinsic ] : @xmath54 where @xmath55 , where the rms - apparent torque is equal to @xmath56 . @xmath53 also follows directly from the gaussian distribution of each component of the torque . this `` ensemble '' distribution also characterizes the apparent curvatures of large groups of bacteria , since they will each have a different intrinsic curvature chosen from eq . [ eqn : intrinsic ] and each will have a random axial angle @xmath48 . the differences between the ensemble , apparent , and intrinsic curvature distributions is dramatic , as shown in fig . [ fig : distributions ] .    = 3.25truein    for bacteria in a bulk sample , two angles are needed to characterize the bacterial path with respect to the viewer  a polar angle @xmath57 with respect to the line of sight , and an azimuthal angle @xmath58 about the line of sight . one must also specify the axial angle @xmath48 about the bacterial axis . if we line up the bacterium to travel away from us along the line of sight , before rotating it towards us by @xmath57 in the @xmath58 azimuthal direction , and measure @xmath48 as the angle between the vectorial torque and @xmath58 , then the apparent curvature is @xmath59 this is the curvature as measured from a microscope or video image , and takes values from @xmath60 with no explicit @xmath58 dependence . extremely large apparent curvatures are seen when bacteria are moving towards or away from the observer with correspondingly small velocities , with @xmath57 small . the apparent speed is @xmath61 , where @xmath14 is the bacterial speed along its path . a convenient quantity is obtained by `` normalizing '' the apparent curvature by multiplying by @xmath62 , to obtain @xmath63 where @xmath64 . this also decreases the weight placed on apparently stationary bacteria , which can be hard to distinguish from other objects , and simplifies the analysis . @xmath65 will have the ensemble distribution @xmath53 _ if _ @xmath48 is uniformly explored in time . note that time or path - length weighted distributions will differ in bulk samples , since the apparent speed @xmath66 will vary dramatically even for a constant intrinsic bacterial speed . the distributions presented in this paper are for time - weighted sampling , appropriate for video microscopy and/or for planar ( @xmath67 ) geometries . for individual bacteria , the experimentally apparent variation of curvature from one moment to the next is striking @xcite . restricting ourselves to thin planar samples , the angular diffusion of the bacterial orientation can lead to changing apparent curvatures through changing axial angles @xmath48 in eq . [ eqn : knormalize ] , and the _ intrinsic _ curvature can also vary if filament locations on the bacterial surface move significantly over time . we explore two cases , where active ( pushing ) filaments are removed and randomly replaced on the bacterial surface , and where active filament locations randomly diffuse . we will later apply these cases to characterize filament repositioning for different motile systems . it is easiest to characterize changes in the net torque acting on the bacterium with respect to a reference frame fixed to the bacterium . we consider the correlation of the intrinsic vector torques separated in time by @xmath68 : @xmath69 where a static intrinsic curvature corresponds to @xmath70 , and the average is over the initial time @xmath71 . the second line follows directly if each filament has a lifetime @xmath72 after which it is replaced _ randomly _ on the rear of the bacterium by another filament . if new filaments are randomly placed they will be uncorrelated with other filaments . the correlation will then be proportional to the fraction of filaments that have not been replaced between the two times , i.e. @xmath73 . exponential decay also applies for actin filaments whose fast - growing barbed - end positions diffuse over the bacterial surface with diffusion constant @xmath74 . solutions of diffusion on a spherical surface of radius @xmath11 @xcite leads to @xmath75 . these results would apply directly to proteolysis / replacement or surface motion of bacterial proteins such as acta or icsa if active filament positions are localized to such bacterial surface features ( see below ) . they should also apply to dynamics intrinsic to the actin tail through capping and nucleation of active actin filaments @xcite , where capping is a loss mechanism . in this case , the timescale of of autocorrelation decay would depend on the details of filament nucleation  how new filaments are placed with respect to pre - existing active filaments . azimuthal diffusion will not affect the intrinsic curvature or its correlations , but it can contribute to decay of correlations of the _ apparent _ curvature by changing the apparent curvature over time . azimuthal diffusion obeys @xmath76 , where @xmath77 is the net angle of rotation in the time @xmath78 and @xmath79 is the diffusion constant . this has a direct effect on the correlation between apparent curvatures separated in time by @xmath68 : @xmath80 where @xmath72 is the decay time from intrinsic correlations in eq . [ eqn : torquecorr ] and the average is over @xmath71 for a single bacterium . [ we have used the identity @xmath81 for gaussian distributed @xmath82 . ] of course , rotation of the bacterium around its long axis will lead to decaying autocorrelations only if active filament tips are localized to bacterial surface features . if not , azimuthal diffusion might not affect the apparent curvature .    for individual bacteria tracked for times much less than @xmath72 , the intrinsic curvature will appear constant . for times much longer than @xmath72 , each bacterium will sample the ensemble of intrinsic curvatures . the characteristic timescale may be measured from the decay of curvature autocorrelations . filament decay / replacement , filament diffusion , and axial rotation all contribute to exponential decay of the apparent curvature correlations . their contributions to a particular motile system may be separated through independent measurements or through systematic studies where parameters such as the particle size or the cytoplasmic viscosity are varied . random rotation and diffusion of bacterial positions will also contribute to the measured curvature and curvature autocorrelations . in principle this is a complicated hydrodynamic effect @xcite leading to exponential asymptotic decay , however the timescales are very short ( @xmath83 for a bacterium in a cell , where @xmath5 is the cell size and @xmath84 the cytoplasmic density ) compared to the measurement intervals in typical bacterial experiments ( seconds ) . the autocorrelation decay will effectively be discontinuous at @xmath85 , where thermal and measurement jitter will contribute at @xmath86 but not for @xmath68 . to eliminate those contributions , the experimental rms curvature @xmath87 should be extracted from the @xmath88 limit of the autocorrelations or should be fit from sufficiently long segments of the bacterial path . curvature autocorrelations in bulk samples are simple only when the intrinsic curvature is extracted from full @xmath44 tracking of the bacterial trajectory ( see e.g. @xcite ) . in that case , eq . [ eqn : torquecorr ] will describe the autocorrelation decay . in this section we discuss several specific motile systems , and use the details to refine our discussion of curved bacterial paths . for illustrative purposes , curvature has been estimated from published images of _ l. monocytogenes_. this should be considered an order of magnitude estimate only . we only analyze motion within _ xenopus laevis _ cell extracts , since cellular organelles and cell membranes , which can locally affect bacterial trajectories through collisions and which are hard to control for in published images , are absent . also absent in extracts is a polarized cytoskeleton , which could plausibly align bacterial motion in intact cells  this could be explored through a systematic comparison of bacterial motion in cells and in cell extracts . it must be emphasized that _ proper studies of curvature require unbiased data _ and individual images previously selected for publication may be biased by aesthetic considerations . distributions and autocorrelations require much more data than is available from published individual images , and will require analysis of video data . the details of the nanoscale mechanical connection between the actin filament tail and a particular bacterium or motile particle are not yet known , nor are the details of the dynamics . indeed , these details may differ for different bacteria or for different natural or reconstituted cytoplasmic environments . we present some plausible scenarios below and indicate the expected results of a curvature analysis in each . l. monocytogenes _ have a distribution of tail lengths ranging up to about @xmath89 @xmath90 @xcite , and speeds of up to @xmath91 @xmath92 @xcite . mature _ l. monocytogenes _ are roughly cylindrical gram - positive bacteria , @xmath93 @xmath90 long with a diameter of approximately @xmath94 @xcite . polar surface expression of acta is required @xcite for motility . _ l. monocytogenes _ in _ xenopus _ extract @xcite have apparent curvatures of approximately @xmath95 , corresponding to @xmath96 filaments pushing on the bacterium . while this is a relatively small number , it is consistent with electron microscopy images @xcite . the role of acta in polymerization is being uncovered @xcite but questions remain . it is not yet clear whether individual filaments are associated with individual acta molecules and if so , for how long . direct mechanical attachment is possible and indeed indicated by optical tweezer studies @xcite . indirect attachment is also possible if the complex of acta and cytoplasmic proteins serve as a source of monomeric actin with locally enhanced polymerization affinity . for example , profilin has been shown to interact with acta through vasodilator - stimulated phosphoprotein ( vasp ) @xcite and hence can provide a local `` plume '' of profilin - atp - g - actin which in some conditions can polymerize more readily than atp - g - actin @xcite . we can readily obtain the leading behavior of the steady - state concentration @xmath97 diffusing a distance @xmath98 from a disk - like source of radius @xmath2 and strength @xmath99 @xcite , @xmath100 . the diffusive plume would provide significantly enhanced polymerization only to distances on order the size @xmath2 of the acta itself . if acta is well separated on the bacterial surface , then filament nucleation and growth would be closely associated with individual acta molecules , which in turn would be held stationary by the external peptidoglycan layer of the bacterium . the proteolysis induced lifetime @xmath72 of individual acta is approximately @xmath101 hours _ in vivo _ @xcite , and would directly contribute to the curvature autocorrelation decay given by eq . [ eqn : apparentcorr ] . if there is a connection between the bacterium and its tail @xcite , then axial diffusion will be dramatically reduced and autocorrelation decay due to proteolysis should dominate and could be directly observed . however , if the bacterium is not tightly attached to its tail , then it will rotate with @xmath102 , corresponding to a timescale in eq . [ eqn : apparentcorr ] of @xmath103 , where @xmath104 is the viscous drag coefficient for axial rotation @xcite , and we take @xmath105 poise ( @xmath106 ) following @xcite . the gram - negative _ s. flexneri _ has a similar motility mechanism to _ l. monocytogenes _ @xcite ; for example , it has a unipolar surface protein required for motility , icsa . _ s. flexneri _ are about @xmath107 long and @xmath94 in diameter , and move at speeds comparable to _ l. monocytogenes _ @xcite . however , differences are observed between _ s. flexneri _ and _ l. monocytogenes_. the tails of _ s. flexneri _ appear to have fewer actin filaments than _ l. monocytogenes _ icsa is targeted to one bacterial pole in _ s. flexneri _ and may diffuse in the outer membrane @xcite , in contrast to _ l. monocytogenes _ where acta is stationary . curvature studies can help investigate these differences . for example , if fewer filaments are actually pushing the bacterium , rather than simply fewer filaments involved in cross - linking , then according to eq . [ eqn : rmsk ] , the curvature of the path of _ s. flexneri _ will be systematically larger . if actin filament tips are associated with individual icsa , then diffusion of icsa on the outer bacterial membrane will contribute a term @xmath108 where @xmath109 in eq . [ eqn : apparentcorr ] , in addition to the finite icsa lifetime due to proteolysis @xcite . unfortunately , _ s. flexneri _ are not motile in _ xenopus _ extracts @xcite , but they do have qualitatively similar curvature to _ l. monocytogenes _ in intact cells @xcite . the spotted - fever group of _ rickettsiae _ use actin - based motility for intracellular movement @xcite . while a surface protein ( rompa ) of motile _ r. rickettsii _ has been implicated in tail formation and has sequence similarity to a domain of icsa @xcite , its surface distribution and specific biochemical role have not yet been characterized . the most studied species , _ r. conorii _ @xcite and _ r. rickettsii _ @xcite , are roughly the same size as _ l. monocytogenes _ , but move only @xmath110 as fast . while _ rickettsiae _ are obligate pathogens that are not viable in _ xenopus _ extracts , the curvature of their paths in intact cells is qualitatively smaller than that of _ l. monocytogenes _ or _ s. flexneri _ @xcite . yet the tails in _ r. conorii _ are found to have very long parallel filaments , with relatively few filaments observed in cross - section electron - micrographs @xcite . it is worth considering two possibilities . the first is that the filaments are not uniformly distributed on the bacterial surface . the numeric prefactor of the curvature eq . [ eqn : rmsk ] will range from @xmath31 for polar filaments , to @xmath111 for uniform distribution on a hemisphere ( eq .  [ eqn : distrib ] ) , to @xmath112 if all filaments are along the outer edge at @xmath113 . a smaller than expected curvature can result from clustering of active filaments near the pole . however this appears to be unlikely from the electron micrographs of decorated actin tails @xcite . a second possibility is that the filaments are not randomly distributed on the bacterial surface . if the arrangement is symmetric , or regularly spaced , then the expected torque would be reduced . a paracrystalline surface structure is observed on _ rickettsiae _ bacteria @xcite , though it is unknown whether it affects polymerization dynamics . actin polymerization - based motility is exhibited by the _ vaccinia _ virus , where @xmath114 diameter oblate virus particles move at @xmath115 with tails of length @xmath116 in hela cells @xcite . one of the interesting unsolved puzzles of this system is that the virus always travels in the symmetry direction , which is the orientation of highest drag .    if filaments are localized to the viral surface by a specific protein @xcite , and if it diffuses over the viral surface , the intrinsic curvature will change with time with @xmath117 following eq .  [ eqn : torquecorr ] and @xcite , where @xmath11 is the vesicular radius and @xmath74 is the diffusion constant of the motility protein on the viral membrane . using @xmath118 , appropriate for diffusion within vesicular membranes , we have @xmath119 ! this is much less than the timescale of rotational diffusion and would dominate autocorrelation decay if present . polymerization - based motility with curved comet - tails also occurs in motile vesicle systems , which are attractive systems for systematic study since they have fluid outer layers , spherical geometry , and a variety of sizes . vesicle motion has been re - constituted in _ xenopus _ egg extracts @xcite , in endocytosed vesicles @xcite , and in extracts of nematode sperm @xcite . in some systems the vesicle lipids directly mediate actin polymerization @xcite , in which case the filaments are unlikely to be localized to particular spots on the vesicle surface . effective filament motion could still occur due to random nucleation and loss of filaments from the vesicle surface , and this is a possible mechanism of intrinsic curvature autocorrelation decay in bacterial systems as well . a simplified _ in vitro _ system using small polystyrene microspheres , coated with purified acta and added to _ xenopus lavis _ egg extract , has been shown to reconstitute actin - based motility @xcite . could different intrinsic curvatures be sampled by a single `` inert '' microsphere ? the acta has its transmembrane domain replaced by a @xmath120 his repeat , and is non - specifically bound to the carboxylated polystyrene microsphere . it may be possible for the acta to randomly crawl on the microsphere surface without detaching ( for example , see @xcite ) . allowing a small surface diffusion rate , @xmath121 , results in a decay time for correlations of @xmath122 for a @xmath94 diameter microsphere . data from curvature studies may thus may be able to demonstrate diffusion of acta on the microsphere . microspheres are also good systems for systematic studies of various radii @xmath11 with a constant surface density of acta and , presumably , actin filaments @xmath123 . in the autocorrelation decay , a finite filament lifetime would make a contribution that scales as @xmath124 , diffusion on the microsphere surface would have @xmath125 , while axial diffusion would have @xmath126 @xcite . varying the cytoplasmic viscosity , on the other hand , should only affect axial diffusion , with @xmath127 . random filament interaction with the bacterial or particle surface can explain the characteristic curved paths observed in polymerization - based motility systems , such as _ l. monocytogenes _ , _ s. flexneri _ , spotted - fever _ rickettsiae _ , _ vaccinia _ virus , and motile lipid vesicles and microspheres . we distinguish between the intrinsic curvature , which can only be measured with the full three - dimensional trajectory of the bacterium or particle , and the apparent curvature observed in microscope images . we derived explicit distributions for these curvatures and showed how they can uncover important qualitative differences between the various polymerization - based motility systems . we showed , in eq . [ eqn : apparentcorr ] , how the lifetime and dynamics of surface - associated proteins , such as acta or icsa , affects the evolution of the intrinsic curvature of the motion of individual bacteria , virus particles , vesicles , or protein - coated microspheres .    systematic experimental analysis of curvature in polymerization - based motility systems has not yet been done , but would supplement genetics , biochemistry , and microscopy by providing structural information about the interface between the actin tail and the bacterium . curvature studies could estimate the number of filaments actively pushing the bacterium , the distribution of these active filaments on the bacterial surface , their localization with respect to motility protein complexes , and surface motility protein lifetime and diffusion on the bacterial surface . a similar analysis can be done for virus , vesicle , and microsphere systems . it is useful to summarize the specific applications of this analysis . there are three . _ first _ , the relation between curvature and number of filaments in the actin tail , eqn . [ eqn : rmsk ] , can be compared with electron - microscopy cross - sections and with normalized fluorescence studies . the relation between curvature and particle size , also in eqn . [ eqn : rmsk ] , can be used for different sized particles with similar surface preparations , such as microspheres . _ second _ , the distribution of observed curvatures is predicted to be gaussian , eqn . [ eqn : ensemble ] . for particles with constant intrinsic curvatures a qualitatively distinct distribution of apparent curvatures , eqn . [ eqn : apparent ] , is expected . if three - dimensional tracking of particles in a thick sample is used , then the intrinsic distribution would apply , eqn . [ eqn : intrinsic ] . _ third _ , the variation of curvature in time is predicted to be described by an exponentially decaying autocorrelation function , eqn . [ eqn : apparentcorr ] . the timescale of autocorrelation decay , @xmath72 , characterizes how the position of active filaments in the bacterial tail change . studies of different size particles , or direct tracking of azimuthal particle rotation , could help to untangle the possible contributions to curvature autocorrelation decay . we have made simplifying assumptions to facilitate our analysis . we have assumed particular particle shapes and surface distributions of filaments . we also took the individual filament forces @xmath26 to be in the direction of particle travel . different shapes , surface distributions , and filament orientations would change the numerical prefactor in eqn . [ eqn : rmsk ] , though the curvature distributions would not be affected . we have also assumed that individual filaments are _ independently _ randomly located . non - random symmetric filament locations will result in curvatures much _ less _ than predicted in this paper . in contrast filament distributions that not symmetric will lead to qualitatively larger curvature than discussed here , where we assume a random but azimuthally symmetric distribution . we have also assumed that the viscosity does not vary strongly over bacterial length - scales . strong viscous heterogeneities , perhaps caused by particle motion itself , as well as local constraints posed by cellular organelles and membranes , will affect particle trajectories . this could dominate the effects described here _ in vivo_.    this work was supported financially by the natural sciences and engineering research council of canada , _ le fonds pour la formation de chercheurs et laide  la recherche du qubec _ , and by the canadian institute of advanced research program in the science of soft surfaces and interfaces . we would like to thank lisa cameron , julie theriot , and bob heinzen for discussions , and sarah keller and jennifer robbins for critical readings of earlier versions of the manuscript . j. a. theriot , annu . . biol . * 11 * , 213 ( 1995 ) . s. dramsi and p. cossart , annu . * 14 * , 137 ( 1998 ) . r. a. heinzen _ et al . _ , infect . immun . * 67 * , 4201 ( 1999 ) . s. cudmore _ et al . _ , nature * 378 * , 636 ( 1995 ) . l. m. machesky , nature cell biol . * 1 * , e29 ( 1999 ) . et al . _ , nature * 401 * , 613 ( 1999 ) . b. alberts _ et al . _ , _ molecular biology of the cell , third edition _ , ( garland publishing , new york , 1994 ) . a. mogilner and g. oster , biophys . j. * 71 * , 3030 ( 1996 ) . f. gerbal _ _ , pramana -j . phys . * 53 * , 155 ( 1999 ) ; f. gerbal _ et al . _ , j. * 79 * , 2259 ( 2000 ) . c. kocks _ et al . _ , cell * 68 * , 521 ( 1992 ) . g. a. smith , d.a . portnoy , and j.a . theriot , mol . microbiol . * 17 * , 945 ( 1995 ) .      m. b. goldberg _ et al . _ , j. bacteriol . * 175 * , 2189 ( 1993 ) . m. b. goldberg and j.a . theriot , proc . usa * 92 * , 6572 ( 1995 ) . r. a. heinzen _ et al . _ , infect . immun . * 61 * , 1926 ( 1993 ) . f. frischknecht _ et al . _ , nature * 401 * , 926 ( 1999 ) . c. kocks _ et al . _ , mol . micro . * 18 * , 413 ( 1995 ) . l. a. cameron _ et al . _ , usa * 96 * , 4908 ( 1999 ) . c. j. merrifield _ et al . _ , nature cell bio . * 1 * , 72 ( 1999 ) . j. e. italiano jr _ et al . _ , cell * 84 * , 105 ( 1996 ) . _ , j. cell . biol . * 140 * , 1125 ( 1998 ) . a. l. rozelle , _ et al . _ , curr . biol . * 10 * , 311 ( 2000 ) . j. a. theriot _ _ , nature * 357 * , 257 ( 1992 ) . f. perrin , j. de physique et le radium * 5 * , 497 ( 1934 ) . k. luby - phelps _ et al . _ , biophys . j. * 65 * , 236 ( 1993 ) . a. r. bausch , w. mller , and e. sackmann . j. * 76 * , 573 ( 1999 ) . l. g. tilney , d.j . derosier , and m.s . tilney , j. cell . biol . * 118 * , 71 ( 1992 ) . k. kroy and e. frey , phys . * 77 * , 306 ( 1996 ) . f. c. mackintosh , j. ks , and p. a. janmey , phys . lett . * 75 * , 4425 ( 1995 ) . berg , h. , _ random walks in biology , second ed . _ ( princeton university press , princeton , 1993 ) . et al . _ , sci . * 112 * , 1697 ( 1999 ) . d. e. koppel , biophys . j. * 47 * , 337 ( 1985 ) . l. m. machesky and k. l. gould , curr . cell biol . * 11 * , 117 ( 1999 ) . i. pagonabarraga _ e * 59 * , 4458 ( 1999 ) ; a. v. zvelindovsky and a. v. zatovsky , nuovo cimento * 19d * , 725 ( 1997 ) . r. thar , n. blackburn , and m. khl , appl . . microbiol . * 66 * , 2238 ( 2000 ) ; p. d. frymier _ et al . _ , usa * 92 * , 6195 ( 1995 ) . j. a. theriot _ _ , cell * 76 * , 505 ( 1994 ) . m. d. welch _ at al . _ , science * 281 * , 105 ( 1998 ) . d. pantaloni and m.f . carlier , cell * 75 * , 1007 ( 1993 ) . j. crank , _ the mathematics of diffusion , second edition _ , ( oxford university press , oxford , 1975 ) . m. a. moors , v. auerbach , and d.a . portnoy , cellular microbiology * 1 * , 249 ( 1999 ) . m. l. bernardini _ et al . _ , usa * 86 * , 3867 ( 1989 ) . w. l. zeile , d.l . purich , and f.s . southwick , j. cell . biol . * 133 * , 49 ( 1996 ) . j. steinhauer _ . microbiol . * 32 * , 367 ( 1999 ) . m. charles _ et al . _ , j. bacteriol . * 181 * , 869 ( 1999 ) . e. l. palmer _ et al . _ , j. bacteriol . * 118 * , 1158 ( 1974 ) ; s. f. hayes and w. burgdorfer , infect . * 37 * , 779 ( 1982 ) . e. j. jervis , c.a . haynes , and d.g . kilburn , j. biol . chem . * 272 * , 24016 ( 1997 ) .", "tags": [], "output_text_a": "This paper explores the mechanisms of actin polymerization-based motility in intracellular pathogens such as _L. monocytogenes_, _S. flexneri_, spotted fever group _Rickettsiae_, and the _Vaccinia_ virus. These pathogens move by forming actin \"comet-tails\" that propel them through the host cell's cytoplasm. The study focuses on understanding the curvature of the paths these bacteria take, which is influenced by the random placement of actin filaments pushing against them. The curvature provides insights into the number of active filaments, their lifetime, and surface diffusion rates. The paper proposes that the curvature results from the random location of actin filaments and can be used to predict static and dynamic structures at the bacterial surface. The study also discusses the implications of these findings for understanding the motility mechanisms of different pathogens and suggests that systematic experimental analysis of curvature could provide valuable structural information about the interface between the actin tail and the bacterium. The research highlights the potential for curvature studies to estimate the number of filaments actively pushing the bacterium, their distribution, and the dynamics of surface-associated proteins, which could enhance our understanding of polymerization-based motility systems.", "output_text_b": "Intracellular pathogens, such as L. monocytogenes, S. flexneri, the spotted fever group of Rickettsiae, and the Vaccinia virus, move through the cell by polymerizing actin into comet-like tails. The force generated by actin polymerization propels the pathogen forward, and the necessary bacterial contribution is a single surface protein that orchestrates cellular cytoplasmic proteins to locally promote the nucleation, elongation, and cross-linking of actin filaments. The curvature of the path taken by the pathogen is determined by the number of active filaments pushing against it and the location of these filaments with respect to the bacterial surface. The radius of curvature is inversely proportional to the curvature and directly probes the ratio of force and torque applied to the bacterium.\n\nThe paper proposes that the curvature of the bacterial path can be used to predict static and dynamic structures at the bacterial surface. The average curvature is determined by the number of active filaments pushing the bacterium, while information about filament lifetime and surface diffusion rates may be obtained from curvature autocorrelations. If filaments are closely localized to specific bacterial surface proteins, then lifetimes and diffusivities of those proteins can be inferred.\n\nThe paper focuses on the most common experimental geometry of a thin quasi-two-dimensional system constrained between a glass slide and cover slip, and discusses the apparent curvature appropriate to video microscopy. The curvature is defined as the rate of rotation of direction or the rotation per unit path length, where the polar angle is measured in the current plane of motion and distance is measured along the particle path.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by discussing the mechanisms of actin polymerization-based motility and the role of actin filament curvature in understanding bacterial movement.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the curvature of bacterial paths due to actin filament placement.\n4. **Methodology**: The summary mentions the approach of analyzing the curvature of paths to gain insights into actin filament dynamics.\n5. **Significant Results**: The summary includes significant results, such as the relationship between curvature and filament dynamics.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"actin comet-tails.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not explicitly mention key experiments or data used in the research.\n10. **Significance**: The summary reflects the paper's significance by discussing the potential impact of curvature studies on understanding motility systems.", "1. **Accurate Reflection**: The summary captures the main findings and contributions of the paper, such as the movement of intracellular pathogens through actin polymerization and the role of surface proteins.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the curvature of the bacterial path and its implications.\n4. **Methodology**: The summary mentions the approach of using curvature to predict structures at the bacterial surface.\n5. **Significant Results**: The summary includes significant results, such as the relationship between curvature and the number of active filaments.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"curvature\" and \"actin polymerization.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not mention specific experiments or data used in the research.\n10. **Significance**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "our attitudes and opinions have a reciprocal relationship with those around us : who we know depends on what we have in common , while simultaneously our beliefs influence , and are influenced by , those of our peers . these two mechanisms  homophily and social influence  underpin a wide range of social phenomena , including the diffusion of innovations @xcite , complex contagions @xcite , collective action @xcite , opinion dynamics @xcite and the emergence of social norms @xcite . thus homophily and social influence represent the atomistic ingredients for models of social dynamics @xcite . starting with these basic elements , we investigate a new type of modelling framework intended to describe the coevolution of sub - conscious attitudinal states and social tie strengths in a population of interacting agents . the first ingredient in our modelling framework , homophily , relates the similarity of individuals to their frequency of interaction @xcite . thus homophily is structural , affecting the strength of ties between people and hence the underlying social network . homophily has been observed over a broad range of sociodemographics : implicit characteristics , such as age , gender and race ; acquired characteristics , such as education , religion and occupation ; and internal states that govern attitudes and behaviour @xcite . homophily inextricably links state dynamics with the evolution of social tie strength , and consequently a faithful model must be coevolutionary , connecting both the dynamics _ of _ the social network and the dynamics _ on _ the social network @xcite . such network models are known as _ coevolving _ or _ adaptive _ ; see @xcite for a review . there has been a recent surge of interest in coevolving networks , particularly models of opinion dynamics @xcite , which build on simple models of voting behaviour . the second ingredient is social influence , which affects people s attitudinal state through typically dyadic interactions . it is a fundamental result of social psychology that people tend to modify their behaviour and attitudes in response to the opinions of others @xcite , sometimes even when this conflicts sharply with what they know to be true @xcite or believe to be morally justifiable @xcite . similarly to flache and macy @xcite , we use diffusion to model social influence : agents adjust their state according to a weighted sum of the differences between their state and their neighbours. the weights , which represent the strength of influence between pairs of agents , are the corresponding elements of the undirected ( dynamic ) social network , whose evolution is driven by homophily . although our model is built on the notions of homophily and social influence described above , we point out that differentiating between the effects of these processes , particularly in observational settings , may be very difficult @xcite . social scientists have developed ` agent - based ' models that incorporate homophily and social influence in order to examine a variety of social - phenomena , including group stability @xcite , social differentiation @xcite and cultural dissemination @xcite , where a culture is defined as an attribute that is subject to social influence . in such models , an agent s state is typically described by a vector of discrete cultures and the more similar ( according to some metric ) two agent s states are , the higher the probability of dyadic interactions between them ( homophily ) in which one agent replicates certain attributes of the other ( social influence ) . surprisingly , the feedback between homophily and social influence does not necessarily lead to a global monoculture @xcite . in fact , the dissolution of ties between culturally distinct groups , or equivalently the creation of ` structural holes ' @xcite , may lead to _ cultural polarisation_equilibrium states that preserve diversity . however , such multi - cultural states are not necessarily stable when there is ` cultural drift ' , i.e. small , random perturbations or noise , which inevitably drive the system towards monoculture @xcite . there have been a number of attempts to develop models with polarised states that are stable in the presence cultural drift @xcite , but this is still an open area of research @xcite . two key features differentiate our approach from those described above . firstly , we specifically focus on _ sub - conscious _ attitude formation driven by a general class of activator - inhibitor processes . this is motivated by neuropsychological evidence that the activation of emotional responses are associated with the ( evolutionarily older ) regions of the brain know as the limbic system and our inhibitions are regulated by the ( evolutionarily younger ) prefrontal cortex @xcite . this has led psychologists to develop theories in which various personality traits ( such as extraversion , impulsivity , neuroticism and anxiety ) form an independent set of dimensions along which different types of behaviour may be excited or regulated @xcite . thus it is natural in our modelling framework for these processes to be communicated independently and in parallel through distinct transmission channels and hence via distinct diffusion coefficients . the consequence of activator - inhibitor attitudinal state dynamics is that we would expect to encounter turing instability , since the rates at which social influence can change homophilious attributes may differ dramatically . secondly , and in sharp contrast to recent models of cultural dissemination @xcite and indeed many other types of behavioural model @xcite that are stochastic or probabilistic , we consider a _ , continuous - time dynamical systems formulation . while this does not reflect the mercurial nature seemingly ingrained in human interaction , it allows us to probe the underlying mechanisms driving dynamical phenomena . in fact , our principle observation is that the tension between turing instability and the coevolution of the social network and attitudinal states gives rise to aperiodic dynamics that are sensitive to initial conditions and surprisingly unpredictable . this begs the question , are the mechanisms that govern our behaviour the cause of its volatility ? for parsimony , we also consider systems of homogeneous agents . this allows us to identify parameters that destabilise the global monocultural steady state , giving rise to transient sub - group formation . this paper is organised as follows : in section  [ sec : model ] , we describe our model in detail , analyse the stability of global monoculture and describe the underlying dynamical mechanisms ; in section  [ sec : examples ] we illustrate typical numerical results from both a large population of individuals and a simple example consisting of just two agents ; in section  [ sec : conclusion ] we summarise our work and finally in section  [ sec : discussion ] we discuss our results in the context of other models of cultural dynamics and polarisation phenomena . consider a population of @xmath0 identical individuals ( agents / actors ) , each described by a set of @xmath1 real attitude state variables that are continuous functions of time @xmath2 . let @xmath3 denote the @xmath4th individual s attitudinal state . in the absence of any influence or communication between agents we assume that each individual s state obeys an autonomous rate equation of the form @xmath5 where @xmath6 is a given smooth field over @xmath7 , such that @xmath8 for some @xmath9 . thus ( [ one ] ) has a uniform population equilibrium @xmath10 , for @xmath11 , which we shall assume is locally asymptotically stable . as discussed in the introduction , we shall more specifically assume that ( [ one ] ) is drawn from a class of activator - inhibitor systems . now suppose that the individuals are connected up by a dynamically evolving weighted network . let @xmath12 denote the @xmath13 weighted adjacency matrix for this network at time @xmath2 , with the @xmath14th term , @xmath15 , representing the instantaneous weight ( frequency and/or tie strength ) of the mutual influence between individual @xmath4 and individual @xmath16 at time @xmath2 . throughout we assert that @xmath12 is symmetric , contains values bounded in [ 0,1 ] and has a zero diagonal ( no self influence ) . we extend ( [ one ] ) and adopt a first order model for the coupled system : @xmath17 here @xmath18 is a real , diagonal and non - negative matrix containing the maximal transmission coefficients ( diffusion rates ) for the corresponding attitudinal variables between neighbours . thus some of the attitude variables may be more easily or readily transmitted , and are therefore influenced to a greater extent by ( while simultaneously being more influential to ) those of neighbours . note that @xmath10 , for @xmath11 , is also a uniform population equilibrium of the augmented system . let @xmath19 denote the @xmath20 matrix with @xmath4th column given by @xmath21 , and @xmath22 be the @xmath20 matrix with @xmath4th column given by @xmath23 . then ( [ two ] ) may be written as @xmath24 here @xmath25 denotes the weighted graph laplacian for @xmath12 , given by @xmath26 , where @xmath27 is a vector containing the degrees of the vertices ( @xmath28 ) . equation  ( [ eq : xmat ] ) has a rest point at @xmath29 , where the @xmath4th column of @xmath30 is given by @xmath9 for all @xmath11 .    to close the system , consider the evolution equation for @xmath12 given by @xmath31 here @xmath32 denotes the adjacency matrix of the fully weighted connected graph ( with all off - diagonal elements equal to one and all diagonal elements equal to zero ) ; @xmath33 denotes the element - wise ` hadamard ' matrix product ; @xmath34 is a rate parameter ; @xmath35 is a homophily scale parameter ; and @xmath36 is a symmetric matrix function that incorporates homophily effects . we assume @xmath37 to be of the form @xmath38 , where @xmath39 is an appropriate norm or semi - norm , and the real function @xmath40 is monotonically increasing with @xmath41 . note that the sign of the differences held in @xmath42 controls the growth or decay of the corresponding coupling strengths . all matrices in ( [ eq : a ] ) are symmetric , so in practice we need only calculate the super - diagonal terms . for the @xmath14th edge , from ( [ eq : a ] ) , we have @xmath43 the nonlinear  logistic growth \"- like term implies that the weights remain in [ 0,1 ] , while we refer to the term @xmath44 as the _ switch _ term .      by construction , there are equilibria at @xmath29 with either @xmath45 or @xmath46 . to understand their stability , let us assume that @xmath47 so that @xmath12 evolves very slowly . we may then consider the stability of the uniform population , @xmath30 , under the fast dynamic ( [ eq : xmat ] ) for any fixed network @xmath48 . assuming that @xmath48 is constant , writing @xmath49 and linearising ( [ eq : xmat ] ) about @xmath30 , we obtain @xmath50 here @xmath51 is an @xmath52 matrix given by the linearisation of @xmath53 at @xmath9 . letting @xmath54 , be the eigen - pairs of @xmath55 , then we may decompose uniquely @xcite : @xmath56 where each @xmath57 . the stability analysis of ( [ thic ] ) is now trivial since decomposition yields @xmath58 thus the uniform equilibrium , @xmath30 , is asymptotically stable if and only if all @xmath0 matrices , @xmath59 , are simultaneously stability matrices ; and conversely is unstable in the @xmath4th mode of the graph laplacian if @xmath59 has an eigenvalue with positive real part . consider the spectrum of @xmath60 as a function of @xmath61 . if @xmath61 is small then this is dominated by the stability of the autonomous system , @xmath62 , which we assumed to be stable . if @xmath61 is large then this is again a stability matrix , since @xmath18 is positive definite . the situation , dependent on some collusion between choices of @xmath18 and @xmath51 , where there is a _ window of instability _ for an intermediate range of @xmath61 , is know as a turing instability . turing instabilities occur in a number of mathematical applications and are tied to the use of activator - inhibitor systems ( in the state space equations , such as ( [ one ] ) here ) , where inhibitions diffuse faster than activational variables . now we can see the possible tension between homophily and turing instability in the attitude dynamics when the timescale of the evolving network , @xmath63 , is comparable to the changes in agents states . there are two distinct types of dynamical behaviour at work . in one case , @xmath25 has presently no eigenvalues within the window of instability and each individual s states @xmath21 approach the mutual equilibrium , @xmath9 ; consequently all switch terms become positive and the edge weights all grow towards unity , i.e. the fully weighted clique . in the alternative case , unstable eigen - modes cause the individual states to diverge from @xmath9 , and subsequently some of the corresponding switch terms become negative , causing those edges to begin losing weight and hence partitioning the network . the eigenvalues of the laplacian for the fully weighed clique , @xmath64 , are at zero ( simple ) and at @xmath0 ( with multiplicity @xmath65 ) . so the interesting case is where the system parameters are such that @xmath66 lies within the window of instability . then the steady state @xmath67 is unstable and thus state variable patterns will form , echoing the structure of ( one or many of ) the corresponding eigen - mode(s ) . this turing driven symmetry loss may be exacerbated by the switch terms ( depending upon the choice of @xmath68 being small enough ) , and then each sub - network will remain relatively well intra - connected , while becoming less well connected to the other sub - networks . once relatively isolated , individuals within each of these sub - networks may evolve back towards the global equilibrium at @xmath9 , providing that @xmath12 is such that the eigenvalues of @xmath55 have by that time left the window of instability . within such a less weightily connected network , all states will approach @xmath9 , the switch terms will become positive , and then the whole qualitative cycle can begin again . thus we expect aperiodic or pseudo - cyclic emergence and diminution of patterns , representing transient variations in attitudes in the form of different _ norms _ adopted by distinct sub - populations . as we shall see though , the trajectory of any individual may be sensitive and therefore effectively unpredictable , while the dynamics of the global behaviour is qualitatively predictable .    in the next section we introduce a specific case of the more general setting described here . we wish to consider activator - inhibitor systems as candidates for the attitudinal dynamics in ( [ one ] ) and hence ( [ eq : xmat ] ) . the simplest such system has @xmath69 , with a single inhibitory variable , @xmath70 , and a single activational variable , @xmath71 . let @xmath72 in ( [ two ] ) , and consider the scnackenberg dynamics defined by the field @xmath73 where @xmath74 are constants . the equations have the required equilibrium point at @xmath75 and in order that @xmath76 be a stability matrix , we must have @xmath77 we employ @xmath78 as the homophily function and we must have @xmath79 in ( [ eq : xmat ] ) .    when @xmath69 , the presence of turing instability depends on the sign of the determinant of @xmath80 , which is quadratic in @xmath61 . for the schnakenberg dynamics defined above , the roots of this quadratic are given by @xmath81 ^ 2   -   4\\frac{d_2}{d_1 }   ( p+q)^4 }    } { 2 d_2   ( p+q ) }        > 0.\\ ] ] it is straightforward to show that if @xmath82 then @xmath83 are real positive roots and hence @xmath84 is a stability matrix if and only if @xmath61 lies outside of the interval @xmath85 , the _ window of instability_. inside there is always one positive and one negative eigenvalue , and the equilibrium @xmath30 is unstable for any fixed network @xmath48 . note that , as is well known , it is the _ ratio _ of the diffusion constants that determines whether there is a window of instability . we now present simulations of the schnakenberg dynamics with @xmath86 . parameter values are @xmath87 , @xmath88 , @xmath89 , @xmath90 , @xmath91 and @xmath92 . the ratio of the diffusion constants is @xmath93 , and to ensure that the window of instability is centred on the fully coupled system we have @xmath94 the initial coupling strengths were chosen uniformly at random between 0.1 and 0.5 . the initial values of @xmath95 and @xmath96 were chosen at equally spaced intervals on a circle of radius @xmath97 centred on the uniform equilibrium .    in figure [ fig : dua ] we illustrate the trajectories of @xmath98 and the corresponding coupling strengths @xmath99 up to @xmath100 .     and @xmath99 for all @xmath101 pairs for unstable parameters integrated until @xmath100 . parameter values and initial conditions are described in the main text . in the light grey shaded region , @xmath102 and the direction of trajectories are indicated with arrows . the grey horizontal line indicates the scaled stability threshold ( unstable above , stable below ) . [ fig : dua],scaledwidth=55.0% ]    the shaded region corresponds to @xmath102 , within which the @xmath99 increase and outside of which they decrease , indicated by the dark grey arrows . the horizontal grey line marks the scaled instability threshold @xmath103 , which is indicative of the boundary of instability , above being unstable and below being stable . because agents are only weakly coupled initially , their attitudes move towards the steady state @xmath9 , which causes the differences @xmath104 to decrease . the switch terms subsequently become positive and hence the coupling strengths increase , along with the eigenvalues of the laplacian @xmath105 . when one or more of the @xmath105 are within the window of instability , some of the differences @xmath104 begin to diverge . however , this eventually causes their switch terms to become negative , reducing the corresponding coupling strengths and hence some of the @xmath105 . this then affects the differences @xmath104 , which start to decrease , completing the qualitative cycle . as the system evolves beyond @xmath106 , this quasi - cyclic behaviour becomes increasingly erratic . although the long term behaviour of any given agent is unpredictable , the behaviour of the mean coupling strength of the system fluctuates around the instability boundary @xmath107 . in figure [ fig : network](a ) , we plot the time series of the mean coupling strength , @xmath108 , between @xmath109 and @xmath110 .    , time series . panels ( b)(g ) : network snapshots at sequential time intervals . node positions are plotted in the rotated coordinates @xmath111 , shading illustrates coupling strength for edges and mean coupling strength for nodes . [ fig : network],scaledwidth=79.0% ]    the dashed line indicates the instability boundary @xmath112 , which is very close to the time - averaged mean coupling strength @xmath113 . also plotted in figure  [ fig : network ] are snapshots of the network at six sequential times . to improve the visualisation of the network , the positions of nodes have been rotated by approximately @xmath114 , since the differences in diffusion rates mean that the unrotated coordinates , @xmath115 , become contracted in one direction . the shading of the nodes corresponds to their average coupling strength and the shading of the edges correspond to their weight . the sequence of figures illustrate the general scenario : agents trajectories cycle around the origin with the network repeatedly contracting and expanding as agents become more and less similar in attitude respectively . we now illustrate how the quasi - equilibrium end state changes as the window of instability is moved . we fix all parameters as above , but consider a range of values of @xmath116 whilst keeping the ratio @xmath117 held fixed . this has the effect of shifting the window of instability from above @xmath118 to below as @xmath116 increases . we integrate until @xmath119 and then compute the mean coupling strength @xmath120 for @xmath121 . we compute 50 realisations for each set of parameters , the results of which are plotted in figure  [ fig : bif ] .    . shading indicates the window of instability , the dashed grey line indicates where @xmath46 . the black line is the median of 50 realisations and the black markers are the mean coupling strengths for each of the realisations . [ fig : bif],scaledwidth=55.0% ]    the shaded region corresponds to the ( scaled ) region of instability , the dashed grey line is where @xmath118 , the black line is the median of the fifty realisations and the dots are the values from each of the realisations . at low values of @xmath116 , where the @xmath64 equilibrium first becomes unstable , the mean coupling strength fits tightly to the lower edge of the instability boundary at @xmath122 . when the @xmath46 equilibrium restabilises ( at @xmath123 ) , the long time behaviour of the mean coupling strength changes , moving away from the @xmath122 boundary . in the region between @xmath124 and @xmath125 , some realisations return to the fully coupled equilibrium @xmath46 , but not all . we would expect that simulating for longer would result in more realisations reaching the fully coupled equilibrium , although it is possible that its basin of attraction does not include every initial condition in the set that we are sampling from .      to probe the mechanism driving the aperiodic dynamics illustrated in section  [ sec : group ] , we consider a simpler dynamical setting consisting of just two agents . this reduces the coupling strength evolution ( [ eq : a ] ) to a single equation , and hence five equations in total , @xmath126.\\label{eq : dyada}\\end{aligned}\\ ] ]    in figure  [ fig : chaos ] , we plot the trajectories for each of the two agents ( black and grey lines ) in @xmath115 space , and in @xmath127 space in the upper - right inset . space with unstable parameters . upper - right inset : trajectories in @xmath127 space . lower - left inset : zoom of boxed region in the main plot . parameters described in the main text . [ fig : chaos],scaledwidth=99.0% ]    the parameter values are @xmath87 , @xmath88 , @xmath89 , @xmath90 , @xmath128 and @xmath129 . again , the diffusion constants have the ratio @xmath117 and the window of instability is centred on the fully coupled system via ( [ eq : centre ] ) . the initial conditions are chosen near to the uniform equilibrium @xmath130 , specifically @xmath131 , @xmath132 , @xmath133 , @xmath134 ; the initial coupling strength is @xmath135 . this system is numerically stiff  on each cycle , trajectories get very close to the equilibrium @xmath9 and the invariant planes @xmath136 and @xmath137thus very low error tolerances are necessary in order to accurately resolve the trajectories . the mechanisms driving the near cyclic behaviour illustrated in figure  [ fig : chaos ] are qualitatively similar to those described in section  [ sec : stability ] , but the present case is much simpler since the coupling constant , @xmath138 , is a scalar . if we consider @xmath138 as a parameter in the attitudinal dynamics ( [ eq : dyadx1][eq : dyady2 ] ) , then a turing instability occurs as a pitchfork bifurcation at some @xmath139 , where @xmath140 . the equilibria at @xmath141 and @xmath142 are both saddle - foci , where the unstable manifolds are respectively parallel to the @xmath138-axis and entirely within the attitudinal state space , @xmath143 . near to the @xmath142 equilibrium , a given trajectory tracks the unstable manifold of @xmath142 in one of two opposing directions , the choice of which is sensitively dependent on its earlier position when @xmath144 . the combination of this sensitivity together with the spiral dynamics around the unstable manifold of @xmath145 , leads to an orbit switching sides unpredictably on each near - pass of @xmath142 ( c.f . the top - right inset of figure  [ fig : chaos ] ) . the mechanism by which this chaotic behaviour arises is not standard ( e.g. via a shilnikov bifurcation or homoclinic explosion ) and warrants its own study , which we address in an article currently in preparation . we have proposed a new modelling framework to describe the evolution of sub - conscious attitudes within social groups . we based this framework on the fundamental mechanisms of homophily and social influence , but it differs from previous approaches in two respects . firstly , we have focused on sub - conscious attitudes , where it is natural to consider dynamics described by a class of activator - inhibitor processes . secondly , we have formulated a deterministic system , enabling us to highlight ( via mathematical analysis and simulation ) the mechanisms driving dynamical phenomena . specifically , we have illustrated that the tension between turing instability and the evolving network topology gives rise to behaviour that at the system level is qualitatively predictable  sub - group formation and dissolution  yet at the level of individual agent journeys is entirely unpredictable . we point out that a stochastic model based on similar principles to those described in this paper is presented in @xcite , where qualitatively similar dynamical phenomena are also observed . thus we might conclude that even if stochasticity is entirely absent , the mechanisms that govern human behaviour seem to give rise to unpredictable dynamics . while we have differentiated our modelling framework from other models of attitudinal dynamics @xcite , we now discuss our findings in the context of more general cultural models and cultural polarisation . current interest in cultural models largely stems from the work of axelrod @xcite , who demonstrated that local convergence could lead to cultural polarisation . this topic has particular resonance in our digital society : will global connectivity accelerate a descent into monoculture , or can diversity persist ? models such as axelrod s provide us with an optimistic outlook , suggesting that even the most basic mechanisms that model social influence and homophily can lead to cultural diversity . but by no means is there presently a completely satisfactory understanding of this phenomena . the polarised states of the axelrod model are fragile ; even low rates of random perturbations to cultural traits can reinstate global monoculture @xcite . thus additional dynamical rules have been investigated in this context . the variant of the axelrod model proposed by centola et al . @xcite allows agents to disassociate themselves from neighbours that have no similar traits and select a new neighbour at random . similarly , a number of adaptive network models of opinion dynamics have also found absorbing polarised states , in which groups with differing opinions are completely disconnected @xcite . such polarised states seem artificial and we conjecture that a form of cultural drift , characterised by random rewiring of a small number of edges , would destabilise these states . this touches on another key issue : in the absence of noise , the mechanisms employed by cultural dissemination models typically _ reduce _ diversity . it is not surprising then that these types of models can be perturbed in such a way that the eventual result is monoculture . an approach that allows diversity to increase has been suggested by flache and macy @xcite . they model social influence via diffusion , whereby an agent adjusts their cultural state , described by a vector of continuous real variables , according to a weighted sum of the differences between their state and their neighbours. the weights are dynamic and their evolution is driven by homophily . in some sense , the corresponding elements of our model are like a continuous - time version of the flache and macy model . however , flache and macy consider the weights embedded on a clustered network and , more importantly , allow their weights to be negative , representing _ xenophobia_. it is this feature that allows diversity to both decrease and increase via diffusion and convergence respectively . the effects of cultural drift on polarised states in the flache and macy model have not been investigated in detail , but perturbations can cause agents to switch groups @xcite and so we would expect that sustained noise would erode smaller groups . monoculture is also a stable fixed point of their model . the key element that differentiates our model is that agents cultural states have an activator - inhibitor dynamic that is independent of other agents . the presence of diffusion allows for turing instability and hence means that diversity can increase . moreover , we can identify regions in which global monoculture is _ unstable_. for fixed or slowly evolving networks , instability gives rise to stable ` turing patterns ' @xcite , which could be interpreted as culturally polarised states . however , one would expect inter - group connections to be weaker than intra - group connections within polarised states . but if homophily dissolves such inter - group ties then the patterned or polarised states can no longer be stable , since it is precisely the differences in culture that balance individuals attitudinal dynamics with diffusion . if non - trivial stable equilibria were to exist in our model , they would involve a delicate balance of cultural differences within the switching terms . however , we have seen no evidence of this occurring in numerical simulations . thus in its present form , sub - group formation and polarisation are transient phenomena in our model . it is possible however that extensions to our model could produce stable polarised states . for example , introducing agent heterogeneity , in the form of distinct uncoupled equilibria , offers some promise . agents could then adopt a state close to their uncoupled equilibrium , allowing distinct groups to form , but turing instability could still destabilise the monocultural equilibrium . alternatively , the network evolution equations could include higher order effects such as edge snapping @xcite or triangulation . these ideas will be investigated further in follow - up work and we hope that our model may provide a new paradigm from which to explore cultural polarisation phenomena . jaw and pg acknowledge the epsrc for support through molten ( ep / i016058/1 ) . we would like to thank jon dawes , michael macy and those at the centre for mathematics of human behaviour for their valuable input , discussion and comments . 48 natexlab#1#1[2]#2 , , ( ) . , , ( ) . , , , , , ( ) . , , , ( ) . , , , , ( ) . , , , ( ) . , , , , ( ) . , , , ( ) . , , ( ) . , , , ( ) . , , , ( ) . , , , ( ) . , , , ( ) . , , , , , ( ) . , , , ( ) . , , , ( ) . , , , ( ) . , , ( ) . , , , , , ( ) . , , , , , , , , , ( ) . , , , ( ) . , , , , ( ) . , , , , ( ) . , , , , ( ) . , , , , , . , , , , , ( ) . , , , ( ) . , , in : , , , . , , , , , . , , in : , , , . , , , ( ) . , , , , ( ) . , , , ( ) . , , , , , in : , , , . , , , , , ( ) . , , , , ( ) . , , , ( ) . , , , , . , , , , edition , . , , , ( ) . , , , . , , , , , ( ) .", "tags": [], "output_text_a": "This paper explores a new modeling framework to describe the coevolution of subconscious attitudinal states and social tie strengths in a population of interacting agents. The framework is based on two fundamental social mechanisms: homophily, which relates the similarity of individuals to their frequency of interaction, and social influence, which affects people's attitudinal states through interactions. The model incorporates activator-inhibitor processes to simulate subconscious attitude formation, motivated by neuropsychological evidence. Unlike previous models, this approach uses a continuous-time dynamical systems formulation, allowing for the analysis of underlying mechanisms driving social dynamics.\n\nThe study finds that the tension between Turing instability and the coevolution of social networks and attitudinal states leads to aperiodic dynamics that are sensitive to initial conditions and unpredictable at the individual level, yet qualitatively predictable at the system level. The model demonstrates that sub-group formation and dissolution are transient phenomena, with the potential for cultural diversity to increase due to Turing instability. The paper suggests that extensions to the model, such as introducing agent heterogeneity or higher-order network effects, could lead to stable polarized states, providing a new paradigm for exploring cultural polarization phenomena.\n\nThe research highlights the complex interplay between homophily, social influence, and subconscious attitude dynamics, offering insights into the mechanisms that govern social behavior and cultural diversity. The findings have implications for understanding how global connectivity might influence cultural convergence or diversity in digital societies.", "output_text_b": "This article presents a modelling framework for the coevolution of sub-conscious attitudinal states and social tie strengths in a population of interacting agents. The authors propose a framework that combines homophily and social influence, where homophily relates the similarity of individuals to their frequency of interaction, and social influence affects people's attitudinal state through typically dyadic interactions. The model is built on the notions of homophily and social influence, and the authors highlight the challenges in differentiating the effects of these processes in observational settings.\n\nThe paper discusses the interplay between homophily and social influence in shaping various social phenomena, such as the diffusion of innovations, complex contagions, collective action, opinion dynamics, and the emergence of social norms. The authors also mention the challenges in capturing the coevolution of social networks and attitudinal states in a faithful model.\n\nThe article highlights the importance of considering the coevolution of social networks and attitudinal states, as homophily and social influence are intertwined and affect each other. The authors also emphasize the need for coevolutionary models that connect the dynamics of the social network and the dynamics on the social network.", "score": 0.5, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the new modeling framework, the role of homophily and social influence, and the implications for cultural diversity and polarization.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the coevolution of subconscious attitudinal states and social tie strengths.\n4. The methodology, including the use of activator-inhibitor processes and continuous-time dynamical systems, is mentioned.\n5. Significant results, such as the impact of Turing instability and the potential for cultural diversity, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Turing instability\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data used in the research, which is a requirement.\n10. The potential impact of the research in understanding cultural convergence or diversity is mentioned, reflecting the paper's significance.", "1. **Accurate Reflection**: The summary captures the main focus of the paper, which is the modeling framework for the coevolution of sub-conscious attitudinal states and social tie strengths. However, it does not mention the specific findings or contributions, such as the tension between Turing instability and network evolution leading to aperiodic dynamics.\n   \n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem**: The summary does not explicitly state the research problem or question addressed by the paper, which is understanding the coevolution of social networks and attitudinal states.\n\n4. **Methodology**: The summary mentions the use of homophily and social influence but does not detail the specific methodology or approach, such as the use of activator-inhibitor processes and continuous-time dynamical systems.\n\n5. **Significant Results**: The summary lacks mention of significant results or conclusions, such as the unpredictability of individual agent dynamics and the potential for transient sub-group formation.\n\n6. **Language**: The language is clear and professional.\n\n7. **Technical Jargon**: The summary avoids technical jargon and does not explain terms like \"Turing instability\" or \"activator-inhibitor processes,\" which are central to the paper.\n\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n\n9. **Experiments/Data**: The summary does not mention any key experiments or data used in the research.\n\n10. **Significance/Impact**: The summary does not reflect the paper's significance or potential impact, such as its implications for understanding cultural polarization and social dynamics."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the _ fermi gamma - ray space telescope ( fermi ) _ has revolutionized our understanding of the high - energy universe . in particular , gamma - ray emitting pulsar is a major population discovered with the large area telescope ( lat ) onboard _ fermi_. in the second lat pulsar catalog , there are 117 gamma - ray pulsars for which 43 of them are millisecond pulsars ( msps ; abdo et al . 2013 ; ray et al . msps are of particular interest because they represent an important stage for the evolution of compact stars . in recent radio surveys of _ fermi_-observed msps , @xmath1% them are found in binary systems ( see abdo et al . 2013 for references ) and some of the binary systems have a tight orbit ( @xmath2 hours ) . based on the radio and optical lightcurves , a significant amount of intrabinary materials exist in the systems and it is very likely that the gamma - ray radiation from the pulsar and/or the pulsar wind is ablating the companion . eventually it will evaporate the companion leaving an isolated msp . since the pulsar is destroying its companion , it is called the black widow ( if the companion star mass @xmath3 ) or redback ( @xmath4 ) pulsar . with new radio pulsar surveys targeted on _ fermi _  sources , new black widows and redbacks have been found ( e.g. roberts 2013 ; ray et al . 2012 ; abdo et al . 2013 ) . traditionally , msps are discovered and studied with radio timing . indeed , all 43 gamma - ray emitting msps are `` radio - loud '' ( abdo et al . however , `` radio - dim '' msps have not been identified so far . this may be because gamma - ray emissions from msps always accompany radio emissions ; the radio beam must be large enough so that an observer can see the radio emission in any geometrical configurations . on the other hand , radio and gamma - ray emission regions can be different and depending on the geometry , it can result in `` radio - dim '' msps if we miss the radio beam ( e.g. , venter et al . 2009 ) . if msps are `` radio - dim '' , radio observations may not be able to find them . alternatively , gamma - ray observations are the best way to identify this class of sources . interestingly , nearly 1/3 of the 1873 _ fermi _  gamma - ray sources are still unidentified ( nolan et al . 2012 ) and they are the best candidates for `` radio - dim '' msps .    to identify suitable targets for investigation , we first selected candidates from the _ fermi _  unidentified source catalog based on three criteria : 1 ) source variability ; 2 ) high galactic latitude , and 3 ) gamma - ray spectral shape . we used the variability index in the _ fermi _  catalog to characterize source variability . for pulsars , we expect that they are steady sources . we also identified potential candidates from the gamma - ray spectra . for gamma - ray pulsars , their gamma - ray spectra are usually described by a power - law plus an exponential cutoff model ( abdo et al . we selected sources that are not well fitted with a power - law model as shown in the catalog . we have carried out a multi - wavelength campaign to search for such objects ( kong et al . 2012 ; hui et al . 2014a ) and identified the first `` radio - dim '' msp candidate 2fglj2339.60532 ( kong et al . 2011 ; romani & shaw 2011 ; kong et al . however , more recently , radio and gamma - ray pulsation ( ray et al . 2014 ) as well as radio continuum emission ( kong et al . 2013 ) were discovered and the source is no longer a `` radio - dim '' msp .    in this letter , we report a multi - wavelength identification of a `` radio - dim '' gamma - ray msp candidate that could be associated with an ultracompact x - ray binary . 2fglj1653.6-0159  is one of the bright _ fermi _  lat sources found in the first three months of _ fermi _  operation ( abdo et al . 2009 ) and it remains unidentified . in the second _ fermi _  lat source catalog ( 2fgl ; nolan et al . 2012 ) , 2fglj1653.6-0159  has a curvature significance of 5.3 indicating that the spectral shape is significantly curved and a variability index of 17 which is equivalent to a steady source ( see section 3.3 for a detailed analysis using 5.8 years of lat data ) . finally , 2fglj1653.6-0159  is located at a galactic latitude of @xmath5 . all these properties indicate that 2fglj1653.6-0159  is a gamma - ray msp candidate . because of these , deep radio timing observations for pulsation searches have been carried out extensively . however , no pulsation has been detected yet ( ray et al . 2012 ; barr et al . 2013 ) .    using the same technique as for searching the x - ray / optical counterpart of the first  radio - dim \" msp candidate 2fglj2339.60532 , we first checked the archival x - ray data to look for possible x - ray counterparts in the _ fermi _  error circle of 2fglj1653.6-0159 . the field of 2fglj1653.6-0159  was observed with _ chandra _  on 2010 january 24 for 21 ks with acis - i . we reprocessed the data with updated calibration files . within the 95% _ fermi _  error circle , there is only one relatively bright x - ray source ( cxou j165338.0 - 015836 ) . the x - ray - to - gamma - ray flux ratio is about 0.007 while all other _ chandra _  sources in the error circle are much fainter ( see cheung et al . 2012 ) with their x - ray - to - gamma - ray flux ratios less than 0.02% . such a low flux ratio is not typical for an x - ray counterpart to a _ fermi _  source . we tentatively identified cxou j165338.0015836 as the possible x - ray counterpart to 2fglj1653.6-0159 . this x - ray source was also listed in cheung et al . ( 2012 ) as a potential x - ray counterpart to 2fglj1653.6-0159 . within the 90% error circle of cxou j165338.0015836 , we identified a @xmath6 star that is 0.44 arcsec from the _ chandra _  position in the supercosmo sky survey ( hambly et al . this is also the same star identified in the usno catalog ( cheung et al . 2012 ) . given the positional coincidence , we suspected that this is the optical counterpart to cxou j165338.0 - 015836 . based on the x - ray spectral fit from cheung et al . ( 2012 ) , cxou j165338.0 - 015836 has an unabsorbed 0.52 kev flux of @xmath7 erg s@xmath8 @xmath9 . this yields an x - ray - to - optical flux ratio of about 3 which is too high for a foreground star and is not typical for an agn ( e.g. green et al . 2004 ; laird et al . instead , the @xmath10 color ( @xmath11 based on the usno catalog ) looks like a late - type star . all these are very similar to 2fglj2339.60532 ( romani & shaw 2011 ; kong et al . we therefore believe that this x - ray / optical counterpart is associated with 2fglj1653.6-0159  as a gamma - ray msp candidate . we have searched for the nvss catalog and there is no 1.4 ghz source at the x - ray / radio position . deep radio timing observations have been conducted to look for pulsation from 2fglj1653.6-0159  and a flux limit of 70@xmath12jy ( 1.36 ghz ) has been set ( barr et al . because 2fglj1653.6-0159  is a potential `` radio - dim '' gamma - ray msp , we have performed an optical follow - up observation for its optical counterpart . we also reanalyzed the _ chandra _ x - ray data and performed a detailed analysis using 5.8 years of _ fermi _  lat data . we carried out an optical time - series observation for the proposed optical counterpart of 2fglj1653.6-0159  in @xmath13 and @xmath14-bands with the 2.5 m isaac newton telescope ( int ) and the wide field camera ( wfc ) in la palma on june 4 - 5 , 2014 . the exposure time for all observations is 6 minutes lasting for about 6 hours each night . the wfc was operated in a @xmath15 windowing mode with a readout time of about 6 sec . all images are flat - field and bias corrected and we performed relative photometry by comparing with several comparison stars in the field . the observing time was barycentric corrected . the lightcurves clearly show variability on a timescale of 1.2 hours ( see fig . we then performed a timing analysis by using the lomb - scargle periodogram and a 75-min periodicity is highly significant in both bands . we then applied an observed - minus - calculated ( o  c ) diagram analysis to obtain a best - fit ephemeris of bjd @xmath16 . the phase 0 is defined as the optical maximum in the @xmath13-band ( superior conjunction ; see discussion ) . we also show a binned @xmath17 lightcurve that also exhibits a 75-min periodicity in fig . 1 . the phase - averaged _ chandra _  observation was reported in cheung et al . ( 2012 ) and here we focus on the timing analysis and phase - resolved spectroscopy . a detailed x - ray analysis will be present in hui et al . ( 2014a ) . using the optical timing ephemeris above , we applied a barycentric correction to the x - ray photon arrival time and folded the background subtracted 0.38 kev lightcurve . a 75-min periodicity is suggestive ( fig . 1 ) and is significant at 97% level based on an @xmath18-statistic ( @xmath18-value=8.65 ) . a more sensitive x - ray observation is required to confirm this .    to investigate whether the x - ray spectral properties vary at different orbital phases , we have performed a phase - resolved spectroscopy . we have extracted the spectra from two phase ranges that encompass the peak ( @xmath19 ) of the x - ray orbital modulation and the other coveres the trough ( @xmath20 ) . the background spectra for the corresponding temporal coverage were sampled from a nearby source - free region . the extraction of the source and background as well as the generation of response files were done by using the ciao script _ specextract_. after background subtraction , there were @xmath21  cts and @xmath22  cts from the peak and trough intervals in @xmath23  kev respectively . we grouped the spectra so as to have at least 10 counts per spectral bin .    since hui et al . ( 2014a ) has confirmed the x - rays from 2fgl  j1653.6 - 0159 are non - thermal dominant , we examined both spectra with an absorbed power - law model ( cf . hui et al . in view of small photon statistics , we fixed the column absorption at the value inferred from the phase - averaged analysis , i.e. @xmath24  @xmath9 ( cf . hui et al . for the peak interval , the best - fit yields a photon index of @xmath25 and a normalization of @xmath26  photons kev@xmath8  @xmath9  s@xmath8 at 1 kev . for the trough interval , the corresponding parameters are @xmath27 and @xmath28  photons kev@xmath8  @xmath9  s@xmath8 at 1 kev . based on this observation , the photon indices inferred in these two intervals are consistent . we concluded that there is no evidence of x - ray spectral variability across the orbit of 2fgl  j1653.6 - 0159 found in our investigation . however , in this phase - resolved analysis , the limited photon statistics do not allow us to examine whether the spectral feature at @xmath29  kev identified by hui et al . ( 2014a ) in a phase - averaged analysis exists or not . the _ fermi _  lat data used in this work were obtained between 2008 august 4 and 2014 may 30 , available at the fermi science support center . we used the fermi science tools v9r33p0 package to reduce and analyze the data . only reprocessed pass 7 data classified as `` source '' events arriving at zenith angles @xmath30100@xmath31 were used . the instrument response functions `` p7rep_source_v15 '' were used . we carried out a binned maximum - likelihood analysis using _ gtlike _ of 0.1300  gev events from the rectangular region of 21@xmath3221@xmath31 centered at 2fgl  j1653.6@xmath330159 . we subtracted the background gamma - ray flux by including the galactic diffuse model ( gll_iem_v05_rev1 ) and the isotropic background ( iso_source_v05 ) , as well as all sources in the second fermi / lat catalog ( nolan et al . , 2012 ) within the circular region of 25@xmath31 radius around 2fgl  j1653.6@xmath330159 . the recommended spectral model for each source employed in the catalog was used , while we modeled 2fgl  j1653.6@xmath330159 with a simple power law ( pl ) @xmath34 and a power law with exponential cutoff ( ple ) @xmath35 the normalization values were set free for the galactic and isotropic diffuse background , as well as sources within 10@xmath31 from 2fgl  j1653.6@xmath330159 . based on the difference between @xmath33log(likelihood ) values for both models , the ple model is preferred over the pl model by 10@xmath36 . using the ple model , @xmath37 , @xmath38  gev , and a 100  mev300  gev energy flux of @xmath39 erg  @xmath9  s@xmath8 are obtained . these spectral parameter values are typical of those found for gamma - ray millisecond pulsars ( abdo et al . we divided the 100  mev300  gev gamma - rays into 9 energy bins and reconstructed the flux using _ gtlike _ for each band separately . the spectrum is shown in fig .  [ gamma_spec ] . for each bin above 10  gev , a pl model with @xmath403.0 was assumed for 2fgl  j1653.6@xmath330159 to derive the 90% confidence - level upper limits . we probed any long - term flux variation by constructing a gamma - ray light curve from august 2008 to may 2014 with a bin size of 90 days . the source model as described above was used to estimate the background using likelihood analysis . no significant variation was seen in the light curve . folding the gamma - ray photons at the 75-min orbital period did not reveal any gamma - ray modulation as well . we derived a @xmath41 upper limit of 21% for the 110 gev fractional variation of the 75-min modulation ( see de jager 1994 ) . using optical , x - ray , and gamma - ray data , we identified the x - ray and optical counterpart of the _ fermi _  unidentified source , 2fglj1653.6-0159 . the most interesting feature is the 74.7792-min periodicity found in optical data and possibly in x - ray data ( see fig . this period can be considered as the binary period of a compact binary system . given the gamma - ray spectrum and the x - ray - to - gamma - ray flux ratio are consistent with a typical gamma - ray pulsar , we propose that 2fglj1653.6-0159  is a black widow / redback msp . since deep radio timing has not yet found the pulsation ( ray et al . 2012 ; barr et al . 2013 ) , 2fglj1653.6-0159  is very likely a `` radio - dim '' gamma - ray msp . this system is very similar to 2fglj2339.60532 . while it is no longer a `` radio - dim '' msp , it proves that this identification technique can discover msp candidates from unidentified gamma - ray sources . using this technique , psr j13113430 was discovered ( romani 2012 ) and more recently 1fglj0523.52529 was identified as a probable gamma - ray pulsar without a radio counterpart ( strader et al . 2014 ) . like 2fglj2339.60532 and other black widows and redbacks , the optical emission of 2fglj1653.6-0159  is affected by the high - energy heating from the msp on the companion surface , producing orbital modulation . this indicates that the optical maximum corresponds to the superior conjunction at which the msp is in between the companion and the observer . we also did a cross - correlation analysis of all lightcurves and did not find any significant time lag . it is worth noting that the x - ray observation was taken more than 4 years ago and given our current uncertainty of the orbital period , a direct comparison may not be correct . contemporary x - ray / optical observations are required to study the phase alignment of 2fglj1653.6-0159 .    with an observed gamma - ray flux of @xmath42 and an assumed typical distance for gamma - ray msp of @xmath43kpc , the gamma - ray power of 2fglj1653.6-0159 is @xmath44 , where @xmath45 is the viewing factor . the estimated gamma - ray luminosity @xmath46 is a typical value of pulsed gamma - rays from well - known msps ( c.f . table  1 ) , and it is likely originated from the pulsar magnetosphere . the orbital modulating x - ray emissions will be produced by the intrabinary shock due to the interaction between the pulsar wind and the stellar wind ( kong et al . the inferred x - ray luminosity from the observed flux is @xmath47 , which is in the range of the observed x - ray luminosity of known black widow / redback systems ( see table  1 ) . since the efficiency of the gamma - ray luminosity of msps is in general @xmath48 ( abdo et al . 2013 ) , suggesting the spin down power is of order of @xmath49 . assuming a typical dipole magnetic field of msps , @xmath50 g , the rotation period is estimated as @xmath51 ( takata , cheng & taam 2012 ) . we do not find significant difference between different orbital phase - resolved x - ray spectra . in the context of intrabinary shock between the pulsar wind and the stellar wind from the companion star , this might imply that the orbit is almost circular so that the shock distance from the pulsar has little dependence on the orbital phase . and hence the spectral properties do not modulate with the orbital phase . we expect that the optical modualtion is caused by the irradiation of the pulsar emissions , indicating the optical peak phase corresponds to the superior conjunction . we also expect that the orbital modulation of the x - ray emission is caused by the doppler boosting effects of the post - shocked pulsar wind . since the shift between the optical peak and x - ray peak is less than 0.5 orbital phase , we expect that the shock covers the pulsar , which will be similar to the shock geometry of the redback psrj1023 + 0038 ( takata et al . 2014 ; li et al . the non - detection of the gamma - ray orbital period may be because the amplitude of the orbital modulation is too small to be detected by _ fermi _  and/or the inverse - compoton flux of pulsar wind is smaller than the magnetospheric emissions .    black widows / redbacks are likely in the late stages of recycling , providing a crucial link between msps and accreting millisecond x - ray pulsars ( amxps ) . in the family of amxps , there are a few ultracompact systems with orbital periods less than 80 min ( xtej1751305 , xtej0929314 , xtej1807294 , hetej1900.12455 , swiftj1756.9 - 2508 , ngc 6440 x2 ) and therefore ultracompact msps should be expected . indeed , simulations suggest that there should be a large number of ultracompact msps in globular clusters ( e.g. rasio et al . although the formation of msps in the field might be different from those in clusters ( e.g. , belczynski & taam 2003 ) , some may be formed in clusters and later kicked out to distribute in the field . the striking feature of 2fglj1653.6-0159  is its very compact binary orbital period ( 74.7792 min ) and it may be the first of its kind . if future radio or gamma - ray observations confirm its msp nature , it will be the most compact rotation - powered msp binary ever found . interestingly , the short orbital period can be linked with ultracompact x - ray binaries for which the binary system consists of a compact object ( neutron star or black hole ) and a degenerate or partially degenerate companion star under a compact ( @xmath53 min ; defined by the period distribution of x - ray binaries ) binary orbit ( e.g. nelson et al . 1986 ; podsiadlowski et al . 2002 ) . these systems are usually hydrogen - poor objects and if 2fglj1653.6-0159  is associated with an ultracompact system , the companion is likely a helium star or a white dwarf . based on binary evolution calculations , 2fglj1653.6-0159  is more likely a black widow system with a companion much less than 0.1 @xmath54 ( chen et al . recently , a new black widow system , psrj1311-3430 , was found to have an orbital period of 94 min and the companion is a helium rich star ( romani et al . . it may be suggestive that the companion star of 2fglj1653.6-0159  could also be helium rich similar to ultracompact x - ray binaries . future optical spectroscopy will confirm this . last but not least , pulsation search is required to confirm the msp nature and gamma - ray pulsation search with lat will be the best way to try given that we now have the binary orbital period . at the same time , deep radio imaging will prove whether the source is `` radio - dim '' or not because imaging observations will not be affected by scattering / absorption due to the intrabinary environment . note to readers : another paper by romani et al . ( 2014 ) was submitted slightly earlier than ours and they also identify a similar orbital period . with optical spectroscopy , they found that the companion star is hydrogen poor . the int is operated on the island of la palma by the isaac newton group in the spanish observatorio del roque de los muchachos of the instituto de astrofsica de canarias . we thank diego torres and nanda rea to arrange the int observations , and ovidiu vaduvescu and teo mocnik for helping the observing runs . akhk , rj , and tcy are supported by the ministry of science and technology of the republic of china ( taiwan ) through grants 100 - 2628-m-007 - 002-my3 , 100 - 2923-m-007 - 001-my3 , and 103 - 2628-m-007 - 003-my3 . jt and ksc are supported by a 2014 grf grant of hong kong government under hku 17300814p . pht and cph are supported by the ministry of science and technology of the republic of china ( taiwan ) through grants 101 - 2112-m-007 - 022-my3 and 102 - 2112-m-008 - 020-my3 , respectively . cyh is supported by the national research foundation of korea through grant 2011 - 0023383 .", "tags": [], "output_text_a": "The Fermi Gamma-ray Space Telescope has significantly advanced our understanding of gamma-ray emitting pulsars, particularly millisecond pulsars (MSPs). These MSPs are crucial for studying the evolution of compact stars. Recent surveys have found many MSPs in binary systems, some with tight orbits, where the pulsar's radiation may be ablating the companion star, leading to isolated MSPs known as \"black widow\" or \"redback\" pulsars. While all known gamma-ray emitting MSPs are \"radio-loud,\" the existence of \"radio-dim\" MSPs is hypothesized, potentially detectable through gamma-ray observations. \n\nThe paper reports on the identification of a \"radio-dim\" gamma-ray MSP candidate, 2FGLJ1653.6-0159, associated with an ultracompact X-ray binary. This source, found in Fermi's LAT data, shows characteristics typical of gamma-ray MSPs, such as a steady gamma-ray emission and a curved spectral shape. Despite extensive radio timing observations, no pulsation has been detected, suggesting it might be \"radio-dim.\"\n\nThe study involved multi-wavelength observations, including X-ray and optical data, to identify potential counterparts. A significant finding is a 75-minute periodicity in optical data, likely indicating the binary period of the system. The X-ray and gamma-ray analyses support the hypothesis that 2FGLJ1653.6-0159 is a black widow/redback MSP, possibly the most compact rotation-powered MSP binary discovered. The companion star might be helium-rich, similar to ultracompact X-ray binaries. Future observations, including optical spectroscopy and gamma-ray pulsation searches, are needed to confirm the MSP nature and further understand the system's characteristics. \n\nThe study highlights the potential of using gamma-ray observations to discover new MSP candidates, especially those that are \"radio-dim,\" and provides insights into the late stages of MSP evolution and their connection to accreting millisecond X-ray pulsars.", "output_text_b": "This article discusses the discovery and identification of a new gamma-ray millisecond pulsar (MSP) candidate, 2FGLJ1653.6-0159, which could be associated with an ultracompact X-ray binary. The MSP is a candidate for being a \"radio-dim\" gamma-ray MSP, which has not been identified through radio observations due to its weak radio emissions. The authors used a multi-wavelength approach, including X-ray and optical observations, to identify the MSP candidate. The article also discusses the potential of 2FGLJ1653.6-0159 to be a black widow or redback pulsar, based on its gamma-ray spectrum and X-ray to gamma-ray flux ratio.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, including the identification of a \"radio-dim\" gamma-ray MSP candidate and its potential association with an ultracompact X-ray binary.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of identifying \"radio-dim\" MSPs and understanding their characteristics.\n4. **Methodology**: The summary mentions the use of multi-wavelength observations, including X-ray and optical data, to identify potential counterparts.\n5. **Significant Results**: The summary includes significant results, such as the 75-minute periodicity in optical data and the hypothesis that 2FGLJ1653.6-0159 is a black widow/redback MSP.\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"black widow\" and \"redback\" pulsars.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments or Data**: The summary mentions key experiments, such as the multi-wavelength observations and the analysis of Fermi's LAT data.\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in advancing the understanding of MSPs and their evolution.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the discovery and identification of a new gamma-ray millisecond pulsar (MSP) candidate, 2FGLJ1653.6-0159, and its potential association with an ultracompact X-ray binary.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the identification of a \"radio-dim\" gamma-ray MSP.\n4. The methodology or approach used in the paper, including multi-wavelength observations, is mentioned.\n5. Significant results or conclusions, such as the potential classification of the MSP as a black widow or redback pulsar, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"radio-dim\" and \"black widow or redback pulsar.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments or data, such as X-ray and optical observations, are mentioned.\n10. The summary reflects the paper's significance in identifying a new MSP candidate and its potential impact in the field of gamma-ray astronomy."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the kinetic roughening of growing surfaces is a problem of fundamental interest in nonequilibrium statistical physics . the interest arises from theoretical , experimental , and numerical evidence of scale invariance and universality of the statistical fluctuations of rough interfaces in a large variety of systems @xcite . one candidate system is the roughening of a driven interface separating two fluids in a porous medium . this problem has important practical applications , and has time and length scales easily accessible in the laboratory . it allows different possible realizations , depending on the relative viscosities and wetting properties of the fluids involved @xcite . one of these possible realizations which has received considerable attention in recent years is _ imbibition _ , i.e. the situation in which a viscous wetting fluid ( typically oil or water ) displaces a second less  viscous , non  wetting fluid ( typically air ) which initially fills the porous medium . the motion of imbibition interfaces can be _ spontaneous _ , i.e. driven solely by capillary forces , or _ forced _ externally at either constant applied pressure or constant injection rate . although there have been many experimental investigations of the scaling properties of imbibition interfaces in the last years , some results , particularly the quantitative values of scaling exponents , remain controversial . the current situation for the case of spontaneous imbibition is reviewed in ref . the situation for the case of forced imbibition is summarized in section [ sec : scaling ] . the limitations of the experiments , in our opinion , arise firstly from the lack of precise knowledge of the properties of the disorder introduced by the model porous medium , and secondly from the related difficulty in tuning the relative strength of stabilizing to destabilizing forces in the flow . in the present work we have attempted to avoid these two limitations by using a particular model porous medium , consisting on a hele  shaw cell with precisely designed and controlled random variations in gap spacing .    in our setup , an initially planar interface becomes statistically rough on a mesoscopic scale , as a result of the interplay between ( i ) the stabilizing effects of the viscous pressure field in the fluid , and the surface tension in the plane of the cell , on long and short length scales respectively , and ( ii ) the destabilizing effect of local fluctuations in capillary pressure , arising from the random fluctuations in gap spacing , on short length scales . although they have a different physical origin , the role of local fluctuations in capillary pressure , in our setup , is very similar to the role of wettability defects in the _ imperfect hele  shaw cell _ introduced by de gennes @xcite , and studied by paterson and coworkers @xcite .    in this paper we present a systematic experimental study of forced imbibition of our model porous medium , by a wetting silicone oil driven at constant flow rate . since the competing forces in our system are the same as in a real porous medium , the physics governing roughening is very similar in the two cases . the relative importance of viscous forces can be finely tuned by changing the injection rate of the invading fluid , and the strength of capillary fluctuations can be tuned by adjusting the distance between the two glass plates . the sequence of photographs in fig . [ fig : close - up ] provides examples of the resulting interfaces . mm , average interface velocity @xmath9 mm / s , and disorder sq 0.40 . the time interval between images is 0.8 s.,width=325 ]    the outline of the paper is as follows . section [ sec : scaling ] reviews the scaling properties of rough interfaces , and their experimental characterization in two  dimensional forced imbibition . section [ sec : setup ] describes the experimental setup , section [ sec : characterization ] introduces several parameters , such as permeability and modified capillary number , useful to characterize the experiments , and section [ sec : dataanalysis ] explains the methodology used in data analysis . the experimental results are described in section [ sec : results ] , and are analyzed and discussed in section [ sec : analysis ] . the final conclusions are given in section [ sec : conclusions ] . to be specific , let us consider a two  dimensional system with cartesian coordinates @xmath10 , of lateral size @xmath11 in the @xmath12 direction and of infinite extension in the @xmath13 direction . the interface is driven in the direction of positive @xmath13 , and its position at time @xmath14 is parametrized by the function @xmath15 . we assume that the interface is initially planar , @xmath16 . let @xmath17 ( the _ rms _ interfacial width ) denote the typical amplitude of transverse excursions on a scale @xmath18 , parallel to the interface , at time @xmath14 . for the complete interface : @xmath19^{1/2},\\ ] ] where @xmath20 . the notation @xmath21 represents an spatial average in the interval @xmath22 $ ] , where @xmath11 is the system size . the standard picture of kinetic roughening is summarized in the dynamical scaling assumption of family and vicsek @xcite : @xmath23 where @xmath3 is the _ roughening _ ( or static ) exponent and @xmath24 is the _ dynamic _ exponent . the scaling function @xmath25 is : @xmath26 this picture assumes that the lateral correlation length of the interface fluctuations increases in time as @xmath27 , in the @xmath12 direction . for all length scales @xmath18 within this correlation length the interface is rough , @xmath28 . as the lateral correlation length increases , the interfacial width increases correspondingly with time as @xmath29 , which defines a _ growth _ exponent @xmath30 . finally , when the lateral correlation length exceeds the system size , @xmath11 , at a crossover time @xmath31 , the interface fluctuations saturate . one way of measuring @xmath3 is through the analysis of the interfacial width as a function of different system sizes @xmath11 , i.e. @xmath32 , at saturation . from an experimental point of view , however , it is not practical to perform experiments at different @xmath11 . usually it is prefered to measure @xmath3 by analyzing @xmath33 for different window sizes @xmath18 , with @xmath34 . the scaling of @xmath35 gives a _ local _ roughness exponent @xmath36 , which is usually identified with the _ global _ exponent @xmath3 . this kind of analysis must be performed with some caution , however , because it can only provide @xmath37 and hence fails for super  rough interfaces ( @xmath38 ) . moreover , a number of problems of kinetic roughening present intrinsic anomalous scaling , characterized by different values of local and global exponents @xcite . these difficulties can be overcome by analyzing the power spectrum of the interfacial fluctuations , defined as @xmath39 where @xmath40 e^{iqx}.\\ ] ] the notation @xmath41 indicates average over disorder configurations . the mean width @xmath33 is related to @xmath42 through @xmath43 where @xmath44 is the sampling interval in the @xmath12 direction . for a 2@xmath45 system , the equivalent of the family vicsek scaling assumption for the power spectrum reads @xcite : @xmath46 where the scaling function is given by @xmath47 the power spectrum can give values @xmath38 and hence is applicable to super  rough interfaces . on the other hand , the presence of intrinsic anomalous scaling can be detected by a systematic shift of the power spectra computed at successive time intervals @xcite . the scaling concept has allowed a classification of kinetic roughening problems in universality classes characterized by different families of scaling exponents . the first class is described by the thermal kardar  parisi zhang ( kpz ) equation @xcite , which provides a local description of interfacial roughening in the presence of an additive white noise . the kpz scaling exponents are @xmath48 and @xmath49 in two dimensions . if the nonlinear term of the kpz equation is supressed , the resulting equation is known as the thermal edwards wilkinson ( ew ) equation @xcite , which gives @xmath50 and @xmath51 in two dimensions . when , instead of being purely thermal , the noise in the kpz equation is supposed to depend on the interface height @xmath52 , the equation displays a depinning transition . at the pinning threshold the interface behaviour of the complete equation with the nonlinear term ( `` quenched kpz '' ) can be mapped to the directed percolation depinning ( dpd ) model , whose scaling exponents in two dimensions are @xmath53 . suppressing the nonlinearity yields the `` quenched ew '' equation , for which @xmath54 and @xmath55 in two dimensions @xcite .    in the case of imbibition , there are two important issues which make the above classification of limited applicability . the first one is the quenched nature of the disorder . it has been argued that for very large driving the disorder may still be considered as a fluctuating in time ( thermal ) noise , but in general the disorder must be treated as a static , quenched noise . the second issue is the nonlocal character of the dynamics , due to fluid transport in the cell @xcite . this issue has received important attention recently , with the introduction of imbibition models which take fluid transport explicitly into account , giving rise to nonlocal interfacial equations @xcite . the models presented in @xcite are consistent with the well known macroscopic equations of the problem ( darcy s law and interfacial boundary conditions ) . they differ in the way the noise is included in the equations and in the noise properties . the starting point of ganesan and brenner @xcite is a random field ising model . the permeability is taken spatially uniform and the noise exhibits long range spatial correlations . in the case of forced imbibition , and based on a flory type scaling , the model predicts that the roughness exponent @xmath3 depends on the capillary number ca , with asymptotic values @xmath56 for the smallest drivings and @xmath51 for the largest drivings . the approaches of dub _ et al . _ @xcite and hernndez  machado _ et al . _ @xcite are both based in a conserved ginzburg - landau model , where the noise is introduced in a fluctuating chemical potential or in the mobility , respectively , without long range correlations . @xcite , however , consider only the case of spontaneous imbibition , which could give results very different from the case of forced imbibition , specially for the growth exponent @xmath57 . by numerical integration they obtain @xmath58 and @xmath59 . @xcite study the case of forced imbibition , and predict a different scaling of the short and long length scales , with exponents @xmath60 in the former regime , and @xmath61 in the latter . a common feature of these models , pointed out in refs . @xcite , is the presence of a new lateral length scale , @xmath62 , related to the interplay of interfacial tension and liquid conservation . for @xmath63 the dominant stabilizing contribution is the interfacial tension in the plane of the cell , while for @xmath64 it is the fluid flow . the interplay leads to a dependence of @xmath6 ( @xmath65 ) on @xmath0 of the form @xmath66 . as mentioned in the introduction , the experimental characterization of the scaling properties of interfaces in two  dimensional forced imbibition remains conflicting . most experiments have been conducted in model porous media consisting of air  filled hele shaw cells packed with glass beads . in a first experiment of this sort on water  air interfaces , carried out by rubio _ @xcite , a roughening exponent @xmath67 was measured , independent of ca and bead size , for ca values in the range @xmath68  @xmath69 . a controversial reanalysis of their data by horvth _ _ gave @xmath70 @xcite , which these authors compared to @xmath71 obtained in their own replication of the experiment . in a subsequent work @xcite , using glycerol instead of water , horvth _ et al . _ reported a clear power law growth regime with a growth exponent @xmath72 , and different values @xmath73 and @xmath74 at short and long wavenumbers , respectively , at saturation . the last set of experiments of this kind is due to he _ @xcite , who explored a very large range of ca ( from @xmath75 to @xmath69 ) and found large fluctuations of the roughness exponent in the saturation regime , between @xmath76 and @xmath77 . in these experiments @xmath33 was shown to fluctuate wildly during growth , and it was impossible to give a value of the growth exponent @xmath57 . other experiments have been directed to characterize the statistical properties of the avalanches displayed by imbibition fronts at sufficiently small ca . the results are also conflicting . the first study @xcite was done on the same air - glycerol interfaces of ref . @xcite , and gave a power law distribution of avalanche sizes . the second one @xcite , on air  water interfaces , reported an exponential distribution .    in our experiments , the possibility of tuning the different competing forces has allowed an accurate measurement of the growth exponent @xmath57 , by enlarging the growth regime before saturation . fine tuning of the forces has also allowed to measure the crossover length @xmath62 , and its dependence on velocity @xmath0 . in our experiments a silicone oil ( rhodorsil 47 v ) displaces air in a horizontal hele - shaw cell , @xmath78 mm@xmath79 , made of two glass plates 20 mm thick . the oil has kinematic viscosity @xmath80 mm@xmath81/s , density @xmath82 kg / m@xmath83 , and surface tension oil  air @xmath84 mn / m at room temperature . fluctuations in the gap thickness are provided by a fiber - glass substrate , fixed on the bottom glass plate , containing a large number of copper islands which randomly occupy the sites of a square grid . the height of the islands is @xmath85 mm . the gap spacing @xmath1 , defined as the separation between the substrate and the top plate , is set by placing several calibrated spacers on the perimeter of the substrate , over the disorder , as shown in fig . [ fig : set - up ] . we have used gap thicknesses in the range @xmath86 ( @xmath87 ) mm . the disorder pattern is designed by computer and manufactured using printed circuit technology . in order to clearly identify the oil air interface when it moves over the copper islands , the plates have been chemically treated to accelerate copper oxidation . otherwise the copper islands are too bright to recognize the interface contour . the silicone oil wets perfectly both fiber  glass and copper , and no differences in the wetting properties due to the oxidation protocol have been observed .    for each experiment , the glass plates are cleaned with soap and water and rinsed with distilled water and acetone . the fiber  glass plate is cleaned using blotting paper only , which leaves a thin layer of oil to avoid further oxidation of the copper surface , ensures a complete wetting in both fiber  glass and copper , and improves the interface contrast in the captured images . next , the fiber  glass plate is fixed over the bottom glass plate using a thin layer of removable glue . the cell is completed by placing the spacers , the upper glass plate , and the o  ring around the fiber  glass plate ( fig.[fig : set - up ] ) finally , the two glass plates are firmly clamped together , to ensure the homogeneity of the gap spacing and the tightness of cell sides closed by the o  ring . the oil is injected at constant flow - rate using a syringe pump perfusor ed-2 . the syringe pump can be programmed to give flow rates @xmath88 in the range 1299 ml / h with less than 2 % fluctuations around the nominal value . the oil enters the cell through two wide holes , drilled on the top plate near one end of the cell . the other end of the cell is left open . to start the experiment with as flat an interface as possible , the oil is first slowly injected on a transverse copper track , on the fiber - glass plate , which is 2 mm ahead the disorder pattern . next , the syringe pump is set to its maximum injection rate until the whole interface has reached the disorder ( about 3 s later ) . the pump is then set to the nominal injection rate of the experiment , and @xmath89 is defined as the time at which the average height of the interface ( measured on the images ) reaches the preset nominal velocity . the oil  air interface evolution is monitored using two jai cv - m10bx progressive scan ccd cameras ( each camera acquiring half side of the cell ) . the 1/2 \" ccd sensor contains 782 ( h ) @xmath90 582 ( v ) pixels . in our experiment we have used an exposure time of 1/25 s in order to minimize the illumination . each camera is equipped with a motorized zoom lens computar m10z1118mp with a focal length in the range 11110 mm ( 1:10 zoom ratio ) . the cameras are connected to an imaging technology pcvision frame grabber installed in a personal computer . a visual basic application controls both cameras and stores the images for further analysis . the images are taken with a spatial resolution of 0.37 mm per pixel , a size of @xmath91 pixels , and 256 grey scale levels per pixel . the acquisition is logarithmic in time , with temporal increments that vary from 0.33 s to 180 s. between 100 and 300 images are taken per experiment . because the background is the same for all the images captured with the same camera , the interface is enhanced by subtracting the first image to all other images , and thresholding the result to get a black and white contour of the interface . the contour is resolved with 1pixel accuracy using edge detection methods , and data are stored for further analysis . this method is automatically performed , with an error in the interface recognition comparable to the width of the oil  air meniscus , about one half the gap width . [ fig : image ] presents two examples of the digitized interfaces , compared with the original images . mm and @xmath9 mm / s in the two cases.,width=325 ] three kinds of disorder patterns have been used . two of them are obtained by random selection of the sites of a square lattice ( fig .  [ fig : set - up](d ) ) . in the first of them ( sq ) we allow nearest neighbour connections only , leaving next nearest neighbours separated by 0.08 mm . in the second one ( sq - n ) both nearest neighbour and next  nearest neighbour connections are allowed . the third kind of disorder pattern ( t ) is formed by parallel tracks , continuous in the @xmath13 direction and randomly distributed along @xmath12 ( fig . [ fig : set - up](e ) ) . the filling fraction @xmath92 ( fraction of lattice sites occupied by copper ) is 35 % in the three cases . however , @xmath93 , the persistence length of the disorder in the direction of growth , is very different in the three different disorder patterns . this length is measured in the following way : ( i ) we consider every site @xmath12 of the lattice along the lateral direction , and measure the average length @xmath94 of the island formed by the connected copper sites at @xmath95 , @xmath12 , and @xmath96 , where @xmath97 is the lattice spacing . ( ii ) we average @xmath94 over the lateral direction in the interval @xmath98 . as can be seen in the inset of fig.[fig : noise ] , @xmath93 increases by a factor @xmath99 when changing from sq to sq - n , and up to the total length of the cell for t. another characteristic of the disorder is the cluster size , which gives the number of disorder unit cells of the copper aggregations . the statistical distribution of copper clusters is shown in the main plot of fig . [ fig : noise ] .    . clusters with only nearest neighbour contacts ( sq ) are represented in dark grey . clusters with nearest and next  nearest neighbour contacts ( sq - n ) are represented in light grey . the inset shows the persistence length of the disorder @xmath93 as a function of the filling fraction @xmath92 . the solid and dashed lines correspond to the sq and sq - n cases respectively . the vertical line indicates the filling fraction used in our experiments.,width=325 ]    we have used two values of the lattice spacing in the lateral direction , @xmath100 mm and @xmath101 mm . from here on we refer to the disorder used in a given experiment by sq , sq - n , or t , followed by the lateral size in mm of the disorder unit cell , @xmath102 or @xmath103 .      to characterize the fluid flow through our hele shaw cell with disorder , we have determined the permeability of the cell for the different disorder patterns as a function of the gap spacing . the experimental set up used for this purpose is similar to the one shown in fig . [ fig : set - up ] , but the injection system has been replaced by a constant pressure device . it consists of an oil column of adjustable constant height in the range from 200 @xmath104 2 mm to 1000 @xmath104 5 mm . the permeability is determined by measuring the oil  air interface average velocity for different applied pressures ( heights of the oil column ) and using darcy s law , @xmath105 where @xmath106 is the interface velocity , @xmath107 the permeability , @xmath108 the dynamic viscosity , and @xmath109 the pressure gradient . [ fig : permeability ] shows the results obtained . at large gap spacings , @xmath110 , the disorder has no effect on the fluid flow , and the permeability tends to the expected value for an ordinary hele  shaw cell , @xmath111 , independently of the disorder configuration . at very small gaps , @xmath112 , the permeability decreases , and tends to a non zero value @xmath113 for @xmath114 , that clearly depends on the disorder configuration . we have found it convenient to write @xmath113 in the form @xmath115 where @xmath116 is a function that depends on the porosity @xmath117 and the geometry of the disorder . the simplest functional form that interpolates between these two limits can be written as : @xmath118 the coefficient @xmath116 can be obtained in general from a fit of the permeability to the experimental data . , as a function of the disorder strength , @xmath119 , for @xmath120 mm . the dotted line is the permeability of an standard hele  shaw cell ( without disorder ) , and the dashed and solid lines are fits to the experimental data for sq and t disorder configurations , respectively . the arrows point to the values of @xmath119 for the gap spacings used in the experiments.,width=325 ]    in the particular case of disorder t and @xmath114 , an analytic expression of @xmath116 can be derived by recognizing that the cell in this case is formed by a parallel array of rectangular capillaries . following avellaneda _ @xcite , in this geometry @xmath116 is directly the porosity @xmath117 , which in the limit @xmath114 is given simply by @xmath121 . hence , since we have @xmath122 , we obtain @xmath123 . this result fits well the experimental data not only in the limit @xmath114 but also in the whole range of @xmath119 ( solid line in fig.[fig : permeability ] ) . notice also that the results presented in fig.[fig : permeability ] show that there are no important differences between t 1.50 mm and t 0.40 mm . this observation generalizes the theoretical result that in the limit @xmath114 the width of the rectangular capillaries does not modify the permeability @xcite . for sq and sq n disorder , due to the difficulty of finding a general expression for @xmath113 ( see refs . @xcite ) , we have fitted @xmath107 to our experimental results ( dashed line in fig .  [ fig : permeability ] ) and have obtained a numerical value @xmath124 .      assuming local thermodynamic equilibrium , the capillary pressure jump at the interface is given by @xmath125 where @xmath126 and @xmath127 are the main curvatures of the interface , in the plane of the cell and perpendicular to it , respectively . @xmath126 varies from @xmath128 for @xmath129 , to @xmath130 for @xmath131 , where @xmath132 mm is the average diameter of the copper obstacles . in the range of gap spacings explored we have measured curvatures in the range @xmath133 mm@xmath134 . notice that @xmath135 in all the range of gap spacings used in the experiments . in ordinary hele shaw flows ( without disorder ) @xmath127 is roughly the same in all points of the interface and therefore adds only a constant contribution to the pressure jump . in our case , however , when the interface is over the copper islands ( gap thickness @xmath136 ) we have : @xmath137 and when it is over the fiber  glass substrate ( gap thickness @xmath1 ) : @xmath138 assuming complete wetting . this difference in curvature , given by @xmath139 makes the interface experience a capillary instability when it passes from one gap spacing to the other . in the range of gap spacings studied , @xmath140 mm , we get @xmath141 mm@xmath134 . we have verified that for gap spacings @xmath142 mm , which correspond to @xmath143 mm@xmath134 , the fluctuations in capillary pressure are no more sufficient to roughen the interface appreciably .      once the permeability of the cell has been characterized , we can introduce a dimensionless number to describe the relative strength of viscous to capillary forces . the simplest number that relates viscous and capillary forces is the _ capillary number _ ca@xmath144 . in order to account for the properties of the disorder , which are not contained in the previous definition of ca , it is customary to introduce a _ modified capillary number_. for an ordinary hele - shaw cell ( without disorder ) , the modified capillary number , which we call ca@xmath145 , comes out from the dimensionless form of the hele shaw equations @xcite : @xmath146 to define a modified capillary number ca for our particular cell with disorder , we consider on one side the average viscous pressure drop across the cell , given by @xmath147 with @xmath148 ( darcy s law ) . @xmath11 , the cell width , provides the macroscopic length scale . on the other side , a measure of the capillary pressure drop is given by @xmath149 the last contribution accounts for the curvature of the interface in the plane of the cell , and is relevant only when @xmath150 , i.e. when the destabilizing role of the disorder vanishes . defining ca @xmath151 and using ( [ perm - general ] ) , ( [ viscous - drop ] ) and ( [ capillary - drop ] ) , we get @xmath152    the ratio ca/ca@xmath145 as a function of @xmath119 is shown in fig . [ fig : ca ] for disorders sq and t. when @xmath150 the destabilizing role of the disorder is negligible , as expected , and ca/ca@xmath145 tends to @xmath153 ( ordinary hele - shaw cell ) . as @xmath119 increases , the increasing strength of the disorder is manifest in the progressive decrease of ca/ca@xmath145 . it is important to notice that our definition of ca is not valid for @xmath114 , because the flow would be essentially different when the free gap disappears . in the range of @xmath119 explored in our experiments the permeability of the cell remains always close to that of an ordinary hele  shaw cell ( fig . [ fig : permeability ] ) , and the decrease of ca/ca@xmath145 is essentially due to the capillary forces associated with the menisci in the @xmath24 direction .    , as a function of the disorder strength , @xmath119 . the dashed and solid lines correspond to disorders sq 1.50 and t 1.50 . the dotted line represents the asymptotic limit ca@xmath154ca@xmath145 . the arrows point to the values of @xmath119 for the gap spacings used in the experiments.,width=325 ]    in the range of gap spacings experimentally explored , @xmath155 mm , the ratio between the free gap @xmath136 and the total gap @xmath1 varies between 62% and 92% . these large ratios , combined with the high viscosity and small surface tension of the silicone oil compared with other fluids ( i.e. water ) , are responsible for the large values of ca in our experiments , in comparison to the values reported for pure porous media . considering for example the disorder t 1.50 mm , ca varies from a value @xmath156 ( for @xmath157 mm and the minimum interface velocity , @xmath158 mm / s ) to a value @xmath159 ( for @xmath160 mm and the maximum interface velocity , @xmath161 mm / s ) . the wetting of the lateral gap spacers by the invading oil changes the physics at the two ends of the interface . to minimize this disturbance , which is particularly important at large gap spacings , we have disregarded 8 mm at each side of the cell , thereby reducing the measured interface from 190 to 174 mm in the @xmath12 direction . the final number of pixels of the interface after this correction is reduced from 515 to 470 . for data analysis convenience these pixels are converted into @xmath162 equispaced points , through a linear interpolation . the final spacing between two consecutive points is @xmath163 mm . although the linear interpolation introduces an artificial resolution 7 % larger than the resolution of the original image , the increase does not affect the final analysis . the interfaces measured at the smallest gap spacings and velocities may present overhangs . these multivaluations , rather exceptional , have been eliminated by taking for each value of @xmath12 the corresponding largest value of @xmath164 . in addition , we have forced periodic boundary conditions for @xmath165 by subtracting the straight line connecting the two ends of the interface . this procedure is well documented in the literature of kinetic roughening @xcite . the linear correction imposed to the interfaces has significant effects on the power spectrum . the fourier spectrum of an interface which is discontinuous at the two end points is dominated by an overall behaviour of the form @xmath166 . forcing periodic boundary conditions eliminates the overall slope -2 @xcite . moreover , the analysis of @xmath35 is insensitive to the linear correction of the interface ( except for values of @xmath18 comparable to the system size ) and gives results consistent with those obtained from @xmath42 only for interfaces with periodic boundary conditions .    since the maximum width of the meniscus is only one half the gap width ( in conditions of complete wetting ) the interface can be considered one  dimensional at the length scale of the copper islands . the resolution of the interface fluctuations in the @xmath13 direction is @xmath1041 pixel at a given point . nevertheless , the measurement of the global interfacial width @xmath33 is much more precise because the width is an average over the @xmath162 points of the interface .    given that , according to our choice of the time origin , the whole interface is already inside the disorder at @xmath89 , @xmath167 . for this reason , we have decided to characterize the interface fluctuations by the _ subtracted width _ @xmath168 , defined by @xmath169 @xcite . notice that , since the data analysis is based on power law dependencies , short times are very sensitive to the definition of @xmath89 and to the value @xmath170 . after analyzing the data for different definitions of @xmath89 , and checking the influence of subtracting @xmath170 , we have found that the analysis based on the subtracted width is the most objective and less sensitive to the details of the experimental procedure . the error bars shown in the @xmath171 plots indicate the dispersion of the different individual experiments with respect to the average curve plus the uncertainty in the determination of @xmath89 . finally , the crossover time @xmath172 has been measured on the @xmath171 log - log plots as the time when the power law with slope @xmath57 crosses the horizontal straight line that corresponds to the average value of the interfacial width at saturation , @xmath173 . the parameters explored in our experiments are summarized in table[tab : exp - list ] . the minimum velocity selected in the experiments , @xmath174 mm / s ( which will be taken as reference unit for interfacial velocities ) , has been chosen to ensure that the interface is always single  valued for gap spacings @xmath175 mm . we have used three different disorder realizations for sq and sq - n and four for t. for each disorder realization and each set of experimental parameters ( @xmath0 , @xmath1 ) we have carried out three runs for sq and sq - n , and two runs for t.    [ cols=\"^,^,^\",options=\"header \" , ]     table  [ tab : main - results ] shows the main results obtained for the roughness exponents @xmath4 ( short length scales ) and @xmath5 ( long length scales ) at different disorder configurations and drivings . for small ca , capillary forces are dominant at all scales , and the dynamics is very sensitive to the disorder configuration . for sq and sq - n , the interfaces get locally pinned , and the measured exponents are close to those obtained in dpd or in experiments where capillary forces are dominant @xcite . in the limit of persistent disorder , the nature of the disorder impedes pinning , but the effect of the destabilizing capillary forces combined with the correlations between neighboring tracks leads to a new regime that can be described using the anomalous scaling ansatz @xcite . this new regime also extends to the region of moderate ca for t disorder . for moderate ca , viscous forces are dominant at long length scales and two clear regimes separated by a crossover wavenumber @xmath6 can be characterized . for sq and sq - n we get roughness exponents @xmath176 and @xmath177 . for t , we get a qualitatively similar behaviour , but obtaining lower values of the exponents due to finite size effects at long length scales and the dominant capillary forces at short length scales . for large ca , the viscous forces cause that the initial super  roughness at short times and short length scales gets frozen in , obtaining the same roughness exponent @xmath178 for all the disorder configurations . our experimental results can be compared now with the predictions of the nonlocal models @xcite discussed in section ii . it appears that none of the models can account for the different results obtained in the whole range of capillary numbers explored . although the flory  type argument used by ganesan and brenner @xcite is difficult to justify in this nonequilibrium situation , they obtain roughness exponents ( @xmath179 and @xmath180 ) consistent with our values for small and moderate ca. the exponents obtained by hernndez @xcite for the long length scales at moderate ca , @xmath181 and @xmath182 ( @xmath183 ) , are in agreement with our experimental values in the long time regime , where the viscous forces are dominant . the value of @xmath3 for short length scales , corresponding to the short time regime of the model , gives a super  rough behaviour ( @xmath184 ) dominated by surface tension in the plane , but larger than the exponent measured in the experiment . for large capillary numbers the numerical result of dub _ et al . _ @xcite , @xmath185 , is in agreement with our experimental results , but not the result @xmath186 because , as pointed out above , these authors assume a spontaneous imbibition . at this point it would be interesting to know whether a model containing a quenched disorder both in the mobility and in the chemical potential would be able to explain the experimental results for the whole regime of ca studied here , and specially the regime of large ca in forced imbibition . this remains an open question . our last analysis is the variation of @xmath6 with @xmath0 . the crossover wavenumber @xmath6 separates the regime in which the long length scale fluctuations ( small @xmath187 ) are damped by the viscous pressure field , from the regime in which the short length scale fluctuations ( large @xmath187 ) are damped by the interfacial tension in the plane of the cell . since the relative importance of the viscous pressure field increases with ca , it is expected that @xmath6 will increase with @xmath0 . specifically , a linear analysis of the interfacial problem shows that the viscous damping is proportional to @xmath188 and the interfacial tension damping is proportional to @xmath189 , which results in @xmath190 @xcite .    in fig . [ fig : qx ] we show the behaviour of @xmath6 with @xmath0 for different kinds of disorder . the error bars are relatively large because the exact location of @xmath6 in the experimental power spectra is difficult to ascertain . for sq 1.50 we find that @xmath191 , in good agreement with the theoretical prediction . it is interesting to note that , as we go to disorders of larger @xmath93 ( increasing persistence ) , @xmath192 tends to be less sensitive to @xmath0 . for t 1.50 we observe that @xmath6 becomes independent of @xmath0 , within error bars . the reason can be understood in the framework of the following scenario : at a local level ( see fig . [ fig : close - up ] ) the motion of the interface in the sq disorder can be viewed as a series of events formed by a period of nearly steady motion , a subsequent period of fast advance over a copper island ( accompanied by an abrupt change of sign of the in plane curvature ) , and a third period of fast advance over fiber glass due to relaxation of the local in  plane curvature . thus , damping of the short length scales due to the interfacial tension in the plane of the cell is basically effective only in this last period , when the interface depins from the copper islands . as the persistence of the disorder in the @xmath13 direction is larger , the relaxation periods are less frequent . this can be observed through the histogram of fig . [ fig : noise ] . when we increase the persistence of the disorder changing from sq to sq - n , the number of the smallest copper aggregations reduces almost one order of magnitude . in the limiting case of t 1.50 the disorder is continuous in the @xmath13 direction , and the damping role of the in  plane interfacial tension is effectively suppressed .     on velocity @xmath0 for three disorder configurations : sq 1.50 ( solid circles ) , sq - n 1.50 ( open circles ) and t 1.50 ( triangles).,width=325 ] we have presented new experiments of forced fluid imbibition in a hele  shaw cell with quenched disorder . we have used three main kinds of disorder patterns , sq , sq - n and t , characterized by an increasing persistence length @xmath93 in the direction of growth . we have measured a robust roughness exponent @xmath2 that is almost independent of the disorder configuration , interface velocity , and gap spacing , although the behaviour of the interfacial width presents important fluctuations both during growth and at saturation , that progressively disappear as the disorder is more persistent in the @xmath13 direction . the roughness exponent @xmath3 , however , shows a clear dependence on the experimental parameters , as summarized in table  [ tab : main - results ] , discussed in the previous section . finally , we have focused on the dependence of the crossover wavenumber as a function of the interface velocity @xmath0 and @xmath93 . for the shortest @xmath93 , @xmath193 , and becomes independent of @xmath0 as the disorder is persistent in the @xmath13 direction . the absence of pinning in experiments with disorders of increasing @xmath93 allows a detailed investigation of the regime of large capillary forces . this regime presents some interesting novel features which are studied in detail in ref.@xcite . we are grateful to m. a. rodrguez , l. ramrez - piscina , j. casademunt , k. j. mly , and j. schmittbuhl for fruitful discussions . the research has received financial support from the direccin general de investigacin ( mct , spain ) , project bfm2000 - 0628-c03 - 01 . j. o. acknowledges the generalitat de catalunya for additional financial support . j. s. is supported also by a fellowship of the dgi ( mct , spain ) .", "tags": [], "output_text_a": "This paper investigates the kinetic roughening of interfaces during forced imbibition in a model porous medium, specifically a Hele-Shaw cell with controlled random variations in gap spacing. The study focuses on the roughening of a driven interface between two fluids, a problem of interest in nonequilibrium statistical physics due to its scale invariance and universality. The authors aim to address limitations in previous experiments by precisely controlling the disorder and tuning the relative strength of stabilizing and destabilizing forces. The experimental setup involves a wetting silicone oil displacing air at a constant flow rate, with the interface becoming statistically rough due to the interplay of viscous pressure, surface tension, and capillary pressure fluctuations.\n\nThe paper provides a detailed experimental study of the scaling properties of rough interfaces in two-dimensional forced imbibition, analyzing the effects of different disorder patterns and flow rates. The authors measure roughness exponents and investigate the influence of disorder persistence on interface dynamics. They find that the roughness exponent is robust across different conditions, but the behavior of the interfacial width varies significantly. The study also explores the dependence of the crossover wavenumber on interface velocity and disorder persistence, revealing novel features in the regime of large capillary forces.\n\nThe results are compared with theoretical models, highlighting discrepancies and suggesting areas for further research. The paper concludes with a discussion on the implications of the findings for understanding kinetic roughening in porous media and the potential for future studies to explore the effects of quenched disorder in more detail.", "output_text_b": "This paper presents a study of kinetic roughening in growing surfaces, specifically in the context of forced imbibition in a porous medium. Forced imbibition is the process where a viscous wetting fluid displaces a less viscous, non-wetting fluid in a porous medium, and can be spontaneous or forced at a constant pressure or flow rate. The paper focuses on a model porous medium consisting of a Hele-Shaw cell with controlled random variations in gap spacing. By studying the roughening of an initially planar interface in this medium under forced imbibition, the authors aim to understand the physics governing roughening in real porous media.\n\nThe paper is structured as follows: after reviewing the scaling properties of rough interfaces and their experimental characterization in two-dimensional forced imbibition, the experimental setup, characterization parameters, and data analysis methodology are described. The experimental results are then presented and analyzed, with the final conclusions given in the last section.\n\nThe main findings of the paper are that the roughness exponent @xmath3, which characterizes the self-affinity of the interface, shows a clear dependence on the experimental parameters, while the roughness exponent @xmath2, which characterizes the local fluctuations, is almost independent of the disorder configuration, interface velocity, and gap spacing. The crossover wavenumber @xmath6, which separates the regime in which long length scale fluctuations are damped by the viscous pressure field from the regime in which short length scale fluctuations are damped by the interfacial tension in the plane of the cell, is found to increase with the capillary number @xmath0 and to become independent of @xmath0 for certain disorder configurations.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the investigation of kinetic roughening in a Hele-Shaw cell and the study of scaling properties.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The research problem of kinetic roughening of interfaces during forced imbibition is clearly highlighted.\n4. **Methodology**: The methodology involving a Hele-Shaw cell with controlled random variations and the use of silicone oil is mentioned.\n5. **Significant Results**: The summary includes significant results, such as the measurement of roughness exponents and the influence of disorder persistence.\n6. **Language**: The language used is clear and professional.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"roughness exponent\" and \"crossover wavenumber.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions key experiments involving the displacement of air by silicone oil and the analysis of disorder patterns.\n10. **Significance**: The summary reflects the paper's significance in understanding kinetic roughening and its potential impact.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the study of kinetic roughening in forced imbibition and the dependence of roughness exponents on experimental parameters.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is understanding the physics of roughening in porous media, is highlighted.\n4. The methodology, involving a model porous medium with a Hele-Shaw cell, is mentioned.\n5. Significant results, such as the dependence of the roughness exponent @xmath3 on experimental parameters, are included.\n6. The summary is written in clear and professional language.\n7. Technical terms like \"roughness exponent\" and \"crossover wavenumber\" are used but not explained, which may not fully align with the guideline to avoid jargon unless necessary.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments involving the Hele-Shaw cell and controlled gap spacing are mentioned.\n10. The summary reflects the paper's significance in understanding roughening in porous media."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the study of cosmic rays with energies near and above the greisen - zatsepin - kuzmin ( gzk ) cut - off @xmath1 ev @xcite is of great interest in particle astrophysics . above the gzk energy , proton interactions @xmath2 on cosmic microwave background ( cmb ) photons are possible . the universe in effect becomes opaque over mpc scales . to check the existence of this cut - off is therefore an important motivation for cosmic ray experiments like auger @xcite and hires @xcite . complementing the cosmic ray experiments , a number of experiments perform direct searches for ultra high energy ( uhe ) neutrinos from the gzk pion decays ( @xmath3 ) . the search for neutrinos above the gzk energy is also motivated in the context of grand unification theories ( gut ) @xcite . relic x-particles with ultra high mass @xmath4  ev originating from the gut phase - transition in the early universe could be decaying in the present epoch . thereby they would produce uhe neutrinos . as a final example of a theoretically very appealing possibility , is the z - burst process @xcite . in this scenario , the highest energy cosmic rays are produced following resonant interactions ( @xmath5 ) of uhe neutrinos on the relic neutrino background . to explain the full cosmic ray spectrum , this would require a very high flux of neutrinos in the @xmath6 regime to be present . limits constraining the possible uhe ! neutrino flux from these processes exist , with the most stringent one to date being presented by the anita - lite experiment @xcite .    among the various methods for detecting ultra high energy ( uhe ) particles , a promising technique utilizes the askaryan effect @xcite . this effect causes electromagnetic cascades , induced by the uhe particle interactions in dense media , to develop a negative charge excess . the charge excess will radiate coherently at radio wavelengths , thereby producing strong coherent pulses of erenkov radiation . in a series of accelerator experiments , the askaryan mechanism has been confirmed to work in different media . most important for our purposes , it was tested in silica sand specifically to mimic the conditions of the lunar material @xcite . it was first proposed by askaryan @xcite , later by dagkesamanskii and zheleznyk @xcite , that the radio transparent lunar regolith ( the 10 - 20 m deep surface layer of the moon , consisting mainly of fractured rock ) would be an ideal target for studying such uhe particles . an additional advantage is the absence of an atmosphere which implies that electromagnetic showers in the lunar regolith are caused by the primary cosmic particles . a number of attempts at observing cosmic ray induced radio waves from the moon have since been carried out using ground based radio telescopes . the first experiment @xcite used the 64 m diameter parkes radio telescope in australia to make coincidence measurements from two polarization channels . a 500-mhz band centered at 1.425 ghz was used after making appropriate corrections for the ionospheric delay between two sub - bands . the second was the goldstone lunar ultra - high energy neutrino experiment ( glue ) @xcite that used two large telescopes of the jpl / nasa deep space network in goldstone ( ca ) . a third experiment of this kind took place at kalyazin radio astronomical observatory , using again a single 64 m radio telescope @xcite . none of these experiments however , resulted in any detection of signals from uhe particles . under the name numoon , there is one currently on - going search using the westerbrok synthesis radio telescope ( wsrt ) in the netherlands @xcite . for future experiments with increased sensitivity there are proposals @xcite to study this effect with upcoming radio telescopes like the low frequency array ( lofar ) and the square kilometer array ( ska ) , or to use lunar orbiting artificial satellites carrying one or more radio antennas @xcite .    in this paper we study in detail the possibility of detection of uhecr and neutrino radio waves from the moon with the giant metrewave radio telescope ( gmrt ) facility @xcite . the gmrt comprises @xmath7 fully steerable dishes spread over distances up to @xmath8 km , each with a diameter of @xmath9 m. half of these antennas are distributed randomly over about @xmath10 km@xmath11 in a compact array while the rest are spread out in an approximate `` y '' configuration . the gmrt currently operates in eight frequency bands around @xmath12 , @xmath13 , @xmath14 , @xmath15 and @xmath16-@xmath17 mhz . the shortest baseline is @xmath18 m while the longest one is @xmath19 km . the telescope has an effective area in total of @xmath20 m@xmath11 for frequencies up to @xmath21 mhz and @xmath22 m@xmath11 at the higher frequencies . the rms sensitivity of the gmrt , using a @xmath23 s integration time and a bandwidth of @xmath24 mhz is @xmath25 mjy and @xmath26 mjy at @xmath21 mhz and @xmath27 ghz respectively . with such high sensitivity , we expect a substantial improvement from previous experiments in the measurement of the askaryan radio waves from the moon . high energy charged particles from uhe cosmic ray ( cr ) or uhe neutrino interactions in the lunar regolith will initiate a cascading shower with total energy @xmath28 and typical length scale @xcite @xmath29 in units of radiation length . for the lunar regolith with radiation length @xmath30 g / cm@xmath11 and density @xmath32 g/@xmath33 , the shower length for a particle with energy @xmath34 ev is therefore @xmath35 m. since the particles in the cascade travel at speeds very close to the speed of light the duration of the shower is @xmath36ns . the radio waves of about @xmath37 ns duration which are emitted from the lunar regolith are dispersed as they propagate through the atmosphere of the earth . the electrons in the ionosphere cause a time delay @xcite of @xmath38 seconds , where @xmath39 m@xmath40 is the typical night - time column density of electrons . the dispersion of a radio signal of frequency @xmath41 and bandwidth @xmath42 at zenith is therefore @xmath43 one must thus look for erenkov radio pulses of about @xmath18 ns duration from the moon and use coherent de - dispersion to recover the broadband structure of the signals . the intensity of radio waves on earth from a shower in the lunar regolith with energy @xmath28 emitting erenkov emission has been parameterized from simulations @xcite . at an angle @xmath44 to the shower axis , for radiation frequency @xmath41 and bandwidth @xmath42 , it is given by @xmath45}\\right)^2 \\ , \\frac{\\delta \\nu}{100\\,\\mathrm{mhz}}\\,\\,\\ , \\mathrm{jy } \\label{f}\\ ] ] where @xmath46 is the distance between the emission point on the moon s surface to the telescope and @xmath47 ghz . furthermore there is an angular dependence given by @xmath48 with @xmath49 and @xmath50 . the angular distribution of the radiation pattern is illustrated in fig . [ radioflux1 ] . in this figure we also show the commonly used gaussian approximation where the forward - suppression factor @xmath51 in ( [ f ] ) is ignored . for high frequencies this has no effect . for low frequencies , the differences at small angles only plays a role for showers nearly parallel to the surface normal , while the effects of changing the normalization near the erenkov angle is important also for more horizontal showers . a measure of the effective angular spread @xmath52 of the emission around the erenkov angle @xmath53 is given in terms of @xmath54 for the example in fig . [ radioflux1 ] this becomes @xmath55 . the erenkov radio waves are expected to be @xmath56 linearly polarized @xcite . radio signals should therefore be observed with both the lcp and rcp modes . a simultaneous triggering of both the lcp and rcp modes ( with @xmath57 of the total intensity in each mode ) will be a good signature of the transient erenkov radio wave emission from uhe particles . in addition , the large number of gmrt dishes should allow pointing discrimination and spatial - temporal coincidence measurements to be used for signal identification and background rejection . for cosmic rays , which produce showers by hadronic processes , the shower energy @xmath28 is equal to the energy of the primary particle . when instead the showers are produced by deep inelastic neutrino scattering off target nucleons , the fraction of the total energy which produces the hadronic showers is , on average , @xmath58 @xcite . we model the lunar regolith as a homogeneous medium with dielectric permittivity @xmath59 , hence refractive index @xmath60 . the erenkov angle is @xmath61 . the radio waves are also absorbed in the regolith , which we take to have a frequency dependent attenuation length @xmath62 m @xcite . this means the attenuation length of radio waves is always much smaller than the mean free path of the neutrinos , conveniently parameterized as @xmath63 km using the cross sections of @xcite . as can be seen from this expression , the mean free path for an uhe neutrino is not sufficient to escape the moon . most of the passing neutrinos will therefore interact in the material . the threshold energy required for showers to be detectable is determined by the sensitivity of the radio telescope . this is commonly presented in terms of a noise intensity @xmath64 where @xmath65 is the system temperature , @xmath66 is boltzmann s constant , @xmath67 the integration time , @xmath68 the bandwidth , and @xmath69 the effective area of the telescope . in units of jansky ( @xmath10 jy = @xmath70 w / m@xmath11/hz ) the noise intensity is given by @xmath71 at gmrt , for frequencies @xmath72 and @xmath21 mhz we use the effective area @xmath73 m@xmath11 while for the higher frequencies @xmath74 m@xmath11 . the integration time @xmath75 for the bandwidth limited case . in table 1 we list the system temperatures at the different observation frequencies and the corresponding noise levels . using equation ( [ f ] ) , we can solve for @xmath28 at the threshold required for measurement with the radio telescope ( obtained for @xmath76 and @xmath77 ) . if we take a required signal - to - noise ratio @xmath78 , the threshold shower energies @xmath79 which can be measured at gmrt at the different observation frequencies are listed in table 1 . the radio waves produced below the lunar surface get attenuated while propagating to the surface and they get refracted at the surface before reaching the telescope . the transmission coefficients are different for the electric field polarization which is parallel and perpendicular to the lunar surface . it is therefore convenient to express the erenkov radiation intensity ( [ f ] ) in terms of the electric field magnitude @xmath80 of the radio waves . the conversion is @xmath81 using this conversion we also list the threshold electric fields measurable at gmrt in table 1 . if attenuation is factored in separately , the quantity @xmath82 remains a constant between the point of emission and the point of refraction at the surface : @xmath83}\\right)\\ , \\frac{\\mu \\mathrm{v}}{\\mathrm{mhz } } . \\label{re}\\ ] ] at the surface , there is partial reflection which changes the intensity of the outgoing electric field . the electric field observed at the telescope is determined relates to the incident electric fields by the fresnel relations @xmath84 t_{\\parallel}=\\frac{r { \\cal e}_{\\parallel}}{(r { \\cal e}_{\\parallel})_\\mathrm{inc}}=\\frac{2 \\cos r}{n \\cos r+ \\cos i } \\label{fresnel}\\end{aligned}\\ ] ] where the angles of incidence @xmath85 and refraction @xmath86 are related by snell s law . the refraction angle is fixed by the polar angle @xmath87 through the geometrical condition @xmath88 here @xmath89^{1/2}$ ] is the distance between the detector and the point of refraction on the lunar surface , and @xmath90 km is the average earth - moon distance . putting everything together , the parallel component of the electric field at the telescope on earth is given by @xmath91 where @xmath92 is given by ( [ re ] ) as a function of @xmath44 and @xmath28 . the dependence on the polar angle @xmath87 of the radio flux on earth is shown in fig . [ flux_theta ] . evaluating @xmath92 at @xmath76 and equating @xmath93 with the threshold field @xmath94 which can be measured with the telescope , we obtain the threshold energy @xmath95 as a function of the polar angle @xmath87 . fig . [ threshold ] illustrates that for observing the radio waves from the limb of the moon ( @xmath96 for @xmath97 ) , one has to have a higher threshold energy of the shower owing to the fact that the transmission coefficients @xmath98 and @xmath99 vanish when @xmath100 . when @xmath101 is not large compared to @xmath102 ( which is the case for a telescope aboard a satellite orbiting the moon ) then only a small disc around the center of the moon will be visible .    by equating the signal @xmath103 at the erenkov angle we determine the threshold @xmath104 at different frequencies and bandwidths . the values so obtained are listed in table  [ tab1 ] . .gmrt parameters , sensitivity and threshold energy . @xmath105 is the noise intensity of gmrt and @xmath106 the corresponding electric field . the threshold energy in the last column is calculated with @xmath107 . [ cols=\"<,<,<,<,<,<,<,>\",options=\"header \" , ]     the event rate that would be expected at the telescope can be related to an isotropic flux @xmath108 of uhe particles on the moon through @xmath109 where @xmath110 denote the type of primary particle and @xmath111 is an aperture function corresponding to the effective detector area . we will differentiate between neutrinos , which have a large mean free path and therefore can penetrate the interior of the moon before producing the erenkov radio waves , and the strongly interacting cosmic rays ( referred to by the subscript @xmath112 ) which can penetrate only small distances below the surface of the moon . the aperture can be further decomposed into an angular aperture @xmath113 and a geometric area factor for the moon @xmath114 with @xmath115 km . to evaluate the aperture , we use the analytical methods described in @xcite . for the case of cosmic rays , the angular aperture is given by @xmath116 \\times \\theta(\\cos\\beta ) \\mathrm{d}\\alpha\\mathrm{d}\\cos\\beta , \\label{angle}\\ ] ] where @xmath117 and @xmath118 are the polar and azimuthal coordinates of the ray normal to the moon s surface in a system where the shower direction defines the @xmath119 axis . the full geometry and the different angles are described in fig . [ geometry ] . using the gaussian approximation for the radiation pattern , the angular aperture for cosmic rays is obtained by directly integrating over the shower coordinates @xmath120 : @xmath121.\\ ] ] here @xmath122 , and in the lower integration limit @xmath123 this takes into account all directions with sufficiently strong radio emission . after performing this integration , the expression for the angular aperture reduces to @xmath124 , \\label{omega - cr}\\ ] ] where @xmath125 and @xmath126 the total aperture for cosmic rays is obtained by substituting ( [ omega - cr ] ) in ( [ acr ] ) and integrating over the polar angle @xmath87 . when the uhe primary is instead a neutrino , it can produce showers deep below the surface of the moon and there will be considerable attenuation of the radio waves which travel distances longer than @xmath127 below the surface . for the neutrino induced showers , the aperture is defined in the same way as for the cr , but the angular aperture is now given @xcite by @xmath128-{\\cal e}_{th}\\bigr\\ } \\times \\exp[-l(z,\\beta)/\\lambda_{\\nu } ] \\times \\mathrm{d}\\alpha \\mathrm{d}\\cos\\beta , \\label{omega - nu}\\ ] ] where @xmath129 is the distance the neutrino travels inside the material to reach the interaction point at a distance @xmath119 below the surface . in performing this integration we allow @xmath119 to go below the known depth of the regolith . the aperture can therefore pick up contributions from sufficiently strong signals coming from deep showers , especially for the lower frequencies . numerically we find for the worst case ( when @xmath130 mhz ) , that imposing a sharp cutoff at a depth of @xmath131  m would reduce the aperture by nearly an order of magnitude , similarly to what was discussed in @xcite . it has been observed @xcite , that if the absorption length of radio waves @xmath127 is much smaller than the neutrino mean free path @xmath132 ( which is indeed here the case ) then eq . ( [ omega - nu ] ) reduces approximately to @xmath133 \\times \\mathrm{d}\\alpha \\mathrm{d}\\cos\\beta . \\label{omega - nu1}\\ ] ] as for the cosmic rays , the total aperture is obtained by substituting ( [ omega - nu ] ) into ( [ acr ] ) and integrating over the polar angle @xmath87 .    to estimate the sensitivity of gmrt to cosmic ray and neutrino events we have evaluated the angular apertures by employing this technique and performing numerical integrations for the different parameters given in table [ tab1 ] . in the next section we will discuss these results further in the context of prospective flux limits . should no events be observed at gmrt during observation over a time @xmath134 , an upper limit can be established on sufficiently smooth uhecr and neutrino fluxes at the moon . the conventional model - independent limit @xcite is given by @xmath135 where still @xmath136 , @xmath137 and @xmath138 . the poisson factor @xmath139 for a limit at @xmath140 confidence level . the limits on the flux of uhecr that could be established for 100 hours and 30 days of observation time at gmrt are shown in fig . [ crlimit100 ] and fig . [ crlimit30 ] respectively . we also show the results of carrying through our calculations for the lofar parameters given in @xcite . when compared to the lofar monte carlo simulation results , the two methods of calculation agree within a factor two over the full energy range . this is an acceptable discrepancy in level with known uncertainties from _ e.g. _ the regolith depth . a residual difference of @xmath141 is also expected since we used the gaussian approximation . the limit we obtain for the lofar parameters is less stringent than the one published , so in this respect our result constitutes a conservative estimate . > from comparing the limits for different frequencies , it can be seen that low frequency observations give more stringent limits on the flux at the expense of a higher threshold . this is due to the well - known increase in the aperture @xcite from radiation spreading at lower frequencies . the figures also show the auger data @xcite on uhe cosmic rays . although the extrapolation to higher energies is highly uncertain , the gmrt would most probably be sensitive to a post - gzk proton flux . similarly for the uhe neutrinos , prospective limits on their flux for @xmath142 hours and @xmath143 days are shown in figs . [ nlimit100 ] and [ nlimit30 ] . also here we show a calculation for the lofar parameters , again in quantitative agreement with previous results . since many radio experiments exist for uhe neutrino detection , we have compiled a comparison in fig . [ fluxgmrt ] . this figure contains , in addition to the gmrt results for @xmath130 mhz with two different observation times , the already existing limits from rice @xcite , glue @xcite , forte @xcite and anita - lite @xcite . also we have indicated the prospective future limits that has been calculated for anita @xcite , lofar @xcite or lord @xcite . we have calculated the potential for gmrt to detect uhe cosmic rays and neutrinos through their radio wave emission produced when showering in the lunar regolith . our results indicate that gmrt could be competitive to future experiments in the @xmath144 ev range . if one assumes that the cr spectrum continues beyond the gzk limit with unchanged energy dependence , observation of these particles with the gmrt should indeed be possible . for uhe neutrinos there exists a theoretical upper bound on the flux from cosmogenic sources , as given by waxman and bahcall @xcite : @xmath145 gevcm@xmath40 s@xmath147 sr@xmath147 . the gmrt could , using a mere 30 days of observation time , probe fluxes a factor five smaller . as a benchmark scenario , we indicate in fig . [ fluxgmrt ] the predicted flux from one td model where the mass scale resides around @xmath148 ev . it is notable that the gmrt ( for the low frequencies ) has only a somewhat higher threshold , and slightly worse sensitivity for this type of experiment , than will the lofar telescope . this clearly points to the interesting potential of utilizing the gmrt for uhe particle searches in the near future . the results we have presented here obviously depend on to what extent the experimental realization of these measurements are possible at the gmrt facility . we therefore foresee a future analysis taking more thoroughly into account the requirements on the technical infrastructure and the experimental techniques for signal identification and background discrimination . j. alvarez - muiz , r. a. vazquez , and e. zas , phys . rev . d*61 * , 23001 ( 1999 ) ; j. alvarez - muniz and e. zas , astr - ph/0102173 , in `` radio detection of high energy particles radhep 2000 '' , aip conf . 579 ( aip , new york , 2001 ) ;", "tags": [], "output_text_a": "This paper explores the potential for detecting ultra-high energy cosmic rays (UHECR) and neutrinos using the Giant Metrewave Radio Telescope (GMRT) by observing radio waves emitted from the Moon. The study focuses on particles with energies near and above the Greisen-Zatsepin-Kuzmin (GZK) cutoff, which are of significant interest in particle astrophysics. Above the GZK energy, protons can interact with cosmic microwave background photons, making the universe opaque over large scales. Detecting these particles is crucial for understanding cosmic ray origins and testing grand unification theories.\n\nThe paper discusses the Askaryan effect, where electromagnetic cascades in dense media develop a negative charge excess, radiating coherent radio waves. The lunar regolith, a radio-transparent layer on the Moon's surface, is an ideal target for detecting such emissions. Previous experiments using radio telescopes have not detected signals from UHE particles, but the GMRT's high sensitivity offers a promising improvement.\n\nThe GMRT consists of 30 fully steerable dishes with high sensitivity across various frequency bands. The study calculates the threshold energies required for detection and evaluates the potential event rates for UHECR and neutrinos. The results suggest that GMRT could be competitive with future experiments in detecting post-GZK cosmic rays and probing cosmogenic neutrino fluxes.\n\nThe paper concludes that GMRT has the potential to contribute significantly to UHE particle searches, with the capability to probe fluxes below theoretical upper bounds. Future work will focus on the technical and experimental requirements for implementing these measurements at the GMRT facility.", "output_text_b": "The article discusses the study of cosmic rays with energies near and above the Greisen-Zatsepin-Kuzmin (GZK) cut-off and the motivation for cosmic ray experiments like Auger and HiRes. The GZK cut-off is an important motivation for cosmic ray experiments as it makes the universe opaque to proton interactions on cosmic microwave background (CMB) photons over Mpc scales. The search for neutrinos above the GZK energy is also motivated in the context of Grand Unification Theories (GUT) and relic X-particles from the GUT phase-transition in the early universe. The paper also explores the possibility of detecting ultra-high energy (UHE) particles using the Askaryan effect, which causes electromagnetic cascades induced by UHE particle interactions in dense media to develop a negative charge excess. This charge excess radiates coherently at radio wavelengths, producing strong coherent pulses of radio waves.\n\nThe paper focuses on the possibility of detection of UHECR and neutrino radio waves from the moon with the Giant Metrewave Radio Telescope (GMRT) facility. The GMRT comprises fully steerable dishes spread over distances up to several kilometers, each with a diameter of 45 meters. The telescope has an effective area in total of 30,000 square meters for frequencies up to 300 MHz and 15,000 square meters at higher frequencies. The shortest baseline is 18 meters while the longest one is 19 kilometers. The telescope has an rms sensitivity of 0.3 mJy and 0.03 mJy at 210 MHz and 1.4 GHz, respectively.\n\nThe paper also discusses the threshold energy required for showers to be detectable, which is determined by the sensitivity of the radio telescope. The threshold energy required for measurement with the radio telescope is obtained by solving for Eshower at the threshold required for measurement with the radio telescope. If a required signal-to-noise ratio is taken, the threshold shower energies that can be measured at GMRT at the different observation frequencies are listed in table 1.\n\nThe event rate that would be expected at the telescope can be related to an isotropic flux of UHE particles on the moon through an aperture function corresponding to the effective detector area. The aperture can be further decomposed into an angular aperture and a geometric area factor for the moon. To evaluate the aperture, the paper uses analytical methods described in the reference. The angular aperture is given by the equation ([omega-cr]) for cosmic rays and by the equation ([omega-nu]) for neutrinos.\n\nThe total aperture is obtained by substituting the angular aperture into the equation for the aperture and integrating over the polar angle. The sensitivity of GMRT to cosmic ray and neutrino events is evaluated by employing this technique and performing numerical integrations for the different parameters given in table 1.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the potential of GMRT for detecting UHECR and neutrinos, the significance of the GZK cutoff, and the Askaryan effect.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of detecting UHECR and neutrinos and the significance of the GZK cutoff.\n4. **Methodology**: The summary mentions the use of the GMRT and the Askaryan effect as the methodology for detection.\n5. **Significant Results**: The summary includes significant results, such as the potential competitiveness of GMRT with future experiments and its ability to probe below theoretical upper bounds.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"Askaryan effect\" and \"GZK cutoff\" but provides sufficient context for understanding.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary mentions the GMRT and previous experiments but does not detail specific experiments or data used in the research.\n10. **Significance**: The summary reflects the paper's significance in contributing to UHE particle searches and its potential impact.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the study of cosmic rays, the GZK cut-off, and the use of the GMRT for detecting UHE particles.\n2. The summary exceeds the 250-word limit, making it less concise than required.\n3. The research problem addressed by the paper is mentioned, focusing on the detection of UHE particles and cosmic rays.\n4. The methodology, including the use of the GMRT and the Askaryan effect, is highlighted.\n5. Significant results, such as the threshold energy for detection and the sensitivity of the GMRT, are included.\n6. The language is clear and professional.\n7. The summary uses technical terms like \"Askaryan effect\" and \"GZK cut-off\" but does not explain them, which may not be accessible to all readers.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments and data, such as the use of the GMRT and the threshold energy calculations, are mentioned.\n10. The potential impact of the research, such as the GMRT's competitiveness in detecting UHE particles, is discussed."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "qcd is expected to undergo a transition to a deconfined state , where thermodynamics can no longer be described by hadronic degrees of freedom but should be described in terms of elementary quark and gluon degrees of freedom . in addition , the chiral symmetry which is broken in qcd vacuum is expected to be restored above some temperature . in the limit of zero quark masses the restoration of the chiral symmetry is expected to be a true phase transition . however , for the quark masses realized in nature this transition turns out to be an analytic crossover @xcite . a question naturally arises whether the deconfinement and the chiral transitions are closely related . early lattice calculations with large quark masses and/or coarse lattices suggested that deconfinement and chiral transition happen at the same temperature @xcite . however , more recent investigations that use so - called stout staggered quark action and finer lattices found that these two transitions are no longer interconnected @xcite . in this paper we are going to discuss the deconfinement and chiral transition in qcd at non - zero temperature using highly improved staggered quark ( hisq ) action and tree - level improved gauge action . we refer to this combination of quark and gauge actions as hisq / tree action . to control discretization effects calculations have been performed at three values of the lattice spacing corresponding to temporal extent @xmath0 and @xmath1 . to fix the lattice spacing we used the @xmath2 scale of the static quark potential @xcite and the kaon decay constant @xmath3 . additional calculations using the asqtad action with @xmath4 and @xmath1 have been performed to demonstrate the consistency of the results obtained with different actions , since the asqtad action was extensively used in the past to study qcd at non - zero temperature @xcite . the breaking of the chiral symmetry in qcd vacuum is signaled by non - zero expectation value of quark condensate @xmath5 . at non - zero temperature the quark condensate is expected to decrease , signaling the restoration of the chiral symmetry . however , the quark condensate needs a multiplicative , and for non - zero quark mass , also an additive renormalization . therefore following ref . @xcite we consider the following quantity , which we will call the renormalized chiral condensate @xmath6 here @xmath7 and @xmath8 refer to quark condensate at zero and non - zero temperatures , @xmath9 and @xmath10 for light and strange quarks , respectively . the numerical results are shown in fig . [ fig : deltals ] using the lattice spacing determined by @xmath2 parameter and @xmath3 . we also show the continuum estimate for @xmath11 obtained with the stout action in fig . [ fig : deltals ] . we use the value @xmath12fm @xcite and @xmath13mev @xcite when setting the scale in mev . when @xmath2 is used to set the scale we see large deviations for asqtad action , while for hisq / tree action these deviations are largely reduced . interestingly enough , when @xmath3 is used to set the scale almost no cutoff effect is seen in @xmath11 both for hisq / tree and asqtad action . this feature was first noticed for stout action @xcite . the difference in the stout action and our result is due to the small difference in the light quark mass @xmath14 . in our calculation @xmath15 , while the stout calculations correspond to @xmath16 . here @xmath17 is the physical strange quark mass . if we perform interpolation in the quark mass using @xmath18 scaling , which can describe the quark mass dependence of the chiral observables obtained with p4 action very well @xcite , to the value @xmath16 we get a very good agreement with the stout results . is compared with the continuum extrapolated data obtained with the stout action @xcite ( left panel ) . the temperature @xmath19 is converted into physical units using @xmath2 in the left panel . in the right panel we show the temperature dependence of the same subtracted chiral condensate for the hisq / tree and asqtad actions using @xmath3 to set the scale . the black diamonds show hisq / tree results for @xmath4 after interpolation to the physical quark mass @xmath16 . , title=\"fig:\",scaledwidth=45.0% ]   is compared with the continuum extrapolated data obtained with the stout action @xcite ( left panel ) . the temperature @xmath19 is converted into physical units using @xmath2 in the left panel . in the right panel we show the temperature dependence of the same subtracted chiral condensate for the hisq / tree and asqtad actions using @xmath3 to set the scale . the black diamonds show hisq / tree results for @xmath4 after interpolation to the physical quark mass @xmath16 . , title=\"fig:\",scaledwidth=45.0% ] quark number susceptibilities , i.e. fluctuations of the quark numbers are sensitive probe of deconfinement . these can be defined as second derivatives with respect to quark chemical potential evaluated at zero chemical potentials @xmath20 at low temperatures quark number fluctuations are determined by massive hadrons and therefore are quite small , while at high temperatures they are determined by light quark degrees of freedom and thus proportional to @xmath21 . the deconfinement transition can bee seen as a rapid change between these two limiting behaviors and thus the quark number susceptibilities are expected to show a rapid increase . in fig . [ fig : chiq ] we show the light and strange quark number susceptibilities and we clearly see the expected rapid rise in these quantities . as before the lattice spacing was fixed using @xmath2 and @xmath3 . if @xmath3 is used to fix the scale cutoff effects turn out to be very small . the rapid rise in the light quark number susceptibilities happens at temperatures , where @xmath11 sharply decreases . the strange quark susceptibility shows a rapid rise at somewhat higher temperatures . note , however , that this behavior of quark number susceptibilities is not related to different transition temperatures . the inflection points of quark number susceptibilities are dominated by the regular part of the free energy density , and the difference in the inflection points is simply due to the difference in the quark mass . is used to set the lattice scale , while in the right panel we use @xmath3 . the filled squares correspond to @xmath22 . , title=\"fig:\",scaledwidth=49.0% ]   is used to set the lattice scale , while in the right panel we use @xmath3 . the filled squares correspond to @xmath22 . , title=\"fig:\",scaledwidth=49.0% ]    the polyakov loop is an order parameter for the deconfinement transition in pure gauge theory , which is governed by @xmath23 symmetry . for qcd this symmetry is explicitly broken by dynamical quarks . there is no obvious reason for the polyakov loop to be sensitive to the singular behavior close to the chiral limit although speculations along these lines have been made @xcite . the polyakov loop is related to the screening properties of the medium and thus to deconfinement . after proper renormalization , the square of the polyakov loop characterizes the long distance behavior of the static quark anti - quark free energy ; it gives the excess in free energy needed to screen two well - separated color charges . the renormalized polyakov loop has been studied in the past in pure gauge theory @xcite as well as in qcd with two @xcite , three @xcite and two plus one flavors @xcite . the renormalized polyakov loop , calculated on lattices with temporal extent @xmath24 , is obtained from the bare polyakov loop @xmath25 where @xmath26 and @xmath27 is the additive normalization of the static potential chosen such that it coincides with the string potential at distance @xmath28 with @xmath29 being the sommer scale . this procedure of normalizing the polyakov loop follows ref . some earlier calculations used the singlet free energy in coulomb gauge to estimate the renormalized polyakov loop @xcite . while the former procedure is expected to be more precise both procedures give the same results within errors . the numerical results for the renormalized polyakov loop for the hisq / tree action are shown in the right panel of fig . [ fig : tc_and_lren ] as function of @xmath30 , with @xmath31 being the transition temperature . as one can see from the figure the cutoff ( @xmath32 ) dependence of the renormalized polyakov loop is small . we also compare our results with the continuum extrapolated stout results @xcite and the corresponding results in pure gauge theory @xcite . we find good agreement between our results and the stout results . we also see that in the vicinity of the transition temperature the behavior of the renormalized polyakov loop in qcd and in the pure gauge theory is quite different . ( right ) . for the hisq / tree data we used the values of @xmath31 discussed in @xcite , while for stout data we used the value of @xmath33 mev from the inflection point of renormalized chiral condensate @xcite.,width=294 ] in this contribution we discussed different quantities , which characterize the deconfinement and chiral transition in qcd at non - zero temperature and studied their cutoff dependence . we showed that when the kaon decay constant @xmath3 is used to set the scale ( lattice spacing ) the cutoff effects in different quantities are quite small and calculations performed with the asqtad and hisq / tree actions are in good agreement with calculations performed with the stout action . we pointed out that it is difficult to define the deconfinement temperature . different observables that are used to characterize the deconfinement transition show rapid rise at different temperatures , which in turn , could be different from the chiral transition temperature . this is due to the fact that the observables used to study the deconfinement transition are not sensitive to the singular part of the free energy density or have limited sensitivity to it . this work has been supported in part by contracts de - ac02 - 98ch10886 and de - fc02 - 06er-41439 with the u.s . department of energy and contract 0555397 with the national science foundation . the numerical calculations have been performed using the usqcd resources at fermilab as well as the bluegene / l at the new york center for computational sciences ( nyccs ) . y.  aoki _ et al . _ , phys . b * 643 * , 46 ( 2006 ) y.  aoki _ et al . _ , jhep * 0906 * , 088 ( 2009 ) s.  borsanyi _ et al . _ [ wuppertal - budapest collaboration ] , jhep 1009 , 073 ( 2010 ) c.  aubin _ et al . _ , phys .  rev . d * 70 * , 094505 ( 2004 ) .", "tags": [], "output_text_a": "This paper investigates the deconfinement and chiral transitions in Quantum Chromodynamics (QCD) at non-zero temperatures using the highly improved staggered quark (HISQ) action and tree-level improved gauge action, referred to as HISQ/tree action. The study aims to understand whether these transitions are interconnected, as early lattice calculations suggested they occur at the same temperature, but recent findings indicate they may not be related. The research uses three values of lattice spacing to control discretization effects and compares results with the Asqtad action to ensure consistency. The paper examines the renormalized chiral condensate and quark number susceptibilities, which are sensitive to deconfinement, showing a rapid rise at certain temperatures. The study also analyzes the renormalized Polyakov loop, an order parameter for deconfinement, and finds good agreement with previous results. The findings highlight the difficulty in defining a precise deconfinement temperature, as different observables show rapid changes at varying temperatures, which may differ from the chiral transition temperature. The research is supported by the U.S. Department of Energy and the National Science Foundation, with numerical calculations performed using USQCD resources and the BlueGene/L at the New York Center for Computational Sciences.", "output_text_b": "This arXiv paper discusses the deconfinement and chiral transitions in QCD at non-zero temperature using highly improved staggered quark (hisq) action and tree-level improved gauge action, referred to as hisq/tree action. The study aims to control discretization effects by performing calculations at three values of the lattice spacing. Additional calculations with the asqtad action are conducted for consistency checks. The paper focuses on the renormalized chiral condensate and quark number susceptibilities as probes of deconfinement. The renormalized chiral condensate is expected to decrease with increasing temperature, indicating chiral symmetry restoration, while quark number susceptibilities show a rapid increase near the deconfinement transition temperature. The paper also examines the cutoff dependence of different quantities and observes good agreement between calculations performed with the asqtad, hisq/tree, and stout actions when the kaon decay constant is used to set the scale.", "score": 0.19999999999999996, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, discussing the deconfinement and chiral transitions in QCD and the methodologies used.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of whether deconfinement and chiral transitions are interconnected.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of HISQ/tree action and lattice spacing to control discretization effects.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the difficulty in defining a precise deconfinement temperature.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms but explains them adequately.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of lattice spacing and comparison with Asqtad action.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in understanding QCD transitions.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the deconfinement and chiral transitions in QCD at non-zero temperature using the hisq/tree action.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding deconfinement and chiral transitions in QCD.\n4. **Methodology**: The methodology, including the use of hisq/tree action and calculations at different lattice spacings, is mentioned.\n5. **Significant Results**: Significant results, such as the behavior of the renormalized chiral condensate and quark number susceptibilities, are included.\n6. **Language**: The language is clear and professional.\n7. **Technical Jargon**: The summary uses some technical terms like \"renormalized chiral condensate\" and \"quark number susceptibilities\" but does not explain them, which might be necessary for clarity.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions the use of different actions and lattice spacings but does not detail specific experiments or data.\n10. **Significance/Impact**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the ability to perform quantum error correction ( qec ) by feedback is a crucial step towards fault - tolerant quantum computation @xcite . an open challenge , that has drawn considerable interest recently@xcite , is to find the best strategy for this task . two nominally distinct feedback strategies for qec are the measurement - based and driven - dissipative approaches . the former has been more well - understood@xcite , owing to an existing foundation in classical control and feedback in engineering . in the measurement - based ( mb ) approach , a classical controller performs projective measurements of a set of multi - qubit stabilizer operators that encode the logical qubit@xcite in order to track errors and/or perform any necessary correction . thus for good performance , this approach requires both high - fidelity projective measurements and low - latency control electronics to process the measurement result within the relevant coherence times of the quantum system . the elements required for this mb strategy have been demonstrated for small quantum systems on various physical platforms such as rydberg atoms@xcite , trapped ions@xcite , photons@xcite , spin@xcite and superconducting qubits@xcite . however , a steady - state multi - qubit qec capability has yet to be achieved and one of the key questions for this development is whether the mb strategy is scalable to larger systems or whether an alternative approach is more optimal . one such alternative , driven - dissipative ( dd ) schemes@xcite , also called reservoir / bath engineering or coherent feedback ( as discussed below ) , utilizes coupling between the quantum system of interest and a dissipative environment to transfer the entropy caused by decoherence - induced errors out of the quantum system . they have been demonstrated on a variety of physical systems including atomic ensembles@xcite , trapped ions@xcite , mechanical resonators@xcite and superconducting qubits@xcite . moreover , experiments with trapped ions@xcite and superconducting qubits@xcite have demonstrated some of the basic elements of autonomous qec . these schemes do not require high - fidelity projective measurements , external control and its associated latency . they can also be described as autonomous or coherent feedback@xcite , where the reservoir coupled to the target quantum system can be considered as an effective `` quantum controller '' that reacts with quantum degrees of freedom@xcite . adjusting the feedback by changing the `` quantum controller '' , however , can be more challenging than re - programming a classical controller , built with conventional electronics . thus , a further question is whether one can combine this dd approach and the conventional mb approach with minimal negative consequences from their respective drawbacks . here we report an experiment in which we built a feedback platform utilizing a nearly quantum - limited measurement chain and a customized field - programmable gate array ( fpga ) system to perform mb and dd schemes within the same setup . the task of this platform was to stabilize an entangled bell state of two superconducting transmon qubits@xcite . this particular task of stabilizing a single state is a proxy for more general qec experiments where a manifold of states is protected . we realize , for the first time , an mb _ stabilization _ of a bell state by repeated active correction through conditional parity measurements@xcite . we compare this scheme to a dd entanglement stabilization scheme@xcite in which the conditional parity switch is autonomous . by performing both schemes on the same hardware setup and circuit qed ( cqed ) system@xcite , we shed light on their close connection and compare them on a level playing field . previous theoretical works have compared dd ( under the name of `` coherent feedback '' ) and mb for linear quantum control problems@xcite , such as for minimizing the time required for qubit state purification@xcite or for cooling a quantum oscillator@xcite . these comparisons showed coherent feedback to be significantly superior . in our particular setup , we find that distinguishing the superior approach among dd and mb is a more subtle task . the subtlety is two - fold . first , the performance difference depends on which process can be better optimized : the design of the cqed hamiltonian or the efficiency of quantum measurement and classical control . in the current experiment , we show that dd has better steady - state performance as the cqed hamiltonian parameters are engineered such that dd has a shorter feedback latency . but dd s advantage over mb is not immutable . as certain experimental parameters are improved , such as coherence times and measurement efficiency , mb s performance can catch up with dd . secondly , in the current situation in which neither the cqed hamiltonian parameters nor the measurement and control parameters are ideal , we can obtain a boosted performance by combining dd and mb to get the best of both worlds . we explored this by devising a heralding method to improve the performance of both stabilization approaches . this protocol exploits the high - fidelity measurement capability and the programmability of the feedback platform . the protocol is termed `` nested feedback '' since it has an inner feedback loop based on either the dd or mb scheme , and an outer loop that heralds the presence of a high - fidelity entangled state in real - time . previously , heralding schemes have been demonstrated for state preparation to combat photon loss or decoherence@xcite . extending such heralding capability to state stabilization will be a valuable addition to the qec toolbox . furthermore , the ability to herald in real time as opposed to post - selection is important for on - demand and deterministic quantum information processing since only successful events lead to subsequent processing . real - time heralding for entanglement stabilization is particularly challenging for superconducting qubits due to their shorter coherence times compared to other systems . in this article , we implement this real - time heralding capability on a time scale faster than the few microsecond coherence time of our qubit - cavity system . by extending the feedback platform developed primary for the mb approach to the dd approach , our results bring to light a new application of mb . adding a level of mb feedback can significantly improve performance beyond what a single layer of feedback , whether dd or mb , can achieve . the simplified schematic of our experimental setup is shown in fig .  [ fig : schematic]a . two transmon qubits@xcite , alice and bob , are dispersively coupled to a three - dimensional aluminum cavity @xcite , with linewidth @xmath0  mhz ( see supp i , for other parameters ) . the qubit - cavity dispersive shifts are nearly equal and in the strong dispersive regime ( @xmath1  mhz , @xmath2  mhz ) with photon - number resolved qubit transition frequencies@xcite . the cavity output is amplified by a josephson parametric converter ( jpc ) operated as a nearly quantum - limited phase - preserving amplifier @xcite enabling rapid , single - shot readout@xcite and thus real - time feedback . the key component of the experiment is a controller realized with two fpga boards that both measure and actively control the cavity - qubit system . an essential operation for our experiment is a two - qubit joint quasi - parity measurement using the common readout cavity @xcite . as shown in fig . [ fig : schematic]b , the cavity is driven at @xmath3 ( both qubits in ground state ) and at @xmath4 ( both in the excited state ) at the same time . the output at @xmath3 and @xmath4 together distinguishes the even parity manifold @xmath5 from the odd parity manifold @xmath6 . when the two cavity output responses _ both _ have an amplitude below a certain threshold , the qubits are declared to be in odd parity ; when either one has amplitude above the threshold , the qubits are declared to be in even parity . we note that , unlike a true parity measurement , this readout actually distinguishes the two even parity states @xmath7 and @xmath8 , hence we refer to it as a `` quasi '' parity measurement . however , the feedback schemes described below apply the same operation on both even states , and thus we need only record the parity of the measured state . the choice of driving at the `` even '' cavity resonances rather than between the `` odd '' resonances ( @xmath9 and @xmath10 ) mitigates the effect of the @xmath11 mismatch , reducing associated measurement - induced dephasing of the odd manifold@xcite . the controller fpga a ( b ) modulates the @xmath3 ( @xmath4 ) drive to the cavity and also demodulates the response . the two fpgas share their measurements of the cavity response to jointly determine the parity . in addition , fpga a and b generate the qubit pulses to alice and bob , respectively , which are conditioned on the joint state estimation during real - time feedback . we first briefly outline the dd stabilization of entanglement , described in detail in ref .   and . this stabilization targets the two - qubit bell state @xmath12 . figure  [ fig : comparison]a displays the states coupled by the autonomous feedback loop . two rabi drives on alice and bob at their zero - photon qubit frequencies ( @xmath13 and @xmath14 , see supp . mat . sec . i ) couple the wrong bell state @xmath15 to the even states , @xmath7 , @xmath8 , in the energy manifold with zero cavity photons . a second pair of rabi drives at the @xmath16-photon qubit frequencies ( @xmath17 and @xmath18 , @xmath19 ) , with their relative phase opposite to the first pair , couple @xmath20 , @xmath21 to the bell state @xmath22 . the two cavity drives , at @xmath3 and @xmath4 connect the two manifolds and hence the combined action of the six drives transfers the population from @xmath7 , @xmath8 and @xmath23 to @xmath22 . finally , cavity photon decay brings @xmath22 back to @xmath24 . in effect , the cavity drives separate qubit states based on their parity , allowing one pair of rabi drives to move the erroneous odd population to the even states while the other pair transfers the even states population to @xmath25 . counterparts to these elements of the dd feedback loop can be found in the corresponding mb feedback scheme . the action of our mb algorithm is shown as a state machine in fig . [ fig : comparison ] . we describe the quasi - parity measurement @xmath26 by the projectors @xmath27 , @xmath28 and @xmath29 . we assign the outcomes @xmath30 to the even projectors , @xmath31 and @xmath32 and @xmath33 to @xmath34 . the mb algorithm is built with a sequence of correction steps , each of which consists of a conditional unitary and a quasi - parity measurement . the two possible states of the state machine correspond to whether we apply the unitary @xmath35 or @xmath36 , followed by the quasi - parity measurement . specifically , @xmath37 where a ( b ) denotes alice ( bob ) , and @xmath38 . in a correction step @xmath39 , the qubits are initially in either @xmath7 , @xmath8 or in the odd manifold , due to the projective quasi - parity measurement in step @xmath40 ; the controller then applies @xmath35 ( @xmath36 ) if @xmath41 in previous step reported @xmath42 ( @xmath43 ) . the effect of the state machine on the two - qubit states is shown in tab . [ tabu : mb ] , where the action of the controller during one correction step is described in terms of the four basis states , @xmath25 , @xmath15 , @xmath7 and @xmath8 ( the latter two are grouped in the `` even '' column ) . the quasi - parity measurement infidelity , labeled by @xmath44 ( @xmath45 ) , gives the error probability of obtaining an even ( odd ) parity outcome after generating an odd ( even ) state . because these measurement infidelities are small , the dominant events are those that occur without measurement errors . at each step , @xmath35 on either @xmath7 or @xmath8 followed by the quasi - parity measurement @xmath26 transfers the states to @xmath46 with 50% probability . since @xmath25 is an eigenstate of @xmath36 and @xmath26 ( modulo a deterministic phase shift that can be undone , see later discussion ) , these operations leave it unaffected . on the other hand , @xmath36 and @xmath26 transform @xmath47 into @xmath5 ; more generally , they take population in any other odd state ( i.e. , a superposition of @xmath25 and @xmath47 ) into @xmath25 and the even states .    l4 cm | p1.8 cm | p1.8 cm | p1.8 cm | p1.8cm| p0.9 cm | p0.9 cm | p0.9 cm | p0.9 cm previous state & & & + @xmath48 & @xmath49 & @xmath50 & @xmath49 & @xmath50 & & + outcome probability & @xmath44 & @xmath51 & @xmath44 & @xmath51 & & + unitary & @xmath35 & @xmath36 & @xmath35 & @xmath36 & & + next state & even & @xmath52 & @xmath47 & even & & +    by repeating a sufficient number of these correction steps in sequence , the controller stabilizes the target bell state irrespective of the initial two - qubit state . the similarity between this active feedback and dd is that mb also transfers population between different parity states by conditional rabi drives . however , while the rabi drives in dd are conditioned autonomously by the photon number in the cavity , the unitary rabi pulses in mb are conditioned by real - time parity measurement performed by active monitoring of cavity outputs . the pulse sequences for dd and mb are shown in fig . [ fig : comparison]b and e. in dd , a set of continuous - wave drives are applied for a fixed time @xmath53 and after some delay @xmath54 to allow remaining cavity photons to decay , a two - qubit state tomography is performed @xcite . the cavity and rabi drive amplitudes and phases were tuned for maximum entanglement fidelity , following the procedure described in ref .  . in particular , the optimal cavity drive amplitudes were found to be @xmath55 . for mb , the continuous drives are replaced by a pre - defined number of correction steps @xmath56 , resulting in a stabilization duration of @xmath57 where @xmath58  @xmath59s . there is no extra delay before tomography since each correction step already contains a delay after the quasi - parity measurement due to feedback decision latency . the strength and duration of the quasi - parity measurement @xmath26 were optimized as discussed in supp .  mat . the optimization achieved low parity measurement infidelities @xmath44 and @xmath45 while keeping the measurement - induced dephasing arising from the @xmath11 mismatch@xcite small compared to the natural decoherence in the same duration . we experimentally determined the infidelity of the quasi - parity measurement to be @xmath44 and @xmath45 of @xmath60 and @xmath61 , respectively . the quasi - parity measurement also causes a deterministic qubit rotation about the respective @xmath62 axis due to an ac stark shift  @xcite ; this rotation was corrected within the unitary gate @xmath36 as discussed in supp . [ fig : comparison]c , f show the fidelity to the target bell state @xmath25 as a function of stabilization time for dd and mb , respectively . the fidelity rises exponentially with a characteristic time constant of @xmath63  @xmath59s ( @xmath64  @xmath59s ) and a steady - state fidelity of @xmath65 ( @xmath66 ) for dd ( mb ) . both fidelity values agree with numerical modeling based on master equation simulation , which gives @xmath65 and @xmath67 for dd and mb , respectively ( see supp .  mat . iv ) . the exponential dependence is a signature of feedback and arises from the characteristic loop time . the experimentally determined time constants are in reasonable agreement with their simulated values of @xmath68  @xmath59s ( @xmath64  @xmath59s ) for dd ( mb ) . in mb , this loop time is related to the step length ( @xmath69  @xmath59s ) , which is given by the sum of the quasi - parity measurement duration ( @xmath70  @xmath59s ) , the cable , instrument and fpga latencies ( @xmath71  @xmath59s ) , and the duration of unitary pulses ( @xmath72  @xmath59s ) . on the other hand for dd , the measured loop time is close to @xmath73 cavity lifetimes , the expected time as shown in ref .  . the superior performance of dd over mb for the steady - state fidelity is due to the difference in correction loop time , which needs to be shorter than the coherence times of the two qubits for high fidelity entanglement . for the current experimental setup , the latency of the controller and quantum efficiency of the measurement chain , which affects the fidelity of the single - shot readout , result in a longer loop time in mb . a source of the longer feedback loop time is the quasi - parity measurement duration . this measurement duration , which was optimized as discussed in supp . ii , is limited by dephasing induced by the mismatch in @xmath11 ( @xmath74 ) and the measurement efficiency of the output chain ( @xmath75 ) , which can both be improved in future experiments . our simulations ( see supp .  mat .  sec . iv ) suggest that with current state - of - the - art measurement efficiency value and optimization of the fpga / cable latency , the mb steady state fidelity can be improved to @xmath76 . the limited measurement efficiency does not affect the performance of dd because the parity measurement and correction take place autonomously within the qubit - cavity system , indicative of its robustness against this hardware limitation . on the other hand , both dd and mb schemes benefit from longer intrinsic coherence times and reduction of the @xmath11 mismatch . for example , simulations show that if the coherence times are improved to one hundred microseconds ( achieved in other state - of - the - art cqed setups ) , both dd and mb fidelities can increase to above 85% . for the rest of the article , however , we consider boosting the fidelity in a different manner , without making any physical changes to the qubit - cavity system . the dd and mb schemes described so far are synchronous in the sense that the stabilization always ends after a pre - determined duration and the tomography follows . decoherence causes the qubits to have a finite probability of jumping out of the target state immediately before the stabilization terminates . hence , this `` fixed time '' protocol does not always output the target state with maximum fidelity . an optimum protocol would rather utilize all available information . for both dd and mb , we can measure the cavity output at the end of the stabilization period . the outcomes of these measurements , @xmath77 and @xmath78 , give real - time information on the state of the two qubits , and thus can herald a successful stabilization sequence .    in fig . [ fig : thresh_sweep ] , we describe how monitoring the cavity outputs improves target state fidelity . we introduce two thresholds @xmath79 ( see supplementary material for details ) to post - select the measurement outcomes of @xmath77 and @xmath78 respectively , and identify successful stabilization runs @xcite . the results of varying @xmath79 are shown in fig . [ fig : thresh_sweep]b , d for dd and mb , respectively . the color plots show fidelity improving as the thresholds become more stringent . the success probability defined as the percentage of stabilization runs kept for tomography given a set of thresholds , is also plotted as contours for both dd and mb . there is a clear trade - off between success probability and fidelity . to reach the maximum fidelity in dd of 82% , at least 75% of experiment runs need to be discarded . the trade - off is less severe in mb , where only 50% of runs need to be discarded to reach the maximum fidelity of 75% . however we aim to eliminate this trade - off all together , i.e. , to improve the fidelity while maintaining a high success probability . this goal is achieved by introducing a nested feedback protocol ( nfp ) , in which the stabilization feedback loop enters into a higher layer of feedback for `` fidelity boosting '' instead of proceeding to state tomography directly . in contrast to the `` fixed time '' protocol , nfp conditions the termination of stabilization on the quality of the entanglement , i.e. , it heralds a successful stabilization run in real - time , as illustrated by the state machine diagram in fig . [ fig : real_time]a . the control variable @xmath80 is given by @xmath81 , where @xmath79 are determined by the same post - selection experiment discussed previously to optimize the fidelity ( black square in fig . 3b and d ) . if the controller determines that the entanglement quality is not sufficient ( @xmath82 ) , a boost phase is attempted which comprises exactly one correction step for mb or a stabilization period of similar duration for dd ( @xmath64  @xmath59s ) . during the boost phase , the cavity outputs are integrated to give @xmath83 which enables the next real - time assessment of @xmath80 . in dd , the parity measurement and first layer of feedback is accomplished autonomously , therefore the fpga only needs to check @xmath80 . however in the mb scheme both layers of feedback are performed solely by the fpga . it therefore checks if @xmath84 to herald that the entanglement meets the desired quality . if not , it uses the quasi - parity thresholds ( grey circles in fig . 3d ) to decide whether the qubits are in even or odd state in order to continue stabilization . this asynchronous pulse sequencing and conditioning by multiple thresholds exploit the programmable nature of the fpga - based platform .    the asynchronous behavior of nfp is displayed in fig .  [ fig : real_time]b(e ) for dd ( mb ) , which demonstrates 200 single - shot runs . the dd ( mb ) fidelity boosting sequence continues until either success or a maximum limit on boost attempts ( set to 11 in the experiment ) is reached . for the mb protocol , the trajectory of the qubits parity can be tracked by the conditioning outcomes of the inner - loop control variable @xmath41 and the outer - loop control variable @xmath80 , which are independent . through repeated boost attempts until success , nfp significantly improves the overall success probability . within 11 attempts , 95% ( 99.8% ) of dd ( mb ) runs satisfy the success condition compared to just 25% ( 50% ) with simple post - selection . this is assessed by the cumulative probability , the integral of the probability of having completed a certain number of boost attempts before tomography , as plotted in fig . [ fig : real_time]c , f . since mb requires a less stringent threshold than dd to gain fidelity improvement , the mb success probability converges to unity much faster than that of dd . finally , we show that the high success probability does not come at the cost of reduced fidelity . the fidelity to @xmath25 for dd improves from an unconditioned value of 76% to 82% ( averaged over all successful attempts ) . for mb , the improvement is more pronounced : fidelity rises from an unconditioned value of 57% to 74% . thus for both dd and mb , nfp attain close to the fidelity achieved via stringent post - selection . these results for nfp also agree well with a numerical simulation ( see supp .  mat .  sec . one will note , however , a continuous downward trend of the fidelity in both dd and mb schemes as the number of attempts increases . this is due to the non - negligible population in the @xmath85 states of the two qubits in the experiment , which escape correction by the stabilization feedback loops . after each further boost attempt of stabilization , the probability of the population escaping outside the correction space thus increases , diminishing the fidelity ( see supp .  mat . vii ) . also note that the error bars on the fidelity of mb are bigger than those in dd for large attempt numbers simply because the probability of needing many attempts is lower in mb than in dd . while real - time heralding by nfp removes the trade - off between fidelity and success probability , it does so by introducing a different trade - off  high fidelity and success probability are achieved but the protocol length now varies from run to run . if nfp is a module within a larger quantum information processing ( qip ) algorithm , then this asynchronous nature must be accommodated by the controller . for our fpga - based control , nfp is easily accommodated because it is a natural extension to `` fixed - time '' or synchronous operation . in `` fixed time '' operation , the controller conditions its state by the protocol length which is pre - determined and stored in an internal counter by the experimenter . on the other hand in nfp , the controller conditions its state on a pre - determined logical function of its real - time inputs . in conclusion , we have implemented a new mb stabilization of an entangled state of two qubits , which parallels a previous dd stabilization scheme . instead of coherent feedback by reservoir engineering , mb relies on actively controlled feedback by classical high - speed electronics external to the quantum system . when comparing both schemes in the `` fixed - time '' protocol , we observe that dd gives a higher fidelity to the target state due to lower feedback latency . furthermore , we have improved the fidelity of both schemes by a nested feedback protocol which heralds stabilization runs with high - quality entanglement in real time . the real time heralding brings about the fidelity improvement without a common trade - off in qip : it does not sacrifice the experiment success probability . it eliminates this trade - off by allowing asynchronicity in the experiment . our experiment shows some of the key advantages of mb platforms that have not been previously explored . typically , the performance of mb feedback has not been at par with methods based on post - selection , due to the latency of the controller . however it is widely recognized that the trade - off of success probability for fidelity in the case of post - selection is untenable for large scale systems . therefore , existing digital feedback@xcite have focused on achieving nearly perfect success probability . here , we are exploring another direction of feedback which achieves high fidelity with high success probability . our nested feedback strategy maximizes the use of the information coming out of the qubit - cavity system in order to make the correction process as efficient as possible . we find that our feedback platform , comprised of a nearly - quantum - limited measurement chain and a real - time classical controller , provides the necessary tool - set to implement such a strategy . we show that this technology can be extended to improve the performance of dd approaches as well as single - layer mb approaches themselves . this strategy could be carried out further in the future . for example , the fpga state estimator could perform a more sophisticated quantum filter of the microwave output of the dd stabilization to herald successful events with better accuracy , significantly improving the success probability convergence rate . similar ideas can be applied in the future towards other forms of stabilization , such as for stabilizing schrdinger cat states of a cavity mode@xcite , a proposed logical qubit . initial experiments on such logical qubits with high fidelity - measurement@xcite or dissipation engineering@xcite have been performed and could now be combined . likewise , future logical qubits based on the surface code@xcite could also be stabilized by either active stabilizer measurements@xcite or as recently proposed by dissipation engineering@xcite . our experiment demonstrates that measurement - based and driven - dissipative approaches , far from being antagonistic , can be merged to perform better than either approach on its own . we thank zaki leghtas , mazyar mirrahimi , matti silveri and shantanu mundhada for helpful discussions . this research was supported by the u.s . army research office ( w911nf-14 - 1 - 0011 and w911nf-14 - 1 - 0563 ) . facilities use was supported by the yale institute for nanoscience and quantum engineering and nsf mrsec dmr 1119826 . all statements of fact , opinion or conclusions contained herein are those of the authors and should not be construed as representing the official views or policies of the u.s . government . 62ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty @noop _ _  ( , ) @noop * * ,   ( ) link:\\doibase 10.1103/physrevlett.105.040502 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.86.032324 [ * * ,   ( ) ] link:\\doibase    10.1103/physrevx.4.041039 [ * * ,   ( ) ] @noop _ _  ( ,  ) http://dx.doi.org/10.1038/nature10376 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1103/physrevlett.109.240502 [ * * ,   ( ) ] http://dx.doi.org/10.1038/nature11505 [ * * ,   ( ) ] link:\\doibase    10.1103/physrevx.3.021008 [ * * ,   ( ) ] @noop * * , ( ) http://dx.doi.org/10.1038/nature12422 [ * * , ( ) ] http://dx.doi.org/10.1038/nature13171 [ * * ,   ( ) ] http://dx.doi.org/10.1038/ncomms5015 [ * * ( ) ] http://arxiv.org/abs/1411.5542 [ * * ( ) ] @noop * * ,   ( ) @noop * * ( ) link:\\doibase 10.1103/physrevlett.77.4728 [ * * ,   ( ) ] link:\\doibase    10.1103/physrevlett.107.080503 [ * * ,   ( ) ] @noop * * ,   ( ) link:\\doibase    10.1103/physrevx.3.021013 [ * * ,   ( ) ] @noop * * ,   ( ) link:\\doibase    10.1103/physrevlett.109.183602 [ * * ,   ( ) ] link:\\doibase    10.1103/physrevlett.110.120501 [ * * ,   ( ) ] link:\\doibase    10.1103/physreva.88.023849 [ * * ,   ( ) ] http://dx.doi.org/10.1038/nature12802 [ * * ,   ( ) ] @noop * * ,   ( ) @noop ( ) @noop * * ,   ( ) http://dx.doi.org/10.1038/nature10786 [ * * ,   ( ) ] @noop * * ,   ( ) \\doibase http://dx.doi.org/10.1016/j.automatica.2009.04.018 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevb.77.180502 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.81.040301 [ * * , ( ) ] link:\\doibase 10.1103/physreva.82.012329 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.69.062320 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase    10.1103/physrevlett.109.050506 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.109.050507 [ * * ,   ( ) ] @noop * * , ( ) link:\\doibase 10.1103/physrevlett.107.240501 [ * * ,   ( ) ] http://dx.doi.org/10.1038/nature05461 [ * * ,   ( ) ] http://dx.doi.org/10.1038/nature09035 [ * * ,   ( ) ] http://dx.doi.org/10.1126/science.1226897 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.102.200402 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.81.062325 [ * * ,   ( ) ] http://stacks.iop.org/1367-2630/16/i=4/a=045014 [ * * ,   ( ) ] http://dx.doi.org/10.1038/nature13436 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.91.062324 [ * * ,   ( ) ]    ( a ) schematic of the experimental set - up . two independently addressable transmon qubits , alice and bob , are dispersively coupled to a three - dimensional microwave cavity . the cavity output is directed to a nearly quantum - limited measurement chain consisting of a josephson amplifier ( jpc ) followed by a semiconductor amplifier ( hemt ) . a pair of custom field - programmable gate array boards ( fpga a , b ) monitor the amplified output and generate real - time modulated microwave drives to control the cavity - qubit system . ( b ) transmission spectra of the cavity . cavity outputs at @xmath3 and @xmath4 are fed to fpga a and b , respectively . ]     ]    fig . comparison between the driven - dissipative ( dd ) and the measurement - based ( mb ) entanglement stabilization , shown in the left ( dd ) and right ( mb ) panels . ( a ) diagram of qubit / cavity state evolution in the dd feedback loop . two - qubit state manifolds are laddered for different photon numbers in the cavity ( labeled by @xmath86 ) . the green and pink sinusoidal double arrows represent cavity drives , while the straight double red / blue and cyan / yellow arrows are rabi drives on the qubits . these six drives and the cavity dissipation ( black decaying arrow ) couple the different states of the system such that the target state @xmath25 is stabilized . ( b ) functional pulse sequence for dd . the duration needed to empty the cavity of residual photons ( see text ) before tomography is indicated by @xmath54 . ( c ) fidelity to the target as a function of stabilization duration ( @xmath53 ) . dashed line at @xmath87 denotes the threshold for entanglement . the time given in the white box , @xmath88 , is the characteristic time constant of the exponential rise of fidelity . ( d ) state machine representation of the mb feedback loop . the quasi - parity measurement reports @xmath7 , @xmath8 as @xmath89 ( even ) and @xmath25 , @xmath15 as @xmath90 ( odd ) . for odd ( even ) parity , two @xmath91 pulses , with identical ( opposite ) phases , are applied to alice and bob , respectively . ( e ) sequence of correction steps conditioned by the quasi - parity measurement and leading into tomography . counter @xmath39 limits the number of steps to @xmath56 . ( f ) fidelity to the target bell state as a function of stabilization duration ( @xmath92 ) or number of correction steps ( @xmath56 ) . trade - off between success probability and fidelity for both dd and mb schemes . ( a ) pulse sequence for heralding dd stabilization by post - selection . at the end of the stabilization period , the cavity outputs , @xmath77 and @xmath78 are measured at their respective frequencies . ( b ) color plot of fidelity to the target state for dd as a function of thresholds chosen for @xmath77 and @xmath78 ( see supplementary material for details of the thresholds ) . also plotted as white dashes are contour lines of the success probability associated with each choice . solid black square indicates the thresholds chosen for the condition @xmath80 in the nested feedback protocol described in fig . ( c ) and ( d ) same as above for mb , including the corresponding thresholds for @xmath80 . gray circle indicates the thresholds chosen for the quasi - parity measurement @xmath41 used to condition mb correction steps . ] nested feedback protocol for boosting fidelity and heralding successful stabilization run in real - time . ( a ) state machine representation . the control variable @xmath80 ( see main text and fig .  3 ) determines the repetition of a boost cycle or the heralding of a successful run . the maximum number of boost attempts allowed is set to 11 in the experiment . ( b ) , ( e ) 200 single - shot sequence trajectories of nested feedback for dd and mb , respectively . the trajectories are colored yellow during boost attempts and black after @xmath80 is satisfied . trajectories that are entirely black satisfied the success criterion without the need for boost . the inset in ( e ) shows an example of an mb trajectory consisting of both @xmath41 and @xmath80 outcomes . ( c),(f ) cumulative success probability ( gray shade ) of having completed at most a given number of boost attempts before tomography for dd and mb , respectively . yellow bars indicate differential success probability . ( d),(g ) fidelity to target bell state for dd and mb , respectively . green squares show the corresponding fidelity as a function of the number of boost attempts . the blue dashed line denotes fidelity without any boosting ( i.e.  unconditioned by @xmath80 ) . blue arrows denote the improvement in fidelity due to nested feedback . while the absolute fidelity of mb is worse than dd due to latency , the fidelity boost is higher . ]    * supplementary materials * the cavity - qubit system was housed in an oxford triton 200 dilution refrigerator , at a base temperature below 20 mk . the setup of the experiment is described in detail in fig . [ fig : exp_setup ] . the key feature is that both data acquisition and arbitrary waveform / digital marker generation were accomplished by two fpga boards programmed with a customized logic . the cavity frequency is @xmath93  ghz when both qubits are in the ground state and its linewidth @xmath94 is @xmath95  mhz . the qubit frequencies with no cavity photons are @xmath96  ghz and @xmath97  ghz , for alice and bob respectively . the two dispersive shifts are @xmath1  mhz , @xmath2  mhz . the anharmonicity for the two qubits are @xmath98  mhz , @xmath99  mhz . alice ( bob ) has a @xmath100 of @xmath101  @xmath59s ( @xmath102  @xmath59s ) , @xmath103 of @xmath104  @xmath59s ( @xmath73  @xmath59s ) and excited state population in @xmath105 and @xmath106 of 5% each .    as mentioned in the main text , the fast dispersive single - shot readout used in the experiment is made possible by a nearly quantum - limited phase - preserving measurement chain based on the josephson parametric converter(jpc ) . the jpc was operated with a gain of @xmath107  db and bandwidth of 6.2 mhz , with the frequency for maximum gain centered between the two readout frequencies , @xmath3 and @xmath4 . the gain and noise visibility ratio at both @xmath3 and @xmath4 were about 17 db and 6 db , respectively . [ sec : msmt time ] the quasi - parity measurement strength and duration were optimized in order to maximize the fidelity of mb . this optimization was done by maximizing the fidelity of the bell state created in a calibration experiment , similar to ref .  . the qubits are prepared in ground states ( by post - selection ) and then two @xmath108 pulses , are applied to alice and bob , producing the state @xmath109 . the quasi - parity measurement , consisting of the two cavity drives on @xmath4 and @xmath3 respectively , projects the qubits into one of the two even states or entangles the qubits into a bell state with odd parity . we varied the duration of this parity measurement and its strength in terms of photon number ( set to be identical ) for each readout frequency to find the parameters that maximize the fidelity of the entangled state to the closest bell state ( fig . [ fig : measurement_calibration ] ) . the bell state fidelity would ideally increase and asymptotically approach one with increasing measurement time as the parity measurement better distinguishes the odd bell state from the even states . on the other hand , at long measurement duration , the coherence of the entangled state decreases due to both natural and measurement - induced dephasing , the latter of which is caused by the @xmath11 mismatch between the qubits and is proportional to the average number of photons used for the measurement @xcite . therefore , there is an optimal measurement strength and duration . for our experiment , @xmath110 for each readout frequency and a measurement duration of @xmath111  ns are found to be close to the optimal values and are chosen to attain a bell state fidelity of @xmath112% .    the value of @xmath112% sets the upper bound on the fidelity that we should expect for heralding mb . in the actual mb experiment , an extra @xmath113  ns delay was introduced after the quasi - parity measurement in a correction step , which does not occur in the sequence described in this section for optimizing the parity measurement parameters . this extra delay was required to accommodate the feedback latency in mb . the conditioned fidelity we obtained for heralded mb is about 6% lower . [ sec : thresholds ] the cavity outputs at @xmath3 and @xmath4 for both dd and mb can be used to monitor the state of the qubits during stabilization ( fig . [ fig : thresh_hist]a ) . histograms of the measurement outcomes @xmath77 and @xmath78 , recorded by integrating the cavity output at @xmath3 and @xmath4 , respectively , are shown in fig . [ fig : thresh_hist]b , c , d , e for dd and mb respectively . in dd , the cavity output signals are captured while all the cw drives are still on , i.e. , the qubits are being driven while their states are being monitored , whereas in mb the outputs are a result of the quasi - parity measurements which occur after the qubit pulses and thus when the qubits are not driven . we observe that the measurement outcome distribution of dd lacks the separation seen in mb which has a clear parity separatrix @xmath114 . this feature also appears in numerical simulations of dd by the stochastic master equation @xcite . the state estimation used in both dd and mb uses the `` box car '' filtering @xcite which simply sums up the recorded cavity output signals over time to obtain the measurement outcomes . this method , while appropriate for mb , is not suited for dd since in the latter , the qubits are undergoing actively - driven dynamics when the measurement is taking place . a more advanced filter , such as a non - linear quantum filter can be designed from either first - principles or machine learning @xcite in the future to improve the state discrimination accuracy in dd . the measurement outcomes to the left of both the @xmath115 ( shown in figure ) and @xmath116 thresholds are much less likely to come from even states than those to the right . therefore the experiment runs with these outcomes are selected for state tomography , giving the results plotted as a color map in fig . 3 ( main text ) . moving the threshold further to the left increases the stringency of the threshold as fewer measurement outcomes are included . the success probability for each threshold choice ( plotted as contours in fig . 3 ) is calculated by the ratio of included outcomes to the total number of experiment runs . [ sec : supp model ]    the steady state behavior of both dd and mb is simulated by a lindblad master equation , given by @xmath117+\\kappa d[a]\\rho(t)+\\sum\\limits_{j = a , b}\\left(\\frac{1}{t_{\\downarrow}^j}d[\\sigma_-^j]\\rho(t)+\\frac{1}{t_{\\uparrow}^j}d[\\sigma_+^j]\\rho(t)+\\frac{1}{2t_{\\phi}^j}d[\\sigma_z^j]\\rho(t)\\right)\\ ] ] @xmath118 is the lindblad super - operator , defined for an operator @xmath119 as @xmath120\\rho = o\\rho o^{\\dagger}-(1/2)o^{\\dagger}o\\rho-(1/2)\\rho o^{\\dagger}o$ ] . the pure dephasing rate for alice and bob , respectively , is given by @xmath121 , where @xmath122 . the hamiltonian @xmath123 is treated differently in dd and mb . for dd , the hamiltonian is described in detail in the theory proposal @xcite and parameters in the hamiltonian , such as the cavity and qubit drive amplitudes , are swept in simulation to find the optimal values . the optimal value for the cavity drive amplitude is found to be @xmath124 with @xmath125 , and @xmath126 for the qubit drive amplitudes at both zero - photon and n - photon qubit frequencies . the dd simulation predicts a characteristic time constant of 1 @xmath59s and a steady state fidelity of 76% ( accounting for the delay between stabilization and state tomography to allow remaining cavity photons to decay ) .    for mb , a correction step is broken into four segments for effectively piecewise master equation simulation . the first part contains the conditional rabi pulses which are simulated as perfect instantaneous unitary operations on the qubits . the second part is the decay during the pulses ( 154 ns total ) . the hamiltonian during this part is just the the dispersive interaction between the qubits and the cavity , @xmath127 , in the rotating frame of the two qubits ( @xmath128 , @xmath129 ) and the cavity mode ( @xmath130 ) . the third part is the quasi - parity measurement during which the cavity drives at the @xmath3 and @xmath4 resonances are on and the hamiltonian is given by @xmath131 , where @xmath132 is the amplitude of the cavity drive ( 660 ns total ) . the last part is the remainder of the correction step , incurred by the latency of the feedback during which all drives are off and the qubit - cavity system is in free - decay . the dynamics in this part is again simulated by the dispersive interaction , @xmath133 ( 686 ns total ) . for the piecewise master equation simulation of a complete correction step as four segments , the density matrix at the end of a segment is used as the initial density matrix for the next segment .    since in mb , the state at the end of a correction step depends only on the initial state at the beginning of the step , we can model the mb scheme as a markov chain ( fig .  [ fig : mb_markov ] ) . in the rest of this section , we show how we derive the transition matrix that describes this markov chain . as discussed in the main text , we can describe the qubits by the density matrix @xmath134 . therefore , in terms of probability distributions in the four basis states , the qubits s state , @xmath135 , can be represented by a vector , @xmath136 if the qubits are prepared in @xmath25 , that is @xmath137 , we can calculate @xmath138 after a correction step by applying the master equation simulation method described above . we need to consider the two possible cases where the conditional unitary applied is @xmath36 or @xmath35 , respectively . the @xmath138 is a weighted average of the two cases . @xmath139 @xmath44 and @xmath45 are the quasi - parity measurement infidelities due to limited measurement efficiency , introduced in the main text . in a similar manner , we can obtain @xmath140 . in the case of an even initial state , for example , @xmath141 , we have @xmath142 and similarly for @xmath143 .    given @xmath138 , @xmath140 , @xmath144 and @xmath143 , we can construct the transition matrix @xmath145 of a correction step , @xmath146 where the @xmath147 s are the columns of the 4 by 4 matrix . now applying this transition matrix on any arbitrary initial state gives the final state after a correction step , @xmath148 the transition matrix @xmath145 is also called the stochastic matrix , with the property that each column sums to 1 . one of @xmath145 s eigenvalues is guaranteed to be 1 and the corresponding eigenvector , @xmath149 , is the steady state of the markov chain . it can easily be shown that for any arbitrary initial state , @xmath150 @xmath151 for the given experimental parameters in mb , the @xmath145 matrix is displayed in fig . [ fig : mb_markov ] and we find the steady state eigenvector to be @xmath152 thus , the markov model predicts a steady state fidelity of 58% to @xmath25 . taking into account of the duration of a correction step ( 1.5 @xmath59s ) , we can also calculate the characteristic time constant of the mb scheme from the model , which gives 1.4 @xmath59s . both values agree very well with experimental results . we can calculate the expected fidelity when some of the experimental parameters are improved in the near future . if the measurement efficiency is improved from 30% to the current state - of - the - art value of 60% , the measurement duration can be reduced by half while maintaining the quasi - parity measurement infidelities@xcite . the instrument and fpga latencies incurred in the experiment can also be reduced by 100 ns , in the latest hardware setup and fpga logic design in operation while this article was being prepared . the measurement duration and control latency reduction can shorten the correction step length to 1 @xmath59s , which can improve the steady state fidelity to 66% . furthermore , if the coherence times are also improved to the state - of - the - art values in the hundred of microseconds for superconducting qubits , both dd and mb fidelities in the `` fixed time '' protocol can be above 85% , limited by the @xmath11 mismatch ( assumed to be 10% , as in the current experiment ) . the prospects of both dd and mb schemes are summarized in tab . [ tab : fidelity_prospects ]    l | l p2 cm p2 cm & + & dd & mb + experiment & current parameters & 76% & 57% + & @xmath153 , latency@xmath154  ns & 76% & 66% + & @xmath100,@xmath155  @xmath59s & 86% & 86% + [ sec : nfp_simulation ] the markov chain model introduced in sec . [ sec : supp model ] can be extended to simulate nfp ( nested feedback protocol ) . we can construct a `` nested '' markov chain ( fig . [ fig : nfp_markov ] ) for each boost attempt of nfp . at the outer - most level , there are two nodes . one node denotes the trajectories that have just been heralded as successful ; the other node denotes the trajectories that require at least another boost attempt . building on the vector description established in the previous section , we represent the heralding of trajectories before a boost attempt by a diagonal matrix @xmath156 ,    @xmath157    after stabilization of some pre - determined duration , if the qubits are ( on average ) in state @xmath158 , then the average state of the qubits that are heralded is then given by ,    @xmath159    where @xmath160 is the @xmath161 norm of the vector ( the sum of the entries in the vector ) . the normalization is required since heralding selects only a subset of the trajectories , i.e. , the matrix , @xmath156 , does not preserve the norm of @xmath135 . each entry on the diagonal of @xmath156 gives the fraction of trajectories that get heralded ( selected ) from a particular state . their values depend on the particular heralding thresholds used , @xmath115 and @xmath116 ( supp . [ sec : thresholds ] ) . this matrix can be determined phenomenologically by the post - selection experiment shown in fig . 3 ( main text ) . from the experiment , we can find the average state without any conditioning ( no heralding ) , @xmath162 and the average state of the heralded trajectories , @xmath163 . given the success probability @xmath164 of using the thresholds ( the white dashed contour line of fig . 3b , d in the main text ) , the diagonal elements can be calculated as ,    @xmath165    for the specific heralding thresholds used in the experiment ( represented by the black squares in fig . 3b , d in the main text ) , @xmath166 and @xmath167 are explicitly given by ,    @xmath168    ideally for @xmath156 , only @xmath169 should be non - zero . but in practice , since we can not distinguish @xmath46 and @xmath47 , @xmath170 is comparable to @xmath169 . furthermore , for both dd and mb , @xmath171 and @xmath172 are also non - neglibile . in dd , this is predominantly due to the lack of separation between the even and odd measurement outcomes as discussed in supp .  sec .  [ sec : thresholds ] . in mb , the qubits can jump during the delay between the completion of the quasi - parity measurement and the end of a correction step due to @xmath100 events . thus for mb , trajectories that are heralded by very stringent thresholds still have a non - zero probability of being in the even parity states .    given the heralding matrices @xmath166 and @xmath167 , we can now calculate the average state of the trajectories that are not heralded and thus require a boost attempt as    @xmath173    where we introduce the lowercase @xmath174 as the unnormalized population distribution vector . @xmath160 denotes the @xmath161 norm of the numerator . after this boost attempt , the qubits are in state @xmath175 ,    @xmath176    where @xmath145 is the stochastic transition matrix that models the stabilization during a boosting attempt . in supp . [ sec : supp model ] , we have already found @xmath145 for mb . by the same method , we can also derive the effective transition matrix of a boost attempt for dd . the calculation of @xmath145 for dd is an approximation : due to the continuous cavity drives , the state of the qubits at the beginning of a boost attempt is entangled with a qubit - state dependent cavity state , which we approximate unconditionally by the average steady - state cavity state in dd . nonetheless , as we shall show , the model still produces a quantitative behavior that agrees very well with the experimental results . from the above equations , it is easy to show that the average qubits state of the heralded trajectories after @xmath39 boost attempts is given by    @xmath177    in the case of a pre - stabilization of sufficient number of correction steps ( or duration ) , @xmath158 is given by the steady - state , @xmath149 , introduced in supp . [ sec : supp model ] . for each of the @xmath39 boost attempts , the first entry in the vector @xmath178 , i.e. , @xmath179 , gives the fidelity to @xmath180 . the @xmath161 norm of the numerator in the expression for @xmath178 gives the percentage of trajectories that have completed @xmath39 boost attempts . summing the percentages over all values of @xmath39 from 0 to the maximum limit gives the overall success probability . [ fig : nfp_sim_results ] , we show the results of the simulation using the model described here and compare them to the experimental results presented in fig .  4 of the main text . furthermore , from the simulation , we find that with the realistic system parameter improvement as specified in supp . [ sec : supp model ] , the fidelity of heralded trajectories can be 90% and 95% for dd and mb , respectively , with order unity success probability . [ sec : ac stark shift ] the quasi - parity measurement induces a deterministic phase shift between the two qubits due to measurement - induced ac stark shift @xcite . this is evidenced by examining the phase of the bell state created in the measurement optimization experiment described in supp . [ sec : msmt time ] , in which we varied the measurement duration . as the measurement duration is increased , the bell angle of the final bell state changes linearly ( fig . [ fig : measurement_dephasing]a ) . in order for mb to work , we need to account for the deterministic phase shift induced by the measurement . this correction is accomplished by a `` _ _ z _ _ '' rotation on bob before the unitary @xmath36 . [ fig : measurement_dephasing]b gives one example of a sequence trajectory to illustrate how the correction works . with no loss of generality ( and the reason will become clear soon in the discussion that follows ) , we construct @xmath181 and @xmath182 ( where @xmath183 = 0 corresponds to the x axis ) such that @xmath184 is the eigenstate of @xmath36 and applying @xmath35 on the even states results in @xmath185 with 50% probability after the quasi - parity measurement . suppose that the qubits are in the ground states , @xmath35 is applied and the subsequent quasi - parity measurement gives @xmath33 . during the quasi - parity measurement , a deterministic phase shift of @xmath186 since the measurement reports odd , the next conditional unitary is @xmath36 . the _ z _ gate before @xmath36 undoes the phase shift and recovers the eigenstate which @xmath36 leaves unchanged . after another parity measurement , the qubits are in the state @xmath187 , with the phase shift added again . consequently , we can see that the mb sequence actually stabilizes @xmath187 state . in practice , for our experiment , the _ z _ rotation for bob is constructed from a composite of _ x _ and _ y _ rotations , such that @xmath188 , and the effective correction angle @xmath189 is swept ( fig . [ fig : measurement_dephasing]c ) to find the optimal value that cancels the deterministic phase shift and thus maximizes the fidelity . furthermore , to make the target state of the stabilization @xmath180 , the rotation axis of the pulses on bob in @xmath36 and @xmath35 is chosen such that @xmath190 . this correction for measurement - induced ac stark shift is also done in the simulation for mb . [ sec : f state ] while we have been treating our two qubits as purely two - level systems , in reality there are higher energy levels , in particular the second excited level is expected to play a non - negligible role in the dynamics . we find that the equilibrium qubit population not in the @xmath7 state was about @xmath191% , and the @xmath192 state was also populated . to investigate whether the decrease of the fidelity in nfp as a function of boost attempts number is due to the role played by the @xmath192-state population , we measured the populations in @xmath193 , @xmath194 , @xmath195 , @xmath196 , @xmath197 after a given number of boost attempts in dd . the population in @xmath193 was measured by applying a @xmath198 pulse on alice s _ e - f _ transition , then a @xmath198 pulse on its _ e - g _ transition , followed by a measurement of the population in @xmath7 . the other @xmath192-state populations are similarly obtained . the sum of these 5 populations gives the total @xmath192-state population plotted in fig . [ fig : f_pop ] , which indeed increases as a function of boost attempt number . it is therefore plausible that the decrease in fidelity with respect to number of boost attempts is due to the system being trapped in other levels outside the correction space . this problem , which is common in similar atomic physics experiments , could be addressed by additional drives . 7ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty @noop * * , ( ) link:\\doibase 10.1103/physreva.82.012329 [ * * ,   ( ) ] @noop ( ) link:\\doibase 10.1103/physreva.76.012325 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.114.200501 [ * * ,   ( ) ] link:\\doibase    10.1103/physreva.88.023849 [ * * ,   ( ) ] http://dx.doi.org/10.1126/science.1226897 [ * * ,   ( ) ]      fig .  s.1 . setup of the experiment . the qubit - cavity system was placed at the base stage of a dilution refrigerator ( oxford triton200 ) below 20 mk . on the input side : two fpgas ( innovative integration x6 - 1000 m ) generated the pulse envelopes in i and q quadratures to modulate the qubit drives at @xmath199 and @xmath200 frequencies ( vaunix labbrick lms-802 ) for alice and bob , respectively . the i / q modulations were output by the fpgas with one and two single - sideband modulations in mb and dd ( so that both zero - photon and n - photon qubit frequencies were addressed ) , respectively . the microwave frequency drives and i / q modulation were mixed by iq mixers . two agilent n5183 microwave generators produced the cavity drives at @xmath4 and @xmath3 respectively . the cavity drives were also pulsed by the fpgas . on the output side : the transmitted signal through the cavity was directed by two circulators to the jpc for nearly quantum - limited amplification . it was further amplified at the 3 k stage by a cryogenic hemt amplifier . after additional room temperature amplification , the signal was split into two interferometric setups for readouts at the @xmath3 and @xmath4 frequencies , respectively . in each of the interferometers , the signal arriving from the fridge was mixed with a local oscillator set @xmath201 mhz away to produce a down - converted signal at 50 mhz . a copy of the cavity drive that did not go through the fridge was also down - converted in the same manner to produce a reference . finally , the two signals with their respective references were sent to the analog - to - digital - converters on the fpga boards for digitization and further demodulated inside the fpgas . the two fpgas jointly estimate the qubits state by communicating their results with each other . along the input and output lines , attenuators , low pass filters and homemade eccosorb filters were placed at various stages to protect the qubits from thermal noise and undesired microwave and optical frequency radiation . moreover , the cavity and jpc were shielded from stray magnetic fields by aluminum and cryogenic @xmath59-metal ( amumetal a4k ) shields .     experimental calibration of measurement strength and duration for mb . fidelity to the state @xmath202 after preparing the qubits in a maximally superposed state followed by a quasi - parity measurement with post - selection . the fidelity is plotted as a function of measurement duration and shown for a set of measurement strengths . the optimal values chosen for the experiment are 660 ns and @xmath110 . ] ( a ) the cavity outputs at @xmath3 and @xmath4 are integrated to obtain measurement outcomes @xmath77 and @xmath78 , respectively . ( b),(c ) , ( d ) , ( e ) histograms of the measurement outcomes @xmath77 and @xmath78 for dd and mb , respectively . the leftmost dashed line ( labeled @xmath115 and @xmath116 ) indicates a particular choice of threshold for heralding the measurement outcomes . counts to the left of both thresholds are declared success . the right dashed line ( @xmath203 and @xmath204 ) indicates the threshold for quasi - parity measurement in mb . ] markov model of a correction step in mb . transition between any two nodes is possible and is represented as a directional edge . the 16 possible transitions make up the 16 matrix elements in the stochastic transition matrix , @xmath145 , corresponding to a correction step in mb . numbers next to the edges represent the elements of @xmath145 calculated for the current experiment parameters by a master equation simulation . ]     markov model of the nfp ( nested feedback protocol ) for real - time heralding . this model is an extension of the model introduced for mb . during a boost attempt , transitions occur inside the `` boosting '' node for further stabilization . the edge leading from the `` boosting '' to the `` heralded '' node represents the real - time heralding that selects some fraction of trajectories by the threshold - dependent matrix @xmath156 ( see text ) at the end of a boost attempt . those that are not selected ( @xmath205 ) enter into another boost attempt . ]     simulation of real - time heralding by nfp . the left ( right ) panel presents the results for dd ( mb ) . ( a ) , ( c ) cumulative success probability of having completed at most a given number of boost attempts before tomography for dd and mb , respectively . green curve shows the experimental result as presented in the main text . blue curve is the simulation result using the same experimental parameters . ( b ) , ( d ) fidelity to @xmath46 for dd and mb , respectively . cyan dashed line denotes the unconditioned steady state fidelity obtained in the experiment . green squares ( blue circles ) show the corresponding fidelity as a function of the number of boost attempts during nfp obtained in the experiment ( simulation ) . ]     correcting for deterministic measurement - induced ac stark shift ( a ) deterministic phase shift induced by measurement as a function of measurement duration . ( b ) one example of a sequence trajectory illustrating the phase correction @xmath206 at work . see detailed explanation in accompanying text . ( c ) fidelity of the steady state to the target bell state as a function of the correction angle of the effective _ z _ gate on bob . ]", "tags": [], "output_text_a": "This paper discusses the implementation of quantum error correction (QEC) using feedback mechanisms, which is essential for fault-tolerant quantum computation. The study compares two feedback strategies: measurement-based (MB) and driven-dissipative (DD) approaches. The MB approach relies on projective measurements and classical control, while the DD approach uses coupling with a dissipative environment to autonomously correct errors. The authors present an experiment using a feedback platform that integrates both MB and DD strategies to stabilize an entangled Bell state of two superconducting transmon qubits.\n\nThe experiment demonstrates the first MB stabilization of a Bell state through repeated active correction using conditional parity measurements. The performance of MB and DD schemes is compared, revealing that DD has better steady-state performance due to shorter feedback latency. However, improvements in experimental parameters could allow MB to catch up with DD. The study introduces a nested feedback protocol (NFP) that combines both approaches to enhance performance, achieving high fidelity and success probability without sacrificing one for the other.\n\nThe results show that combining MB and DD strategies can outperform either approach alone, suggesting that these methods are complementary rather than antagonistic. The paper highlights the potential of MB platforms, which have not been fully explored, and suggests that future improvements in measurement efficiency and coherence times could further enhance the performance of QEC systems. The research demonstrates the feasibility of integrating MB and DD approaches for more effective quantum error correction, paving the way for more robust quantum information processing systems.", "output_text_b": "This article discusses the implementation and comparison of two feedback strategies for quantum error correction (QEC): the measurement-based (MB) approach and the driven-dissipative (DD) approach. The MB approach has been more widely understood, relying on classical control and feedback engineering principles. In this method, a classical controller performs projective measurements of multi-qubit stabilizer operators to track errors and perform necessary corrections. High-fidelity projective measurements and low-latency control electronics are essential for good performance. The DD approach, on the other hand, utilizes coupling between the quantum system and a dissipative environment to transfer entropy caused by decoherence-induced errors out of the quantum system. This method has been demonstrated on various physical systems, including atomic ensembles, trapped ions, mechanical resonators, and superconducting qubits.\n\nThe authors report an experiment comparing MB and DD schemes within the same setup, aiming to stabilize an entangled Bell state of two superconducting transmon qubits. They realize MB stabilization of a Bell state by repeated active correction through conditional parity measurements and compare it to a DD entanglement stabilization scheme. The performance of both schemes is analyzed on the same hardware setup and circuit QED system.\n\nThe article highlights the subtle differences in performance between DD and MB schemes, depending on whether the design of the CQED Hamiltonian or the efficiency of quantum measurement and classical control can be better optimized. The authors demonstrate that DD has better steady-state performance when the CQED Hamiltonian parameters are engineered for shorter feedback latency. However, as certain experimental parameters are improved, such as coherence times and measurement efficiency, MB's performance can catch up with DD.\n\nAdditionally, the authors explore a heralding method to improve the performance of both stabilization approaches. This protocol, termed \"nested feedback,\" exploits the high-fidelity measurement capability and programmability of the feedback platform. By implementing real-time heralding on a timescale faster than the few microsecond coherence time of the qubit-cavity system, the authors show the potential of combining MB and DD approaches to achieve better performance.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the implementation of quantum error correction using feedback mechanisms and comparing the measurement-based and driven-dissipative approaches.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of implementing quantum error correction for fault-tolerant quantum computation.\n4. The summary mentions the methodology of using a feedback platform that integrates both measurement-based and driven-dissipative strategies.\n5. It includes significant results, such as the first measurement-based stabilization of a Bell state and the introduction of a nested feedback protocol.\n6. The summary is written in clear and professional language.\n7. It avoids excessive technical jargon and explains terms like measurement-based and driven-dissipative approaches.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. It mentions key experiments, such as the stabilization of an entangled Bell state of two superconducting transmon qubits.\n10. The summary reflects the paper's significance by discussing the potential impact of integrating measurement-based and driven-dissipative approaches for more effective quantum error correction.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the implementation and comparison of the measurement-based (MB) and driven-dissipative (DD) feedback strategies for quantum error correction.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of finding the best strategy for quantum error correction.\n4. The summary mentions the methodology used, including the comparison of MB and DD schemes and the implementation of a heralding method.\n5. Significant results and conclusions, such as the performance differences between DD and MB and the potential of combining both approaches, are included.\n6. The language used is clear and professional.\n7. Technical jargon is minimized, and terms like \"nested feedback\" are explained.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the stabilization of an entangled Bell state, are mentioned.\n10. The potential impact of the research in improving quantum error correction strategies is reflected."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "cosmological inflation provides an explanation for the formation of structures in the universe . however , we lack a fundamental theory from which inflation would emerge as a natural consequence . instead , a large number of inflationary scenarios have been proposed . on the other hand , the standard model of particle physics ( sm ) unifies three of the four fundamental forces of nature and requires the existence of a particle with the same properties as the field driving inflation in many models . if the higgs field could act as the inflaton field , current particle physics experiments at tevatron and lhc would probe the physics of inflation . the study of this problem has first been addressed long ago @xcite . it was shown that a false vacuum scenario for the higgs field ( at the electroweak energy scale ) leads to an overproduction of density perturbations and is thus ruled out . an alternative would be to concentrate on much higher values of the higgs potential in the spirit of chaotic ( or large field ) inflation @xcite . this scenario has been investigated in the context of a higgs field minimally coupled to gravity , approximating the potential by its quartic term @xcite and in theories with a non - minimal coupling @xcite . it has been shown @xcite that the sm could in principle be well defined up to the planck scale . then the @xmath2 potential , presumably the dominant contribution to the effective higgs potential at high energies , could provide enough inflation , but generically overproduces density perturbations as @xmath3 and is thus ruled out . even if one allows for an arbitrary value of @xmath4 , data from 5 years of wmap observations exclude the scenario of an extended slow - roll epoch in a @xmath5-potential @xcite . likewise , the inclusion of a non - minimal coupling allows the possibility of adjusting the higgs potential so that cosmological perturbations can be in accordance with observational restrictions @xcite . here we consider a different situation in which the total amount of inflation is not much more than 60 e - foldings . the onset of inflation is thus observable and violates the slow - roll assumptions . the resulting primordial power spectrum is not scale invariant , as the moment of the onset of the slow - roll regime distinguishes a scale . it turns out that such a situation can not be discarded on grounds of current analysis and observations@xcite . this new scenario of `` just enough '' chaotic inflation seems to be generic if two fundamental energy scales are relevant in the very early universe . the planck scale @xmath6 is the fundamental scale of quantum gravity . the notions of spatial curvature , expansion rate @xmath7 and kinetic energy density are well defined and real quantities , at least up to that scale . however , this is less clear for the effective potential @xmath8 of the inflaton . the effective potential carries the information about all interactions of the inflaton , except its gravitational ones . if we consider the sm higgs as a candidate for the inflaton , it is clear that inflation would only take place if the effective higgs potential is real  the existance of an imaginary part would lead to the immediate decay of the inflaton .    the quartic self - coupling of the higgs runs with energy . depending on the mass of the top - quark , the self - coupling decreases with increasing energy scale @xmath9 and can become negative at high energy ( see fig .  1 ) . the effective higgs potential is real as long as the quartic self - coupling is positive , but becomes complex as soon as it runs to negative values @xcite . such an imaginary contribution would give rise to the decay of the higgs field and thus establishes an effective upper bound for an effective real higgs potential @xmath10 , with @xmath11 . motivated by the sm higgs , we can assume that @xmath12 gev and @xmath13 at that scale . we applied that idea to @xmath5-inflation @xcite . as for chaotic inflation , curvature , expansion rate and kinetic energy density start at the planck scale . however , if the potential energy were at @xmath1 as well , the inflaton would decay and the universe would not grow old . only regions with @xmath10 ( occurs with a finite probability ) start to inflate . these regions are dominated by kinetic energy initially . it decays quickly and the universe enters a state of fast - roll inflation , followed by about 60 e - foldings of slow - roll inflation . the trajectory of the universe in the observable plane of tensor - to - scalar ratio vs. spectral tilt is shown in fig . 2 . it turns out that this model evades the constraints form the wmap 5 year data @xcite , as it breaks scale - invariance at the largest cosmological scales @xcite . we found that by means of a fine tuned running of @xmath4 , the tree - level sm higgs effective potential could give rise to such a scenario . the inclusion of one- and higher - loop corrections spoils that consistency .      99 a.  d.  linde , phys . b * 108 * , 389 ( 1982 ) ; a.  j.  albrecht and p.  j.  steinhardt , phys . lett .   * 48 * , 1220 ( 1982 ) . a.  d.  linde , phys . b * 129 * ( 1983 ) 177 . g.  isidori _ et al . _ , phys . d * 77 * , 025034 ( 2008 ) . f.  l.  bezrukov and m.  shaposhnikov , phys . b * 659 * , 703 ( 2008 ) . l.  maiani , g.  parisi and r.  petronzio , nucl . b * 136 * , 115 ( 1978 ) ; c.  d.  froggatt and h.  b.  nielsen , phys .  lett . b * 368 * , 96 ( 1996 ) ; j.  ellis _ et al . _ , phys . b * 679 * , 369 ( 2009 ) . e.  komatsu _ et al . _ [ wmap collaboration ] , astrophys .  j.  suppl .   * 180 * , 330 ( 2009 ) .", "tags": [], "output_text_a": "The paper discusses the challenges and possibilities of using the Higgs field as the inflaton in cosmological inflation, which is a theory explaining the formation of structures in the universe. While the Standard Model of particle physics unifies three fundamental forces and includes a particle similar to the inflaton, a fundamental theory for inflation is still lacking. The paper reviews various inflationary scenarios, particularly focusing on the Higgs field's potential role. It highlights that a false vacuum scenario for the Higgs field is ruled out due to overproduction of density perturbations. Instead, the paper explores chaotic inflation scenarios, where the Higgs field is minimally or non-minimally coupled to gravity. The study suggests that the Standard Model could be valid up to the Planck scale, but typically overproduces density perturbations. The paper proposes a \"just enough\" chaotic inflation scenario, where inflation is not much more than 60 e-foldings, leading to a non-scale invariant primordial power spectrum. This scenario is not ruled out by current observations and suggests that two fundamental energy scales, the Planck scale and the scale of the Higgs potential, are relevant in the early universe. The paper concludes that while a finely tuned running of the Higgs self-coupling could support this scenario, higher-loop corrections disrupt this consistency.", "output_text_b": "This arXiv paper discusses the possibility of the Higgs field acting as the inflaton field, which would allow for the probing of inflation physics through current particle physics experiments. The authors examine a scenario of \"just enough\" chaotic inflation, where the total amount of inflation is not much more than 60 e-foldings, making the onset of inflation observable and violating slow-roll assumptions. This scenario is found to be generic if two fundamental energy scales are relevant in the very early universe: the Planck scale and the effective potential of the inflaton.\n\nThe authors consider the Standard Model (SM) Higgs as a candidate for the inflaton and discuss the implications of the quartic self-coupling of the Higgs running with energy. They show that the effective Higgs potential is real as long as the quartic self-coupling is positive, but becomes complex as soon as it runs to negative values, leading to the decay of the inflaton.\n\nThe authors then apply their idea to SM Higgs-inflation, showing that the universe enters a state of fast-roll inflation, followed by about 60 e-foldings of slow-roll inflation. They find that this model evades constraints from WMAP 5-year data by breaking scale-invariance at the largest cosmological scales.\n\nThe paper concludes with a discussion of the fine-tuned running of the Higgs effective potential and the inclusion of one- and higher-loop corrections.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the challenges and possibilities of using the Higgs field as the inflaton and exploring various inflationary scenarios.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the role of the Higgs field in cosmological inflation.\n4. The methodology or approach used in the paper is mentioned, including the exploration of chaotic inflation scenarios and the consideration of the Higgs field's coupling to gravity.\n5. Significant results and conclusions are included, such as the proposal of a \"just enough\" chaotic inflation scenario and the impact of higher-loop corrections.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"inflaton\" and \"e-foldings.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance by discussing its potential impact on understanding inflation and the role of the Higgs field.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings about the Higgs field as a candidate for the inflaton and the scenario of \"just enough\" chaotic inflation. It also mentions the implications of the quartic self-coupling and the evasion of WMAP constraints.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of the Higgs field acting as the inflaton and the implications for inflation physics.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the examination of the Higgs field as the inflaton and the application to SM Higgs-inflation.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results such as the evasion of WMAP constraints and the implications of the quartic self-coupling.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"e-foldings\" and \"quartic self-coupling\" without explanation, which may not be clear to all readers.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear progression of ideas.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data, such as the WMAP 5-year data, which is a key part of the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the potential impact of probing inflation physics through particle physics experiments."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the fragmentation of molecular clouds ( mcs ) induced by supersonic turbulence is a fundamental aspect of the star formation process . recent models of the star formation rate @xcite and of the stellar initial mass function @xcite are based on the statistics of turbulent fragmentation , such as the probability density function ( pdf ) of gas density and the scalings of velocity and density fluctuations . so far , these statistics have been derived almost exclusively from numerical simulations with rather idealized setups , including periodic boundary conditions , driving by a random volume acceleration , isothermal equation of state , or no self - gravity ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? these simulations do not address important issues related to the coupling of the internal dynamics of mcs with the turbulence on larger scales , such as the ( large - scale ) origin of the turbulence and its role in the formation and dispersion of mcs and the cloud s finite lifetime .    to study mc turbulence in a more realistic larger - scale context , and specifically to test the idea that mc turbulence is driven primarily by sn explosions , we have carried out a magneto - hydrodynamic ( mhd ) adaptive - mesh - refinement ( amr ) simulation of sn - driven turbulence with the ramses amr code @xcite . the numerical method and setup were discussed extensively in @xcite paper i hereafter  and are only briefly summarized in the next section . although still somewhat idealized ( e.g.  periodic boundary conditions and no vertical stratification ) , this simulation represents a major advance relative to previous statistical studies of supersonic turbulence : it allows us i ) to test the effect of a realistic and physically motivated driving force , such as sn explosions , ii ) to see the development of mc turbulence as an integral part of the process of cloud formation and dispersion , iii ) to select a very large sample of mcs , forming _ ab initio _ from the large scale turbulence with realistic initial and boundary conditions ( and realistic statistical distributions of such conditions ) . in paper i we demonstrated that clouds selected from the simulations have mass and size distributions , and velocity - size and mass - size relations in agreement with the observations . using tracer particles , we also studied their evolution and found that they form and disperse in approximately four dynamical times . we also studied the velocity scaling in the whole volume and within individual mcs , showing that the turbulence , driven purely by sn explosions , is efficiently injected into mcs , with a realistic velocity dispersion in the dense gas . in this work , we focus on a specific aspect of direct interest to the modeling of star formation , that is the compressive ratio ( the ratio of powers in compressive and solenoidal motions ) of mc turbulence and its relation to the statistics of density fluctuations ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? besides sne , galactic gas infall , large - scale disk instabilities and spiral arm shocks are also sources of large - scale turbulence ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) , but it is generally accepted that sn explosions dominate the energy budget of star - forming galaxies at mc scales ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? because the primary goal of this work is to study the compressive ratio of the turbulence in mcs , we focus on the driving by sne . prior to our work , large - scale sn - driven turbulence in the multi - phase ism has been studied with fully - periodic volumes without stratifications ( e.g. * ? ? ? * ) , or with vertically extended , stratified galactic - fountain simulations ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? these works demonstrated that sne can drive ism turbulence with an outer scale of @xmath2 pc , and derived its velocity scaling laws and gas density pdfs . however , they did not reach the necessary spatial resolution to study mc properties , particularly the cascade of sn - driven turbulence in their interior . more recent simulations in periodic boxes @xcite or stratified galactic - fountains @xcite have significantly lower spatial resolution than earlier works , and do not tackle the problem of mc turbulence either . with resimulations of a kpc - size region from a global disc - galaxy simulation , @xcite achieved a large enough dynamic range to study the formation and disruption of mcs . in these simulations , mc turbulence is generated with various prescriptions for sn feedback , resulting in mcs with realistic velocity dispersion . however , the feedback is instantaneously inserted in any region of converging flows as the gas density reaches a threshold value of 500 @xmath3 , so the ability of sn feedback to drive the turbulence within mcs is assumed rather than demonstrated . the statistical properties of sn - driven turbulence from these simulations are not discussed . this paper is structured as follows . in section 2 , we give a brief description of the simulation setup , and in section 3 we summarize our recent findings concerning the compressibility of sn - driven turbulence . section 4 derives the overall expansion / contraction and rotation of the mcs selected from our simulation . section 5 analyzes the statistics of the compressive ratio of the turbulence within those mcs . the density variance - mach number relation and the density probability distribution in the mcs are explored in sections 6 and 7 , respectively . our conclusions are summarized in section 8 . we simulate a cubic region of size @xmath4 pc , with a minimum cell size of @xmath5 pc ( a maximum resolution equivalent to a mesh of @xmath6 cells ) , periodic boundary conditions , a mean density of 5 @xmath3 ( corresponding to a total mass of @xmath7 m@xmath8 ) and a core - collapse sn rate of 6.25 myr@xmath9 . we distribute sn explosions randomly in space and time ( see discussion in paper i in support of this choice ) , so our sn rate could also be interpreted as the sum of all types of sn explosions . individual sn explosions are implemented with an instantaneous addition of 10@xmath10 erg of thermal energy and 15 m@xmath8 of gas , distributed with an exponential profile in a spherical region of radius @xmath11 pc , which guarantees numerical convergence of the sn remnant evolution @xcite . besides the pdv work , and the thermal energy introduced to model sn explosions , our total energy equation adopts uniform photoelectric heating up to a critical density of 200 @xmath3 , and parametrized cooling functions from @xcite . the simulation is started with zero velocity , a uniform density @xmath12 @xmath3 , a uniform magnetic field @xmath13 @xmath14 g and a uniform temperature @xmath15 k. the first few sn explosions rapidly bring the mean thermal , magnetic and kinetic energy to approximately steady - state values , with the magnetic field amplified to an rms value of 7.2 @xmath14 g . we have run the simulation for 45 myr without self - gravity and then continued with self - gravity for 11 myr . the interested reader is referred to paper i for further details about the numerical setup . before analyzing the compressive ratio of the turbulence within mcs , we briefly summarize our recent results on the overall compressibility of sn - driven turbulence ( see details in paper i ) . in our discussion , we shall make a strict distinction between the driving acceleration , @xmath16 , for the turbulent velocity and the driving force , @xmath17 , for the flow momentum . as in previous works on supersonic turbulence , we are more concerned with the effective driving acceleration , @xmath16 , rather than the driving force , @xmath18 , because the compressibility of the velocity field is directly related to that of the driving acceleration , not the force . all studies of the compressibility of interstellar turbulence decompose the velocity , @xmath19 , rather than the momentum , @xmath20 , into solenoidal and compressive modes , and refer to the compressibility of the driving acceleration , rather than that of the driving force ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) .    in our simulation , the sn explosion energy is deposited as thermal energy in small , randomly - selected spheres , so it is initially injected via the pressure term in the navier - stokes equation . denoting as @xmath21 the pressure source due to sn explosions , the effective driving force and acceleration can be written as @xmath22 and @xmath23 , respectively . although the effective force , @xmath22 , is purely compressive , the driving acceleration , @xmath23 , is not so , in general . clearly , the divergence and the curl of this effective acceleration , @xmath23 , are given , respectively , by @xmath24 and @xmath25 . the latter , known as the baroclinic effect ( e.g. * ? ? ? * ; * ? ? ? * ) , is nonzero in general . in particular , considering random density and pressure fluctuations outside a sn - explosion sphere , the baroclinic term is always nonzero at the boundary of such a sphere . therefore , the effective acceleration for sn driving is neither purely compressive nor purely solenoidal , rather it consists of a mixture of solenoidal and compressive modes . if the direction of @xmath26 is random with respect to @xmath27 , the divergence and curl of @xmath23 are comparable , suggesting similar amounts of solenoidal and compressive modes in the effective acceleration . with the expansion of the remnant , solenoidal motions generated around the pressure  sources \" are transferred to larger scales . for example , a single sn remnant leads to an energy spectrum that peaks at a wavenumber @xmath28 , with @xmath29 the remnant radius ( see paper i ) . we find that , at large scales , the solenoidal and compressive modes in our simulation are roughly in equipartition , supporting the above picture . ( unshaded histogram ) , and contraction velocity , @xmath30 ( solid - line shaded histogram ) , normalized to the rms velocity in the cloud , for a sample of 507 clouds selected before the introduction of gravity . the dashed - line shaded histogram shows the probability distribution of mean cloud contraction velocity for a sample of 802 clouds selected after gravity is included in the simulation . this histogram has been normalized to the same total probability as the other two histograms . ] while the remnant expansion brings the velocity power to large scales , the nonlinear advection term causes cascades of both solenoidal and compressive modes towards small scales . if the sn rate is not too high and there is sufficient time in between sn events to allow the flow to fully develop , a dynamically quasi - relaxed state is reached . during the relaxation phase , one might expect the interaction between solenoidal and compressive modes via the nonlinear term to establish an equipartition between the two modes in the inertial range , as seen in simulations adopting an isothermal equation of state and purely solenoidal driving . however , this inertial - range equipartition is not observed in our simulation , because , in the relaxation phase , the baroclinic effect preferentially converts compressive modes ( shocks or expansions ) to solenoidal motions . due to its dependence on density and pressure gradients , the baroclinic effect is more efficient at smaller scales , and , as a result , the compressive spectrum decreases towards small scales faster than the solenoidal one ( see figure 8 in paper i ) . as a consequence , at scales corresponding to mc sizes , the ratio of compressive to solenoidal power is , on average , below the equipartition value of 0.5 . the goal of this work is to derive the distribution of the compressive ratio of sn - driven turbulence in mcs and the corresponding amplitude and probability distribution of density fluctuations . mcs may have non - negligible mean radial motions ( expansion or contraction ) and overall rotation . although these mean motions can be considered as the large - scale components of mc turbulence , it is nonetheless interesting to examine their importance relative to the random motions . in the next section , we will consider the compressive ratio of mc turbulence both with and without the contribution of the mean radial motion and of the overall rotation . , for the same cloud samples as in figure [ vex_hist ] , selected before and after the inclusion of gravity . ] we select mcs in the simulation as connected regions above a density threshold of @xmath31 @xmath3 ( see paper i ) and with mass @xmath32 m@xmath8 , and analyze the velocity field in the volume within the smallest rectangular cuboid ( ` bounding box ' hereafter ) containing each cloud . the actual cloud may cover only a small fraction of the total volume of its bounding box , so the velocity field we analyze includes lower - density , possibly warmer , gas . the inclusion of this surrounding gas in the analysis of the velocity field is justified because the dynamical evolution of the cloud involves the surrounding region , with lower density gas accreting onto the cloud , and denser gas expanding out of the cloud . the cloud boundary at 200 @xmath3 only serves the purpose of selecting individual objects and has no special dynamical significance . the overall expansion rate of a cloud is evaluated as @xmath33 , with @xmath34 the mean velocity divergence in the cloud bounding box . assuming a uniform expansion velocity , @xmath35 , with @xmath36 the separation to the cloud center , we define a characteristic expansion velocity , @xmath37 , as @xmath38 where @xmath39 is the volume of the bounding box and @xmath40 is the effective cloud radius , @xmath41^{1/2 } , \\label{eq_rc}\\ ] ] with @xmath42 the sides of the minimum bounding box . the absolute value , @xmath43 , is the rms of the overall expansion velocity . we find a characteristic value of @xmath44 km s@xmath9 . to evaluate the dynamical importance of @xmath37 , we plot in figure [ vex_hist ] the histograms of @xmath43 divided by the total rms velocity , @xmath45 , for 507 clouds selected from 30 snapshots before the introduction of gravity in the simulation , and 802 clouds selected from 30 snapshots after gravity was included . the histograms show that @xmath37 is typically only 10 - 20% of @xmath45 . for expanding ( @xmath46 ) clouds , @xmath47 and 0.19 , in the cases with and without gravity respectively , while for contracting ( @xmath30 ) clouds , @xmath48 in both cases . the comparison of the mean values for contracting clouds with and without gravity and their very similar histograms shown in figure [ vex_hist ] demonstrate that , despite the presence of self - gravity causing the collapse of their dense cores , mcs do not undergo global collapse . however , the fraction of clouds that are contracting ( rather than expanding ) is 0.62 with gravity and 0.45 without gravity , suggesting that gravity may be causing a global contraction in at least a fraction of the clouds ( even if their kinetic energy is dominated by random motions ) .    , and compressive power , @xmath49 , normalized to their values when the clouds are extracted at the maximum resolution , @xmath50 and @xmath51    the rate of the overall rotation of a cloud can be characterized by an angular velocity @xmath52 , with @xmath53 the average vorticity in the cloud . the velocity field of a solid - body rotation is given by @xmath54 , so we define the rms velocity of the overall rotation in the bounding box of each cloud , @xmath55 , as @xmath56 figure [ vrot_hist ] shows that the histograms of @xmath57 of clouds before ( solid line ) and after ( dashed line ) the inclusion of self - gravity are quite similar , with mean values of 0.28 and 0.27 , respectively . the comparison with figure [ vex_hist ] also illustrates that the solid - body rotation of the clouds contains more energy than the overall expansion or contraction , perhaps because the rotation has a larger number of degrees of freedom than the mean radial motion . we define the compressive ratio , @xmath58 , of the velocity field , @xmath19 , in a mc as @xmath59 where @xmath60 and @xmath61 are the compressive and solenoidal components of @xmath19 in the cloud bounding box . the two velocity components are derived with the standard helmholtz decomposition in fourier space . we have verified that the values of @xmath58 are quite insensitive to the boundary of the bounding box : making the velocity field in the bounding box periodic with a tapered cosine window function ( a gradual drop to zero of the velocity , affecting only the three outermost cell layers ) only changes the measured @xmath58 within a few percent .    as an independent check , we also measured @xmath58 based on the longitudinal ( @xmath62 ) and transverse ( @xmath63 ) structure functions in each cloud . under the assumption of statistical isotropy , exact relations exist between the structure functions and the compressive and solenoidal power spectra ( @xmath64 , @xmath65 ) . using equations ( 12.35 ) of @xcite , we find that @xmath66 /r \\,dr$ ] and @xmath67/r \\,dr$ ] , where @xmath68 is the 1d velocity dispersion . the value of @xmath58 computed from this method shows a tight correlation with that from the helmholtz decomposition , confirming the reliability of the measurement . below , we will only consider results from the helmholtz decomposition . our derived values of @xmath58 are expected to be numerically converged , because the selected clouds are very well resolved ( see images of selected clouds in figure 3 of paper i ) , with bounding box volumes between @xmath69 and @xmath70 computational cells ( only 3% of the boxes are below @xmath71 cells ) and because @xmath58 is a large - scale quantity within each cloud bounding box , as it only depends on total powers . to illustrate the large - scale nature of @xmath58 and the fact that it is insensitive to spatial resolution , we have analyzed the selected clouds at four different resolutions ( of the same simulation ) , corresponding to a range of @xmath72 to @xmath6 cells in the whole computational volume . figure [ converge ] shows this convergence test , where @xmath58 and @xmath49 have been normalized to their values at the highest resolution and then averaged over all clouds . convergence is clearly achieved at @xmath73 , and deviations in @xmath58 are within the 1-@xmath74 uncertainty even at the lowest resolution .    the solid unshaded histogram in figure [ chi_hist ] shows the distribution of @xmath58 for the 507 mcs selected before the inclusion of self - gravity . the histogram is well approximated by a lognormal distribution ( with the mean and rms of @xmath75 equal to -1.16 and 0.38 , respectively ) that peaks at @xmath76 , below the equipartition value of 0.5 found in isothermal simulations of highly supersonic turbulence with purely solenoidal driving ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) and the value of @xmath77 from isothermal simulations with purely compressive driving ( e.g. * ? ? ? * ; * ? ? ? * ) , and comparable to the value found in isothermal simulations with random solenoidal driving and with a relatively low sonic or alfvnic mach numbers @xmath78 @xcite . as discussed in section 3 and in paper i , this low mean value of @xmath58 at mc scales is likely the result of the baroclinic effect ( absent in isothermal simulations ) making the power spectrum of the solenoidal modes much shallower than that of the compressive modes ( see further discussion in section 8) . the overall expansion ( or contraction ) of a cloud contributes to the power in compressive motions , @xmath79 , while the solid - body rotation contributes to the solenoidal power , @xmath80 ; the power ratio of compressive to solenoidal motions may be computed after subtracting these contributions . thus , for each cloud , we define a new turbulent compressive ratio , @xmath81 , as @xmath82/[\\langle { \\bs v}_{\\rm s}^2 \\rangle - v_{\\rm r}^2 ] . \\label{chit}\\ ] ] the shaded solid - line histogram in figure [ chi_hist ] shows the probability distribution of @xmath81 for the same clouds as in the unshaded histogram of @xmath58 . it turns out that , after subtracting the contributions of the overall expansion and rotation , the distribution of the compressive ratio remains largely unchanged . the pdf of @xmath81 also peaks around 0.3 , confirming that the majority of _ turbulent _ energy is in solenoidal motions . the shaded dashed - line histogram in figure [ chi_hist ] shows the distribution of @xmath81 for the clouds selected after the inclusion of self - gravity . interestingly , the histograms of @xmath81 for the cases with and without gravity appear to be very similar as well ( peaking at @xmath83 and 0.30 , respectively ) , demonstrating that the presence of gravity does not noticeably affect the compressive ratio of turbulent motions in mcs .    , ( unshaded , thick solid line histogram ) and its turbulent component , @xmath81 ( shaded histograms ) . the probability of @xmath81 is plotted for clouds selected before ( solid - line histogram ) and after ( dashed - line histogram ) the inclusion of gravity ( the same cloud samples as in figures [ vex_hist ] and [ vrot_hist ] ) . the smooth curves are lognormal fits with mean values of -1.16 , -1.19 and -1.27 and rms values of 0.38 , 0.40 and 0.41 for @xmath58 , @xmath81 without gravity and @xmath81 with gravity respectively . ] although the probability distributions of @xmath58 and @xmath81 shown in figure [ chi_hist ] are nearly identical , the subtraction of the mean radial and rotational motions from the compressive ratio can have quite a large effect for individual clouds . figure [ h_chi ] shows the probability distribution of the ratio @xmath84 for the same samples of clouds with and without gravity as in the previous figures . although centered around a mean value @xmath77 , the distribution is quite broad . it is also rather insensitive to gravity . for the same cloud samples with and without gravity as in the previous figures . ] using isothermal simulations , it has been shown that the rms density , @xmath85 , where @xmath86 is the mean density , scales linearly with the rms mach number of the flow , @xmath87 , or , introducing the logarithm of the density , @xmath88 , @xmath89 where @xmath90 if the turbulence is driven by a purely compressive acceleration , @xmath91 if the acceleration is solenoidal , and even smaller values are possible with magnetic fields ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? expressions different from ( [ rms ] ) ( e.g. * ? ? ? * ; * ? ? ? * ) or extensions to non - isothermal polytropic or adiabatic turbulence @xcite have also been proposed . because @xmath92 is a crucial quantity in models of star formation based on turbulent fragmentation , it is important to verify if equation ( [ rms ] ) holds with realistic energy equation and sn driving as well . computed in logarithmic intervals of @xmath93 . the long - dashed line is the model prediction . ] considering the strong correlation between the parameter @xmath94 and the compressive ratio @xcite , and because only the compressive part of the velocity field can cause density fluctuations , we make the ansazt that , in eq . ( [ rms ] ) , @xmath95 is simply the compressive component of the mach number , @xmath96 . furthermore , to account for the effect of magnetic pressure , we adopt the model in ( * ? ? ? ( 28 ) ) and obtain : @xmath97 where @xmath98 is the ratio of gas to magnetic pressure ( see also @xcite ) and @xmath93 is a compressive effective mach number that includes the effect of magnetic pressure .    to test this relation , we have computed @xmath98 from the ratio of the alfvnic and sonic rms mach numbers , @xmath99 , where @xmath100 , and @xmath101 , with @xmath102 and @xmath103 the local sound speed and alfvn velocity respectively . similarly , we have computed the compressible rms mach number as @xmath104 , where @xmath105 is the modulus of the compressive part of the local velocity . figure [ mach ] shows @xmath92 versus @xmath93 for the mcs in our simulation . the upper panel shows the full sample , while the lower one includes only clouds with positive mean velocity divergence ( @xmath46 ) . as shown by the mean values of @xmath106 computed in logarithmic intervals of @xmath93 , the density fluctuations in the mcs from the simulation are roughly consistent with eq . ( [ rms2 ] ) , particularly in the case of expanding clouds , probably because expanding mcs are , on average , older than contracting ones and thus more relaxed . however , the relation has a very large scatter , so one should not expect a precise correlation between rms density and rms mach number in real mcs ( e.g. * ? ? ? * ) . and @xmath92 vary from cloud to cloud . _ inset _ : sum of all pdfs without any shifting or normalization , for clouds with gravity . the slope of the pdf tail is fit by a power law with exponent @xmath107 , in the range @xmath108 , corresponding to a slope of -2.64 for the pdf of @xmath109 . notice that the mean density , @xmath86 , varies from cloud to cloud . ] the compressive ratio of the turbulence has been shown to affect also the probability density function ( pdf ) of density fluctuations . the pdf is nearly lognormal in isothermal supersonic flows driven by a prescribed large - scale solenoidal acceleration ( e.g * ? ? ? * ) , though different function forms have also been proposed ( e.g. * ? ? ? * ) . however , if the driving acceleration is purely compressive , the pdf exhibits significant negative skewness ( e.g. * ? ? ? here we analyze the distribution of @xmath110 ( @xmath111 ) in the mcs selected from our simulation , where the effective sn driving consists of a mixture of compressive and solenoidal modes .    to focus on the pdf shape , we normalize the measured pdf of @xmath110 in the bounding box of each cloud , @xmath112 , to a mean of zero and an rms of one . the normalized pdf corresponds to the distribution of @xmath113 , which would be gaussian with zero mean and unity rms if the density pdf were exactly lognormal . the thick solid line in figure [ pdf ] shows the average of the normalized pdfs in the clouds selected before the inclusion of gravity . this composite pdf is in agreement with a gaussian distribution ( dashed line ) , except for an excess of probability on the left tail . the excessive left tail causes a small negative skewness , @xmath114 ( where @xmath115 corresponds to the uncertainty in the measurement of the mean skewness ) . this value is consistent with that found in simulations with solenoidal driving , @xmath116 , and significantly smaller than that from purely compressive driving , @xmath117 @xcite . notice that here we have converted the rms value of the skewness from 81 snapshots given in table 1 of @xcite to the uncertainty in the measured mean skewness by dividing their reported rms value by @xmath118 . this nearly lognormal shape of our composite pdf is consistent with the earlier observation that the effective driving of mc turbulence is more solenoidal than compressive . the thin solid - line plot in figure [ pdf ] shows the average of the normalized pdfs for the clouds selected after gravity is included . gravity gives rise to a power - law tail due to the formation of dense cores , as found in previous numerical studies ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? @xcite showed that , if a collapsing core has a density profile , @xmath119 , it would contribute a power - law tail , @xmath120 , to the distribution , @xmath121 , of the density , @xmath109 . in the inset of figure [ pdf ] , we show the overall probability distribution , @xmath121 , of the density , @xmath109 , for all the gas in the selected clouds in the presence of gravity . the right tail exhibits a @xmath122 power law , corresponding to a @xmath123 density profile for collapsing cores . we have shown that the compressive ratio of sn - driven turbulence within mcs follows a broad lognormal distribution , with an average value @xmath124 . here we provide tentative arguments to explain why the mean value is lower than the equipartition one and why @xmath125 exhibits a broad distribution .    the first baroclinic effect discussed in section 3 is concerned with the effective sn driving through a pressure source term , and we have argued that the compressive ratio of the effective driving acceleration is likely close to the equipartition value of 0.5 . the argument is supported by the fact that the relative directions of the pressure and density gradients in our simulated flow is roughly random . in paper i , we computed the compressive and solenoidal power spectra of the whole computational volume , @xmath126 and @xmath127 . inspection of figure 8 in paper i shows that @xmath128 at the effective energy - injection scale , @xmath129 pc , consistent with the compressive ratio of the effective driving acceleration being close to 0.5 . this shows that sn driving is not purely compressive , and that the average value of @xmath58 in mcs is expected to be no higher than 0.5 . furthermore , the compressive ratio computed from the solenoidal and compressive spectra drops rapidly with increasing wavenumber , @xmath130 , or decreasing length scales ( see paper i ) . we argued that this rapid drop in @xmath58 ( or steep decrease of the compressive spectrum with increasing @xmath130 ) is due to a second baroclinic effect , which preferentially converts compressive motions into solenoidal ones . this is the general baroclinic effect ( more general than the first one from the sn pressure source ) arising when the pressure and density gradients are misaligned ( e.g. , when a sn shock sweeps over a dense cloud ) . as discussed in paper i , due to its dependence on pressure and density gradients , the baroclinic effect is more efficient at small scales , meaning that it extracts \" energy from compressive modes and converts it to solenoidal modes faster at smaller scales , causing the rapid drop of the compressive spectrum toward larger @xmath130 . this efficient conversion of compressive modes into solenoidal ones at small scales is supported by the finding that the baroclinic effect contributes to the production of vorticity at a similar rate as vortex stretching ( kritsuk , private communication ) . due to this baroclinic effect , @xmath58 is typically smaller than the equipartition value of 0.5 at inertial - range scales . the average value of the effective size of our cloud bounding boxes , @xmath131 , where @xmath40 is the effective radius defined in equation ( [ eq_rc ] ) , is 48.2 pc , just below the energy - injection scale of our simulated flow . figure 8 of paper i shows that a value of approximately 0.3 is consistent with the time - averaged value of @xmath132 at a scale of approximately 48 pc . the broad distribution of @xmath58 can be understood by considering the amplitudes , @xmath133 and @xmath134 , of the solenoidal and compressive velocities at the cloud size . if @xmath135 is close to the energy injection scale , @xmath136 , the distributions of @xmath133 and @xmath134 are roughly gaussian . since the compressive power ratio is related to the ratio of @xmath137 , and the ratio of two gaussian variables has a distribution much broader than gaussian , one expects @xmath58 to show a broad , non - gaussian distribution , as found in section 5 . furthermore , at scales @xmath135 below @xmath136 , the solenoidal and compressive velocity amplitudes , @xmath138 and @xmath139 , would become non - gaussian due to turbulent intermittency . this tends to make the distribution of the ratio @xmath140 at small scales ( and hence the distribution of @xmath58 for smaller clouds ) even more non - gaussian with fatter tails . in this work , we have analyzed the sn - driven simulation of interstellar turbulence presented in paper i , focusing on the statistics of the compressive ratio of the turbulence within mcs . our main results are as follows :    1 .   the estimated compressive ratio of sn - driven turbulence within mcs follows a broad lognormal distribution , with the average @xmath141 in the case with gravity , and @xmath142 without gravity , comparable to the value found in isothermal simulations with random solenoidal driving and sonic or alfvnic mach numbers @xmath78 , and significantly lower than in isothermal simulations with purely compressive driving . self - gravity does not affect the compressive ratio significantly . the mean expansion or contraction velocity , @xmath37 , in the clouds is , on average , only a small fraction of the total rms velocity , with @xmath48 for the contraction velocity of both clouds with and without self - gravity . thus , even in the presence of self - gravity , mcs do not collapse as a whole . however , the fraction of clouds that are contracting grows from 45% to 62% after gravity is included . 3 .   the cloud solid - body rotation velocity is larger than the mean radial velocity , but still a small fraction of the total rms velocity on average , with @xmath143 and 0.27 for clouds before and after the inclusion of self - gravity . thus , cloud rotation is not significantly affected by gravity either . 4 .   the amplitude of the density fluctuations in mcs follows approximately a similar @xmath92 @xmath144 relation as in idealized simulations with random driving , but with a very large scatter around the mean @xmath92 @xmath144 curve . although significant deviations may exist for individual mcs , the composite gas density pdf obtained by the combination of the normalized pdfs of all clouds , in the absence of gravity , is very well described by a lognormal distribution , over nearly seven orders of magnitude for the probability at the high - density tail . once gravity is included in the simulation , the pdf develops a power - law high - density tail , @xmath145 , due to the presence of collapsing cores . our results demonstrate that numerical studies of mc turbulence on small to intermediate scales , which attempt to imitate the effect of the ism turbulent cascade by using a large - scale random acceleration , should adopt a driving scheme resulting in values of @xmath81 consistent with its distribution derived here , assuming sn explosions are the main driving mechanism of the ism turbulence . this distribution should also be accounted for when modeling star formation with statistics of supersonic turbulence . we acknowledge useful comments by the anonymous referee and discussions with alexei kritsuk that helped us improve the manuscript . computing resources for this work were provided by the nasa high - end computing ( hec ) program through the nasa advanced supercomputing ( nas ) division at ames research center , by prace through a tier-0 award providing us access to the computing resource supermuc based in germany at the leibniz supercomputing center , and by the port dinformaci cientfica ( pic ) , spain , maintained by a collaboration of the institut de fsica daltes energies ( ifae ) and the centro de investigaciones energticas , medioambientales y tecnolgicas ( ciemat ) . pp acknowledges support by the spanish mineco under project aya2014 - 57134-p . th is supported by a sapere aude starting grant from the danish council for independent research . research at centre for star and planet formation was funded by the danish national research foundation and the university of copenhagen s programme of excellence .                                    , a. , walch , s. , low , m .- m. , naab , t. , girichidis , p. , glover , s.  c.  o. , wnsch , r. , klessen , r.  s. , clark , p.  c. , baczynski , c. , peters , t. , ostriker , j.  p. , ibez - meja , j.  c. , & haid , s. 2015 , , 449 , 1057", "tags": [], "output_text_a": "This paper investigates the fragmentation of molecular clouds (MCs) driven by supersonic turbulence, a key process in star formation. The study uses a magneto-hydrodynamic adaptive-mesh-refinement simulation to explore the role of supernova (SN) explosions in driving turbulence within MCs. The simulation, while still idealized, represents a significant advancement by incorporating a realistic driving force and allowing the study of MC formation and dispersion. The research focuses on the compressive ratio of MC turbulence, which is the ratio of compressive to solenoidal motions, and its impact on density fluctuations.\n\nKey findings include:\n1. The compressive ratio of SN-driven turbulence in MCs follows a broad lognormal distribution, with an average value lower than the equipartition value found in isothermal simulations with solenoidal driving. This suggests that SN explosions contribute to a mix of solenoidal and compressive modes.\n2. The mean expansion or contraction velocity of clouds is a small fraction of the total rms velocity, indicating that MCs do not undergo global collapse even with self-gravity. However, the fraction of contracting clouds increases with gravity.\n3. Cloud rotation is not significantly affected by gravity, with rotation velocities being larger than mean radial velocities but still a small fraction of the total rms velocity.\n4. The amplitude of density fluctuations in MCs is consistent with previous models but shows large scatter. The density probability distribution function (PDF) is lognormal without gravity and develops a power-law tail with gravity due to collapsing cores.\n\nThe study emphasizes the importance of considering the distribution of the compressive ratio in models of star formation and suggests that SN explosions are a dominant driving mechanism of interstellar medium turbulence. The results provide insights into the dynamics of MCs and the role of turbulence in star formation processes.", "output_text_b": "This arXiv paper discusses a study on the fragmentation of molecular clouds (MCs) induced by supersonic turbulence, which is a crucial aspect of the star formation process. The authors use magneto-hydrodynamic (MHD) adaptive mesh refinement (AMR) simulations to investigate MC turbulence driven primarily by supernova (SN) explosions. The simulation, conducted with the Ramses AMR code, allows for a more realistic study of MC turbulence by testing the effect of a realistic driving force, observing the development of MC turbulence as part of cloud formation and dispersion, and selecting a large sample of MCs with realistic initial and boundary conditions.\n\nThe authors find that the simulated clouds have mass and size distributions, velocity-size and mass-size relations that are consistent with observations. They also find that the clouds form and disperse in approximately four dynamical times. The study focuses on the compressive ratio (the ratio of powers in compressive and solenoidal motions) of MC turbulence and its relation to the statistics of density fluctuations.\n\nThe work highlights the importance of SN explosions as the primary driver of the energy budget of star-forming galaxies at MC scales. The authors also emphasize the need to study the compressive ratio of the turbulence in MCs, as it is directly related to the effective driving acceleration of the turbulent velocity field.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings and Contributions**: The summary accurately reflects the main findings and contributions of the paper, including the investigation of the fragmentation of molecular clouds driven by supersonic turbulence and the role of supernova explosions.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem, which is the role of supernova explosions in driving turbulence within molecular clouds.\n\n4. **Methodology or Approach**: The summary mentions the use of a magneto-hydrodynamic adaptive-mesh-refinement simulation as the methodology.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the findings on the compressive ratio, cloud dynamics, and the density probability distribution function.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"compressive ratio\" and \"lognormal distribution.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Mention of Key Experiments or Data**: The summary mentions the simulation as a key experiment used in the research.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance by emphasizing the importance of the findings for models of star formation and the role of supernova explosions in interstellar medium turbulence.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the study of MC turbulence driven by SN explosions and the focus on the compressive ratio.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the fragmentation of MCs due to supersonic turbulence.\n4. **Methodology**: The summary mentions the use of MHD AMR simulations with the Ramses AMR code.\n5. **Significant Results**: The summary includes significant results, such as the consistency of simulated clouds with observations and the focus on the compressive ratio.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"compressive ratio.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions the use of simulations as key data in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding the energy budget of star-forming galaxies."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "strontium titanate has been the subject of ongoing theoretical and experimental investigation for over 30 years , due to its unusual properties . in cubic perovskite structure knbo@xmath0 and batio@xmath0 , transitions to ferroelectric phases occur as the temperature is lowered . srtio@xmath0 , which has the same high - temperature structure , behaves somewhat differently in that it undergoes an antiferrodistortive ( afd ) transition as the temperature drops below about 105  k@xcite . this is due to a softening of the lowest frequency triply degenerate zone - corner r - point vibrational mode of lowest energy@xcite . in this mode , the sr and ti atoms remain fixed , while the oxygen octahedra rotate about one of the cubic axes passing through the ti atom . the sense of the rotation is opposite in adjacent cells in all directions as shown in fig . [ fig1 ] . as the temperature continues to drop below the afd transition , there is a sharp rise in the value of the static dielectric constant . this increase appears to follow a curie - weiss law consistent with an impending ferroelectric ( fe ) transition at about 20  k. with decreasing temperature , however , the static dielectric constant saturates at a high value , and the material does not become ferroelectric even at the lowest temperatures@xcite . it has been suggested that the fe transition is inhibited due to quantum paraelectric behavior , in which the zero - point motion of the atoms suppresses the long - range fe order@xcite . it is thus of great interest to characterize the structural instabilities of srtio@xmath0 . the present work is concerned with the wavevector dependence of structural instabilities in srtio@xmath0 , obtained from first - principles calculations , and their interpretation in light of previous similar calculations on knbo@xmath0 . our calculations are carried out utilizing the lapw formalism@xcite , wherein the wave functions , charge density , and potential all have dual representations . within non - overlapping muffin - tin spheres , these quantities are expanded as numerical radial functions times spherical harmonics , while in the interstitual region , a plane wave representation is used . this method has several attractive features , such as employing an unbiased representation in the interstitual region and the ability to easily treat first - row and d - band atoms . the major drawback presented by this method is the use of position - dependent basis functions . this introduces correction terms when computing such quantities as the forces on the atoms@xcite , and thus complicates the computer programs . in order to investigate all possible soft phonon modes in a particular substance , we must map out the dispersion curves throughout the brillouin zone . this is accomplished quite easily using linear response theory@xcite . in linear response theory , the total variational energy is expanded to second order as a function of the equilibrium charge density and the first - order change in the charge density : @xmath1 + \\lambda e^{(1)}[\\rho^{(0 ) } ] +          \\lambda^2 e^{(2)}[\\rho^{(1 ) } ] + \\cdots.\\ ] ] minimizing this energy with respect to the first - order change in the charge density yields a pair of equations which must be solved self - consistently : @xmath2 @xmath3 \\biggl )    \\psi_i^{(0)}.\\ ] ] the equations are the first - order analogs of the usual local density approximation ( lda ) equations , i.e. this is an exact theory ; there are no approximations beyond lda . the dynamical matrix elements for a given wavevector @xmath4 are found via the first - order forces . the forces on all the atoms are calculated for at most 3n selected atomic displacements at each wavevector , where n is the number of atoms in the primitive cell . to map the phonon dispersion curves throughout the brillouin zone , we compute the dynamical matrix on a uniform grid of q - points . the short - range real - space force constants are then obtained by fourier transform , after subtracting out the analytic long - range dipolar contribution . by inverse fourier transform , adding in the long - range part , we may compute the dynamical matrix at an arbitrary q - point . for the srtio@xmath0 calculations , we have used a 6@xmath56@xmath56 mesh of q - points . exploiting symmetry , we had to compute the dynamical matrix at only 20 q - points in the irreducible bz wedge . typically , at each q - point , 3n=15 self - consistent calculations were performed . the electronic contribution to the static dielectric constant , @xmath6 , is determined from the induced potential : @xmath7.\\ ] ] the macroscopic polarization at long wavelength is given by the first order change in the charge density @xmath8 and from this we can compute the born effective charges @xmath9 here , z@xmath10 is the ionic contribution , and the second term is the unit cell volume times the derivative of the polarization with respect to displacements of the atoms at zero electric field . we first performed self - consistent total - energy calculations in the cubic phase to determine the equilibrium properties . table  [ table1 ] lists the theoretical lattice parameters and bulk moduli for the present work , along with those of king - smith and vanderbilt @xcite , as well as some experimental values . our calculated lattice parameter is only 0.4% larger than the experimental value , so we have used the theoretical value in the following calculations . the electronic component of the static dielectric constant , @xmath6 , was found to be 6.63 , which is about 28% larger than an experimental value of 5.18 . this kind of overestimation of @xmath6 is typical of lda calculations@xcite . table  [ table2 ] lists the born effective charges ( z@xmath11 ) for each type of atom . for sr and ti , the values are isotropic , while for the o atoms , there are two distinctive values  for displacements along and perpendicular to the ti - o bonds , labeled @xmath12 and @xmath13 , respectively . also listed are the results of calculations by zhong , king - smith , and vanderbilt@xcite . respective theoretical lattice parameters were used for the calculations . note the anomalously large values for z@xmath14(ti ) and z@xmath14(o)@xmath15 due to strong covalent interactions between these atoms@xcite . we find that our results are generally in good agreement with those of zhong _ et al._@xcite . table  [ table3 ] compares our zone - center optic phonon frequencies with planewave pseudopotential frozen phonon calculations and experimental data . both calculations find unstable transverse optic ( to ) modes at the @xmath16-point with imaginary frequencies . the longitudinal optic ( lo ) mode frequencies were obtained using @xmath17 where _ d_@xmath18 is the zone - center dynamical matrix without macroscopic field , * z@xmath19 * and m@xmath20 are the born effective charge tensor and mass for atom @xmath21 , @xmath22 is the volume of the unit cell , @xmath23 , @xmath24 are cartesian indices , and @xmath25 is a unit wavevector . the results of zhong , king - smith , and vanderbilt were determined using @xmath6=5.18 from experiment , whereas we used our larger calculated value of 6.63 . to determine what effect @xmath6 has on the lo mode eigenvalues , a second calculation was performed using @xmath6=5.18 . the highest lo mode is most sensitive , changing from 751 to 832 @xmath26 , while the other two are fairly insensitive . we present the calculated phonon dispersion curves for cubic srtio@xmath0 plotted along high - symmetry directions in fig . the @xmath16x , @xmath16 m , and @xmath16r lines correspond to the @xmath27100@xmath28 , @xmath27110@xmath28 , and @xmath27111@xmath28 directions , respectively . imaginary frequencies are represented by negative values . the character of the modes at the zone - center and zone - boundaries has been labeled according to the notation by cowley@xcite . the form of some of our lower dispersion curves for the @xmath16 m and @xmath16r directions is roughly in accordance with data reported by shirane and yamada at 120  k@xcite , including an apparent softening of a mode at the r - point . similar behavior is seen at the m - point , but the lowest zone - boundary phonon mode m@xmath0 was reported as being temperature - independent through the afd transition . since we are mainly concerned with structural instabilities and how they relate to the observed phase transitions , we will focus on the portions of the dispersion curves which lie below the @xmath29=0 dashed line in fig . note the large phase space for unstable modes . our calculations indicate unstable modes at the r - point ( r@xmath30 ) , zone - center ( @xmath31 ) , and m - point ( m@xmath0 ) . these instabilities are of two types : fe ( @xmath31 ) , and afd ( r@xmath30 and m@xmath0 ) . in the @xmath31 to mode , ti atoms move parallel to one of the ti - o bonds , and the oxygen octahedra move in the opposite direction . this mode is responsible for the fe transitions in materials like batio@xmath0 and knbo@xmath0@xcite . the m@xmath0 mode is nearly identical to the r@xmath30 mode in fig . [ fig1 ] with one exception . the rotation of the octahedra is in the @xmath32 sense in neighboring cells along the vertical c - axis , but remains opposite in the horizontally adjacent cells . the dispersion curves of fig . [ fig2 ] show @xmath33 , suggesting that lda may find a fe structure ( rhombohedral ? ) to be lower in energy than the afd tetragonal structure . of course experimentally there is no observed transition from afd to fe phase , although it is seen in the monte carlo simulations of zhong and vanderbilt@xcite . recently , they have included quantum fluctuation effects into these simulations , and find the fe transition completely suppressed@xcite . the regions of instability in the bz are better visualized in fig . [ fig3 ] , in which isosurfaces , corresponding to @xmath29=0 , are shown for the lowest unstable phonon modes . the cubic bz , with @xmath16 at the center , is also shown . the inner isosurface is centered at the @xmath16-point , and can be visualized as three interpenetrating `` cookies '' , one perpendicular to each cartesian direction . the region of fe - type instability is interior to this first isosurface . between the first and the second isosurface , which lies near the zone edges , all modes are stable . thus unstable modes are present along the entire r - m - r edge of the bz . in a repeated - zone scheme , this isosurface would appear as narrow cylindrical tubes extending from r - m - r . we now discuss the current work in light of results for similar calculations on cubic knbo@xmath0 by yu and krakauer@xcite . the dispersion curves of knbo@xmath0 also reveal a large region of instability for the lowest modes . in contrast to srtio@xmath0 , a soft mode is present at the x - point , and the lowest r - point mode is stable . although m - point instabilities exist for both materials , the character of these modes is quite different . in knbo@xmath0 the motion of the atoms is the same as for the zone - center @xmath31 mode with the exception that two o atoms perpedicular to the motion remain fixed , i.e. it is essentially the `` ferroelectric '' soft mode . in srtio@xmath0 , the motion is a rotation of the octahedra as described above . a similar @xmath29=0 isosurface plot for knbo@xmath0 shows that the fe instability extends from the zone - center all the way to the zone - boundary within planar slab - like regions . an afd instablility was not present in the knbo@xmath0 calculations . notice that in srtio@xmath0 , the large planar regions of fe instability have shrunk down to three interpenetrating `` cookies '' , and the phase space corresponding to the fe character is greatly reduced . because the regions of instability in knbo@xmath0 reside in slabs which extend across the entire bz , any linear combination of phonon modes within one of these regions will also be unstable . in a real - space picture , unstable atomic chain - like structures can develop , where the nb atoms are all displaced in the same direction@xcite . the width of the slab - like regions in knbo@xmath0 indicates the length of the shortest such chains to be about 5 lattice parameters@xcite . we can perform a similar qualitative analysis of the real - space motion of the atoms in srtio@xmath0 from its isosurface plot . since there exists a continuous instability extending from r - m - r , linear combinations of phonon modes along this cylindrical tube - like region will also be unstable . the character of modes along the zone edges is one of rotating oxygen octahedra ; thus , an unstable thin disk or planar region could form in real space wherein the octahedra are rotated in opposite senses in neighboring cells , with the surrounding regions remaining undisplaced . from the width of the cylinders containing the instability , we estimate the smallest radius of the real - space disks to be approximately 35 lattice parameters . because of the sensitive dependence of the soft modes on volume , it is possible that these cylinders may pinch off at the m - point at slightly reduced volumes . we have not investigated this yet . in summary , we performed first - principles linear response calculations of the wavevector dependence of structural instabilities for cubic srtio@xmath0 . in comparison with previous work on knbo@xmath0 , we notice three differences . first , calculations on knbo@xmath0 show a ferroelectric - type instability only , while srtio@xmath0 calculations exhibit both fe and afd instabilities . second , the phase space of the two - dimensional fe instability ( corresponding to chains in real space ) is greatly reduced and no longer extends to the zone - edges as in knbo@xmath0 , but is restricted to the interior of a region likened to three inter - penetrating `` cookies '' . third , the afd instability occupies a rather large region of phase space extending along the entire bz edges in cylindrical tubes . the essentially 1-d character of these tubes corresponds to real - space planar instabilities characterized by rotations of the oxygen octahedra . future calculations for srtio@xmath0 in the tetragonal phase ( below the afd transition ) will be required in order to investigate any instabilities  especially ferroelectric instabilities  that persist . this research was supported by office of naval research grant n00014 - 94 - 1 - 1044 . wang was supported by national science foundation grant dmr-9404954 . computations were carried out at the cornell theory center . o. k. andersen , phys . b * 12 * , 3060 ( 1975 ) ; e. wimmer , h. krakauer , m. weinert , and a. j. freeman , phys . rev . b * 24 * , 864 ( 1981 ) ; s .- h . wei and h. krakauer , phys . lett . * 55 * , 1200 ( 1985 ) ; d. j. singh , _ planewaves , pseudopotentials and the lapw method _ ( kluwer academic publishers , massachusetts , 1994 ) .", "tags": [], "output_text_a": "The paper investigates the structural instabilities of strontium titanate (SrTiO3) using first-principles calculations. Unlike other perovskites like KNbO3 and BaTiO3, which transition to ferroelectric phases at lower temperatures, SrTiO3 undergoes an antiferrodistortive (AFD) transition below 105 K due to the softening of a specific vibrational mode. Despite an increase in the static dielectric constant suggesting a potential ferroelectric transition at around 20 K, SrTiO3 does not become ferroelectric, likely due to quantum paraelectric behavior. The study uses the LAPW formalism to map phonon dispersion curves and identify soft phonon modes throughout the Brillouin zone. The results show both ferroelectric (FE) and AFD instabilities, with the FE instability being more restricted compared to KNbO3. The AFD instability is extensive, suggesting planar instabilities characterized by rotating oxygen octahedra. The findings highlight differences in phase space and instability character between SrTiO3 and KNbO3, with implications for understanding phase transitions in these materials. Future work will explore instabilities in the tetragonal phase of SrTiO3. The research was supported by the Office of Naval Research and the National Science Foundation, with computations conducted at the Cornell Theory Center.", "output_text_b": "This article discusses the investigation of structural instabilities in SrTiO3, which has a cubic perovskite structure and undergoes an antiferrodistortive (AFD) transition at around 105 K. The AFD transition is caused by the softening of the lowest frequency triply degenerate zone-corner R-point vibrational mode, resulting in oxygen octahedra rotation about one of the cubic axes passing through the Ti atom. The article also explores the potential for a ferroelectric (FE) transition, which is inhibited due to quantum paraelectric behavior.\n\nThe authors present a study on the wavevector dependence of structural instabilities in SrTiO3 using first-principles calculations. They utilize the Linear Response Theory to map out the dispersion curves throughout the Brillouin zone and compute the dynamical matrix at an arbitrary q-point. The study reveals unstable modes at the R-point, zone-center, and M-point, which are of two types: FE and AFD. The authors also compare their results with similar calculations on cubic KNbO3 by Yu and Krakauer, highlighting differences in the regions of instability and the character of unstable modes.", "score": 0.20000000000000007, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the structural instabilities of SrTiO3 and comparing it with other perovskites.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem, which is the investigation of structural instabilities in SrTiO3.\n4. **Methodology**: The summary mentions the use of first-principles calculations and the LAPW formalism to map phonon dispersion curves.\n5. **Significant Results**: The summary includes significant results, such as the identification of both FE and AFD instabilities and the implications for phase transitions.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"antiferrodistortive\" and \"quantum paraelectric behavior\" but provides context to understand them.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions the use of first-principles calculations and phonon dispersion curves but does not detail specific experiments or data.\n10. **Significance/Impact**: The summary reflects the paper's significance by discussing the implications for understanding phase transitions.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings regarding the structural instabilities in SrTiO3 and the comparison with KNbO3.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the investigation of structural instabilities in SrTiO3.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of first-principles calculations and Linear Response Theory.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results such as the unstable modes and the comparison with KNbO3.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"antiferrodistortive\" and \"ferroelectric\" but does not explain them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly mention the significance or potential impact of the research."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "classical ensemble theory with its liouville equation implies the absence of a stable ground state , when rewritten as a hilbert space theory with an analogue of the schrdinger equation  @xcite . correspondingly , the analogue of the vonneumann equation obtains an unusual superoperator which couples the hilbert space and its dual  @xcite , cf . section  2 below . these features have presented serious obstacles to a number of recent attempts to understand quantum mechanics as an emergent phenomenon  @xcite , see also refs .  @xcite . such studies are strongly motivated by issues surrounding quantum gravity , in particular , the fact that quantum theory is hardly compatible with the symmetry requirements of general relativity or of other theories describing gravity and spacetime , which are based on general coordinate invariance . furthermore , despite the great successes in explaining statistical aspects of experiments , the intrinsically indeterministic features of quantum mechanics remain problematic . this is seen , for example , in the unresolved measurement problem , with related issues of wave function collapse or objective reduction  @xcite , and in the quantum mechanics of the universe , considered as a whole , which might be self - contradictory . yet there is a proof of existence of deterministic models for quantum mechanical objects , in which dissipation , i.e. , a fundamental information loss mechanism , has been an essential ingredient  @xcite .    with these findings in mind , we presently discuss aspects of a dynamical transition _ from _ classical _ to _ quantum behaviour , assuming that : _ quantum features originate from a dissipative process which affects all physical objects . dynamics and statistical interpretation of quantum states ( born rule ) originate from deterministic rules , such as embodied in classical mechanics , in an ensemble theory . _    we speculate that the _ atomistic _ structure of spacetime itself is responsible for effects which are attributed to quantum mechanics , typically operating at length scales very much larger than the planck length . here `` atomistic '' refers to a discrete set of elements with the presence , or absence , of a certain order relation between any two elements . furthermore , this set , in particular the number of its elements changes dynamically , possibly establishing new order relations , or erasing old ones . in this way , `` time happens '' . similar ideas about the nature of spacetime have been formulated every now and then throughout the history of natural philosophy  @xcite . however , only recently such general scenario has been elaborated in more detail in the theory of _ causal sets_. in mathematical terms , these are locally finite ordered sets . their evolution by sequential growth through random ( `` sprinkling '' ) appearance of new set elements together with their order relations has been studied  @xcite .    in the absence of an equally elaborate theory of matter in relation to such atomistic structure of spacetime , we can nevertheless state the following , concerning the situation of a typical object . consider an electron , for example , an object that to highest known precision behaves according to the laws of quantum mechanics . we may term its `` situation '' a hypothetical complete set of its properties that are accessible by experiments . now , first of all , there are interactions between such object and its environment ( the `` rest of the universe '' ) , last not least gravitational ones . besides more familiar aspects , however , there must exist a continual _ information loss _ about its situation , since the atomistic spacetime beneath evolves . with respect to the latter , quantum theory at present deals with very coarse - grained phenomena , when describing the dynamics of matter . loosely speaking , in order to fully characterize an electron , the evolution of its causal relations with a continually changing number of spacetime `` atoms '' has to come into play . consequently , in a coarse - grained picture where this is not explicitly taken into account , information about an object degrades , due to the evolving always and everywhere present  environment which is spacetime . secondly , however , common objects are characterized by a certain persistence , which makes them identifiable in experiments . therefore , the information loss must be a delicate one . it must be compatible with the _ conservation of probability _ , which is a basic tenet of a reasonable ensemble theory . contrary to measurement processes in quantum mechanics , where information is transferred from microscopic to macroscopic objects ,   we propose here that matter degrees of freedom are continually `` measured '' by the evolution of spacetime . these heuristic considerations lead us to modify the classical ensemble theory in important ways . we will incorporate dissipation into the liouville equation , however , in such a way that probability conservation remains intact . this provides us with a glimpse of the mechanism that might be responsible for turning the deterministic evolution of classical objects , described here by an ensemble theory , into the schrdinger evolution of quantum objects . it will be shown here how the _ classical _ liouville equation can be written in the form of the _ quantum mechanical _ vonneumann equation , generally , incorporating a characteristic extra term . we consider objects with a single continuous degree of freedom , for simplicity .   to begin with , we consider conservative forces , such that the equations of motion are determined by the generic hamiltonian function : @xmath0 depending on generalized coordinate @xmath1 and momentum @xmath2 , and where @xmath3 denotes the _ true potential_. in section  3 , we will come back to the notion of the true potential and distinguish it from a related _ coarse - grained potential _ @xmath4 . an ensemble of such objects , for example , following trajectories with different initial conditions , is described by a distribution function @xmath5 in phase space , i.e. , by the probability @xmath6 to find a member of the ensemble in an infinitesimal volume at point @xmath7 . this distribution evolves according to the liouville equation : @xmath8 with @xmath9 . we recall that the relative minus sign in the poisson bracket , or between terms here , reflects a symplectic phase space symmetry . this will translate into the familiar commutator structure in eq.([schroed ] ) .    a fourier transformation , @xmath10 , replaces the liouville equation by : @xmath11 without changing the notation for the distribution function , whenever changing variables . thus , momentum is eliminated and a _ doubled number of coordinates _ results . finally , with the transformation : @xmath12 we obtain the liouville equation in the form : @xmath13 \\label{hx }   \\hat h_\\chi & : = & -\\frac{1}{2}\\partial_\\chi ^{\\;2}+v(\\chi ) \\;\\ ; ,   \\;\\;\\;\\mbox{for}\\;\\;\\chi = q , q   \\;\\ ; , \\\\ [ 1ex ] \\label{i }   { \\cal e}(q , q)&:=&(q - q)v'(\\frac{q+q}{2 } ) -v(q)+v(q)\\;=\\;-{\\cal e}(q , q ) \\;\\;. \\end{aligned}\\ ] ] several comments are in order here :    * the present reformulation of classical dynamics in phase space can be carried out rather independently of the number of degrees of freedom and is applicable to matrix or grassmann valued variables as well ; see , for example , refs . gauge theories or , generally , theories with constraints have to be examined carefully . + * most importantly , the eq.([schroed ] ) closely resembles the _ vonneumann equation _ for a density operator @xmath14 , considering @xmath15 as its matrix elements . we automatically recover the hamiltonian operator @xmath16 related to the hamiltonian function , eq.([hamiltonianf ] ) , as in quantum theory . however , an essential difference consists in the interaction @xmath17 between _ bra- _ and _ ket- _ states . the hilbert space and its dual here are coupled by a _ superoperator_.  ) . it differs from a lindblad superoperator , often obtained as a symmetric double commutator structure , in the case of open quantum mechanical systems  @xcite ; this is seen , for example , in our eq.([vnlm ] ) below . ] + * alternatively , the eq.([schroed ] ) might be read as the _ schrdinger equation _ for two identical ( sets of ) degrees of freedom . however , their respective hamilton operators , @xmath18 , contribute with opposite sign , which must be traced to the classical symplectic symmetry . since their interaction @xmath17 is antisymmetric under @xmath19 , the complete ( liouville ) operator on the right - hand side of eq.([schroed ] ) has a symmetric spectrum with respect to zero and , in general , will not be bounded below . + * finally , the following observation will be important : @xmath20 the analogous vanishing of @xmath17 in a field theory is equivalent with having massive or massless free fields , with or without external sources , and with or without bilinear couplings . generally , in all these cases , anharmonic forces or interactions are absent . we emphasize that the coupling of the hilbert space and its dual and the related lacking of a stable ground state , in general , show that our reformulation of hamiltonian dynamics does not qualify as a proper quantum theory . however , we will motivate certain modifications from which dynamical aspects of quantum mechanics seem to emerge after all . here we present a simple - minded argument indicating that the discreteness of spacetime may be relevant for the emergence of quantum mechanical phenomena , turning the liouville equation into the vonneumann  -  lindblad equation , in particular . given that spacetime is discrete , there must be a characteristic length scale , the planck length , where the continuum description of all phenomena breaks down . this implies that one might overlook important traces of this atomistic structure by employing continuum quantities which allow to arbitrarily extrapolate their functional dependence to scales @xmath21 , where @xmath22 denotes the planck length .    instead of having a _ coarse - grained potential _ @xmath4 , for example , the _ true potential _ @xmath3 should become piecewise defined somehow , when approaching smaller and smaller scales in the continuum picture . thus , the function @xmath4 is an approximation to @xmath3 and the difference between the two must give rise to local _ fluctuations _ therefore , we set : @xmath24 in order to relate the short distance behaviour to its coarse - grained description . two sources of fluctuations can enter here : first , the spatiotemporal discreteness @xcite . second , the possibly discrete nature of interactions or matter . the latter might go beyond what is usually seen as _ effects _ of quantum mechanics . this has not been explored in parallel with the causal set theory of the deep structure of spacetime and will not be further discussed at present . however , there is an important `` asymptotic freedom '' effect , caused by spatiotemporal discreteness : on a ( background ) causal set , cross sections must fall to zero when the center of mass energy of two scattering particles reaches the planck scale @xcite . this is based on viewing the causal set _ as if _ generated by a poisson process , `` sprinkling '' set elements with an average density of one element per planckian volume , @xmath25  for example , into minkowski space , if this is considered as the continuum limit . the `` asymptotic freedom '' effect suggests to consider the _ true potential _ function @xmath3 as _ piecewise linear _ , with the pieces  simplices in higher dimensions  characterized by short `` linearity lengths '' @xmath26 . they must be , however , sufficiently larger than the planck length , @xmath27 , such that the continuum description is meaningful .     with these remarks in mind , we reconsider the force term @xmath28 in eq.([schroed ] ) . we rewrite this equation , admitting more than one spatial dimension , more simply as : @xmath29_{(\\mathbf{q},\\mathbf{q};t ) } + ( \\mathbf{q}-\\mathbf{q})\\!\\cdot\\!\\mathbf{\\nabla } v(\\frac{\\mathbf{q}+\\mathbf{q}}{2})f(\\mathbf{q},\\mathbf{q};t ) \\;\\;,\\ ] ] where @xmath30 , with @xmath31 denoting the laplacian , in an obvious generalization . now , the term involving the derivative of the potential is related to the _ would - be quantum mechanical _ term  the potential difference between points @xmath32 and @xmath33  as a linear mid - point approximation to an integral : @xmath34 the approximate relation becomes an exact equality in the cases covered by observation ( [ ezero ] ) .    more generally , the integral  which yields _ exactly _ the quantum mechanical term  can be decomposed into a sum of integrals along straight line segments : @xmath35 determined by a set of positions @xmath36 which match the piecewise linearity of the true potential with the path of integration from @xmath37 to @xmath38 , i.e. , with the linearity lengths , @xmath39 . we conclude that within small volumes , the linear size of which is determined by the linearity length @xmath40 of the potential there , the liouville equation of _ classical _ statistical mechanics , in the form of eq.([schroed ] ) or eq.([schroedr ] ) , is _ indistinguishable _ from the corresponding _ quantum mechanical _ vonneumann equation , which both refer to the continuum description . furthermore , we learn from eqs.([schroedr])([qmintegral ] ) that for larger distances , covering several linearity lengths @xmath26 , the potential ( commutator ) term of the vonneumann operator is obtained as a _ sum of classical contributions_. this summation is natural in view of the fact that each term adds an appropriate amount of energy to the potential difference @xmath41 , with one contribution per interval over which the potential is linear .    in this way , we obtain the hamilton operator for arbitrarily extended , piecewise linear potentials : @xmath42 in the coordinate representation , and readily infer the vonneumann equation in operator form : @xmath43 \\;\\;.\\ ] ] however , following the argument from eq.([schroedr ] ) to eq.([vnplp ] ) , there is a subtlety behind the last two equations here , concerning the composition of the simplices .    in the continuum picture , each simplex forms a tiny `` box '' with a _ sharply localized _ boundary condition , which prohibits the leaking of probability to the outside  as long as they are sufficiently separated . bringing two such boxes next to each other , such that a common border region arises which is less than a planck length `` thick '' , the confining boundary condition will dissolve into a free boundary condition , no matter how it originated in the first place . this is another manifestation of the `` asymptotic freedom '' property , caused by the discrete spacetime structure . thus , we imagine that the range of variables entering the matrix elements of @xmath44 can adiabatically increase to the full range over both simplexes . while this `` gedankenexperiment '' might seem plausible , a serious justification of the extension of the range of validity of eq.([vnplp ] ) over more than one linearity length seems necessary . we intend to come back to this important point elsewhere .      in order to extend our considerations further to reach the scales where quantum mechanics is known to work , we have to address also the coarse - graining that must be involved . this can not be analyzed rigorously without understanding how the common forces / interactions that we encounter relate to phenomena at much shorter distance scales , such as the linearity scale . however , qualitatively , we expect the coordinates to _ fluctuate _ , which enter the continuum description , in particular , when we write down the vonneumann equation with the potential terms obtained in eq.([qmintegral ] ) . indeed , let us consider , for example , an event determined in the continuum picture . the position ascribed to it in a fixed lorentz frame can not be exactly maintained with time , if minkowski space is a _ continuum approximation _ to an underlying discrete structure : to the future of this event there likely will be planck scale size ( or larger ) patches of minkowski space which contain no element of the approximated causal set . it appears to us that the event , respectively its successors , must change position by small amounts with time ( `` swerve '' ) , effectively performing a random walk within its future lightcone @xcite . we can get a feeling for the linear size @xmath45 of these swerves by estimating the probability to have a spherical void of volume @xmath46 that lasts for a planck time interval . for the poisson process mentioned earlier and with @xmath47 , we find this to be @xmath48 . therefore , uncertainties @xmath45 of the order of a typical distance pertaining to the standard model , for example , are extremely improbable . nevertheless , at the linearity scale they may play an essential role in washing out the piecewise linear potentials .     by experience , smooth polynomial interactions play an essential role , say in the standard model and , to be derived from there , in phenomenological forces of physics at still lower energies . since details of the coarse - graining are unknown , in particular those leading to highly constrained gauge symmetries , we now consider the phenomenological _ ansatz _ of eq.([ansatz ] ) , which connects _ short distance behaviour at the linearity scale _ with its _ coarse - grained description_. in particular , this replaces a true , piecewise linear potential @xmath3 by a coarse - grained potential @xmath4 plus local fluctuations @xmath23 . the fluctuations are treated as white noise with mean and correlation , respectively , given by : @xmath49 \\label{correl }   \\langle\\delta v(\\mathbf{x})\\delta v(\\mathbf{y})\\rangle   & = & \\nu^2(\\mathbf{x})\\delta ( \\mathbf{x}-\\mathbf{y})/\\delta ( 0 )     \\;\\ ; , \\end{aligned}\\ ] ] where @xmath50 describes the width of the local distribution of fluctuations . this distribution can not be assessed without further insight into how forces arise at small spacetime scales . we now implement eq.([ansatz ] ) , @xmath51 , in the vonneumann equation following from eqs.([schroedr])([qmintegral ] ) , with piecewise linear potential . this yields the vonneumann equation with the coarse - grained potential @xmath4 and additional fluctuating terms : @xmath52 \\;\\;,\\ ] ] where the effective hamilton operator is now given by : @xmath53 \\label{heff1 } & : = & -\\frac{1}{2}\\partial_{\\mathbf{x}}^{\\;2}+v(\\mathbf{x})+\\delta v(\\mathbf{x } ) \\;\\ ; , \\end{aligned}\\ ] ] in the coordinate representation , cf . eq.([vnplp ] ) . in order to evaluate the influence of the fluctuations , we iterate eq.([vnl ] ) once : @xmath54+\\mbox{o}(\\delta v ) -[\\delta v,[\\delta v,\\hat f ] \\;\\;.\\ ] ] integrating once , with the initial condition : @xmath55_{t=0}+\\mbox{o}(\\delta v ) \\;\\;,\\ ] ] and averaging over the fluctuations , with the help of eqs.([mean])([correl ] ) , leads to : @xmath56 -\\int_0^t\\mbox{d}t'(\\{\\hat\\nu^2,\\hat f\\}-2\\hat\\nu\\hat f\\hat\\nu ) \\;\\;,\\ ] ] with the matrix elements @xmath57 and @xmath58 . for sufficiently short times and slowly varying @xmath44 , we may use the approximation : @xmath59 -t(\\{\\hat\\nu^2,\\hat f\\}-2\\hat\\nu\\hat f\\hat\\nu ) \\;\\;,\\ ] ] thus , we arrive at a markovian master equation with a dissipative _ lindblad term _ , in addition to the leading commutator , which is responsible for unitary quantum evolution  la vonneumann in the absence of dissipation . linearity in the density matrix is an important feature of our resulting equations . in particular , in the form of eqs.([vnl2])([vnlm ] ) , the master equation preserves the normalization of @xmath44 , say @xmath60 , which expresses the conservation of probability . it seems worth while to point out that we arrive at the standard , i.e. , in particular _ local _ , quantum mechanical evolution equation  even if modified by a less standard yet wellcome lindblad term . however , we emphasize that the relation to the primordial deterministic degrees of freedom , which involves a fourier transformation ( cf . section2 ) , is highly nonlocal . this may ease the tension created by bell s theorem , when it comes to deterministic ( `` hidden '' ) variables . the lindblad term in eq.([vnlm ] ) implies an interesting _ decoherence and continuous localization mechanism _ , which causes the decay of spatial superpositions ( `` schrdinger cat states '' ) . while the diagonal matrix elements of @xmath44 are not affected by the lindblad term , the off - diagonal matrix elements decay : @xmath61 where we neglected the effect of @xmath16 , for simplicity , which can not stop the decay . ultimately , spacetime discreteness produces this mechanism  via the induced fluctuations in interactions . since there is no theory yet to tell us about the correlation function @xmath62 , it may suffice to point out that considerations of stochastic effects on quantum mechanics  as it is  have quite a history , see , for example , refs . @xcite and the literature cited there . this is related to attempts to solve the measurement problem and to account for the apparent absence of spatial superposition states of macroscopic objects @xcite . also quantum gravity is conjectured to lead to characteristic stochastic effects @xcite . in this context , various proposals for the analogue of our lindblad operator @xmath63 in eq.([vnlm ] ) have been made as well and it has similarly been concluded that spatial superposition states decohere and decay . while these issues are not settled , our heuristic arguments suggest that if quantum mechanical behaviour indeed emerges dynamically , then the resolution of the measurement problem may be linked to this . ` prequantum ' dynamics may account for an objective selection mechanism in accordance with the observed wave function collapse in measurement outcomes .    generally , lindblad master equations present a large class of linear markovian master equations , which are usually derived to describe open quantum systems that interact with particular environments  @xcite . here spacetime itself forms the universal environment that `` measures '' all physical objects . we have derived this _ quantum mechanical master equation _ , beginning with _ classical statistical mechanics _ , by incorporating several assumptions about the atomistic nature of spacetime , as well as about the nature of forces acting on matter . we have presented a heuristic discussion to the effect that quantum mechanics  together with a natural decoherence and continuous localization mechanism  is a consequence of classical statistics and concerns dynamics with respect to an atomistic spacetime that is observed with low resolution , i.e. , at large distance scales . the spatiotemporal discreteness results in permanent information loss affecting all matter , when described in the corse - grained way that is appropriate with distances much larger than the planck scale . we were motivated here by the theory of causal sets , where such a picture of spacetime does not follow from a quantization of gravity but is assumed as primary feature . there are a number of topics for further study . work is in progress making newly use of the formalism adopted here , of using hilbert space operators to describe classical statistics , and going beyond the early suggestions  @xcite . furthermore , as pointed out in ref.@xcite , the problem of negative probabilities needs to be resolved , which is met when carrying the notion of probability density from the classical phase space theory over to the emergent quantum mechanical one , as we do . the generalization of the ideas sketched here to field theories has to face the fundamental problem to understand the nature of matter fields and the emergence of ( the symmetries of ) their interactions with decreasing spatiotemporal resolution . our approach , paying special attention to piecewise linear potentials at sufficiently small scales , is in accordance with the suggestion of noninteracting fields at the planck scale . there , the atomistic structure of spacetime becomes effective and  for an underlying causal set induces such an  asymptotic freedom property \" . i am grateful to lajos disi , jose isidro , andrei khrennikov and rafael sorkin for discussions or correspondence . 99          elze h - t 2009 _ int . j. qu . ( ijqi ) _ * 7 * 83 - 96 ( _ preprint _ arxiv:0806.3408 ) ; _ do . _ 2009 symmetry aspects in emergent quantum mechanics _ proceedings discrete08 , valencia ( spain ) , december 11 - 16 , 2008 , j. phys . _ to appear                    isidro j m , santander j l g and fernandez de cordoba p 2008 a note on the quantum - mechanical ricci flow _ arxiv:0808.2717 ; _ do . _ 2008 ricci flow , quantum mechanics and gravity _ preprint _ wetterich c 2008 emergence of quantum mechanics from classical statistics _ preprint _ arxiv:0811.0927 , to appear in ref . @xcite ; _ do . _ 2008 probabilistic observables , conditional correlations , and quantum physics _ preprint _ arxiv:0810.0985 ; _ do . _ 2008 quantum entanglement and interference from classical statistics _ arxiv:0809.2671                dowker f 2005 causal sets and the deep structure of spacetime _ 100 years of relativity - space - time structure : einstein and beyond _ ed a ashtekar ( singapore : world scientific ) ( _ preprint _ arxiv : gr - qc/0508109 )", "tags": [], "output_text_a": "The paper explores the transition from classical to quantum behavior by examining the role of spacetime's atomistic structure. It suggests that quantum features emerge from a dissipative process affecting all physical objects, with dynamics and statistical interpretations originating from deterministic rules akin to classical mechanics. The study proposes that spacetime's discrete nature, characterized by causal sets, influences quantum phenomena, particularly at scales larger than the Planck length. The authors reformulate classical ensemble theory, incorporating dissipation into the Liouville equation while maintaining probability conservation, to bridge classical and quantum mechanics. They argue that the evolution of spacetime continually \"measures\" matter, leading to a modified Liouville equation resembling the quantum mechanical von Neumann equation. The paper also discusses the implications of spacetime discreteness on quantum mechanics, suggesting it could lead to a natural decoherence and localization mechanism, potentially resolving the measurement problem. The study is motivated by the theory of causal sets and aims to provide a framework for understanding quantum mechanics as an emergent phenomenon from classical statistics and atomistic spacetime. Further research is needed to address issues like negative probabilities and the generalization to field theories.", "output_text_b": "This arXiv paper discusses the possibility of understanding quantum mechanics as an emergent phenomenon from classical ensemble theory. The authors propose that quantum features originate from a dissipative process affecting all physical objects, and that the atomistic structure of spacetime itself is responsible for effects attributed to quantum mechanics. They suggest that the evolution of spacetime continually \"measures\" matter degrees of freedom, leading to a modification of the classical ensemble theory.\n\nThe authors present a reformulation of classical dynamics in phase space, which closely resembles the von Neumann equation for a density operator in quantum theory. However, an essential difference is the interaction between bra- and ket-states, which is mediated by a superoperator. The paper also explores the idea that the discreteness of spacetime may be relevant for the emergence of quantum mechanical phenomena, turning the Liouville equation into the von Neumann-Lindblad equation.\n\nThe authors conclude that within small volumes, the Liouville equation of classical statistical mechanics is indistinguishable from the corresponding quantum mechanical von Neumann equation. For larger distances, the potential (commutator) term of the von Neumann operator is obtained as a sum of classical contributions.\n\nThe paper also discusses the coarse-graining that must be involved in extending these considerations to the scales where quantum mechanics is known to work. The authors suggest that coordinates fluctuate in the continuum description, leading to a random walk within the future lightcone. They propose a phenomenological ansatz connecting short distance behavior at the linearity scale with its coarse-grained description.\n\nThe paper then derives a Markovian master equation with a dissipative Lindblad term, in addition to the leading commutator responsible for unitary quantum evolution. The Lindblad term implies a decoherence and continuous localization mechanism, which causes the decay of spatial superpositions.\n\nThe authors suggest that if quantum mechanical behavior indeed emerges dynamically, then the resolution of the measurement problem may be linked to this. They also discuss the possibility of quantum gravity leading to characteristic stochastic effects and propose that Lindblad master equations present a large class of linear Markovian master equations, which are usually derived to describe open quantum systems that interact with particular environments.", "score": -0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the transition from classical to quantum behavior and the role of spacetime's atomistic structure.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding quantum mechanics as an emergent phenomenon from classical statistics and atomistic spacetime.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the reformulation of classical ensemble theory and the incorporation of dissipation into the Liouville equation.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant conclusions, such as the potential resolution of the measurement problem and the influence of spacetime discreteness on quantum mechanics.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"Liouville equation\" and \"von Neumann equation\" without explanation, which may not be necessary for a general audience.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of ideas.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any key experiments or data, which may be a missing element if they are present in the paper.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing its potential impact on understanding quantum mechanics and resolving the measurement problem.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the emergence of quantum mechanics from classical ensemble theory and the role of spacetime's atomistic structure.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on understanding quantum mechanics as an emergent phenomenon.\n4. The methodology or approach used in the paper is mentioned, including the reformulation of classical dynamics and the derivation of a Markovian master equation.\n5. Significant results and conclusions drawn by the authors are included, such as the indistinguishability of the Liouville equation from the von Neumann equation within small volumes.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"superoperator\" and \"Lindblad term.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance by discussing its potential impact on understanding quantum mechanics and the measurement problem."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "it is observationally well established that the velocity dispersion of main sequence stars increases with advancing spectral type . this fact has been recognised ever since velocity dispersions were first measured in the solar neighbourhood ( e.g. king 1990 ) . initially these observations were explained as the result of equipartition of energy because the mass of the stars decreases along the main sequence . however the two - body relaxation time scale is much too long to have any effect on the stellar velocity ellipsoid , prompting explanations relying on collective effects instead . some of the different functional forms that have been suggested for the velocity dispersion - age relation are reviewed by lacey ( 1991 ) . this increase in velocity dispersion , or heating , depends on the roughness of the gravitational potential in the disk , so knowledge about the shape of the velocity ellipsoid will tell us a great deal about the dynamical history of a disk .    until recently direct measurements of the three - dimensional shape of the velocity ellipsoid have been restricted to the solar neighbourhood . observations of the stellar velocities in external spiral galaxies have concentrated on systems that are either close to edge - on or face - on ( van der kruit and freeman 1986 ; bottema 1995 ) and will therefore only provide information about a single component of the velocity dispersion . from these measurements only indirect inferences can be drawn about the shape of velocity ellipsoids in galaxies because the results of a small sample of _ different _ galaxies are being compared in a statistical way . moreover , this shape will be subject to rather large uncertainties because the errors of the face - on and edge - on galaxies are compounded , and because relating face - on and edge - on galaxies is rather delicate .    in this pilot study we show that it is possible to derive the shape of the velocity ellipsoid within a _ single _ galaxy . we use the fact that an intermediate - inclination galaxy shows different projections of the velocity dispersion at different galactocentric azimuths . in section 2 the method by which we extract the velocity dispersions information is described . in section 3 we apply this analysis to the large early type spiral ngc 488 and in section 4 we discuss the results obtained for ngc 488 and compare them to the velocity ellipsoid in the solar neighbourhood . in cylindrical polar coordinates @xmath0 the line - of - sight velocity dispersion as a function of ( intrinsic ) position angle @xmath1 in a thin axisymmetric disk is    @xmath2 \\sin^2 i + \\sigma_z^2 \\cos^2 i , \\ ] ]    which can be written as    @xmath3.\\ ] ]    thus , it consists of an element with a @xmath4 variation that depends only on the components of the dispersion in the plane of the galaxy , and an element with no dependence on @xmath1 that depends on all three components of the velocity dispersion . observations along at least two axes ( preferably the major and minor axes , which provide maximum leverage ) , are therefore required to extract both coefficients . furthermore , in disk galaxies , in which most orbits are well - described by the epicycle approximation the radial and azimuthal dispersions obey the relation    @xmath5    where @xmath6 is the circular speed in the galaxy . ( in the solar neighbourhood , this expression reduces to @xmath7 , where @xmath8 and @xmath9 are the oort constants . ) within the epicycle approximation the stellar rotation speed @xmath10 equals the circular speed @xmath11 , so the righthandside of eq . [ eq : ax ] can be derived from the same spectral observations that are used to measure the velocity dispersions . the effect of higher - order approximations on this formula are discussed by kuijken & tremaine 1991 , who showed that the strongest deviations from eq . [ eq : ax ] are to be found at radii of several disk scale lengths ( see also cuddeford & binney 1994 ) .    where the circular speed @xmath6 can be measured separately ( e.g. , from an emission - line rotation curve ) , a further constraint on the dispersions and velocities is the asymmetric drift equation , @xmath12 -r\\frac{\\partial \\sigma^2_{r z}}{\\partial z}\\ ] ]    the last term of equation 4 describes the tilting of the velocity ellipsoid . the two limiting cases of this tilting term are zero and ( @xmath13 ) . orbit integration by binney & spergel ( 1983 ) and by kuijken & gilmore ( 1989 ) suggest that in the solar neighbourhood the truth lies close to midway between the two extremes . as will be seen below , the uncertainty in this term is not a concern in the present analysis .    in summary , the three components of the stellar velocity ellipsoid can be deduced from measurements of the line - of - sight dispersions along two position angles in a galaxy disk . the two sets of measurements , together with the ratio of tangential and radial velocity dispersions appropriate for nearly circular orbits , provide the three equations necessary to deproject the ellipsoid . if the asymmetric drift can also be measured , e.g. when a rotation curve for cold interstellar gas is available , the system is overdetermined , allowing a consistency check on the result . we choose the large early type spiral ngc 488 for this analysis because of its regular optical appearance and its intermediate inclination . table 1 lists some properties of this galaxy . note the very high rotational velocity ( peterson 1980 ) . .parameters of ngc 488 [ cols=\"<,^ \" , ]     we have tested this procedure on a large ( @xmath14 ) set of artificial major and minor axis spectra , created from the template star to resemble the observed galactic spectra as closely as possible , with a different poisson noise realisation for each spectrum . the best - fit parameters obtained from these spectra scatter with the same dispersion as the errors obtained from any individual fit to a spectrum . therefore , we conclude that the parameters returned by the fit programme are reliable . an obvious extension to our fitting procedure would be to use different scale lengths for the @xmath15 and @xmath16 dispersion components . unfortunately the data are not of sufficient quality to allow for a six parameter fit . one of the six eigenvalues that we obtained from diagonalising the correlation matrix was much larger than the other five , a clear indication that a six parameter fit is stretching the data a bit too much . interestingly , the kinematic scale length of the disk appears to be comparable to the photometric one . this is not the expectation from local isothermal approximation for disks , which predicts a scale length double the photometric one . the most likely explanation is probably the fact that we measure the scale length in the b band while the stellar mass distribution is best traced in the k band , the near infra - red . empirically it is found that scale lengths in the k band are shorter than the b band up to a factor of about  2 ( de jong 1995 , figure 4 and peletier et al . 1996 ) . alternatively the approximation of a local isothermal distribution breaks down . the fits described above are to the stellar data only . the lowest panel in fig . 2 shows the emission line data of peterson and the predictions from our two fits . both our fits are fully consistent with these data , and provide extra confirmation of the validity of our analysis . ( a simple power - law fit to the emission - line data plotted in fig . 2 gives a power index of 0.18 @xmath17 0.13 . ) unfortunately there are no measured emission line velocities in the inner part of the disk . peterson gives velocities around 195 km / s near a radius of 10 arcsec which are a little higher than our fits would predict . however there is no reason why a power - law rotation curve should persist into those central , bulge dominated regions . this is the first direct measurement of the vertical - to - radial velocity dispersion ratio anywhere outside the solar neighbourhood . previous determinations have all been indirect , and hence suffer from large uncertainities . the method we have described here is quite straightforward , and could be applied to many systems . the derived value of @xmath18 , which is effectively the average ratio near one photometric scale length , is somewhat higher than the solar neighbourhood value of 0.52 @xmath17 0.03 that wielen ( 1977 ) derived from the mccormick sample of k and m dwarfs . however , the error of 0.03 is the purely statistical error , but the scatter between the published observational estimates of this ratio suggests that the true error may be larger ( see lacey 1991 ) . any difference between the two ratios is consistent with the findings about the relative effects of the two dominant heating mechanisms , molecular clouds and spiral structure , as we now show . heating by molecular clouds was originally proposed by spitzer and schwarzschild ( 1951 ) . they proposed that stars in star - cloud encounters gain kinetic energy at the expense of the clouds because of the huge masses of the latter . subsequent analysis by lacey ( 1984 ) and @xmath19-body simulations by villumsen ( 1985 ) showed however that this mechanism saturates rather quickly ( once the stars have sufficient energy that they spend most of their time outside the cloud layer the heating rate drops ) and could not fully explain the observed heating .    an alternative proposal to heat the disk , due to barbanis and woltjer ( 1967 ) , explains the heating as the result of stars scattering from spiral irregularities in the galactic potential . carlberg and sellwood ( 1985 ) have extended this work and showed that this can indeed heat up the disk . however this process can not heat the stars efficiently in the vertical direction because the vertical oscillation frequency of stars is much larger than the frequency at which a spiral wave sweeps past the stars orbiting the disk . hence the stars respond almost adiabatically to this force . giant molecular clouds create large spiral wakes , often much larger than a cloud itself ( julian and toomre 1966 ) . this interplay between clouds and spiral irregularities is not yet completely understood but it is clear that they are not independent . jenkins and binney ( 1990 ) examined the combined effects of both processes based on monte carlo simulations of the fokker - planck equation describing these processes . they expressed the relative importance of heating by spiral structure to heating by clouds by a parameter denoted @xmath20 and calculated the corresponding ratio of @xmath21 ( see their figure 2 ) . from the observed shape of the velocity ellipsoid and velocity dispersion - age relations they concluded that in the solar neighbourhood the heating of the disk is dominated by spiral structure ( @xmath22 ) . the mean surface density of the cloud layer near the sun is 1.8 @xmath23 pc@xmath24 ( clemens , sanders and scoville 1988 ) . from the fcrao extragalactic co survey ( young et al . 1995 ) a mean surface density for ngc 488 is derived of 3.5 @xmath23 pc@xmath24 . ( young et al . find that the co layer in ngc 488 is best described by a uniform distribution with a radius of 1.65 arcmin and a co flux of @xmath25 jy km / s . ) , higher than in the solar neighbourhood . ngc 488 is classified as an sb galaxy . it has a very regular tightly wound spiral pattern ( the pitch angle is only 5@xmath26 ) . it is therefore quite likely that the potential associated with this spiral pattern is much smoother that that of our own galaxy , which has an sbc hubble type . both these observations imply that the parameter @xmath20 must be smaller for ngc 488 than for the solar neighbourhood . according to the predictions of jenkins and binney a smaller @xmath20 corresponds to a larger @xmath21 ratio . we do indeed find that the @xmath21 ratio for ngc  488 is higher than for the milky way , however the difference is only one sigma . we conclude therefore that the shape of the velocity ellipsoid that we have determined is qualitatively consistent with the picture sketched by jenkins and binney . the technique we have described in this paper would be straightforward to apply to a larger sample of disk galaxies . with higher quality data , it would also be possible to extend the analysis to map out the radial variation of the velocity ellipsoid shape , a quantity which has never been observationally constrained . both projects would provide important measurements for comparison with the theoretical treatments of the heating processes in stellar disks . the data presented in this paper were obtained using the multiple mirror telescope , which is a joint facility of the smithsonian institute and the university of arizona . much of the analysis was performed using iraf , which is distributed by noao . we thank the referee , cedric lacey for his helpful comments . barbanis b. , woltjer l. , 1967 , apj , 150 , 461 binney j. , spergel d. n. , 1983 , iau colloquium no . 76 bottema r. , 1995 _ phd thesis , university of groningen _ carlberg r. g. , sellwood j. a. , 1985 , apj , 292 , 79 clemens d. p. , sanders d. b. , scoville n. z. , 1988 apj , 327 , 139 cuddeford p. , binney j. , 1994 , mnras , 266 , 273 de jong r. s. , 1995 _ phd thesis , university of groningen _ de jong r. s. , 1996 , a&a , 313 , 45 jenkins a. , binney j. , 1990 , mnras , 245 , 305 julian w. h. , toomre a. , 1966 , apj , 146 , 810 king i. r. , 1990 , in _ the milky way as a galaxy _ , eds buser r. , king i. r. , p. 172 kuijken k. , gilmore , g. , 1989 , mnras , 239 , 571 kuijken k. , tremaine s. , 1991 in _ dynamics of disc galaxies _ , ed . sundelius b. , p. 71 kuijken k. , merrifield m. r. , 1993 , mnras , 264 , 712 lacey c. g. , 1984 , mnras , 208 , 687 lacey c. g. , 1991 , in _ dynamics of disc galaxies _ , ed . sundelius b. , p. 257 merrifield m. , kuijken k. , 1994 , apj , 432 , 575 peletier r. f. et al . , 1996 a&a , 300 , l1 peterson c. j. , 1980 , aj , 85 , 226 press et al . , 1986 , _ numerical recipes _ , cambridge university press , cambridge shombert j. m. , bothun g. d. , 1987 , aj , 93 , 29 shu f. h. , 1969 , apj , 158 , 505 spitzer l. , schwarzschild m. , 1951 , apj , 114 , 385 van der kruit p. c. , freeman k. , 1986 , apj , 303 , 556 van der marel r. p. , franx m. , 1993 , apj , 407 , 525 villumsen j. v. , 1985 , apj , 290 , 75 wielen r. , 1977 , a&a , 60 , 263 young j. s. , et al . , 1995 , apjsupl , 98 , 257", "tags": [], "output_text_a": "This paper investigates the velocity dispersion of stars in disk galaxies, focusing on the shape of the velocity ellipsoid, which provides insights into the dynamical history of a galaxy. Traditionally, measurements of the velocity ellipsoid have been limited to the solar neighborhood, but this study demonstrates a method to derive the shape within a single galaxy, specifically the early-type spiral galaxy NGC 488. The method involves analyzing the line-of-sight velocity dispersions at different galactocentric azimuths in an intermediate-inclination galaxy. The study finds that the vertical-to-radial velocity dispersion ratio in NGC 488 is higher than in the solar neighborhood, suggesting differences in the heating mechanisms, such as molecular clouds and spiral structures. The results are consistent with theoretical predictions and highlight the potential for applying this method to other disk galaxies to better understand stellar disk heating processes. The study also notes that the kinematic scale length of the disk is comparable to the photometric one, contrary to expectations from local isothermal approximations. The findings provide a basis for further research into the radial variation of the velocity ellipsoid shape in galaxies.", "output_text_b": "This arXiv paper discusses the increase in velocity dispersion, or heating, of main sequence stars as they age and advance in spectral type. Initially, this was attributed to equipartition of energy due to the decrease in stellar mass along the main sequence. However, the two-body relaxation time scale is too long for this to be the case, prompting explanations relying on collective effects. The velocity dispersion-age relation has different functional forms, and the shape of the velocity ellipsoid can provide insights into the dynamical history of a disk.\n\nDirect measurements of the three-dimensional shape of the velocity ellipsoid have been limited to the solar neighborhood, with observations of external spiral galaxies providing information about only a single component of the velocity dispersion. This paper presents a pilot study that derives the shape of the velocity ellipsoid within a single galaxy, using the fact that an intermediate-inclination galaxy shows different projections of the velocity dispersion at different galactocentric azimuths.\n\nThe authors describe their method for extracting velocity dispersions information and apply it to the large early-type spiral NGC 488. They discuss the results obtained for NGC 488 and compare them to the velocity ellipsoid in the solar neighborhood. The three components of the stellar velocity ellipsoid can be deduced from measurements of the line-of-sight dispersions along two position angles in a galaxy disk, allowing for a consistency check if the asymmetric drift can also be measured.\n\nThe authors choose NGC 488 for this analysis due to its regular optical appearance and intermediate inclination. They have tested their procedure on artificial major and minor axis spectra and found that the parameters returned by the fit programme are reliable. The kinematic scale length of the disk appears to be comparable to the photometric one, which is not the expectation from the local isothermal approximation for disks. The fits to the stellar data are consistent with emission line data, and this is the first direct measurement of the vertical-to-radial velocity dispersion ratio anywhere outside the solar neighborhood.\n\nThe derived value of the velocity dispersion ratio is somewhat higher than the solar neighborhood value, but the true error may be larger due to the scatter between published observational estimates. The authors show that any difference between the two ratios is consistent with the findings about the relative effects of the two dominant heating mechanisms, molecular clouds and spiral structure.", "score": -0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the investigation of velocity dispersion in disk galaxies and the method applied to NGC 488.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding the velocity dispersion and shape of the velocity ellipsoid in disk galaxies.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the methodology of analyzing line-of-sight velocity dispersions at different galactocentric azimuths.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the higher vertical-to-radial velocity dispersion ratio in NGC 488.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms but explains them adequately, such as the velocity ellipsoid and dispersion ratio.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not explicitly mention key experiments or data used, which is a missing element.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by highlighting its potential application to other disk galaxies.", "1. **Accurate Reflection of Main Findings and Contributions**: The summary captures the main findings and contributions of the paper, such as the increase in velocity dispersion of main sequence stars, the methodology used to derive the shape of the velocity ellipsoid, and the comparison of results with the solar neighborhood.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding the increase in velocity dispersion and the shape of the velocity ellipsoid in galaxies.\n\n4. **Methodology or Approach**: The summary mentions the methodology of using intermediate-inclination galaxies to derive the shape of the velocity ellipsoid and the application to NGC 488.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the derived velocity dispersion ratio and its comparison with the solar neighborhood.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary uses some technical terms but explains them adequately, such as \"velocity ellipsoid\" and \"asymmetric drift.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the use of artificial spectra and the application to NGC 488.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in providing a method to measure velocity ellipsoids in galaxies."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the rsp game  @xcite is a game where players take their move simultaneously , each choosing a hand from the rock ( r ) , the scissors ( s ) and the paper ( p ) . the cyclic strength relation of the three hands determines the win and the loss ; the rock crushes the scissors , the scissors cut the paper and the paper wraps up the rock . the cyclic competition of the rsp game can mimic various relations in reality , particularly in the population dynamics ; _ e.g. _  a colony of three competing mutations of _ e.  coli _ @xcite and a three - morph mating system of a lizard  @xcite . the present study proposes a model of the rsp game on lattices . each player on a lattice point chooses the next hand from the hand of the neighboring player with the maximum point . ( we refer to such a player as a copy player . ) we found interesting spatial patterns , such as vortices and sinks , appearing particularly on the triangular lattice . the spatial pattern with vortices and sinks appears as a coexisting steady state on the triangular lattice . as far as we know , the previous studies considered the rsp game either on the square lattice  @xcite or on various networks  @xcite . it is , however , easy to imagine that triangles appear in the population dynamics in reality , _ e.g. _  clusters in complex networks . it is also known that elementary properties can be very different in many - body systems on non - bipartite lattices and on bipartite lattices . the vortex pattern that we observe in the present study is , in fact , due to the frustration of the triangular lattice ( fig . [ fig1 ] ) , a three - sided situation where each of the three players around a triangle chooses the rock , the scissors and the paper , respectively . ( hereafter , we refer to the three hands simply as the hands  2 , 1 and  0 , respectively . ) the existence of vortices was pointed out by some studies in the past  @xcite . we here stress the importance of the frustration as the cause of the stationary vortex pattern . we show that the stationary vortex pattern does not appear on the square lattice nor on the honeycomb lattice . the paper is organized as follows . in sec . [ sec2 ] , we introduce the new model and discuss its elementary properties . we show that pairs of vortices and sinks can appear as spatial patterns . we also argue that players close a vortex core scores a high point while players close to a sink scores a low point . we report the results of our simulation on the triangular lattice in sec . [ sec3 ] and on the square and honeycomb lattices in sec . we confirm that the spatial pattern with vortices and sinks is stationary on the triangular lattice , while it is not on the square nor honeycomb lattices . in sec . [ sec5 ] , we introduce a random player , who chooses its hand randomly . we show that a random player can be a source in the spatial pattern . we propose a model where players residing on lattice points repeatedly play the rsp game with the nearest neighbors . we hereafter consider the triangular lattice , the square lattice and the honeycomb lattice , with an emphasis on the triangular lattice , whose frustration generates stationary vortices in the course of the rsp game . all players on the lattice points make their moves all at once , which constitutes one time step . a move is either 0 , 1 or 2 . the hand  1 wins over the hand  0 , the hand  2 wins over the hand  1 , and the hand  0 wins over the hand  2 . a win , a draw or a loss are determined between each pair of the nearest neighbors of the lattice . each player scores one point for a win , zero point for a draw and minus one point for a loss . hence , a player can score @xmath0 points at most and minus @xmath0 points at least in each time step , where @xmath0 is the number of the nearest neighbors on the lattice ( @xmath1 for the triangular lattice , @xmath2 for the square lattice and @xmath3 for the honeycomb lattice ) . this is a zero - sum game ; that is , the sum of the scores of all the players is always zero .    particularly on the triangular lattice , we define the frustration and its sign ( fig . [ fig1 ] ) . we refer as a positive frustration to the situation where the hands  2 , 1 , and  0 appear in this order when we circle around a triangle counterclockwise . on the other hand , a negative frustration is the situation where the hands  0 , 1 , and  2 appear in this order when we circle around a triangle counterclockwise . we will argue in the next subsection that a positive frustration generates a counterclockwise vortex , whereas a negative frustration generates a clockwise vortex . all the players choose their hands at random in the initial time step with an equal probability . each player adopts the copy strategy or the random strategy afterwards . the copy strategy is to choose a hand of the player who , of all the nearest neighbors and the player itself , marked the highest score in the last time step . we refer to a player adopting the copy strategy as a copy player hereafter . if there are more than a player of the highest score with different hands , a copy player chooses a hand from their hands randomly . the random strategy is to choose a hand at random . we refer to a player adopting the random strategy as a random player . in the present study , we consider only the case where each player is either a copy player or a random player all through the game . we mostly consider copy players hereafter . we show that copy players on the triangular lattice exhibit vortex structure . in sec . [ sec5 ] , we discuss an impact of random players on the structure as impurities .      before showing the simulation results , let us argue that two spatial patterns typically appear . one is a vortex and the other is a sink . they are logical consequences of the combination of the rsp game and the copy strategy . note first that copy players tend to form domains of the same hands . a copy player well inside a domain of , say , the hand  0 , will keep the hand  0 in the next time step because all its neighbors are of the hand  0 and their scores are all zero ; hence the bulk of the domain is stable . copy players on the boundary of a domain , on the other hand , may change their hands in the next time step , and hence the boundary moves . let us argue how the boundary moves in the following two cases . the three domains of the hands 0 , 1 and 2 can have either the topology of fig .  [ fig2 ]  ( a ) or  ( b ) . ( a )     ( b )     +        ( c )    in the topology of fig .  [ fig2 ]  ( a ) , there is a negative frustration around the point a and a positive frustration around the point b. a copy player of , say , the hand  0 , located just outside the domain of the hand  1 , tends to choose the hand  1 in the next time step because the neighbors with the hand  1 get high scores . thus the boundary between the domains of the hand  0 and the hand  1 moves onto the the domain of the hand  0 , so that the domain of the hand  1 expands . likewise , the boundary between the domains of the hand  1 and the hand  2 moves onto the domain of the hand  1 and the boundary between the domains of the hand  2 and the hand  0 moves on to the domain of the hand  2 . hence the boundaries rotate clockwise around the negative frustration at the point a and counterclockwise around the positive frustration at the point b. we will indeed show below in section  [ sec3 - 2 ] that the boundaries take a configuration schematically illustrated in fig . [ fig2 ]  ( c ) . that is , the topology of fig . [ fig2 ]  ( a ) generates a pair of vortices of moving boundaries . ( a similar argument for a different model can be found in refs . @xcite . ) we refer to the counterclockwise vortex as a positive vortex and the clockwise vortex as a negative vortex . in short , a positive frustration of a configuration generates a positive vortex of moving boundaries and a negative frustration generates a negative vortex .    in the topology of fig . [ fig2 ]  ( b ) , on the other hand , the circular boundaries shrink toward the center ; the players with the hand  0 just inside the boundary mimic the players with the hand  1 just outside the boundary . the central domain of the hand  0 collapses eventually . then the domain of the hand  1 becomes the central domain and will collapse after a while . thus the topology of fig . [ fig2 ]  ( b ) generates a sink . finally , a source does not appear when there are only copy players , because a new domain is never generated inside a domain . it is spontaneously generated only when some players adopt strategies other than the copy strategy . specifically , a random player can be a source as is shown in sec . [ sec5 ] . we here argue that the scores of the players near a vortex core are high , while those near a sink are low . both in fig . [ fig2 ]  ( b ) and  ( c ) , the boundaries are not straight . near the vortex cores in fig . [ fig2 ]  ( c ) , the boundary is convex from the viewpoint of the winners ( the hand  2 in fig . [ fig3 ]  ( a ) ) and concave from the viewpoint of the losers ( the hand  1 fig . [ fig3 ]  ( a ) ) . near the sink in fig . [ fig2 ]  ( b ) , on the other hand , the boundary is convex from the viewpoint of the losers ( the hand  1 in fig . [ fig3 ]  ( b ) ) and concave from the viewpoint of the winners ( the hand  2 in fig . [ fig3 ]  ( b ) ) . ( c ) and  ( b ) : ( a ) a bend around the frustration a of fig . [ fig2 ]  ( c ) ; ( b ) a bend around the sink of fig . [ fig2 ]  ( b ) . ( c ) a simple case of two subsequent steps.,title=\"fig : \" ] ( a )    ( c ) and  ( b ) : ( a ) a bend around the frustration a of fig .  [ fig2 ]  ( c ) ; ( b ) a bend around the sink of fig .  [ fig2 ]  ( b ) . ( c ) a simple case of two subsequent steps.,title=\"fig : \" ] ( b )     +    ( c ) and  ( b ) : ( a ) a bend around the frustration a of fig . [ fig2 ]  ( c ) ; ( b ) a bend around the sink of fig . [ fig2 ]  ( b ) . ( c ) a simple case of two subsequent steps.,title=\"fig : \" ] + ( c )    around the bend of the boundary in fig . [ fig3 ]  ( a ) , the number of the winners ( the hand  2 ) is one less than the number of the losers ( the hand  1 ) . since this is a zero - sum game even locally , the total of the positive scores of the winners is equal to the total of the negative scores of the losers . therefore , the time - averaged positive score of a winner is greater than the time - averaged negative score of a loser . for example , the player with the hand  2 at the corner of the boundary scores @xmath4 , whereas the player with the hand  1 at the corner of the boundary scores @xmath5 . in other words , each player wins a high score when it is a winner and loses a low score when it is a loser . since each player spends about equal time as a winner and as a loser over a long time , the time - averaged score is positive . in short , the time - averaged score of a player around a vortex is positive . the closer a player is to the vortex core , the more often the bend appears in the boundary , and the higher the time - averaged score of the player is . the situation is the opposite near a sink . around the bend of the boundary in fig . [ fig3 ]  ( b ) , the number of the winners ( the hand  2 ) is one greater than the number of the losers ( the hand  1 ) . each player , as a winner , share the total positive score with more players and , as a loser , share the total negative score with less players . hence the time - averaged score of a player around a sink is negative . the closer a player is to the center of the sink , the lower the time - averaged score of the player is .    for example , let us calculate the time - averaged score over the two steps of fig . [ fig3 ]  ( c ) . the score of the central player is zero in the first step and @xmath6 in the next step . the time - averaged score over the two steps is @xmath7 for the central player . the score of the player next to the central player is @xmath7 in the first step while @xmath8 in the next step . the time - averaged score over the two steps is @xmath5 for the player next to the central player . in this section , we show results of our simulations on the triangular lattice . we simulated the society of copy players on a triangular lattice with @xmath9 players . we imposed periodic boundary conditions . we demonstrate that the stationary vortex structure appear . we first show the convergence to a steady pattern , presenting snapshots of the simulations . the initial configuration fig . [ fig4 ]  ( a ) was chosen randomly . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( a )     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( b )     +     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( c )     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( d )    the domains of the three hands are quickly formed in the first few iterations as shown in fig . [ fig4 ]  ( b)(d ) . a typical pattern consisting of vortices and sinks emerge by the 20th step as shown in fig . [ fig5 ] .     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( a )     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( b )     +     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( c )     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( d )     +     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( e )     players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( f )    in the 17th step ( fig .  [ fig5 ]  ( a ) ) , we have , for example , a pair of a positive vortex around @xmath10 and a negative vortex around @xmath11 , which is indicated by a red circle . these vortices have cancelled each other by the 22nd step ( fig . [ fig5 ]  ( f ) ) . after such cancellations , the pattern settles into a fairly steady state by the 1  000th step as shown in fig . [ fig6 ] . players the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( a )     players the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( b )     +     players the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( c )     players the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( d )    there is a vortex pair , for example , around @xmath12 and @xmath13 , which is indicated by a red circle . there is also a sink , for example , around @xmath14 , which is indicated by a blue circle .    in order to look into details of the convergence , we plot the time dependence of the total number of frustrations per player in fig . [ fig7 ] . we can see that the number of frustrations becomes almost constant after the 3  000th step . we now discuss the structure of the steady pattern . the snapshots in fig . [ fig6 ] indicate that most of the domains in the steady pattern consist of three layers of the players , where a layer means a straight line on the triangular lattice ; see fig . [ fig8 ]  ( a ) . ( a )     ( b )    the situation is the same for lattices of different sizes . the three - layer domains are generated at a vortex ; see fig .  [ fig9 ] . players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( a )     players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( b )     players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( c )     +     players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( d )     players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( e )     players with the initial configuration shown in ( a ) . the con figurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the 45th step ( f ) . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( f )    here we started a simulation from a configuration of the form in fig . [ fig2 ]  ( a ) , specifically the configuration in fig . [ fig9 ]  ( a ) . we can concretely see the vortex structure schematically shown in fig . [ fig2 ]  ( c ) . furthermore , we can see that a vortex spontaneously takes the core structure of fig . [ fig10 ] with tails of three - layer domains . vortices thus generate domains with three layers .    a domain with three layers , once generated , is stabilized because it has a layer to be beaten by a stronger hand , a layer to remain unchanged and a layer to win over a weaker hand . in fig . [ fig8 ]  ( a ) ,    * every player in the layer of the domain  2 scores the point  @xmath15 , * every player in the uppermost layer of the domain  1 scores the point  @xmath16 , * every player in the mid layer of the domain  1 scores the point  @xmath17 , * every player in the lowermost layer of the domain  1 scores the point  @xmath15 , and * every player in the layer of the domain  0 scores the point  @xmath16 ,    under the assumption that the layer above the shown area in fig . [ fig8 ]  ( a ) belongs to the domain  2 and the layer below it belongs to the domain  0 . for every player in the uppermost layer of the domain  1 , a neighbor with the highest score is one in the layer of the domain  2 , and hence will change the hand to  2 in the next step as a copy player . for every player in the mid layer of the domain  1 , a neighbor with the highest score is one in the lowermost layer of the domain  1 , and hence hence will remain unchanged in the next step . for every player in the lowermost layer of the domain  1 , a neighbor with the highest score is in the same layer , and hence will remain unchanged in the next step . for every player in the layer of the domain  0 , a neighbor with the highest score is one in the layer of the domain  1 , and hence will change the hand to  1 in the next step as a copy player . therefore , the domain  1 will shift one layer below in the next step , remaining to be three layers . a domain with only two layers can grow to a domain with three layers . in fig . [ fig8 ]  ( b ) ,    * every player in the layer of the domain  2 scores the point  @xmath15 , * every player in the upper layer of the domain  1 scores the point  @xmath16 , * every player in the lower layer of the domain  1 scores the point  @xmath15 , and * every player in the layer of the domain  0 scores the point  @xmath16 ,    under the assumption that the layer above the shown area in fig . [ fig8 ]  ( b ) belongs to the domain  2 and the layer below it belongs to the domain  0 . for each player in the upper layer of the domain  1 , a neighbor with the highest score is _ either _ one in the layer of the domain  2 or one in the lower layer of the domain  1 . each player will choose either the hand  2 or the hand  1 randomly in the next step ; _ i.e. _  only half of the players will turn into the hand  2 . for every player in the lower layer of the domain  1 , a neighbor with the highest score is in the same layer , and hence will remain unchanged in the next step . for every player in the layer of the domain  0 , a neighbor with the highest score is one in the layer of the domain  1 , and hence will change the hand to  1 in the next step as a copy player . therefore , the upper boundary of the domain  1 shifts downward only halfway , whereas the lower boundary certainly shifts one layer below . thus the domain  1 grows gradually to a domain with three layers . we do not have any arguments for the fact that domains with more than three layers are rare . we speculate that a vortex , as in fig . [ fig10 ] , tends to generate the minimum stable domain , which is a domain with three layers . once its generated with just three layers , there is no mechanism that makes the domain grow to more than three layers . in this section , we show results of our simulations on the square lattice and the honeycomb lattice . we simulated the society of copy players on a square lattice with @xmath9 players and on a honeycomb lattice with @xmath18 players . we imposed periodic boundary conditions on both lattices . we do not repeat discussion on the convergence to the steady pattern here for the square and honeycomb lattices ; it is basically the same as the triangular lattice . we demonstrate that the stationary vortex structure does _ not _ appear in these lattices , thereby emphasizing that the frustration is essential to the stationary vortex structure . figure  [ fig11 ] shows snapshots of a simulation on the triangular lattice with @xmath9 players . players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( a )     players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( b )     +     players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( c )     players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( d )    there is obviously no vortex structure on the square lattice . the boundaries run diagonally in each snapshot . this means that each boundary runs between the two sublattices of the square lattice ; on the boundary indicated by the red circle in fig .  [ fig11 ]  ( a ) , for example , the players with the hand  0 on the immediately lower left side of boundary is on the different sublattice from the players with the hand  1 on the immediately upper right side of the boundary . the boundaries move either upward , downward or sideways in the next step the upward and downward movements do not interfere with the sideway movements . we demonstrate in fig . [ fig12 ] that an initial configuration of the type in fig . [ fig2 ]  ( a ) never generate vortices . players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( a )     players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( b )     +     players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( c )     players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( d )     +     players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( e )     players with the initial configuration shown in ( a ) . the configurations at the first step ( b ) , the second step ( c ) , the third step ( d ) , the fourth step ( e ) , and the fifth step ( f ) . the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( f )    here we started a simulation from the configuration in fig . [ fig12 ]  ( a ) , which mimics fig .  [ fig2 ]  ( a ) . we do not see any structure of the form schematically shown in fig . [ fig2 ]  ( c ) . figure  [ fig13 ] shows snapshots of a simulation on the honeycomb lattice with @xmath18 players . players the black triangles denote the player with the hand  0 , the gray triangles the hand  1 , and the white triangles the hand  2.,title=\"fig : \" ] ( a )     players the black triangles denote the player with the hand  0 , the gray triangles the hand  1 , and the white triangles the hand  2.,title=\"fig : \" ] ( b )     +     players the black triangles denote the player with the hand  0 , the gray triangles the hand  1 , and the white triangles the hand  2.,title=\"fig : \" ] ( c )     players the black triangles denote the player with the hand  0 , the gray triangles the hand  1 , and the white triangles the hand  2.,title=\"fig : \" ] ( d )    the pattern may appear to have a vortex structure . we hereafter argue that the seemingly vortex structure on the honeycomb lattice is not stationary and hence is essentially different from the stationary vortex structure on the triangular lattice .    as a piece of evidence for the essential difference , we first show the spatial distribution of the time - averaged frustration . figure  [ fig14 ]  ( a ) shows the time - averaged frustration on the _ triangular _ lattice with @xmath9 players .     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( a )     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( b )     +     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( c )     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( d )     +     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( e )     players . the red circles indicate positive frustrations and the blue circles indicate negative frustrations . ( c ) and  ( d ) the square lattice with @xmath9 players . ( e ) and  ( f ) the honeycomb lattice with @xmath18 players . in the panels  ( a ) , ( c ) and  ( e ) , white symbols indicate the time - averaged frustration more than @xmath19 , black symbols indicate the time - averaged frustration less than @xmath20 and gray symbols with gradation indicate the time - averaged frustration in between . in the panels ( b ) , ( d ) and  ( f ) , white symbols indicate the time - averaged score more than @xmath21 , black symbols indicate the time - averaged score less than @xmath22 and gray symbols with gradation indicate the time - averaged score in between.,title=\"fig : \" ] ( f )    the time average was taken over 200 steps after the 5  000th step . we can see that the frustrations on the triangular lattice ( the red and blue circles ) remain mostly at the same positions over the 200 steps . the spatial distribution of the time - averaged score ( fig . [ fig14 ]  ( b ) ) shows a corresponding structure , where players closer to the vortex cores get higher scores . we do not see such structures on the square and honeycomb lattices ( fig . [ fig14 ]  ( c)(f ) ) . ( we define the frustration on the square and honeycomb lattices similarly to the definition for the triangular lattice as in sec . [ sec2 - 1 ] . on the honeycomb lattice , we can have from a @xmath16 frustration to a @xmath23 frustration on a honeycomb plaquette . ) in fig . [ fig14 ]  ( c ) and  ( e ) , we can vaguely see vortex cores crawl around over the 200 steps . they do not stay at the same positions . the corresponding spatial distributions of the time - averaged score do not show steady patterns . in order to show further the difference between the non - bipartite triangular lattice and the bipartite lattices , we plot in figure  [ fig15 ] the auto - correlations of the score and the frustration on the three lattices .     players . squares on a solid ( dotted ) line denotes the auto - correlation of the score ( the frustration ) of a simulation on the square lattice with @xmath9 players . hexagons on a solid ( dotted ) line denotes the auto - correlation of the score ( the frustration ) of a simulation on the honeycomb lattice with @xmath18 players . each data point represents the spatial average as well as the time average over the 10  000 steps after the 3  000th step.,scaledwidth=55.0% ]    we can clearly see that the auto - correlations of the triangular lattice are one - order magnitude greater than the auto - correlations of the square lattice and the honeycomb lattice . we thereby conclude that vortices seen in fig . [ fig13 ] on the honeycomb lattice are not stationary in time and does not grow spatially . we now introduce random players among the copy players on the triangular lattice . we show that a random player can be a source , which was not present in the system with copy players only . we demonstrate in fig . [ fig16 ] that a random player can be a source .     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( a )     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( b )     +     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( c )     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( d )     +     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( e )     players . there is only one random player at the position indicated by the red circle ; the rest are copy players . the black hexagons denote the player with the hand  0 , the gray hexagons the hand  1 , and the white hexagons the hand  2.,title=\"fig : \" ] ( f )    figure  [ fig16 ] shows snapshots of a simulation on the triangular lattice with one random player and @xmath24 copy players . the random player chooses its hand randomly at every step . when its hand happens to be stronger than the hand of the copy players around the random player ( such as in fig . [ fig16 ]  ( a ) when the random player chooses the hand  2 among the copy players of the hand  1 ) , the copy players neighboring the random player will mimic the random player s hand in the next step . this may propagate as demonstrated in fig . [ fig16 ] . thus the random player can be a source with the probability of about @xmath25 . we argued in sec . [ sec2 - 3 ] that the players near a sink get lower scores . because of the same reason working in the opposite direction , the players around a random player , or a possible source , get higher scores than the average . ( the random player itself obviously gets the average . ) figure  [ fig17 ] shows that the players around the random player have higher scores than the average . copy players . the average was take over 10  000 steps after the 3  000th step . white hexagons indicate the time - averaged score more than @xmath26 and black hexagons indicate the time - averaged score less than @xmath27 . gray hexagons with gradation indicate the time - averaged score in between @xmath27 and @xmath26 . , scaledwidth=45.0% ]      in this subsection , we randomly scatter many random players over the triangular lattice . figure  [ fig18 ] shows the population density distribution of the time - averaged scores of the copy players and the random players of a simulation on the triangular lattice with @xmath9 players . players in total . in every panel , the solid circles indicate the distribution of the copy players while the solid lines indicate the distribution of the random players . ( a ) no random players and @xmath9 copy players . ( b ) 400 random players ( @xmath28 ) . ( c ) 1  600 random players ( @xmath29 ) . ( d ) 3  600 random players ( @xmath30 ) . ( e ) 8  100 random players ( @xmath31 ) . note that a parabola on a semi - logarithmic plot is a gaussian distribution.,title=\"fig : \" ] ( a )     players in total . in every panel , the solid circles indicate the distribution of the copy players while the solid lines indicate the distribution of the random players . ( a ) no random players and @xmath9 copy players . ( b ) 400 random players ( @xmath28 ) . ( c ) 1  600 random players ( @xmath29 ) . ( d ) 3  600 random players ( @xmath30 ) . ( e ) 8  100 random players ( @xmath31 ) . note that a parabola on a semi - logarithmic plot is a gaussian distribution.,title=\"fig : \" ] ( b )     +     players in total . in every panel , the solid circles indicate the distribution of the copy players while the solid lines indicate the distribution of the random players . ( a ) no random players and @xmath9 copy players . ( b ) 400 random players ( @xmath28 ) . ( c ) 1  600 random players ( @xmath29 ) . ( d ) 3  600 random players ( @xmath30 ) . ( e ) 8  100 random players ( @xmath31 ) . note that a parabola on a semi - logarithmic plot is a gaussian distribution.,title=\"fig : \" ] ( c )     players in total . in every panel , the solid circles indicate the distribution of the copy players while the solid lines indicate the distribution of the random players . ( a ) no random players and @xmath9 copy players . ( b ) 400 random players ( @xmath28 ) . ( c ) 1  600 random players ( @xmath29 ) . ( d ) 3  600 random players ( @xmath30 ) . ( e ) 8  100 random players ( @xmath31 ) . note that a parabola on a semi - logarithmic plot is a gaussian distribution.,title=\"fig : \" ] ( d )     +     players in total . in every panel , the solid circles indicate the distribution of the copy players while the solid lines indicate the distribution of the random players . ( a ) no random players and @xmath9 copy players . ( b ) 400 random players ( @xmath28 ) . ( c ) 1  600 random players ( @xmath29 ) . ( d ) 3  600 random players ( @xmath30 ) . ( e ) 8  100 random players ( @xmath31 ) . note that a parabola on a semi - logarithmic plot is a gaussian distribution.,scaledwidth=45.0% ]    ( e )    when there is no random players , the distribution of the score is almost gaussian ( fig . [ fig18 ]  ( a ) ) . the fluctuation of the score is due to the fact that each player is occasionally close to a vortex , getting high scores , and occasionally close to a sink , getting low scores . as we introduce a few random players , the copy players just around the random players get scores higher than the average owing to the same reason described in the previous subsection . this generates the additional peak on the right of the highest peak in fig . [ fig18 ]  ( b ) .    as we increase the number of random players , the vortex structure disappears from the steady pattern ( fig . [ fig19 ] ) .    ) and @xmath32 copy players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( a )    ) and @xmath32 copy players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( b )     +    ) and @xmath32 copy players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( c )    ) and @xmath32 copy players the black squares denote the player with the hand  0 , the gray squares the hand  1 , and the white squares the hand  2.,title=\"fig : \" ] ( d )    when the number of random players is 1  600 ( fig ,  [ fig18 ]  ( c ) ) , random players are scattered in the system every three lattice points on average . this is enough to destroy a vortex which generates the three - layer structure explained in sec . [ sec3 - 2 ] . the copy players not neighboring the random players can not get high scores generated by vortices and keep losing scores because of sinks . hence the highest peak in fig . [ fig18 ]  ( b ) shifts in the direction of the lower score in fig . [ fig18 ]  ( c ) . the copy players just around the random players , on the other hand , keep getting scores higher than the average . the number of such players is increased and hence the side peak in fig . [ fig18 ]  ( b ) has grown in fig . [ fig18 ]  ( c ) . as we further increase the number of random players , the peak on the side of the lower score keeps shrinking and the other peak keeps growing until the latter dominates as in fig . [ fig18 ]  ( e ) . the width of the distribution is the greatest when random players are about @xmath33 of all players , or in the case fig . [ fig18 ]  ( c ) . figure  [ fig20 ] shows how the standard deviation of the distribution of the time - averaged score depends on the concentration of random players . players in total.,scaledwidth=55.0% ] we introduced a new lattice model of the rsp game with copy players , who mimic the hand of the player with the maximum score . the key feature is the existence of the frustration , which is the three - sided situation where the hands of the three players on a triangle are all different ; then the hand  1 wins over the hand  0 , the hand  2 wins over the hand  1 and the hand  0 wins over the hand  2 . we showed that the frustration generates a stationary vortex on the triangular lattice . we argued that the structure which consists of vortex pairs , sinks and domains of three layers is stable on the triangular lattice . the structure does not appear on the square lattice nor on the honeycomb lattice .    finally , we introduced random players , each of which chooses the hand randomly at every step . a random player can be a source , which was not existent in the copy society . random players of about @xmath33 destroy the structure of vortex pairs . the authors express their sincere gratitude to dr . naoki masuda for many valuable comments to the earlier version of the paper .", "tags": [], "output_text_a": "This study explores a new model of the Rock-Scissors-Paper (RSP) game on different lattice structures, focusing on the triangular lattice. The RSP game, known for its cyclic competition, is used to simulate various real-world dynamics, such as population dynamics. The model involves players on lattice points who choose their next move based on the highest-scoring neighboring player, termed as \"copy players.\" The study finds that on the triangular lattice, unique spatial patterns like vortices and sinks emerge as steady states due to the lattice's inherent frustration, where each player around a triangle chooses a different hand. This phenomenon does not occur on square or honeycomb lattices, highlighting the importance of lattice structure in the game's dynamics. The paper also introduces random players, who choose their moves randomly, showing that they can act as sources in the spatial pattern, disrupting the vortex structures when present in sufficient numbers. The findings emphasize the role of lattice geometry in the stability and formation of complex patterns in competitive systems.", "output_text_b": "This article presents a model of the Rock-Scissors-Paper (RSP) game on lattices, where each player on a lattice point chooses the next hand based on the hand of the neighboring player with the maximum point. The study focuses on the RSP game on triangular lattices and observes interesting spatial patterns such as vortices and sinks. The authors emphasize the importance of frustration, a three-sided situation causing each of the three players around a triangle to choose rock, scissors, and paper, respectively, as the cause of the stationary vortex pattern. They show that the stationary vortex pattern does not appear on square or honeycomb lattices.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper, discussing the RSP game model on different lattice structures and the emergence of spatial patterns like vortices and sinks on the triangular lattice.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding the dynamics of the RSP game on different lattice structures.\n4. **Methodology**: The summary mentions the methodology of using lattice structures and the concept of \"copy players\" and \"random players.\"\n5. **Significant Results**: The summary includes significant results, such as the emergence of vortices and sinks on the triangular lattice and the impact of random players.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"copy players\" and \"random players.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not explicitly mention key experiments or data used in the research.\n10. **Significance**: The summary reflects the paper's significance by emphasizing the role of lattice geometry in competitive systems.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by mentioning the model of the RSP game on lattices, the focus on triangular lattices, and the observation of spatial patterns like vortices and sinks.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem by mentioning the study of the RSP game on lattices and the observation of spatial patterns.\n4. **Methodology**: The summary mentions the methodology by describing how players choose the next hand based on neighboring players' points.\n5. **Significant Results**: The summary includes significant results, such as the observation of stationary vortex patterns on triangular lattices and their absence on square or honeycomb lattices.\n6. **Clear Language**: The summary is written in clear and professional language.\n7. **Avoidance of Jargon**: The summary avoids technical jargon and explains terms like \"frustration\" in the context of the study.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not explicitly mention key experiments or data used in the research.\n10. **Significance**: The summary does not explicitly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the coupling between dynamical systems can give rise to a number of collective phenomena such as synchronization , phase locking , phase shifting @xcite , amplitude death @xcite , phase - flip @xcite , hysteresis @xcite , riddling @xcite and so on @xcite . since communication between the individual systems is mediated by signals that can have a finite transmission time , many studies account for this by the introduction of time  delay in the coupling @xcite . a number of recent studies have examined the manner in which delay coupling can affect the collective dynamics , particularly since time  delay makes the systems effectively infinite dimensional @xcite .    when conservative systems are coupled via time delayed interactions , then there are additional considerations . to start with , the system becomes explicitly non  conservative and thus the nature of the dynamics changes drastically : in the uncoupled system , the phase flow preserves volumes @xcite , but in the coupled system there can be attractors . this issue is of added interest when studying hamiltonian systems where there can be a hierarchy of conserved quantities @xcite . studies of coupled hamiltonian systems have largely examined the case of instantaneous coupling @xcite which does not affect the hamiltonian structure .    in the present work we study time delay coupled hamiltonian systems and examine the effect of interaction on the nature of the dynamics . we consider the following examples , that of diffusively coupled harmonic oscillators that models delay  coupled pendulums , for instance , and coupled hnon  heiles oscillators . in the absence of coupling , in the former case the motion is periodic , while in the latter case the dynamics can be ( quasi)periodic or chaotic . in both instances we find that the effect of introducing dissipation is to cause the oscillatory dynamics to be damped to a fixed point , namely we find that there is the so  called amplitude death ( ad ) @xcite as has been seen in delay  coupled dissipative dynamical systems @xcite . although the major effect of the coupling is to make the overall system dissipative , there are differences from the case when non - hamiltonian systems are coupled . when the dynamics is decaying to a point attractor , there is an abrupt transition in the relative phases of the oscillatory transient motion . this is the phase flip transition that has been seen in a number of other systems @xcite . here , however , there are special values of the time delay when the coupling term effectively vanishes : the underlying hamiltonian structure then becomes apparent . our main results are presented in sections ii and iii where we consider the cases of coupled harmonic oscillators and coupled hnon heiles systems respectively . we show how ad is reached and the nature of the phase - flip transition in both cases . since the uncoupled systems are hamiltonian , it is possible to define an energy , and while this quantity has been studied in coupled feedback oscillators @xcite as a tool to determine onset of ad , its variation in the ad regime itself has not been examined . in this work we do energy analysis in the ad region and find that the energy dissipation is non monotonic as a function of the coupling , decaying faster prior to the phase flip transition and slower subsequently . the paper concludes in section iv with a summary and discussion of the results . the simplest system we consider is that of diffusively coupled harmonic oscillators . we consider the following equations of motion @xmath0=0 \\label{eq : shm}\\end{aligned}\\ ] ] where @xmath1=1 , 2 and @xmath2 and @xmath3 and @xmath4 represent the position and the velocity of the @xmath5th oscillator , and @xmath6 is the intrinsic frequency . we take the oscillators to be identical @xcite , @xmath7 . the parameters @xmath8 and @xmath9 represent coupling strength and time delay respectively . in the absence of delay , @xmath10 causes the systems to synchronize completely . due to the simple dynamics of the system no other significant behavior is observed . when , delay is finite the coupling quenches oscillations leading to ad . stability analysis of eq . ( [ eq : shm ] ) around the fixed point , namely the origin , gives the characteristic equations @xmath11taking the roots of the jacobian to be @xmath12 , the condition for marginal stability is @xmath13 , and substituting this condition in eq . ( [ eq : ch ] ) we get @xmath14 where @xmath15 is the critical value at which @xmath13 and @xmath16 is the time - period of the uncoupled oscillators . shown in fig . [ fig : ho1](a ) are the first two lyapunov exponents @xcite of the system as a function of @xmath9 for fixed coupling strength @xmath8 = 1 . the largest le is zero only at @xmath17 ( marked in fig . 1(a ) as b and d ) and remains negative for all other values of @xmath9 , implying that the system is driven to ad except when the delay is an integral multiple of half the time period . further , at these critical delay values the system oscillates at the frequency of the uncoupled system namely @xmath18 , and the parameter space is divided into multiple ad regions by the critical delay values which are independent of the coupling strength @xmath8 . in contrast , in non hamiltonian systems ad islands are separated by finite range of delay values @xcite where the coupling function need not vanish . hence , in those systems the reappearance of oscillations after ad depends both on the coupling strength and on the delay , whereas in coupled hamiltonian systems we find that this happens only due to delay .    in the ad regime(s ) points of discontinuity in the slope of the largest le ( marked in fig . 1(a ) as a and c ) indicate the change in the relative phases of oscillation . this is the so  called phase - flip transition @xcite , and the difference in the phases of the coupled subsystems changes by @xmath19 ; see ( fig.[fig : ho1]b ) . as in other cases where this phenomenon has been observed , there is simultaneously a discontinuous change in the oscillation frequency @xcite , as shown in fig.[fig : ho1](c ) .    ) as a function of the time delay @xmath9 for fixed @xmath10 = 1 ; ( b ) phase difference between the oscillators around point a indicated in ( a ) . inset figures show trajectories @xmath20 and @xmath21 as a function of time for the in  phase and the out  of  phase dynamics at @xmath9 = 1 and 2 respectively , namely on either side of the phase  flip transition , and ( c ) the frequency of oscillation of the subsystems . ]    the uncoupled conservative hamiltonian systems are made dissipative through the time  delay coupling , and this is also reflected in the fact that the sum of all the les remains negative for all @xmath9 . defining the energy of the individual oscillators as @xmath22 where @xmath23 is the instantaneous frequency of oscillation , the approach to the fixed point can be seen to be at an exponential rate in the ad regime @xcite as can be seen in fig . [ fig : ho2](a ) . the exponential decay is however modulated , the oscillatory behavior being due to coupling ( see the inset in the figure ) . in order to capture the dynamics , we define a decay constant as @xmath24 where @xmath25 represents the @xmath26-th maxima in the energy time series of the @xmath5th oscillator . the averages @xmath27 and @xmath28 are performed on @xmath26 and 100 initial conditions respectively . since the oscillatory behavior is modulated by exponential decay , @xmath29 is also an exponentially decaying function of @xmath26 , at rate @xmath30 . this rate can be measured experimentally and its variation with @xmath9 is shown in fig . [ fig : ho2](b ) ; the variation mirrors that of the frequency change at phase  flip , suggesting that energy decays more rapidly before the transition than after it .    ) , as a function of time for @xmath31 . the marked box is expanded in the inset . ( b ) the decay rate , @xmath32 as a function of @xmath9 ( see eq . ( [ eq : decay ] ) ) . errorbars ( marked in red ) are calculated for 100 initial conditions . ]    at the critical delay values @xmath33 ( see points b and d in fig . [ fig : ho1](a ) ) the largest lyapunov exponent is zero and thus the motion is periodic . [ fig : ho3](a ) shows orbits for five different initial conditions at the critical point ; these resemble invariant curves as in conservative systems . however , in the vicinity of the critical delay values the largest lyapunov exponent is near zero and the motion appears periodic after an initial transient . the time series of one such periodic orbit is shown in fig . [ fig : ho3](b ) . also , as can be seen in the inset , there is very slow decrease in amplitude . this occurs since delay is not strictly @xmath34 . away from delay @xmath34 , the dissipation is more pronounced . the rate of decrease of the amplitude can be quantified through the measure    @xmath35    where @xmath36 is the @xmath26-th maxima of @xmath3 . this is plotted in fig . [ fig : ho3](c ) as a function of @xmath9 in the vicinity of @xmath37 , namely the point b in fig . [ fig : ho1](a ) . at @xmath33 the rate of decrease of amplitudes approaches zero and hence the orbits are almost periodic . similar behavior is observed at point d of fig.[fig : ho1](a ) . the reason for reappearance of oscillatory motion is straightforward . when the delay is a multiple of half the natural period of oscillation , then the coupling term effectively vanishes since @xmath38 and the system effectively becomes conservative . clearly when this occurs , each initial condition gives rise to an invariant curve ( or , in this case , a nearly invariant curve ) . the better the equality above is realized , the more long lived the transients are . there is the phase flip transition at a , c and also higher values of @xmath9 . at each transition a phase difference of @xmath19 is introduced between the oscillators resulting in anti phase synchronization at @xmath39 and in  phase synchrony as @xmath40 and so on . hence , the coupling function becomes zero at these critical delays . the consecutive oscillatory states alternate between having the oscillations being in  phase or out  of  phase , as shown in fig . [ fig : ho3](d ) ( out  of  phase at @xmath37 , namely at b ) and fig . [ fig : ho3](e ) ( in  phase at @xmath41 at the point marked @xmath42 ) respectively . note that the phase - relation between oscillators is independent of the initial conditions .    ; ( b ) time series of position variable @xmath20 as a function of time at @xmath43 . the inset figure shows decrease in amplitude of @xmath20 ; ( c ) the averaged distance @xmath44 with errorbars , as function of delay @xmath9 near @xmath37 . the errorbars are calculated for 100 initial conditions ; ( d ) out - of - phase motion and ( e ) in - phase motion in relative phase plane @xmath45 at @xmath37 and @xmath46 respectively ( corresponding to points b and d of fig . [ fig : ho1](a ) ) . ] in order to examine the dynamics when the uncoupled systems are capable of exhibiting chaotic motion , we examine the behavior of two non - integrable hnon - heiles systems @xcite , @xmath47    as is well  known , in the uncoupled case ( @xmath10=0 ) the system has both regular and irregular behavior largely depending on the total energy as well as on the initial condition @xcite . shown in fig . [ fig : hh0 ] are the poincar maps for two different initial conditions , one leading to regular motion ( red points ) , while another leads to chaotic dynamics ( black points ) , at the same energy @xmath48 = 0.13 just below the dissociation limit @xmath48 = 1/6 .    ) , at energy @xmath49 . red ( outer ) and black ( inner ) dots represent regular and chaotic motion respectively . ]      in the absence of delay @xmath51 , eq . ( [ eq : hh ] ) reduces to the case of simple diffusive coupling . the effect of increasing the coupling strength , namely @xmath10 , is to induce simplicity to the resulting collective dynamics . shown in fig.([fig : hhic ] ) are the the fraction of initial conditions @xmath52 leading to quasiperiodic motion . we take 100 pairs of random initial conditions from the bounded region of phase space ( fig . [ fig : hh0 ] ) . in one case , when the initial condition pairs of quasiperiodic motions are taken , the collective dynamics due to interaction remains quasiperiodic ( solid line ( black circles ) : @xmath53 ) . however , if the initial motion is chaotic then the resulting dynamics becomes quasiperiodic only after certain value of coupling strength ( dashed line ( red triangles ) : @xmath54 ) . similar behavior is observed when initial conditions of mixed chaotic and quasiperiodic motions are used ( dotted line ( green stars ) : @xmath55 ) . these results indicate that for small coupling strength the hamiltonian structure still exists , but for larger values of coupling the collective dynamics becomes quasiperiodic ; in this sense coupling induces simplicity in such coupled systems .    ) , chaotic ( @xmath54 ) and mixed chaotic and quasiperiodic @xmath56 motions respectively . averages have been taken over a sample of 100 initial conditions . ] 0.2 cm [ fig : hhic ]      , and ( b ) the oscillation frequency , for coupling strength @xmath8 = 1 . the inset shows trajectories @xmath57 and @xmath58 for @xmath9 = 1.4 and 1.8 respectively . ( c ) the decay constant @xmath32 as a function of the delay @xmath9 . ]    when the two systems are coupled in presence of delay , @xmath9 ( initial conditions taken from either the regular or irregular motion ) the largest lyapunov exponent quickly becomes negative . this is shown as a function of the delay in fig . [ fig : hh1](a ) : almost as soon as the delay is switched on the oscillators are driven to ad state . the phenomenology of this higher dimensional system is very similar to that of the coupled harmonic oscillators : the largest le has the same characteristic shape  there is a change in the slope at point a , where it is clear that the phase - flip transition occurs . shown in fig . [ fig : hh1](b ) is the common frequency of oscillations as a function of delay which changes discontinuously at @xmath591.65 . since the phase of the oscillators is not clearly defined in such systems , we infer the phase relation from the time  series ( inset figures ) of the two systems in the neighborhood of the point of discontinuity . the phase difference changes from 0 to @xmath19 along with the frequency jump as in the simpler 1dimensional harmonic system .    here also energy decreases exponentially in this ad region . we define the energy of individual systems in the usual manner @xcite @xmath60 and quantify the energy dissipation as in eq . ( [ eq : en ] ) by a quantifier @xmath30 . the variation of this quantity with @xmath9 can be seen in fig . [ fig : hh1](c ) . it confirms that energy dissipation is faster before phase flip transition and slower thereafter .    when the largest lyapunov exponents approach zero ( at points marked b and d in fig . [ fig : hh1](a ) ) the motion is oscillatory , decaying very slowly to the fixed point . critical delays are at half the natural time period of oscillation , and since the natural frequencies of the oscillators is equal to ` 1 ' , the time period is 2@xmath19 . the poincar sections of representative trajectories at @xmath43 are shown in fig . [ fig : hh2](a ) which are quasiperiodic ( cf . section iia ) . in the vicinity of this point , the rate of decay can be computed numerically as discussed earlier , and the quantifier @xmath61 , eq . ( [ eq : dis ] ) defined to locate the oscillatory state also has a minimum for at @xmath62 . at successive critical points ( @xmath43 and @xmath63 ) the quasiperiodic motions alternate in the nature of the phase synchrony ; see fig . [ fig : hh2](d , e ) . unlike the case of harmonic oscillators , though , the coupling term does not quite vanish , so the emergence of oscillations is not as pronounced in this case .    0.8 cm   for three different initial conditions ; ( b ) time series of @xmath20 ; ( c ) variation of @xmath44 as a function of delay . the error bars are computed from a large number of initial conditions . ( d ) the relative phase in @xmath64 plane to show anti - phase motion at @xmath65 and ( e ) in - phase motion at @xmath66.,title=\"fig : \" ] in the present paper we have explored the effects of incorporating time delay in the coupling between hamiltonian systems . the coupled system effectively becomes dissipative , and in the absence of other attractors , the total system displays amplitude death . however the coupling can effectively vanish for specific values of the time delay , at which delay the the system naturally appears to be conservative . we find that this behaviour differs from that of delay  coupled non hamiltonian systems , where ad islands are separated by finite ranges of delay values where the coupling function need not vanish . orbits near these critical delay values reflect both dissipative and conservative behavior : different initial conditions give rise to different ( seemingly ) invariant curves which are very long lived transients . energy dissipation in the ad regime is found to be associated with the phase flip transition , and the damping is faster prior to the transition , and slower after it .    the finite velocity with which signals are transmitted gives rise to intrinsic delays in the coupling , and as such this is germane in both dissipative as well as conservative systems . nevertheless , the effect of delay has been explored to a limited extent in conservative systems . the results presented here may have more general applicability in coupled systems with other conservation laws such as in ecological contexts @xcite . * acknowledgment : * gs gratefully acknowledges the support of the csir , india . ap and rr acknowledge the research support of the department of science and technology ( dst ) . ap also acknowledges dst for du - dst - purse grant for financial support . this work was started when ap was a sabbatical visitor at the mpi - pks in dresden , germany , and he acknowledges their kind hospitality . y. yamaguchi and h. shimizu , ; k. bar - eli , . d. g. aronson , , ; p. c. mathews and s. h. strogatz , ; g. b. ermentrout , ; v. resmi , g. ambika and r. e. amritkar , ; v. resmi , g. ambika , r. e. amritkar and g. rangarajan , . g. saxena , a. prasad , and r. ramaswamy , phys . reports * 521*,205 ( 2012 ) . a. prasad , . a. prasad , j. kurths , s. k. dana and r. ramaswamy , ; a. prasad , s. k. dana , r. karnataka , j. kurths , b. blasius and r. ramaswamy , chaos * 18 * , 23111 , ( 2008 ) ; c. masoller , m. torrent and j. o. garcia , ; y. chen , j. xiao , w. liu , l. li and y. yang , ; j. m. cruz , j. escalona , p. parmananda , r. karnatak , a. prasad , and r. ramaswamy , phys . rev . e. * 81 * , 046213 ( 2010 ) ; b. m. adhikari , a. prasad , m. dhamala , chaos * 21 * , 023116 ( 2011 ) ; r. karnatak , p. nirmal , a. prasad and r. ramaswamy , phys . e. * 82 * , 046219 ( 2010 ) ; p. nirmal , r. karnatak , a. prasad , j. kurths and r. ramaswamy , . s. kim , s. h. park and c. s. ryu , ; a. prasad , l. d. iasemidid , s. sabesan and k. tsakalis , pramana * 64 * , 513 ( 2005 ) . h. g. schuster and p. wagner , . k. konishi , m. ishii and h. kokame , ; k. konishi , h. kokame and k. hirato , ; k. konishi , ; k. konishi , k. senda and h. kokame , ; k. konishi , h. kokame and n. hara , ; l. b. le , k. konishi and n. hara , nonlinear dyn . * 67 * , 1407,(2012 ) . d. v. ramana reddy , , ; s. h. strogatz , nature ( london ) * 394 * , 316 ( 1998 ) ; f. m. atay , ; f. m. atay , j. jost , ; f. m. atay , ; g. saxena , a. prasad , and r.ramaswamy , phys . rev . e. * 82 * , 017201 ( 2010 ) . w. zou , c. yao and m. zhan , ; w. zou , j. lu , y. tang , c. zhang and j. kurths , ; w. zou , y. tang , l. li and j. kurths , ; w. zou , d. v. senthilkumar , y. tang and j. kurths , . m. tabor , _ chaos and integrability in nonlinear dynamics : an introduction _ ( john wiley & sons , new york , 1989 ) . v. i. arnold , _ mathematical methods of classical mechanics _ ( springer , new york , 1978 ) . d. h. zanette and a. s. mikhailov , ; a. hampton and d. h. zanette , . the flow is integrated using the runge - kutta @xmath67 order scheme with integration step @xmath68 where @xmath69 is fixed . as we increase the value @xmath70 ( checked upto @xmath71 ) the decrease in amplitude in fig . 3(b ) becomes slower . lyapunov exponents are calculated using the method as given in ref . phase and frequency are numerically calculated as per ref . @xcite .    understanding the transient dynamics is essential in describing ad since this state is asymptotically featureless . transients can be significant in applications that are restricted to finite times , as for example in ecology @xcite .", "tags": [], "output_text_a": "This paper investigates the effects of time delay in the coupling of Hamiltonian systems, which are typically conservative in nature. When these systems are coupled with a time delay, they become dissipative, leading to phenomena such as amplitude death (AD) and phase-flip transitions. The study focuses on two examples: diffusively coupled harmonic oscillators and coupled H\u00e9non-Heiles oscillators. In both cases, the introduction of time delay causes the oscillatory dynamics to dampen to a fixed point, resulting in AD. The paper highlights that the coupling can effectively vanish at specific time delays, making the system appear conservative again. This behavior is distinct from non-Hamiltonian systems, where AD islands are separated by finite delay ranges. The study also examines energy dissipation in the AD regime, finding it to be non-monotonic, with faster decay before the phase-flip transition and slower afterward. The results suggest that time delay in coupling can significantly alter the dynamics of Hamiltonian systems, with potential implications for other systems with conservation laws, such as ecological models. The paper concludes with a discussion on the broader applicability of these findings.", "output_text_b": "This paper studies the impact of time delay in the coupling of Hamiltonian systems. The coupled system becomes dissipative, leading to amplitude death in the absence of other attractors. However, for specific time delay values, the coupling effectively vanishes, and the system appears conservative. This behavior differs from delay-coupled non-Hamiltonian systems, where amplitude death islands are separated by finite ranges of delay values where the coupling function need not vanish. Orbits near critical delay values exhibit both dissipative and conservative behavior, with different initial conditions resulting in different (seemingly) invariant curves that are long-lived transients. Energy dissipation in the amplitude death regime is associated with the phase flip transition, with faster damping before the transition and slower damping after it.\n\nThe paper discusses the effect of time delay in conservative systems, which may have broader applicability in coupled systems with other conservation laws, such as ecological contexts.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, such as the effects of time delay in Hamiltonian systems leading to amplitude death and phase-flip transitions.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding the effects of time delay in the coupling of Hamiltonian systems.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the study of diffusively coupled harmonic oscillators and coupled H\u00e9non-Heiles oscillators as the methodology.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the non-monotonic energy dissipation and the distinct behavior from non-Hamiltonian systems.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like amplitude death and phase-flip transitions.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear beginning, middle, and end.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not explicitly mention key experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by mentioning potential implications for other systems with conservation laws.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the impact of time delay in the coupling of Hamiltonian systems and the resulting phenomena such as amplitude death and phase flip transition.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the effect of time delay in the coupling of Hamiltonian systems, is highlighted.\n4. The summary does not explicitly mention the methodology or approach used in the paper, such as the specific examples of coupled harmonic oscillators and H\u00e9non-Heiles systems.\n5. Significant results, such as the conditions under which the system appears conservative and the behavior of energy dissipation, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids technical jargon and explains terms like \"amplitude death\" and \"phase flip transition.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention key experiments or data used in the research, such as the stability analysis or Lyapunov exponents.\n10. The summary reflects the paper's significance by mentioning its broader applicability in systems with conservation laws."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "it has been 60 years since casimir @xcite found a profound explanation for the retarded van der waals interaction as a manifestation of the zero - point energy of the quantum electromagnetic field . for many years the casimir effect was little more than a theoretical curiosity . but interest in the phenomenon has blossomed in recent years . experimental physicists have realized that the casimir force affects the workings of micromachined devices , while advances in instrumentation have enabled the force to be measured with ever - greater accuracy . on theoretical grounds , considerable progress has also been achieved by studying the dependence of the casimir force with the geometry of the conducting surfaces @xcite .    up to now , most experiments aiming at a measurement of the casimir force have been performed with parallel plates @xcite , or with a sphere in front of a plane @xcite . the parallel plates configuration has a stronger signal , but the main experimental difficulty is to achieve parallelism between the plates . this problem is of course not present in the case of a sphere in front of a plane , but its drawback is that the force is several orders of magnitude smaller . the problem of the theoretical evaluation of the electromagnetic force for this configuration has been solved recently @xcite . the configuration of two eccentric cylinders have both experimental and theoretical interest @xcite . although parallelism is as difficult as for the plane - plane configuration , the fact that the concentric configuration is an unstable equilibrium position opens the possibility of measuring the derivative of the force using null experiments ( for example , one could consider experimental configurations in which a metallic wire is placed inside a larger hollow cylinder ) . the casimir interaction energy between two eccentric cylindrical shells has been computed in @xcite , and was initially reported in @xcite . therein , it was used the mode summation technique combined with the argument theorem in order to write the casimir energy as a contour integral in the complex plane , to end with an exact formula in which the vacuum energy is written in terms of the determinant of an infinite matrix . as a bonus , it has also been shown that the matrix elements in the general formula for two eccentric cylinders reproduce , as a limiting case of relevance , those of the casimir energy for the cylinder - plane configuration . the latter geometry is also of experimental interest : being intermediate between the sphere - plane and the plane - plane geometries , it can shed some light on the longstanding controversy about thermal corrections to the casimir force . keeping the two plates parallel has proved very difficult , while the sphere and plate configuration avoids this problem , the force is not extensive . in the case of the cylinder - plane configuration , it is easier to hold the cylinder parallel and the force results extensive in its length . there is an ongoing experiment to measure the casimir force for this configuration @xcite . the aim of this paper is to provide a precise numerical evaluation of the analytical results obtained in @xcite . the numerical evaluations will allow as to test different approximations , as the proximity force approximation ( pfa ) for close surfaces , and the `` around the diagonal '' approximation for quasi concentric cylinders . we will also show numerically that the energy of the eccentric cylinders configuration reproduces that of the cylinder - plane configuration , in the limit of very large eccentricity , when the radius of the external cylinder is also very large . finally , we will present a detailed numerical evaluation for the vacuum energy for the cylinder - plane configuration , providing numerical support for the analytic predictions of the first order corrections to pfa @xcite . the paper is organized as follows . in section [ numeric ] we will discuss the general procedure used for the numerical evaluation of the casimir energy in every case considered . in section [ eccentric ] , we will evaluate the exact formula for the interaction energy between eccentric cylinders . the complexity of the numerical evaluation increases as the radii of the cylinders get closer , and we provide details of the size of the matrices needed to assure convergence of the numerical results . in section [ quasi ] we analyze the particular case of quasi - concentric cylinders . we test the validity of the approximation developed in @xcite , based on tridiagonal matrices , that we extend to the next order by considering pentadiagonal matrices . in section [ concentric ] we consider the particular case of concentric cylinders . we will obtain a new analytic result in the small distance limit , that includes the corrections to pfa up to the second order . we will also present an improved numerical method to evaluate the interaction energy at small distances . finally , in section [ cp ] , we will numerically show that the interaction energy for the cylinder - plane configuration can be derived in the appropriate limit from the eccentric cylinders configuration , a result that was anticipated analytically for the matrix elements in @xcite . in addition , we will evaluate numerically the cylinder - plane casimir energy as the minimum distance between the surfaces is much smaller than the radius of the cylinder . we will be able to show numerically that the energy is well reproduced in this limit by the pfa , and to compute the first order correction to pfa for both tm and te modes . in the first case ( tm ) , the fits of the numerical data reproduce with high precision the analytic prediction @xcite . on the other hand , the fits for te modes are close to the analytic results or not , depending on the assumption about the higher order corrections . , length @xmath0 , and eccentricity @xmath1 interact via the casimir force.,width=207 ]    the evaluation of the casimir interaction energy between two eccentric cylindrical shells ( fig.[fig1 ] ) has been initially performed using pfa in ref.@xcite . however , it is possible to go beyond the pfa and find an exact formula for the interaction energy @xcite . this can be done using a mode by mode summation technique combined with the argument theorem . by starting with the expression of the casimir energy as @xmath2 , it has been shown in @xcite that the casimir interaction energy for two eccentric cylinders can be written as @xmath3   \\nonumber \\\\ & = & e^{\\rm te}+e^{\\rm tm } , \\label{e12}\\end{aligned}\\ ] ] where @xmath4 $ ] and @xmath5 $ ] . here @xmath6 is a dimensionless integration variable and @xmath7 are arbitrary integers . roughly speaking , the function @xmath8 that determines the casimir energy through eq.([e12 ] ) is such that its zeros give the eigenfrequencies of the geometric configuration . more precisely , it is the ratio of the function associated to the actual geometric configuration and the one associated to a configuration in which the conducting surfaces are very far away from each other @xcite . the matrices @xmath9 and @xmath10 are defined as @xmath11 and similarly , for the @xmath12 modes , we have @xmath13 where @xmath14 is the radio between the outer and inner cylinder s radii and @xmath1 is the eccentricity ( see fig.1 ) . @xmath15 and @xmath16 denote the modified bessel functions . in order to calculate the casimir interaction energy , one needs to perform a numerical evaluation of the determinants in eq.([e12 ] ) , followed by a numerical integration in the variable @xmath17 . we find that as @xmath18 approaches small values , larger matrices are needed for ensuring convergence . likewise , as @xmath19 , the contribution to the integral is significative for a bigger integration range ( bigger values of @xmath17 contribute ) . that turns the problem into a real challenge from the numerical point of view . we numerically compute the casimir interaction energy using a fortran program . once the @xmath8 matrix elements for each configuration considered is defined , we use a standard routine to calculate its eigenvalues and determinant . finally , we perform a standard integration over all values of @xmath17 . the parameters used by the program are : the dimension of the @xmath8 matrix ( n , n ) , the number of addends @xmath20 corresponding to each element of the m matrix , the integration limit ( @xmath21 ) and the precision desired . the difficulty in running the programme lays in the compromise taken between all the parameters chosen .    in the following , we will evaluate the casimir interaction energy for eccentric , quasi concentric , concentric cylinders , and also for the particular limit of a cylinder in front of a plane . in this section , we present the numerical results for the casimir interaction energy for two eccentric cylinders given by eqs.([fulltm ] ) and ( [ fullte ] ) .     between the eccentric and concentric configurations as a function of @xmath22 for different values of @xmath23 . here @xmath24 . energies are measured in units of @xmath25,width=328 ]    in figs.[njpfig3 ] and [ njpfig4 ] , we reproduce the exact casimir interaction energy difference @xmath26 between the eccentric and concentric configurations . in fig.[njpfig3 ] we plot the interaction energy difference @xmath27 as a function of @xmath28 for different values of the eccentricity @xmath23 . these numerical results interpolate between the pfa and the asymptotic behavior for large @xmath28 @xcite . in fig.[njpfig4 ] we show the casimir interaction energy difference as a function of @xmath29 for various values of @xmath28 . again , it is evident that the equilibrium position ( @xmath30 ) is unstable .    in refs.@xcite similar plots were performed using an algebraic evaluation of the trace of the matrix @xmath8 , and a numerical integration , both using mathematica . due to this procedure , it was possible to evaluate the vacuum energy only for relatively large values of the parameter @xmath28 , in order to reach convergence . with the numerical method we are presenting here , we are able to include smaller values of @xmath28 , closer to the pfa region , where previous numerical calculations could not reach . both in fig.[njpfig3 ] and fig.[njpfig4 ] we include runs for @xmath31 . in order to achieve so , we have used matrices of dimension ( 21,21 ) and 501 addends in the sums of eqs . ( [ fulltm ] ) and ( [ fullte ] ) to assure convergence ( variation smaller than @xmath32 ) . for values @xmath33 , smaller @xmath8 matrices ( 5,5 ) can be used to obtain the plots with equal precision ( indeed , as it was shown in @xcite , for @xmath34 the energy is dominated by the 00-element of the matrix @xmath8 ) . the size of @xmath8 for the runs was set by the smaller values of @xmath28 that needed bigger @xmath8 matrix to obtain the same accuracy .     between the eccentric and concentric configurations as a function of @xmath23 for different values of @xmath22 . energies are measured in units of @xmath35 . the maximum at @xmath30 shows the instability of the concentric equilibrium position.,width=328 ]    the convergence of the numerical results depends both on the values of @xmath28 and @xmath29 . for example , for @xmath36 and @xmath37 matrices ( 5,5 ) are enough , while for @xmath38 matrices ( 9,9 ) are needed . in the case of @xmath39 , it is necessary to use matrices of dimensions ( 55,55 ) and ( 101,101 ) when @xmath29 is 0.01 and 0.1 , respectively . in this section , we consider the situation in which the eccentricity of the configuration is much smaller than the radius of the inner cylinder ( @xmath40 ) . for a small non - vanishing eccentricity , the behaviour of the bessel functions in eqs.([fulltm ] ) and ( [ fullte ] ) is @xmath41 for small arguments . this suggests that the main contribution should be the one coming from the diagonal elements , and that one only needs to use matrix elements near the diagonal . we will test this idea through a numerical comparison between the casimir interaction energy for different approximations and the exact energy derived in the previous section .    _ first order approximation_. to begin with , we will only consider the matrix elements proportional to @xmath42 and @xmath43 as we are assuming small eccentricity @xmath44 . in this particular case , the @xmath8 matrix become tridiagonal and the @xmath1-dependent part of the casimir energy will be quadratic in the eccentricity . we will describe in detail the case of the dirichlet ( tm ) modes ; the treatment of neumann ( te ) modes is similar . as was already mentioned in @xcite , to order @xmath45 , the non - vanishing elements of the matrix @xmath46 are : @xmath47 ,   \\nonumber \\\\ a_{n , n+1}^{\\rm tm(1 ) } & \\simeq & \\frac{i_{n}(\\beta)}{k_n(\\beta ) } \\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+1}(\\alpha \\beta ) } { i_{n+1}(\\alpha \\beta)}\\bigg ] i_0(\\delta \\beta )   i_1(\\delta \\beta ) , \\nonumber \\\\ a_{n+1,n}^{\\rm tm(1 ) } & \\simeq & \\frac{i_{n+1}(\\beta)}{k_{n+1}(\\beta ) } \\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+1}(\\alpha \\beta ) } { i_{n+1}(\\alpha \\beta)}\\bigg ] \\nonumber \\\\ & \\times & i_0(\\delta \\beta )   i_1(\\delta \\beta).\\nonumber\\end{aligned}\\ ] ]    _ second order approximation_. in this case , we will consider that the main contribution to the casimir interaction energy comes from the terms that contain up to @xmath48 , extending the previous approximation to the next non trivial order . then , the matrix a has additional non diagonal contributions , i.e. it is a pentadiagonal matrix with non - vanishing elements given by @xmath49 ,   \\nonumber \\\\ a_{n , n+1}^{\\rm tm(2 ) } & \\simeq & \\frac{i_{n}(\\beta)}{k_n(\\beta ) } \\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+1}(\\alpha \\beta ) } { i_{n+1}(\\alpha \\beta)}\\bigg ] i_0(\\delta \\beta )   i_1(\\delta \\beta),\\nonumber \\\\ a_{n+1,n}^{\\rm tm(2 ) } & \\simeq & \\frac{i_{n+1}(\\beta)}{k_{n+1}(\\beta ) } \\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+1}(\\alpha \\beta ) } { i_{n+1}(\\alpha \\beta)}\\bigg]\\nonumber \\\\ & \\times & i_0(\\delta \\beta )   i_1(\\delta \\beta),\\nonumber \\\\ a_{n , n+2}^{\\rm tm(2 ) } & \\simeq & \\frac{i_{n}(\\beta)}{k_n(\\beta ) }   \\bigg\\{\\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+2}(\\alpha \\beta ) } { i_{n+2}(\\alpha \\beta)}\\bigg ] \\nonumber \\\\ & \\times & i_0(\\delta \\beta )   i_2(\\delta \\beta )   \\nonumber \\\\ & + & \\frac{k_{n+1}(\\alpha \\beta)}{i_{n+1}(\\alpha \\beta ) } i_1 ^ 2(\\delta \\beta ) \\bigg\\ } , \\nonumber \\\\ a_{n+2,n}^{\\rm tm(2 ) } & \\simeq & \\frac{i_{n+2}(\\beta)}{k_{n+2}(\\beta ) } \\bigg\\{\\bigg [ \\frac{k_n(\\alpha \\beta ) } { i_n(\\alpha \\beta ) } +   \\frac{k_{n+2}(\\alpha \\beta ) } { i_{n+2}(\\alpha \\beta)}\\bigg]\\nonumber \\\\ & \\times & i_0(\\delta \\beta )   i_2(\\delta \\beta )   \\nonumber \\\\ & + & \\frac{k_{n+1}(\\alpha \\beta)}{i_{n+1}(\\alpha \\beta ) }   i_1 ^ 2(\\delta \\beta ) \\bigg\\ } . \\nonumber\\end{aligned}\\ ] ]     between the eccentric and concentric configurations as a function of @xmath23 for different values of @xmath28 . the solid line is the exact evaluation of the casimir interaction energy , while the dashed line with triangles is the second order approximation and the dashed line with dots is the first order one . the analytic curve ( dashed line with crosses ) is the result of using eq.([ec48 ] ) . energies are measured in units of @xmath35.,width=328 ]    in the following , we will numerically compare the casimir interaction energy for the quasi concentric configuration computed using the first and second order approximations described above , with the one obtained using the exact formula given in eqs.([fulltm ] ) and ( [ fullte ] ) .    in figs.[cuasifig1 ] , [ cuasifig2 ] and [ cuasifig3 ] we present the casimir interaction energy diference @xmath50 between the eccentric and concentric configurations as a function of @xmath23 for different values of @xmath28 . therein , we can see the different curves corresponding to the exact energy difference ( solid line ) and the approximated ones obtained to first ( dashed line with dots ) and second order ( dashed line with triangles ) in the eccentricity . in all cases , matrix of dimension ( 21,21)@xcite and 501 addends in the sums have been used to assure convergence . we are also comparing the numerical results with the `` analytic '' result for quasi - concentric cylinders obtained ref.@xcite . therein , it was shown that the determinant of the tridiagonal matrix can be explicitly evaluated up to quadratic order in @xmath29 , and therefore it was possible to write the interaction energy as a series @xmath51 . \\label{ec48}\\end{aligned}\\ ] ] here @xmath52 , \\nonumber \\\\ { \\cal n}^{\\rm tm}_n & \\equiv & \\frac{i_n(\\beta ) i_{n+1}(\\beta)}{4 k_n(\\beta ) k_{n+1}(\\beta ) } \\left [ \\frac{k_{n}(\\alpha \\beta)}{i_{n}(\\alpha \\beta ) } + \\frac{k_{n+1}(\\alpha \\beta)}{i_{n+1}(\\alpha \\beta ) } \\right]^2 \\ , , \\nonumber\\\\ { \\cal d}_{n , n}^{\\rm tm , cc } & = & \\frac{i_n(\\beta)}{k_n(\\beta ) } \\frac{k_n(\\alpha\\beta)}{i_n(\\alpha\\beta)}\\ , .   \\label{newd}\\end{aligned}\\ ] ] the contribution of the te modes to the interaction energy @xmath53 has a similar expression , replacing the bessel functions by their derivatives with respect to the argument in the equations above . the numerical evaluation of this formulae in the plot is presented as the  analytic \" curve .     between the eccentric and concentric configurations as a function of @xmath23 for different values of @xmath28 . the solid line is the exact evaluation of the casimir interaction energy , while the dashed line with triangles is the second order approximation and the dashed line with dots is the first order one . the analytic curve is the result of using eq.([ec48 ] ) . energies are measured in units of @xmath35.,width=328 ]    in fig.[cuasifig1 ] we can see that the difference between several approximations increases with @xmath29 , for a given value of @xmath28 . for example , for @xmath54 and @xmath55 , the analytic approximation differs from the exact result in @xmath56 , and the first order approximation in @xmath57 . for a larger value of @xmath29 , as @xmath58 , the differences are @xmath59 and @xmath60 for the analytic and first order approximations , respectively . the results for the second order approximation coincide with the exact result within the accuracy imposed . however , as the value of @xmath28 becomes smaller , the differences become more visible . for @xmath36 the accuracy of the different approximations is , for @xmath55 , @xmath61 ( analytic ) , @xmath62 ( first order ) , and @xmath63 ( second order ) . on the other hand , for @xmath58 , we have @xmath64 ( analytic ) , @xmath65 ( first order ) , and @xmath60 ( second order ) .    in fig.[cuasifig2 ] we present results for smaller values of @xmath28 , and in fig.[cuasifig3 ] , we show a zoom - plot in order to appreciate better the differences .    in all cases considered , we can observe the expected hierarchy between the different approximations : while the second order approximation remains very similar to the exact result ( within a @xmath62 error ) for @xmath66 and @xmath67 , the difference between the first order approximation and the exact result for @xmath68 and @xmath55 is approximately @xmath69 .     between the eccentric and concentric configurations as a function of @xmath23 for different values of @xmath28 ( a smaller range of @xmath29 ) . the solid line is the exact evaluation of the casimir interaction energy , while the dashed line with triangles is the second order approximation and the dashed line with dots is the first order one . the analytic curve ( dashed line with crosses ) is the result of using eq.([ec48 ] ) . energies are measured in units of @xmath35.,width=328 ]    taking into account that the different approximations are derived under the assumption @xmath70 , the validity of the approximate results is , in general , better than expected . moreover , the results of this section show that the combination of analytic and numerical results allow a much more efficient numerical evaluation of the casimir energy . in the particular case considered here ( quasi concentric cylinders ) , from the numerical point of view it is much more convenient to consider sparse matrices concentrated on the diagonal , than large matrices in which all elements are non vanishing . in this section we will derive an analytic result for the vacuum energy in the concentric cylinders configuration valid for small distances , beyond pfa , and we will present an improved numerical method to evaluate the interaction energy at small distances for the particular case of two concentric cylinders .    the exact formula for eccentric cylinders coincides , of course , with the known result for the casimir energy for concentric cylinders ( @xmath71 ) . indeed , as @xmath72 , in this particular case the matrices @xmath73 become diagonal and the exact formula reduces to @xcite : @xmath74 where @xmath75 \\left[1-\\frac{i'_n(\\beta)k'_n(\\alpha \\beta ) } { i'_n(\\alpha \\beta)k'_n(\\beta)}\\right ] . \\label{mcc}\\ ] ] the first factor corresponds to dirichlet ( tm ) modes and the second one to neumann ( te ) modes . the concentric - cylinders configuration is interesting from a theoretical point of view , since it can be used to test analytic and numerical methods . it also has potential implications for the physics of nanotubes @xcite . the proximity limit @xmath76 has already been analyzed for the concentric case @xcite . in order to compute the casimir energy in this limit , it was necessary to use the uniform expansion of the bessel functions and to perform a summation over all values of @xmath77 . as expected , the result is equal to the one obtained via the proximity approximation , namely @xmath78 and both te and tm modes contribute with the same weight to the total energy . we will now compute analytic corrections to the pfa given in eq.([epfacc ] ) . due to the simplicity of this configuration , we will be able to obtain not only the next to leading order , but also the next to next to leading contribution . in order to do that , we need the uniform expansions of the bessel functions . we have @xmath79 } , \\label{ue1}\\ ] ] and @xmath80 } , \\label{ue2}\\ ] ] where @xmath81    with these expansions at hand , we can evaluate the matrix @xmath8 both for the te and tm modes . the expression in eq . ( [ mcc ] ) can be approximated by @xmath82 where @xmath83 with @xmath84 . in eq.([mcc2 ] ) we have defined coefficients @xmath85 and @xmath86 in terms of the expansions of the functions @xmath87 and @xmath88 . they read @xmath89    replacing eq.([mcc2 ] ) into eq.([cc ] ) , and expanding the logarithm as a series , it is possible to compute explicitly the remaining integrals in @xmath17 . after a long calculation , the casimir energy can be written as @xmath90 in the expression above , the first term inside the parenthesis corresponds to the proximity approximation contribution given in eq.([epfacc ] ) , while the second and third terms are the first and second order corrections , respectively . it is worth noticing that the sub - leading term coincides with the result obtained by means of the semiclassical approximation @xcite . it is also important to remark that both tm and te modes contribute with the same weight to the energy in the leading and the next to leading orders . however , this is not the case in the quadratic term . there is a factor @xmath91 coming from the tm mode , and a factor @xmath92 corresponding to the te one . numerical calculations of the casimir energy for @xmath28 very close to one are very difficult since big number of terms have to be considered in the sums , and therefore convergence problems arise , mainly produced by underflows and overflows in the evaluation of bessel functions of large orders .    in order to perform a numerical evaluation of the casimir energy in the proximity region , we will describe a subtraction method , in which we have used the value of the energy in the pfa to improve the numerics @xcite .     and the casimir energy estimated using the pfa up to the next to leading order @xmath93 , as a function of the parameter @xmath28 . this is done for two different methods : the numerical ( of slow convergence ) and the numerical improved ( subtraction method).,width=328 ]    in the case we are concerned here , we can add and subtract the interaction energy for concentric cylinders computed using the leading uniform asymptotic expansion for the bessel functions , up to first order in @xmath94 : @xmath95 we denote by @xmath96 the interaction energy obtained by inserting these expansions into eq . ( [ cc ] ) , which can be computed analytically @xmath97,\\end{aligned}\\ ] ] and contains the leading order of the casimir energy . now we write @xmath98 the difference contained in the brackets in eq . ( [ emodificada ] ) , has a faster convergence than the original sum and , therefore , can be easily calculated numerically .    in fig.[fig6 ] we present both casimir energy of the concentric cylinders for the direct numerical calculation ( of slow convergence ) and the alternative method mentioned above . in this figure we plot the ratio @xmath99 where    @xmath100    as can be seen , with this subtraction method it is possible to compute the exact energy for values of @xmath28 much closer to @xmath101 , while the accuracy of the direct calculation is worse for @xmath102  . moreover , the numerical results confirm the analytic result given in eq.([ntntlead ] ) . we have fit the ratio between the casimir interaction energy with the next to leading correction of eq.([ntl ] ) , @xmath103 , obtaining @xmath104 , and @xmath105 . the analytical results , expected from eqs.([ntntlead ] ) and ( [ ntl ] ) are @xmath106 and @xmath107 , which means that we are checking the next to next leading correction with an error smaller than @xmath108 . a similar method could in principle be applied to the eccentric cylinders or the cylinder - plane configurations , although in these cases the main difficulty is the analytic evaluation of the approximate energy that has to be added and subtracted . is in front of a perfectly conducting plane at a distance @xmath109.,width=302 ]    in this section , we will study the cylinder - plane configuration ( fig.[cpfig ] ) . the casimir energy for this configuration was first evaluated in the pfa in ref.@xcite . the exact formula has been derived in refs.@xcite , and has the same structure than eq.([e12 ] ) , but with the matrix elements @xmath10 and @xmath9 replaced by the corresponding ones for this geometry , that we will denote by @xmath110 and @xmath110 .    as suggested by simple geometric arguments , the eccentric cylinders formula reproduces the cylinder - plane matrix elements in the limit @xmath111 , keeping @xmath112 fixed . indeed , using the uniform expansion of the bessel functions , and as explained in ref.@xcite , the matrix elements @xmath10 and @xmath9 , become respectively , @xmath113 and @xmath114 these expressions coincide with the result for the @xmath12 and @xmath115 modes in the cylinder plane configuration @xcite .    in the following we will , firstly , compare the exact casimir interaction energy for the cylinder - plane configuration with that of the two eccentric cylinders , in the limit that the latter reproduces the former configuration . in the end of the section , we will numerically evaluate the cylinder plane casimir for small distances , in order to discuss the leading correction to the pfa . we will now show explicitly that the numerical evaluation of the vacuum energy for eccentric cylinders , based on eqs.([e12],[fulltm ] ) and ( [ fullte ] ) , reproduce the exact results for the cylinder - plane configuration , described by eq.([e12 ] ) with the matrix elements given by eqs.([acpte ] ) and ( [ acptm ] ) .     for different values of @xmath28.,width=328 ]    in fig.[exandcpfig1 ] we present the ratio of both energies as a function of @xmath109 for different values of @xmath28 . these runs were done by the use of matrices of dimension @xmath116 and @xmath117 addends in the sums of eqs.([fulltm ] ) and ( [ fullte ] ) . the need of big matrices is set by the cylinder - plane configuration program , while the number of addends is set by the eccentric cylinders geometry . from the numerical results we see that , as expected , the vacuum energy of the eccentric cylinders tends to the vacuum energy of the cylinder in front of a plane for large values of @xmath118 and @xmath1 , when @xmath119 and @xmath120 are fixed . the coincidence is of course better for smaller values of @xmath109 , the minimum distance between surfaces .    in all cases , we can see that the exact casimir interaction for eccentric cylinders is bigger than the cylinder plane energy . this result is expected from the pfa , since the conducting surfaces are closer to each other in the case of the two eccentric cylinders than in the cylinder - plane configuration , for a given minimum distance between surfaces .      in this section we present a detailed computation of the vacuum energy for the cylinder - plane configuration . in fig.[ltcpfig1 ] we present the casimir interaction energy for the cylinder - plane configuration obtained by the use of our fortran program . for the runs , we used a matrix of dimension ( 101,101 ) to reach the proximity area ( @xmath121 ) . it must be mentioned that for smaller values of @xmath109 , we need to increase the dimension of the a matrix and the integration range of @xmath17 in eq.([e12 ] ) . this fact becomes our major limitation to reach yet smaller values of @xmath109 .    . a simple fit @xmath122 of the numerical data for @xmath123 gives @xmath124 and @xmath125.,width=328 ]    we now discuss in more detail the limit @xmath126 . this problem has been considered from an analytical point of view in ref.@xcite . using the uniform expansions for the bessel functions appearing in the matrix elements @xmath110 and @xmath110 , and after complex calculations , it can be shown that , in the proximity limit : @xmath127 @xmath128 where we have written separately the contributions of tm and te modes .    . a simple linear fit @xmath129 of the numerical data in the interval @xmath130 gives @xmath131 and @xmath132 . the theoretical values are @xmath106 and @xmath133.,width=328 ]    .different fits for the numerical results of fig . we fix @xmath134 since the numerical data agree this value with high precision . [ cols=\"^,^,^,^\",options=\"header \" , ]     . a simple linear fit @xmath129 of the numerical data in the interval @xmath130 gives @xmath135 and @xmath136 . the theoretical values are @xmath106 and @xmath137.,width=328 ]    . the coefficients are @xmath138 , @xmath139 , and @xmath140.,width=328 ]    we will discuss the first order corrections to pfa for tm and te modes separately . in fig.[cptm ] , we show our numerical results for the tm modes . the fit of the numerical results depends of course on the interval chosen for @xmath141 . there is an obvious compromise : on the one hand , as already mentioned , we can not consider very small values for @xmath141 because of numerical limitations . on the other hand , the expansion in powers of @xmath141 are expected to be valid only for @xmath142 . in any case , as can be seen from table i , the different fits for the numerical results are stable , and confirm both the pfa to leading and next to leading orders . indeed , the results are fully compatible with the analytic results given in eq.([e12cpbtm ] ) , considering both linear and quadratic fits of the numerical results . moreover , a simple linear fit in a smaller range of @xmath141 gives @xmath131 and @xmath143 and already reproduces the analytical results @xcite with high accuracy ( see also numerical findings in @xcite ) .    in fig.[cpte ] , we show our results for the neumann modes , and we include in table ii different fits of the numerical data . in this case , the value obtained for the linear correction to pfa depends strongly on the assumption about the next non trivial correction . this is not surprising : as we can not consider extremely small values for @xmath141 , the non linear corrections may have a non negligible contribution in the intervals chosen for the fits . for example , a simple linear fit gives @xmath144 and @xmath145 which does not coincide with the result in eq.([e12cpbte ] ) . however , based on the discussion about the slower convergence of the neumann corrections presented in ref.@xcite , we have allowed the possibility of non linear corrections proportional to @xmath146 in our fits . remarkably , when this non linear corrections are taken into account , the coefficient of the linear correction gets closer to the analytic prediction in eq.([e12cpbte ] ) , that we reproduce with an error less than @xmath147 . note that , as can be seen in fig.[cptm ] , this is not the case for tm modes , since the best fit of the numerical data contains a quadratic term without a logarithm . in fig.13 we show a fit of the numerical data for tm modes that includes a cubic correction @xmath148 . with this additional term , the fit reproduces the numerical data up to @xmath149 .    to summarize , the fits of the numerical data clearly confirm the analytic prediction for the tm modes , and suggest that the next non trivial correction for the te modes is not quadratic but proportional to @xmath146 . we have numerically evaluated the casimir interaction energy for the two eccentric cylinders configuration and for the cylinder plane geometry , extending in several directions the numerical results presented in ref.@xcite . for quasi concentric cylinders , we have shown that the approximation based on tridiagonal matrices derived in @xcite is in good agreement with the numerical values . we also extended this approximation to the case of pentadiagonal matrices . our results show that , for small eccentricities , it is far more efficient to consider the contribution of the matrix elements near the diagonal , than a `` tour de force '' numerical calculation based on the exact formula .    for concentric cylinders , we have obtained analytically the quadratic corrections to the pfa . as far as we know , this is the first explicit non linear correction to pfa existing in the literature . we have also shown that the pfa can be used as a useful tool in order to improve the numerical evaluation at very small distances , and we have used this improvement in order to check numerically the non linear correction to pfa . finally , we have analyzed in detail some numerical results for the cylinder - plane geometry . on the one hand , we have shown that the casimir energy for this configuration can be obtained from that of the two eccentric cylinders . although this coincidence has been anticipated for the matrix elements in ref.@xcite , the numerical data show that the result is also valid for the energy . on the other hand , we have computed the te and tm contributions to the energy for small distances , and compared the fits of the numerical results with existing analytic predictions for the linear corrections to the pfa . 100 h.b.g . casimir , proc . b 51 , 793 ( 1948 ) . g. plunien , b. muller , and w. greiner , phys . rep . * 134 * , 87 ( 1986 ) ; p. milonni , _ the quantum vacuum _ ( academic press , san diego , 1994 ) ; v. m. mostepanenko and n. n. trunov , _ the casimir effect and its applications _ ( clarendon , london , 1997 ) ; m. bordag , _ the casimir effect 50 years later _ ( world scientic , singapore , 1999 ) ; m. bordag , u. mohideen , and v.m . mostepanenko , phys . rep . * 353 * , 1 ( 2001 ) ; k. a. milton , _ the casimir effect : physical manifestations of the zero - point energy _ ( world scientic , singapore , 2001 ) ; s. reynaud et al . , c. r. acad . paris iv-2 , 1287 ( 2001 ) ; k. a. milton , j. phys . a : math . 37 , r209 ( 2004 ) ; s.k . lamoreaux , rep . phys . * 68 * , 201 ( 2005 ) . g. bressi , g. carugno , r. onofrio , and g. ruoso , phys . rev . lett . * 88 * , 041804 ( 2002 ) . lamoreaux , phys . lett . * 78 * , 5 ( 1997 ) ; u. mohideen and a. roy , phys . lett . * 81 * , 4549 ( 1998 ) ; b.w . harris , f. chen , and u. mohideen , phys . rev . a * 62 * , 052109 ( 2000 ) ; t. ederth , phys . rev . a * 62 * , 062104 ( 2000 ) ; h.b . chan , v.a . aksyuk , r.n . kleiman , d.j.bishop , and f. capasso , science 291 , 1941 ( 2001 ) ; h. b. chan , v.a . aksyuk , r.n . kleiman , d.j . bishop , and f. capasso , phys . 87 * , 211801 ( 2001 ) ; g. bressi , g. carugno , r. onofrio , and g. ruoso , phys . rev . lett . * 88 * , 041804 ( 2002 ) ; d. iannuzzi , i. gelfand , m.lisanti , and f. capasso , proc . usa 101 , 4019 ( 2004 ) ; r.s . decca , d. lopez , e. fischbach , and d.e . krause , phys . lett . * 91 * , 050402 ( 2003 ) ; r.s . decca et al . , phys . lett . * 94 * , 240401 ( 2005 ) ; r.s . decca et al . , annals of physics * 318 * , 37 ( 2005 ) . t. emig , j. stat . mech . , p04007 ( 2008 ) ; p. a. maia neto , a. lambrecht , s. reynaud , phys . a * 78 * , 012115 ( 2008 ) . the case of a scalar field with dirichlet boundary conditions has been discussed in h. gies and k. klingmuller , phys . * 96 * , 220401 ( 2006 ) ; a. bulgac , p. magierski , and a. wirzba , phys . d * 73 * , 025007 ( 2006 ) . dalvit , f.c . lombardo , f.d . mazzitelli , and r. onofrio , europhys . 68 , 517 ( 2004 ) . mazzitelli , in _ quantum field theory under the influence of external conditions _ , k.a.milton ( editor ) , rinton press , princeton ( 2004 ) . f.d.mazzitelli , d.a.r . dalvit and f.c.lombardo , new journal of physics * 8 * , 240 ( 2006 ) . dalvit , f.c . lombardo , f.d . mazzitelli , and r. onofrio , phys . a * 74 * , 020101 ( 2006 ) . m. brown - hayes , d.a.r . dalvit , f.d . mazzitelli , w.j . kim , and r. onofrio , phys . a * 72 * , 052102 ( 2005 ) . m.bordag , phys . d * 73 * , 025007 ( 2006 ) . we are using different programs to simulate the different situations such as the eccentric cylinders , quasi concentric to first order and quasi concentric to second order . as we have to assure convergence in each of them , that is why we have used bigger matrix than before . f. d. mazzitelli , m. j. snchez , n. n. scoccola and j. von stecher , phys . a * 67 * , 013807 ( 2003 ) . blagov , g.l . klimchitskaya , and v.m . mostepanenko , phys . b * 71 * , 235401 ( 2005 ) . lombardo , f.d . mazzitelli , and p.i . villar , j. phys . a * 41 * , 164009 ( 2008 ) . t. emig , r.j.jaffe , m.kardar and a.scardicchio , phys . * 96 * , 080403 ( 2006 ) . see also s. j. rahi , a. w. rodriguez , t. emig , r.l . jaffe , s.g . johnson and m. kardar , phys . a * 77 * , 030101(r ) ( 2008 ) ; s.j . rahi , t. emig , r.l . jaffe , and m. kardar , phys . a * 78 * , 012104 ( 2008 ) . h. gies and k. klingmller , phys . d * 74 * , 045002 ( 2006 ) .", "tags": [], "output_text_a": "This paper revisits the Casimir effect, a quantum phenomenon first explained by Casimir 60 years ago as a manifestation of the zero-point energy of the quantum electromagnetic field. Initially a theoretical curiosity, the Casimir effect has gained practical significance in recent years, particularly in the context of micromachined devices. Advances in experimental techniques have allowed for more precise measurements of the Casimir force, while theoretical studies have explored its dependence on the geometry of conducting surfaces.\n\nThe paper focuses on the Casimir interaction energy between two eccentric cylindrical shells, a configuration of both experimental and theoretical interest. The authors provide a precise numerical evaluation of the analytical results for this configuration, testing various approximations such as the Proximity Force Approximation (PFA) and exploring the energy behavior in different geometric limits, including the cylinder-plane configuration.\n\nThe study involves complex numerical calculations using a Fortran program to evaluate the Casimir interaction energy for different configurations, including eccentric, quasi-concentric, and concentric cylinders. The authors also derive new analytic results for the vacuum energy in the concentric cylinders configuration, providing corrections to the PFA up to the second order.\n\nThe paper concludes with a detailed numerical evaluation of the Casimir energy for the cylinder-plane configuration, confirming the theoretical predictions for the first-order corrections to the PFA. The results have implications for understanding thermal corrections to the Casimir force and could inform future experimental setups and theoretical models in quantum field theory and nanotechnology. \n\nOverall, the paper extends the understanding of the Casimir effect in various geometric configurations, offering both numerical and analytical insights that could aid in the design of experiments and the development of theoretical models.", "output_text_b": "The article discusses the Casimir effect, which is a phenomenon that arises from the quantum fluctuations of the electromagnetic field. The Casimir effect can be observed as a force between two uncharged, conducting plates in a vacuum. The force arises due to the difference in the number of electromagnetic modes that exist between the plates and in the surrounding vacuum.\n\nThe article begins by discussing the history of the Casimir effect, which was first proposed by Hendrik Casimir in 1948. The effect was initially considered to be a theoretical curiosity, but it has since been shown to have important implications for the behavior of micro- and nanoscopic systems.\n\nThe article then goes on to discuss recent developments in the study of the Casimir effect. One area of particular interest has been the dependence of the Casimir force on the geometry of the conducting surfaces. Most experiments to measure the Casimir force have been performed using parallel plates or a sphere in front of a plane. However, the article discusses the potential of using other geometries, such as two eccentric cylinders, to study the Casimir effect.\n\nThe article then goes on to describe the theoretical evaluation of the Casimir force for the configuration of two eccentric cylinders. This has been solved recently using a mode summation technique combined with the argument theorem. This has led to an exact formula for the Casimir force between two eccentric cylinders, which is written in terms of the determinant of an infinite matrix.\n\nThe article also discusses the potential of using the configuration of two eccentric cylinders to measure the derivative of the Casimir force using null experiments. This could be achieved by considering experimental configurations in which a metallic wire is placed inside a larger hollow cylinder.\n\nThe article then goes on to describe the numerical evaluation of the Casimir force for the configuration of two eccentric cylinders. This is important for testing different approximations, such as the proximity force approximation (PFA) for close surfaces, and the \"around the diagonal\" approximation for quasi-concentric cylinders.\n\nThe article also discusses the potential of using the configuration of two eccentric cylinders to study the longstanding controversy about thermal corrections to the Casimir force. This is because the cylinder-plane configuration is intermediate between the sphere-plane and the plane-plane geometries, and it can shed some light on this issue.\n\nIn conclusion, the article provides a detailed overview of the Casimir effect and its potential applications. It discusses recent developments in the study of the Casimir effect, including the theoretical and numerical evaluation of the Casimir force for the configuration of two eccentric cylinders. The article highlights the potential of using this geometry to study the Casimir effect and its implications for micro- and nanoscopic systems.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, discussing the Casimir effect, the focus on eccentric cylindrical shells, and the numerical and analytical evaluations performed.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of evaluating the Casimir interaction energy in different configurations.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of numerical calculations and a Fortran program for evaluating the Casimir interaction energy.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the numerical evaluation of the Casimir energy and the implications for understanding thermal corrections.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like the Proximity Force Approximation (PFA).\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically, with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of numerical calculations and the evaluation of different configurations.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in understanding the Casimir effect and its implications for quantum field theory and nanotechnology.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the theoretical and numerical evaluation of the Casimir force for two eccentric cylinders and its potential applications.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise but slightly exceeds 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the study of the Casimir effect and its dependence on geometry as the research problem.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary describes the use of mode summation technique and numerical evaluations.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the exact formula for the Casimir force and its implications.\n6. \"The summary must be written in clear and professional language.\" - The language is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms but explains them adequately.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is logically structured.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the potential of using experimental configurations with eccentric cylinders.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the significance of the research in understanding the Casimir effect and its applications."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the coherent distortions of background galaxy images by the intervening metric perturbations provide us a direct probe of the large scale mass distribution ( see reviews by @xcite ) . recently , several groups have claimed positive detections of the weak lensing effect and obtained useful constraints on the cosmological model ( @xcite ) . in future weak lensing observations ( vst - kids , des , vista darkcam , pan - starrs , lsst , dune , snap , jdem ) , if the photometric redshift can be well calibrated , we will be able to study the dark energy properties ( its abundance and equation of state ) using the redshift dependence of the shear fields ( @xcite ) . by constraining the growth factor of the mass perturbation and the geometrical distance as functions of redshift separately , weak lensing provides a consistency check of the cosmological model ( @xcite ) , and opens a window for testing alternative gravity theories ( @xcite ) . an important and challenging job in weak lensing is to measure the weak cosmic shear ( of order a few percent ) from the shapes ( or ellipticities ) of the background galaxy images , which have large intrinsic variations . the existing methods are all based on convoluting the galaxy images with some weighting functions , and are called the integral methods hereafter ( see @xcite ) . the integral methods typically have disadvantages in three aspects : * 1 . * since the galaxy images are smeared by the psf ( either instrumental or environmental ) , the integral methods involve at least two folds of convolutions , the math of which is complicated ; * 2 . * the details of the methods are often sensitive to the galaxy morphology and the form of the psf ; * 3 . * the shear information from the shape distortions of galaxy substructures is not considered . strictly speaking , the shapelets method ( see , , refregier 2003 ) may not be called an integral method , because the galaxy weighting functions form a complete set of orthonormal shapelets which have very convenient mathematical properties . it also has the potential of measuring the cosmic shears on galaxy substructures . however , since this method requires calibrations of the intrinsic distributions of the shapelet coefficients , it has strong dependence on the galaxy morphology .    in this paper , we propose to use the spatial derivatives of the galaxy surface brightness field to measure the cosmic shear . this method was first used by seljak and zaldarriaga ( 1999 ) on cmb lensing . we generalize their analysis by including the psf and carrying out the measurement in fourier space . this approach is well defined regardless of the galaxy morphology and the form of the psf , and involves simple image processing procedures . given a high image resolution , the method can potentially probe the cosmic shear from galaxy substructures , greatly suppressing the shape noise . we begin by introducing the method in  [ method ] . in [ test ] , this approach is shown to work well on different types of computer - generated mock galaxy images with general forms of psf . a brief summary is given in [ summary ] . we derive the relation between the cosmic shear and the spatial derivatives of the galaxy surface brightness field without a psf in  [ withoutpsf ] . in the presence of an isotropic gaussian psf , the relation is modified and shown in  [ withisopsf ] . in  [ fourier ] , fourier transformation is introduced not only to simplify the measurement of the spatial derivatives , but also to deal with general forms of psf .      the surface brightness on the image plane @xmath0 and on the source plane @xmath1 ( @xmath2 and @xmath3 are the position angles on the image and source plane respectively ) are related through a simple relation : @xmath4 where @xmath5 , and @xmath6 are the spatial derivatives of the lensing deflection angle , which can be expressed in terms of the convergence @xmath7 and the two shear components @xmath8 and @xmath9 . using eq.[[fifstits ] ] , we get : @xmath10 where we have implicitly assumed that @xmath11 is small , which is true for weak lensing . assuming the original surface brightness field @xmath12 is isotropic on the source plane , the quadratic combinations of the derivatives of the lensed image provide a direct measure of the shear components ( @xcite ) : @xmath13 where the averages are taken over the whole galaxy . the presence of psf brings both advantages and disadvantages . on the positive side , the psf smooths out the galaxy surface brightness field , which is originally not differentiable due to structures on arbitrarily small scales . on the other hand , the convolution of the galaxy image with the psf leads to a nontrivial modification to eq.[[shear12 ] ] , the form of which is calculated in this section . for simplicity , we assume the psf is isotropic and gaussian . general forms of psf will be discussed in [ fourier ] . the observed galaxy surface brightness distribution @xmath14 is related to @xmath15 via : @xmath16 where @xmath17 is the gaussian psf with scale length @xmath18 : @xmath19 using eq.[[fifstits ] ] to replace @xmath15 with @xmath12 and @xmath2 with @xmath3 in eq.[[fofi ] ] , we get : @xmath20 or equivalently : @xmath21f_s(\\vts)\\\\ \\nonumber & \\doteq&\\vert{\\rm det}(\\mathbf{a})\\vert\\int d^2\\vts f_s(\\vts)w_{\\beta}(\\vt-\\vts)\\\\ \\nonumber & \\times&\\left[1-(\\vt-\\vts)\\cdot(\\mathbf{a}-\\mathbf{i})\\cdot(\\vt-\\vts)/\\beta^2\\right]\\end{aligned}\\ ] ] where @xmath22 is the @xmath23 unitary matrix . note that the second part of eq.[[fofs2 ] ] is a result of taylor expansion of the term @xmath24 $ ] due to the small amplitudes of the lensing components @xmath11 . for convenience , let us define : @xmath25 which is the surface brightness field we would observe in absence of lensing . eq.[[fofs2 ] ] can then be re - written as : @xmath26 let @xmath27 , then : @xmath28 using eq.[[fofs3 ] ] and eq.[[fvto ] ] , it is not hard to express the derivatives of @xmath14 in terms of the derivatives of @xmath29 : @xmath30 where @xmath31 note that we have implicitly assumed that the spatial fluctuation of the cosmic shear is negligible on galactic scales . assuming the distribution of @xmath29 is isotropic , we obtain the following relation between the shear components and the spatial derivatives of the surface brightness field : @xmath32 where @xmath33    the derivation of eq.[[shear12psf ] ] and eq.[[delta ] ] is shown in the appendix . note that in the limit when the galaxy image is very smooth over the scale length @xmath18 , the correction @xmath34 approaches zero , eq.[[shear12psf ] ] then reduces to eq.[[shear12 ] ] .      for the method to become useful , there are at least two remaining issues to be addressed : * 1 . * how to measure the spatial derivatives of the surface brightness field ; * 2 . * how to deal with other forms of the psf . it turns out that fourier transformation provides a solution to both problems . since convolutions in real space correspond to multiplications in fourier space , one can easily transform the psf to a desired form ( an isotropic gaussian form in our case ) by multiplying the fourier modes of the observed image with the ratios between the fourier modes of the desired psf and those of the original psf ( known from calibrations with stars ) . this operation is usually well defined if the scale length of the desired psf is larger than that of the original psf . moreover , it turns out that for the purpose of measuring the cosmic shear , one does not need to transform the new image back to real space , because the derivatives of the surface brightness field can be more easily measured in fourier space .    as an example , we show how to measure quantities such as @xmath35 , where @xmath36 is the surface brightness field of interest . first of all , the distribution @xmath36 in real space should be sampled with an interval @xmath37 which is a few times less than the size of the psf to avoid translating high frequency power into the frequency range determined by the sampling resolution through discrete fourier transform ( @xcite ) . in other words , the galaxy image should be `` oversampled '' to avoid aliasing power from small scales in the discrete fourier transform . for undersampled images , one can smooth the images with an additional large enough psf , which can be treated as a part of the psf from the instrumentation , and therefore does not affect our discussion below . similarly , to avoid such aliasing power at low frequency , the box size for the fourier transform should be a few times larger than the image size . given this setup , the fourier transform of the image is defined as : @xmath38\\ ] ] where @xmath39 n is the box size , chosen to be a power of @xmath40 for the fast fourier transform . it is now straightforward to show that @xmath35 can be expressed as the sum over the fourier modes weighted by the wave numbers : @xmath41 eq.[[fourierfinverse ] ] gives exactly the quantity @xmath35 multiplied by the number of bright pixels covered by the galaxy , because the dark pixels have no contributions . similarly , we can calculate the other terms in eq.[[shear12psf ] ] in fourier space . note that for the purpose of obtaining @xmath42 and @xmath43 , it is not necessary to calculate the number of bright pixels because it appears in both the nominator and the denominator in eq.[[shear12psf ] ] . this section is organized as follows : in  [ diskgalaxy ] , we test the method using mock regular galaxies smeared by different forms of psf ; in  [ irregulargalaxy ] , using mock irregular galaxies generated by 2-d random walks , we further demonstrate the usefulness of this approach on galaxies with a different morphology , and explore the possibility of suppressing the shape noise in the shear measurements by including the information from galaxy substructures . each regular galaxy in our simulation contains a thin circular disk with an exponential profile and a co - axial de vaucouleurs - type spheroidal component ( @xcite ) . when viewed face - on , the surface brightness distribution ( before lensing and smearing by the psf ) of the galaxy can be parameterized as : @xmath44\\ ] ] where @xmath45 is the distance to the galaxy center , @xmath46(@xmath47 ) is the scale length of the disk(spheroid ) , and @xmath48 determines the relative importance of the spheroid . the overall luminosity of the galaxy is only important in the presence of noise , which will be discussed in a future paper . our simulation box is @xmath49 . we choose @xmath46 to be @xmath50 of the box size of the simulation , @xmath51 , and @xmath52 . note that changing these particular numbers does not affect our main conclusions . once the galaxy s face - on image is generated , it is projected onto the source plane with a random inclination angle along a random direction perpendicular to the line of sight of the spheroid part is set to one for simplicity . ] . the projected galaxy image is subsequently distorted by a constant cosmic shear and smeared by the psf in real space . we consider two psf models given by the following forms rotated by certain angles ( shown in fig.[psfs ] ) : @xmath53\\\\ \\nonumber & & w_r^{(2)}(x , y)\\propto\\exp\\left[-(x^2 + 0.8y^2)/(2r^2)\\right]\\\\ \\nonumber\\end{aligned}\\ ] ] where @xmath45 is the scale length , which is equal to six times the grid size , comparable to the galaxy size . the shear components @xmath54 are chosen to be @xmath55 , @xmath56 , @xmath57 for @xmath58 , and @xmath59 , @xmath60 , @xmath61 for @xmath62 .    to measure the cosmic shear , we follow the procedures described in  [ fourier ] . the desired psf has an isotropic gaussian form with a scale length about @xmath63 times that of the original psf . the results are plotted in fig.[shear_disk ] . the results are consistent within @xmath64 error regardless of the form of the psf . our irregular galaxies are generated using 2-d random walks . the random walk starts from the center of the simulation box for 20000 steps , each of which is equal to the grid size of the simulation box ( which is now @xmath65 ) . once the distance from the center is more than @xmath66 of the box size , the walk starts from the center again to finish the rest of the steps . the surface brightness of the galaxy is equal to the density of the trajectories . note that these galaxies naturally have abundant substructures , which are useful not only for further testing the method , but also for illustrating how much lensing information may be contained in the substructures . we caution that our random - walk - type galaxies are not based on any physical models , therefore they do not necessarily mimic observed irregular galaxies . in a future paper , more realistic galaxy models will be adopted to study this topic .    for the purpose of this section , we smooth the galaxies directly with the isotropic gaussian psf of different scale lengths , which correspond to different angular resolutions . the scale length @xmath18 ( defined in eq.[[wbeta ] ] ) is chosen to be @xmath67 , @xmath68 , @xmath69 , and @xmath50 of the box size ( roughly corresponding to @xmath70 , @xmath71 , @xmath72 , and @xmath73 of the galaxy size ) . fig.[rwgalaxy ] shows typical images of our irregular galaxy under these four different angular resolutions . for convenience , we plot the minimum @xmath18 as unity in the figures of this section . the shear component @xmath43 is set to zero , and @xmath42 is fixed at @xmath74 . after averaging over @xmath75 irregular galaxies , we find that the measured @xmath42 is @xmath76 for @xmath77 , @xmath78 for @xmath79 , @xmath80 for @xmath81 , and @xmath82 for @xmath83 . more interestingly , as shown in fig.[results ] , the statistical error bar is found to decrease significantly when the angular resolution is increased . this is further illustrated in fig.[sigma ] , which shows an approximate power - law relation between the measured variance of @xmath42 and @xmath18 , the exponent of which is close to one . note that as the angular resolution increases , one gets additional information on the cosmic shears from the galaxy substructures . if we naively assume that each bright pixel on the galaxy map provides an independent measurement of the cosmic shear , we expect the variance of the measured cosmic shear to scale as the inverse of the number of the bright pixels , or @xmath84 , where @xmath85 is the hausdorff dimension of the galaxy image ( @xcite ) . since the hausdorff dimension of our random - walk - generated irregular galaxies is @xmath40 ( @xcite ) , the variance of @xmath42 should scale as @xmath86 , which is not too far from what we have observed in our numerical experiments . in reality , substructures generated by the 2-d random walks are correlated at some unknown level , therefore , the observed exponent indicated in fig.[sigma ] is less than the hausdorff dimension . we have presented a simple approach of measuring the weak cosmic shear using the spatial derivatives of the galaxy surface brightness field . the measurement should be carried out in fourier space , in which it is easy to evaluate the spatial derivatives and to transform the psf to a desired form . the accuracy of the method is demonstrated using computer - generated mock regular and irregular galaxies . we find no systematic errors on the measured shear components in the numerical experiments .    given high image resolutions , this new method may reduce the shape noise in the shear measurement significantly , because it takes into account the shape information on the galaxy substructures . using the mock irregular galaxies generated by 2-d random walks , we have shown that the variance of the measured shear is indeed suppressed by a large factor when the image resolution is increased . this example encourages us to test this method on real galaxies of a wide range of morphology classes in a future paper by joining the shear testing programme ( @xcite ) , the results of which may be useful for optimizing the signal to noise ratio in shear measurements and planning future weak lensing survey . we thank chung - pei ma , tony tyson , martin white , david wittman for useful discussions , gary bernstein , lam hui , bhuvnesh jain , nick kaiser , and the anonymous referee for comments on an earlier version of this manuscript . research for this work is supported by nasa , and by the tac fellowship of uc berkeley . abazajian k. & dodelson s. , 2003 , prl , 91 , 041301    acquaviva v. , baccigalupi c. & perrotta f. , 2004 , prd , 70 , 023515    bacon d. , massey r. , refregier a. , ellis r. , 2003 , mnras , 344 , 673    bacon d. , refregier a. & ellis r. , 2000 , mnras , 318 , 625    bartelmann m. & schneider p. , 2001 , physics reports , 340 , 291    bernstein g. & jain b. , 2004 , apj , 600 , 17    bernstein g. & jarvis m. , 2002 , aj , 123 , 583    bonnet h. & mellier y. , 1995 , a&a , 303 , 331    bridle s. , gull s. , bardeau s. , kneib j. , 2001 , in scientific n.  w. , ed . , proceedings of the yale cosmology workshop    brown m. , taylor a. , bacon d. , gray m. , dye s. , meisenheimer k. , wolf c. , 2003 , mnras , 341 , 100    dahle h. , 2006 , astro - ph/0608480    falconer k. , 1986 , _ the geometry of fractal sets _ , cambridge univ . press    hamana t. , miyazaki s. , shimasaku k. , furusawa h. , doi m. , hamabe m. , imi k. , kimura m. , komiyama y. , nakata f. , okada n. , okamura s. , ouchi m. , sekiguchi m. , yagi m. , yasuda n. , 2003 , apj , 597 , 98    hannestad s. , tu h. & wong y. , 2006 , jcap , 0606 , 025    hausdorff f. , 1919 , math . ann . , 79 , 157    hetterscheidt m. , simon p. , schirmer m. , hildebrandt h. , schrabback t. , erben t. , schneider p. , 2006 , astro - ph/0606571    heymans c. , brown m. , barden m. , caldwell j. , jahnke k. , rix h. , taylor a. , beckwith s. , bell e. , borch a. , huler b. , jogee s. , mcintosh d. , meisenheimer k. , peng c. , sanchez s. , somerville r. , wisotzki l. , wolf c. , 2005 , mnras , 361 , 160    heymans c. , van waerbeke l. , bacon d. , berge j. , bernstein g. , bertin e. , bridle s. , brown m. , clowe d. , dahle h. , erben t. , gray m. , hetterscheidt m. , hoekstra h. , hudelot p. , jarvis m. , kuijken k. , margoniner v. , massey r. , mellier y. , nakajima r. , refregier a. , rhodes j. , schrabback t. , wittman d. , 2006 , mnras , 368 , 1323    hoekstra h. , franx m. , kuijken k. , squires g. , 1998 , apj , 504 , 636    hoekstra h. , mellier y. , van waerbeke l. , semboloni e. , fu l. , hudson m. , parker l. , tereno i. , benabed k. , 2006 , apj , 647 , 116h    hoekstra h. , yee h. & gladders m. , 2002 , apj , 577 , 595    hu w. , 2002 , prd , 66 , 083515    hu w. & jain b. , 2004 , prd , 70 , 043009    ishak m. , 2005 , mnras , 363 , 469    ishak m. , upadhye a. & spergel d. , 2006 , prd , 74 , 043513    jain b. & taylor a. , 2003 , prl , 91 , 141302    jarvis m. , bernstein g. , jain b. , fischer p. , smith d. , tyson j. , wittman d. , 2003 , apj , 125 , 1014    jarvis m. , jain b. , bernstein g. , dolney d. , 2006 , apj , 644 , 71    kaiser n. , 2000 , apj , 537 , 555    kaiser n. , squires g. & broadhurst t. , 1995 , apj , 449 , 460    kaiser n. , wilson g. & luppino g. , astro - ph/0003338    knox l. , song y. & tyson j. , 2006 , prd , 74 , 023512    kratochvil j. , linde a. , linder e. , shmakova m. , 2004 , jcap , 0407 , 001    kuijken k. , 2006 , a&a , 456 , 827k    luppino g. & kaiser n. , 1997 , apj , 475 , 20    maoli r. , van waerbeke l. , mellier y. , schneider p. , jain b. , bernardeau f. , erben t. , 2001 , a&a , 368 , 766    massey r. , bacon d. , refregier a. , ellis r. , 2005 , mnras , 359 , 1277    massey r. , heymans c. , berge j. , bernstein g. , bridle s. , clowe d. , dahle h. , ellis r. , erben t. , hetterscheidt m. , high f. , hirata c. , hoekstra h. , hudelot p. , jarvis m. , johnston d. , kuijken k. , margoniner v. , mandelbaum r. , mellier y. , nakajima r. , paulin - henriksson s. , peeples m. , roat c. , refregier a. , rhodes j. , schrabback t. , schirmer m. , seljak u. , semboloni e. , van waerbeke l. , 2006 , astro - ph/0608643    massey r. & refregier a. , 2005 , mnras , 363 , 197    nakajima r. & bernstein g. , 2006 , astro - ph/0607062    press w. , flannery b. , teukolsky s. , vetterling w. , 1992 , _ numerical recipes _ , cambridge univ . press , 2nd ed . refregier a. , 2003 , ara&a , 41 , 645    refregier a. & bacon d. , 2003 , mnras , 338 , 48    refregier a. , rhodes j. & groth e. , 2002 , apjl , 572 , l131    rhodes j. , refregier a. , collins n. , gardner j. , groth e. , hill r. , 2004 , apj , 605 , 29    rhodes j. , refregier a. & groth e. , 2000 , apj , 536 , 79    rhodes j. , refregier a. & groth e. , 2001 , apjl , 552 , l85    schimd c. , tereno i. , uzan j. , mellier y. , van waerbeke l. , semboloni e. , hoekstra h. , fu l. , raizuelo a. , 2006 , astro - ph/0603158    schrabback t. , erben t. , simon p. , miralles j. , schneider p. , heymans c. , eifler t. , fosbury r. , freudling w. , hetterscheidt m. , hildebrandt h. , pirzkal n. , 2006 , astro - ph/0606611    seljak u. & zaldarriaga m. , 1999 , prl , 82 , 2636    semboloni e. , mellier y. , van waerbeke l. , hoekstra h. , tereno i. , benabed k. , gwyn s. , fu l. , hudson m. , maoli r. , parker l. , 2006 , a&a 452 , 51    simpson f. & bridle s. , 2005 , prd , 71 , 083501    song y. & knox l. , 2004 , prd , 70 , 063510    song y. , 2005 , prd , 71 , 024026    takada m. & jain b. , 2004 , mnras , 348 , 897    takada m. & white m. , 2004 , apj , 601 , l1    taylor a. , kitching t. , bacon d. , heavens a. , 2006 , astro - ph/0606416    tyson j. , wenk r. & valdes f. , 1990 , apjl , 349 , l1    de vaucouleurs g. , de vaucouleurs a. , corwin h. , buta r. , paturel g. , fouqu p. , 1991 , _ third reference catalogue of bright galaxies _ , springer , new york    van waerbeke l. , mellier y. , erben t. , cuillandre j. , bernardeau f. , maoli r. , bertin e. , mc cracken h. , le fvre o. , fort b. , dantel - fort m. , jain b. , schneider p. , 2000 , a&a , 358 , 30    van waerbeke l. , mellier y. & hoekstra h. , 2005 , a&a , 429 , 75    van waerbeke l. , mellier y. , radovich m. , bertin e. , dantel - fort m. , mccracken h. , fvre o. , foucaud s. , cuillandre j. , erben t. , jain b. , schneider p. , bernardeau f. , fort b. , 2001 , a&a , 374 , 757    wittman d. , 2002 , _ dark matter and gravitational lensing _ , _ lnp top . courbin f. , minniti d. , springer - verlag . , astro - ph/0208063    wittman d. , tyson j. , kirkman d. , dellantonio i. , bernstein g. , 2000 , nature , 405 , 143    zhan h. , 2006 , jcap , 0608 , 008    zhang j. , hui l. & stebbins a. , 2005 , apj , 635 , 806 from eq.[[dfodfs ] ] , we have : @xmath87\\\\ \\nonumber & = & ( 1 - 6\\kappa)(f_x^2-f_y^2)-2\\gamma_1(f_x^2+f_y^2)\\\\ \\nonumber & -&\\beta^2\\left[2\\kappa\\pi_1+\\gamma_1(\\lambda+\\upsilon_1)+\\gamma_2(\\upsilon_2-\\tilde{\\lambda})\\right]\\end{aligned}\\ ] ] and @xmath88\\end{aligned}\\ ] ] where @xmath89    note that according to the definitions in eq.[[appendix3 ] ] , @xmath90 is a scalar , @xmath91 is a pseudo scalar , @xmath92 is a spin-2 field , and @xmath93 is a spin-4 field . if the intrinsic surface brightness distribution is isotropic , the spatial averages of @xmath91 , @xmath94 , @xmath95 , @xmath96 , and @xmath97 must vanish . as a result of this , we have : @xmath98 we have neglected the factor @xmath99 which is equal to unity to the 0th order . using the fact that @xmath100 , and @xmath101 to the 0th order , it is now straightforward to prove eq.[[shear12psf ] ] .", "tags": [], "output_text_a": "This paper discusses a novel method for measuring weak cosmic shear using the spatial derivatives of galaxy surface brightness fields. Weak lensing, which involves the distortion of background galaxy images by intervening mass distributions, provides insights into the large-scale structure of the universe and the properties of dark energy. Traditional methods for measuring cosmic shear rely on convoluting galaxy images with weighting functions, which can be complex and sensitive to galaxy morphology and point spread function (PSF) forms. The proposed method, inspired by techniques used in cosmic microwave background (CMB) lensing, involves analyzing the spatial derivatives of galaxy images in Fourier space, allowing for a more straightforward and potentially more accurate measurement of cosmic shear. This approach is less dependent on galaxy morphology and PSF form, and it can utilize information from galaxy substructures, potentially reducing shape noise. The method's effectiveness is demonstrated using computer-generated mock galaxy images, showing no systematic errors and a significant reduction in measurement variance with increased image resolution. The paper suggests that this method could improve the signal-to-noise ratio in shear measurements and aid in future weak lensing surveys. Future work will involve testing this method on real galaxies and exploring its application in optimizing weak lensing surveys.", "output_text_b": "Weak lensing, the distortion of background galaxy images by large scale mass distributions, offers a direct probe of the cosmological model and the potential to study dark energy properties. Future observations, such as VST-KIDS, DES, VISTA DarkCam, Pan-STARRS, LSST, DUNE, SNAP, and JDEM, aim to measure weak cosmic shear from galaxy shapes. This paper proposes a new method to measure cosmic shear using spatial derivatives of the galaxy surface brightness field, which is applicable to various galaxy morphologies and point spread functions (PSFs). The method is shown to work well on computer-generated mock galaxy images with different types of PSFs.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary accurately reflects the main findings and contributions, discussing the novel method for measuring weak cosmic shear and its potential advantages over traditional methods.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of measuring weak cosmic shear and the limitations of traditional methods.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the methodology of using spatial derivatives of galaxy surface brightness fields in Fourier space.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the reduction in measurement variance and the potential for improved signal-to-noise ratio.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"cosmic shear\" and \"Fourier space\" but provides context to understand them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of computer-generated mock galaxy images to demonstrate the method's effectiveness.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance by discussing its potential impact on future weak lensing surveys.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by mentioning the new method for measuring cosmic shear and its applicability to various galaxy morphologies and PSFs.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of measuring weak cosmic shear and its importance in studying dark energy properties.\n4. **Methodology**: The summary mentions the methodology of using spatial derivatives of the galaxy surface brightness field.\n5. **Significant Results**: The summary includes significant results, stating that the method works well on computer-generated mock galaxy images.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like weak lensing and cosmic shear.\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not explicitly mention key experiments or data used in the research.\n10. **Significance**: The summary reflects the paper's significance by mentioning its potential impact on future observations and the study of dark energy."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "many vibrating mechanical systems experience undesirable impacts that cause wear or sub - optimal performance . occasional impacts may be permissible if they result from running components of the system at high speeds for greater efficiency , and some impacts are unavoidable such as those due to random or rare events . in these cases it is important to have a clear understanding of the dynamical behaviour that impacts may induce . impacting dynamics is often complicated or chaotic because impacts are highly nonlinear phenomena @xcite . for instance tubes in heat exchangers vibrate at high fluid velocities and impact against baffles in place to guide the fluid flow . simple mathematical models of heat exchangers reveal that chaotic dynamics may be created at the onset of recurring impacts @xcite . rotating cutters spun at high speeds experience repeated contact loss with the material being cut . the resulting impacts between the cutter and the material may similarly induce chaotic dynamics @xcite . in contrast , some mechanical systems use impacts to achieve their function . atomic force microscopes measure surface topography and the chemical properties of a sample on the nanoscale by gently hitting the sample with a vibrating cantilever . in this context it is important to understand the complex impacting dynamics so that the inverse problem of describing the sample can be performed effectively @xcite . impacts can often be modelled accurately by carefully describing the deformations that components of the system undergo during impacts @xcite . however , for the purposes of understanding vibro - impacting dynamics , such a modelling approach is too cumbersome and a low degree - of - freedom ode model can be more useful . despite the low - dimensionality , such models have been shown to quantitatively match the experimental data of a variety of impacting systems . examples include a cam - follower system involving occasional detachments between the cam and the follower @xcite , a pendulum experiencing near - instantaneous impacts with a solid wall @xcite , and compliant impacts of a steel block with an elastic beam @xcite . ( 15,3.8 ) ( 0,0 ) , where @xmath0 is a system parameter . [ fig : grazbifschem ] , title=\"fig:\",height=136 ] ( 5.1,0 ) , where @xmath0 is a system parameter . [ fig : grazbifschem ] , title=\"fig:\",height=136 ] ( 10.2,0 ) , where @xmath0 is a system parameter . [ fig : grazbifschem ] , title=\"fig:\",height=136 ] ( .5,3.6)*a * ( 5.6,3.6)*b * ( 10.7,3.6)*c * ( 2,3.6)@xmath1 ( 7.1,3.6)@xmath2 ( 12.2,3.6)@xmath3 ( 4.48,.2)@xmath4 ( 9.58,.2)@xmath4 ( 14.68,.2)@xmath4    using a low degree - of - freedom ode model , the evolution of the system between impacts is tracked in phase space . periodic behaviour without impacts corresponds to a periodic orbit in phase space that does not reach the switching manifold , @xmath4 , fig . [ fig : grazbifschem]-a . physically , @xmath4 corresponds to locations or instances where mechanical components come into contact , or lose contact . as parameters vary , the system may transition from an impact - free regime to the repeated ( though not necessarily regular ) occurrence of impacts . in phase space , the transition occurs when the periodic orbit of the ode model attains an intersection with @xmath4 , fig . [ fig : grazbifschem]-b . this is known as a _ grazing bifurcation_.    in this paper we study grazing bifurcations of the three - dimensional piecewise - smooth ode system , @xmath5 where @xmath6 and @xmath7 are smooth functions , @xmath0 is a parameter , and the coordinates @xmath8 are chosen so that @xmath4 is simply the coordinate plane @xmath9 . we assume that for @xmath1 , there exists an attracting periodic orbit describing non - impacting dynamics located entirely in the region @xmath10 , and that the periodic orbit grazes @xmath4 at the origin when @xmath2 . in the context of vibro - impacting systems , @xmath10 corresponds to not - in - contact dynamics governed by @xmath6 , and @xmath11 corresponds to in - contact dynamics governed by @xmath7 . impacts may instead be modelled as instantaneous events with energy loss and velocity reversal , in which case a map is usually defined on the switching manifold to describe the action of an impact @xcite . theoretical studies of piecewise - smooth and hybrid dynamical systems have led to a useful classification of grazing bifurcations @xcite . this paper concerns regular grazing bifurcations . the grazing bifurcation of ( [ eq : f ] ) at @xmath2 is said to be _ regular _ if @xmath12 for all @xmath13 in a neighbourhood of @xmath14 . this condition arises naturally in mechanical systems with compliant impacts , and implies that @xmath4 is neither attracting nor repelling at any point .    as indicated in fig . [ fig : grazbifschem]-c , the steady - state dynamics of ( [ eq : f ] ) for @xmath3 is often complicated . for this reason it is valuable to study the oscillatory dynamics using a return map based on the points on a poincar section . a normal form for such a map for regular grazing in @xmath15 is the nordmark map @xmath16 where @xmath17 with @xmath18 , and @xmath19 , as determined by the sign of certain coefficients , see  [ sec : nordmark ] . the coordinates @xmath20 represent points on a poincar section of ( [ eq : f ] ) , with @xmath21 the bifurcation parameter and the grazing bifurcation occurring at @xmath22 . the nordmark map ( [ eq : n ] ) , applicable also to models with instantaneous impacts @xcite , includes only the leading order terms of the return map , so is valid only for dynamics close to the grazing bifurcation @xcite . each iteration of ( [ eq : n ] ) corresponds to one oscillation of ( [ eq : f ] ) near the grazing periodic orbit . the utility of ( [ eq : n ] ) lies in the fact that the nature of the dynamics can be identified by the location of the corresponding points in the @xmath23-plane . specifically , ( [ eq : n ] ) is formulated so that if @xmath24 then the oscillation lies entirely in @xmath10 , and if @xmath25 then the oscillation enters @xmath11 . the non - impacting , attracting periodic orbit shown in fig . [ fig : grazbifschem]-a corresponds to the fixed point of @xmath26 , @xmath27 with @xmath28 and @xmath29 . more generally , a periodic orbit of ( [ eq : f ] ) appears as a finite set of points in the @xmath23 plane , as in fig . [ fig : detbifdiag ] which shows a typical bifurcation diagram of ( [ eq : n ] ) . this figure shows a period - incrementing cascade , corresponding to several different periodic orbits , and apparently chaotic dynamics , as indicated by a cloud of points . for alternate values of @xmath30 and @xmath31 , the fixed point @xmath32 may bifurcate directly to chaos @xcite . the square - root term in ( [ eq : n ] ) is an artifact of the tangency between the periodic orbit and the switching manifold of ( [ eq : f ] ) at the grazing bifurcation , and is responsible for the distinctive shape of the bifurcation diagram near @xmath22 . for some vibro - impacting systems it is more appropriate for the return map to be piecewise - linear and either continuous @xcite or discontinuous @xcite . such maps predict fundamentally different bifurcation structures to those of ( [ eq : n ] ) . ( 12,6 ) ( 0,0 ) ) with @xmath33 , @xmath34 , and @xmath35 . these parameter values correspond to the vibro - impacting system described in  [ sec : oscillator ] , with @xmath36 . the fixed point of ( [ eq : n ] ) for @xmath29 , given by ( [ eq : xlyl ] ) , corresponds to an attracting , non - impacting periodic orbit of period @xmath37 . the map ( [ eq : n ] ) has attracting @xmath38 and @xmath39-cycles for certain values of @xmath40 as shown , as well as an attracting @xmath41-cycle in the approximate range , @xmath42 . these correspond to periodic orbits of period approximately equal to @xmath43 , for @xmath44 , that experience one impact per period . there also appears to be a chaotic attractor for the approximate range , @xmath45 . [ fig : detbifdiag ] , title=\"fig:\",height=226 ] ( 6.2,0)@xmath46 ( 0,3.8)@xmath47    in order to properly explain complicated vibro - impacting dynamics , the effects of randomness and uncertainties needs to be taken into account . mechanical systems are subject to background vibrations and other sources of noise . experimentally measured parameters involve error , and some physical features are left unmodelled . for instance , one - degree - of - freedom models do not capture high frequency modes that are often excited by impacts @xcite .    to quantitatively describe stochastic impacting dynamics , stochastic averaging methods have proved useful for vibro - impacting systems that experience a wide range of impact velocities @xcite . if only low - velocity impacts are relevant , then it is useful to study ( [ eq : n ] ) . in his phd thesis @xcite , griffin studied ( [ eq : n ] ) in the presence of additive white noise . he found that noise blurs bifurcation diagrams and washes out high - period solutions in the same manner as for smooth maps , such as the logistic map @xcite . recently it was shown that white noise added to ( [ eq : f ] ) translates to additive white noise in ( [ eq : n ] ) , @xcite . such a noise formulation may be sensible for vibro - impacting systems for which a forcing term or external fluctuations represent a significant source of uncertainty . however , impact events themselves constitute a substantial source of randomness . the purpose of this paper is to construct and analyse stochastic versions of ( [ eq : n ] ) for which randomness stems purely from impact events . we consider three different types of impact noise for ( [ eq : f ] ) using an ornstein - uhlenbeck process with stationary density @xmath48 $ ] , where @xmath49 represents the noise amplitude and @xmath50 is the correlation time . we first consider uncertainties in @xmath4 , then uncertainties in @xmath7 , and lastly uncertainties in @xmath7 in the white noise ( zero correlation time ) limit .    here let us indicate the forms of the stochastic maps that we obtain . coloured noise in @xmath4 leads to random perturbations in both the map and the switching condition as @xmath51 where @xmath52 are gaussian random variables , and @xmath53 is a constant . for coloured noise in the impacting dynamics we obtain @xmath54 for a particular nonlinear function @xmath55 . for white noise ( @xmath56 ) in the impacting dynamics the map takes the form @xmath57 where @xmath58 and @xmath59 are random variables , and @xmath60 and @xmath61 are nonlinear functions . notice that @xmath62 is stochastic for @xmath24 , whereas @xmath63 and @xmath64 are not . this is because noise in @xmath4 generates anomalous crossings of @xmath65 . consequently @xmath62 exhibits stochastic dynamics for @xmath29 , while @xmath63 and @xmath64 do not . @xmath63 and @xmath64 involve noise terms proportional to @xmath66 , and for this reason exhibit increasing variability for larger values of @xmath40 .    to obtain a more detailed comparison of @xmath62 , @xmath63 and @xmath64 , we first carefully derive ( [ eq : n ] ) in  [ sec : nordmark ] . in  [ sec : oscillator ] we introduce a prototypical compliant vibro - impacting system to illustrate our results . in  [ sec : randomness ] we add randomness and derive ( [ eq : na2])-([eq : nc2 ] ) . since ( [ eq : na2])-([eq : nc2 ] ) involve fundamentally different noise terms , they exhibit different sensitivities to the noise amplitude @xmath67 . therefore we use different values of @xmath67 in each of the different models , in order to make appropriate comparisons . for each @xmath68 ( @xmath69 ) we write @xmath70 and identify the appropriate value @xmath71 , so that @xmath62 , @xmath63 and @xmath64 display roughly the same dynamics for the vibro - impacting system with the parameters of fig . [ fig : detbifdiag ] and @xmath72 ( chosen for illustration ) and @xmath73 . this enables us to quantitatively compare @xmath62 , @xmath63 and @xmath64 in  [ sec : dynamics ] . conclusions are presented in  [ sec : conc ] . ( 15,7.5 ) ( 0,0 ) ) for the three - dimensional piecewise - smooth system ( [ eq : f ] ) . the solid curve represents an orbit of ( [ eq : f ] ) . the dashed curves show virtual extensions of this orbit into @xmath11 as governed by @xmath6 . [ fig : grazschem3d ] , title=\"fig:\",height=283 ] ( 14.5,3.25)@xmath74 ( 13.65,5.75)@xmath75 ( 9.7,7.1)@xmath76 ( 1.2,5.8)@xmath77 ( 12.1,1.6)@xmath78 ( 11.3,6.2)@xmath4 ( 1.78,4.92)@xmath79 ( 11.94,3.7)@xmath80 ( 10.7,5.84)@xmath81 ( 8.54,1.12)@xmath82 ( 10.7,2.64)@xmath83 ( 3.02,4.48)@xmath84 ( 11.2,3.5)@xmath85    in this section we derive a return map for the generic deterministic system ( [ eq : f ] ) valid near the grazing bifurcation @xmath2 and provide an explicit coordinate change that transforms the map to ( [ eq : n ] ) . such a derivation is given in @xcite . we provide an explicit construction of ( [ eq : n ] ) here in order to provide a basis for deriving the stochastic maps in  [ sec : randomness ] . throughout this section we write @xmath86 for points of ( [ eq : f ] ) in @xmath15 .    as discussed in [ sec : intro ] , we assume that with @xmath2 the system ( [ eq : f ] ) has a periodic orbit that intersects the origin , but is otherwise contained in @xmath10 . this implies that @xmath87 for @xmath6 at the origin with @xmath2 ( i.e.  @xmath88 ) . for simplicity , we assume that we further have @xmath89 for all @xmath90 in a neighbourhood of @xmath14 , which can usually be imposed by an appropriate coordinate change . this assumption is particularly useful in the case that randomness is present in the switching condition , see  [ sub : s1 ] . the key to deriving the nordmark map ( [ eq : n ] ) is selecting a convenient poincar section and constructing a _ discontinuity map _ that accounts for the difference between @xmath6 and @xmath7 , that is , the difference between impacting and non - impacting dynamics . we let @xmath77 represent a generic poincar section of ( [ eq : f ] ) that lies in @xmath10 and intersects the grazing periodic orbit transversally , and let @xmath78 be the coordinate plane @xmath91 , see fig . [ fig : grazschem3d ] .    given @xmath92 , we define @xmath93 as the next intersection of the forward orbit governed by @xmath6 ( i.e.  ignoring the switching condition at @xmath9 ) with @xmath78 . if @xmath11 for the point @xmath80 , then @xmath80 does not represent the true intersection of the orbit of ( [ eq : f ] ) with @xmath77 . nevertheless , we study the return map on @xmath78 ( @xmath94 ) rather than the return map on @xmath77 ( @xmath95 ) , because the two maps are conjugate and the map on @xmath78 has a simpler form than the map on @xmath77 .    to derive the return map on @xmath78 , we must consider three additional points , @xmath81 , @xmath82 , and @xmath83 , see fig . [ fig : grazschem3d ] . the points @xmath81 and @xmath82 correspond to the entry and exit locations of the orbit with the impacting region , @xmath11 . then @xmath80 is obtained by travelling forward from the entry point @xmath81 to @xmath78 using @xmath6 , whilst @xmath83 is obtained by travelling backward from the exit point @xmath82 to @xmath78 using @xmath6 . the discontinuity map is defined as @xmath96 . if @xmath97 for the point @xmath80 , then @xmath98 .    in order to derive an explicit expression for the discontinuity map , we consider the three steps , @xmath99 , @xmath100 , and @xmath101 , individually , and expand @xmath6 and @xmath7 about @xmath2 and the origin by writing @xmath102 where @xmath103 , and @xmath104 . in ( [ eq : alphabetagamma ] ) , and throughout this section , @xmath105 is short - hand big - o notation for @xmath106 . notice that @xmath107 is assumed to be of the same order as @xmath75 , @xmath76 , and @xmath108 , which is appropriate in view of the tangency between the grazing periodic orbit and @xmath4 . we assume @xmath109 such that the tangency is quadratic for both @xmath6 and @xmath7 , and has the orientation depicted in fig . [ fig : grazschem3d ] .    from series expansions of the orbits governed by @xmath6 and @xmath7 , see @xcite , we obtain the following formulas for the three steps in the discontinuity map in the case @xmath110 ( writing @xmath111 ) . for @xmath99 , @xmath112 for @xmath100 , @xmath113 and for @xmath101 , @xmath114 by combining ( [ eq : v2w2])-([eq : u4w4 ] ) we get @xmath115 in terms of @xmath116 , @xmath117 where @xmath118 the discontinuity map is then @xmath119    to complete the map ( [ eq : n ] ) , which represents @xmath94 as shown in fig . [ fig : grazschem3d ] , we must combine @xmath120 with the global return map @xmath121 . @xmath122 depends on global properties of @xmath6 and is smooth , so we can write @xmath123 for some @xmath124 where each @xmath125 . then the desired return map on @xmath78 is the composition @xmath126 . finally we apply a coordinate change to convert the map to the normal form ( [ eq : n ] ) that involves only three parameters , @xmath30 , @xmath31 and @xmath127 . under @xmath128 and with higher order terms omitted , @xmath126 transforms to ( [ eq : n ] ) with @xmath129 since the nordmark map keeps only leading order terms for @xmath90 near @xmath14 , terms that are linear in @xmath47 are omitted since they are dominated by @xmath130 , refer to @xcite for a further discussion . in ( [ eq : coordinatechange ] ) we require @xmath131 and @xmath132 . these represent non - degeneracy conditions for the grazing bifurcation . ( 15,5 ) ( 0,0 ) ) . this system exhibits a _ regular _ grazing bifurcation with a square - root singularity because with @xmath133 and @xmath134 the equations of motion are discontinuous at the grazing point . [ fig : vibroimpactcompliant ] , title=\"fig:\",height=188 ] ( 6.78,.08)@xmath135 ( 8.44,.08)@xmath136 ( 9.64,.08)@xmath9 ( 3.78,3.38)@xmath137 ( 3.78,1.4)@xmath138 ( 11.58,3.64)@xmath139 ( 11.58,1.18)@xmath140 ( 9.34,.63)@xmath141 ( 6.58,3.88)block ( 11.02,4.12)support ( 10.38,4.64)stop    to motivate and illustrate our results for stochastic nordmark maps , we consider the prototypical vibro - impacting system shown in fig . [ fig : vibroimpactcompliant ] and studied in @xcite . this system consists of a harmonically forced one - degree - of - freedom linear oscillator that experiences compliant ( or soft ) impacts with a support , and we use the following non - dimensionalised equations to model the dynamics : @xmath142 here @xmath143 denotes the location of the block , which has the equilibrium position @xmath144 . a rigid stop prevents the support reaching a position with @xmath10 , and prestresses the support by a distance , @xmath134 . the constants @xmath137 , @xmath138 , @xmath139 and @xmath140 represent non - dimensionalised spring and damping coefficients for the oscillator and support . we neglect the mass of the support , ignore energy loss at impacts , and assume that whenever the block is not in contact with the support , the support is located at @xmath9 . experiments of simple vibro - impacting systems with compliant impacts have shown that low - dimensional models such as ( [ eq : impactoscillator ] ) can quantitatively match the physically observed dynamics near grazing bifurcations @xcite .    here we treat the forcing amplitude , @xmath145 , as the primary bifurcation parameter , and assume @xmath146 . the steady - state solution ( behaviour in the limit @xmath147 ) to ( [ eq : impactoscillator ] ) with @xmath10 is @xmath148 when @xmath149 , where @xmath150 the maximum value of @xmath151 over one period is negative , and so @xmath151 is an attracting non - impacting periodic orbit of ( [ eq : impactoscillator ] ) . the critical value , @xmath152 , is a grazing bifurcation at which @xmath151 has unit amplitude and attains the value @xmath153 at times @xmath154 , for @xmath155 , where @xmath156 and @xmath157 .    to convert ( [ eq : impactoscillator ] ) to the general form ( [ eq : f ] ) , we define @xmath158 here the phase space of ( [ eq : impactoscillator ] ) with ( [ eq : vw ] ) is isomorphic to @xmath159 , rather than @xmath15 , but this does not affect the bifurcation structure near grazing . for ( [ eq : impactoscillator ] ) with ( [ eq : vw ] ) , the coefficients in ( [ eq : alphabetagamma ] ) , which describe the behaviour of the system near the grazing point , are given by @xmath160 and by evaluating ( [ eq : c ] ) with ( [ eq : odecoeffsosc ] ) we obtain @xmath161 in addition , from the general solution to ( [ eq : impactoscillator ] ) we find that the coefficients in the global map ( [ eq : g ] ) are given by @xmath162 [ eq : mapcoeffosc ] to model noise and uncertainties we use the one - dimensional ornstein - uhlenbeck process @xmath163 where @xmath164 are constants and @xmath165 is a standard brownian motion . given an initial value @xmath166 , at any positive time @xmath167 is a gaussian random variable with mean and variance @xmath168 = \\xi_0 \\,{\\rm e}^{\\frac{-t}{\\nu } } \\ ; , \\qquad { \\rm var } \\left [ \\xi(t ) | \\xi(0 ) = \\xi_0 \\right ] = \\frac{\\ee^2}{2 \\nu } \\left ( 1 - { \\rm e}^{\\frac{-2 t}{\\nu } } \\right ) \\;. \\label{eq : meanvarxi}\\ ] ] in the limit @xmath147 , @xmath169 $ ] , where @xmath170 $ ] denotes the gaussian distribution of mean @xmath46 and variance @xmath171 . the _ correlation time _ of ( [ eq : xi ] ) , defined as @xmath172}{{\\rm var } \\left [ \\xi(0 ) \\right ] } \\,dt$ ] , with @xmath173 $ ] , is equal to @xmath174 .    in our context , @xmath167 is coloured noise and the parameter @xmath67 governs the size of the noise . unlike white noise , @xmath167 has an inherent time - scale , @xmath174 , and is suitable for modelling various types of uncertainties in mechanical systems , such as background vibrations @xcite . in the white noise limit , forcing by @xmath167 becomes a diffusion process @xmath175 . we first consider the following stochastic perturbation of ( [ eq : f ] ) , @xmath176 where @xmath167 is given by ( [ eq : xi ] ) . in ( [ eq : fa ] ) randomness is present in the switching condition , while evolution between switching events remains deterministic . we expect ( [ eq : fa ] ) to be applicable to a wide variety of piecewise - smooth systems . for the vibro - impacting system of  [ sec : oscillator ] , @xmath167 may capture uncertainties in the point at which contact between the block and support occurs or is lost . for switched control systems , @xmath167 may correspond to measurement errors that produce variability in evaluations of switching rules @xcite .    here we consider orbits of ( [ eq : fa ] ) that are close to the grazing periodic orbit of ( [ eq : f ] ) . orbits of ( [ eq : fa ] ) near grazing only spend short lengths of time in the region @xmath11 while passing near the origin , and for simplicity we suppose that the value of @xmath174 is large compared to such times . in this case it is reasonable to approximate @xmath167 by a constant while an orbit is near the origin . with this approximation , the sum @xmath177 does not switch sign more than twice as the orbit passes near the origin , which substantially simplifies our calculations below . we let @xmath178 denote the value of @xmath167 during the @xmath179 instance that the orbit of ( [ eq : fa ] ) passes near the origin . the time between between consecutive traversals near the origin is well - approximated by the period of the grazing periodic orbit , call it @xmath180 . with this approximation , @xmath181 \\;. \\label{eq : xiiab}\\ ] ] to derive the stochastic version of ( [ eq : n ] ) for ( [ eq : fa ] ) with ( [ eq : xiiab ] ) , we first derive the induced stochastic discontinuity map . here condition ( [ eq : pipcondition ] ) is useful , as it implies that an orbit governed by @xmath6 attains a local maximum value of @xmath74 at an intersection with @xmath78 . for @xmath182 , we conclude that @xmath183 as the orbit passes near the origin , so that @xmath184 . if instead @xmath185 , then the discontinuity map @xmath186 is given by ( [ eq : u4w42 ] ) except that @xmath187 appears inside the square root because this quantity represents the distance from the switching condition . that is , @xmath188 where @xmath189 . by combining ( [ eq : u4w42a ] ) with the global map @xmath122 , applying the coordinate change ( [ eq : coordinatechange ] ) , and dropping higher order terms , we obtain @xmath190 @xmath62 is the stochastic nordmark map corresponding to ( [ eq : fa ] ) . notice that randomness in the switching condition of ( [ eq : fa ] ) has translated to randomness in both the switching condition of ( [ eq : n ] ) and in the image of the map with @xmath25 . in contrast , a piecewise - linear map for which randomness is present purely in the switching condition is studied in @xcite .    in order to fairly compare @xmath62 with other stochastic versions of ( [ eq : n ] ) in  [ sec : dynamics ] , we estimate the effective size of the stochastic contribution for our illustrative parameters values of the prototypical system ( [ eq : impactoscillator ] ) and a representative value of @xmath72 . this motivates us to express @xmath67 in terms of a scaled parameter @xmath191 , and to obtain comparable stochastic contributions for fixed @xmath192 in the different cases . the square - root term of @xmath62 is @xmath193 , where @xmath194 . if @xmath195 is large relative to @xmath196 , then this term is well - approximated by @xmath197 , and so @xmath198 estimates the additive stochastic contribution to @xmath62 . for the impact oscillator with the parameter values of fig . [ fig : detbifdiag ] ( here @xmath199 and @xmath200 ) and using @xmath201 ( corresponding to the value of @xmath25 in fig . [ fig : detbifdiag ] for @xmath72 ) , this quantity is approximately @xmath202 . with @xmath203 ( used in  [ sec : dynamics ] ) , the standard derivation of the stochastic contribution is approximately @xmath204 . therefore , for @xmath191 , where @xmath205 the standard deviation of the stochastic contribution is approximately @xmath206 when @xmath73 . ( 6.8,5.1 ) ( 0,0 ) , ( [ eq : na ] ) , with a numerical solution to ( [ eq : fa ] ) . the three groups of purple dots were obtained by numerically solving ( [ eq : fa ] ) with ( [ eq : xi ] ) , @xmath203 and @xmath207 , for the vibro - impacting system ( [ eq : impactoscillator ] ) with ( [ eq : vw ] ) and @xmath36 ( as in fig . [ fig : detbifdiag ] ) and @xmath208 ( which corresponds to @xmath72 ) . more precisely , @xmath209 points on @xmath78 ( labelled @xmath80 in fig . [ fig : grazschem3d ] ) were obtained by numerically solving ( [ eq : fa ] ) , and these were transformed to @xmath20-coordinates by applying ( [ eq : coordinatechange ] ) and ( [ eq : vw ] ) to produce the purple dots . the three groups of black dots are @xmath209 iterates of @xmath62 with ( [ eq : xiiab ] ) and parameter values chosen to match the vibro - impacting system ( specifically , @xmath203 , @xmath207 , @xmath210 , @xmath72 , @xmath33 , @xmath34 , @xmath35 , @xmath199 and @xmath200 ) . the deterministic @xmath38-cycles of ( [ eq : fa ] ) and ( [ eq : na ] ) are shown with triangles . [ fig : comparea_03 ] , title=\"fig:\",height=192 ] ( 3.76,0)@xmath47 ( 0,3.5)@xmath211    to illustrate the accuracy of @xmath62 , fig .  [ fig : comparea_03 ] compares iterates of @xmath62 ( black dots ) with a numerical solution to ( [ eq : fa ] ) for the vibro - impacting system of  [ sec : oscillator ] ( purple dots ) using @xmath207 . for the given parameter values , the system has an attracting @xmath38-cycle in the absence of noise . for this reason , both sets of points are grouped about the @xmath38-cycle . the two sets of points are slightly separated . this is because the form of the deterministic nordmark map does not include higher order terms of the true return map , as observed by the separation of the values taken by the deterministic @xmath38-cycles shown in fig . [ fig : comparea_03 ] . the size and shape of the spread of the two sets of randomly generated points are similar , as is their location relative to the deterministic values of the map . this demonstrates that @xmath62 can accurately capture the stochastic dynamics of ( [ eq : fa ] ) . a more precise characterisation of the accuracy of @xmath62 is beyond the scope of this paper . next we consider the case where randomness and uncertainty in ( [ eq : f ] ) is associated with @xmath7 . for mechanical systems with impacts , this corresponds to variability in the evolution of the system during an impact . for simplicity we include noise in only the @xmath75-component of @xmath7 , that is @xmath212 where @xmath167 is given by ( [ eq : xi ] ) . indeed , for the vibro - impacting system of fig . [ fig : vibroimpactcompliant ] , if noise is incorporated into the force on the block when it is in contact with the support , then the equations of motion may be put in the form ( [ eq : fbc ] ) . with noise added to the @xmath74-component of @xmath7 ( or @xmath6 ) , orbits may cross @xmath153 many times in a short time frame which makes the system substantially more difficult to analyse . we leave such considerations for future work .    as in  [ sub : s1 ] , we consider near - grazing orbits and assume that the value of @xmath174 is much larger than the time each orbit spends in the region @xmath11 . in this case it is reasonable to treat @xmath167 as constant while @xmath11 . during the @xmath179 instance that an orbit passes near the origin , we approximate @xmath167 by @xmath178 , distributed according to ( [ eq : xiiab ] ) . in this scenario the three components of the discontinuity map ( [ eq : v2w2])-([eq : u4w4 ] ) are unchanged except that @xmath213 is replaced by @xmath214 in ( [ eq : v3w3 ] ) ( because the @xmath75-component of the system with @xmath11 is given by @xmath215 , see ( [ eq : alphabetagamma ] ) ) . by combining ( [ eq : v2w2])-([eq : u4w4 ] ) we find that for @xmath110 the discontinuity map is given by @xmath216 and therefore the corresponding stochastic nordmark map is @xmath217 notice that with @xmath218 , @xmath63 is identical to ( [ eq : we can write the stochastic component of @xmath63 as @xmath219 , where @xmath220 . with the parameter values of the impact oscillator ( [ eq : odecoeffsosc ] ) , and @xmath221 , we have @xmath222 . therefore the noise provides a multiplicative stochastic contribution of approximately @xmath223 , ignoring signs . in order to compare the effect of the noise to the other cases , we write @xmath224 , choosing @xmath225 so that the standard deviation of the stochastic contribution is @xmath206 when @xmath73 . for @xmath201 and @xmath203 ( as in  [ sub : s1 ] ) , the standard deviation of @xmath223 is approximately @xmath226 , so we therefore choose @xmath227    ( 6.8,5.1 ) ( 0,0 ) with a numerical solution to ( [ eq : fbc ] ) . the three groups of purple dots were obtained by numerically solving ( [ eq : fbc ] ) with ( [ eq : xi ] ) , @xmath203 and @xmath228 , for the vibro - impacting system ( [ eq : impactoscillator ] ) with ( [ eq : vw ] ) using the same parameter values as in fig . [ fig : comparea_03 ] . the three groups of black dots are @xmath209 iterates of @xmath63 with ( [ eq : xiiab ] ) and parameter values matching those of the vibro - impacting system ( refer to the caption of fig . [ fig : comparea_03 ] ) . the deterministic @xmath38-cycles of ( [ eq : fa ] ) and ( [ eq : na ] ) are shown with triangles . [ fig : compareb_03 ] , title=\"fig:\",height=192 ] ( 3.76,0)@xmath47 ( 0,3.5)@xmath211    fig . [ fig : compareb_03 ] compares iterates of @xmath63 to intersections with @xmath78 of a numerical solution to ( [ eq : fbc ] ) using @xmath228 . as expected the two sets of points are similarly distributed about the deterministic @xmath38-cycle . lastly we consider ( [ eq : fbc ] ) in the white noise limit , @xmath229 . in this case ( [ eq : fbc ] ) reduces to a diffusion process forced by white noise , specifically @xmath230 is replaced by @xmath175 . by using ( [ eq : alphabetagamma ] ) to expand @xmath7 , ( [ eq : fbc ] ) for @xmath11 may be written as the three - dimensional stochastic differential equation @xmath231 to obtain a stochastic nordmark map corresponding to this scenario , we first derive the stochastic version of the middle component of the discontinuity map ( [ eq : v3w3 ] ) . given an initial point @xmath232 , where @xmath233 and @xmath234 are small , the desired values of @xmath235 and @xmath236 are given by the point @xmath237 of _ first return _ for the stochastic process ( [ eq : frc ] ) to @xmath153 . first return or first passage problems are an important class of theoretical problems in stochastic calculus with applications traditionally in finance and chemical kinetics @xcite . we approximate ( [ eq : frc ] ) by keeping only the leading order contributions , i.e. @xmath238 together with @xmath239 . with this approximation we are able to provide an explicit expression for the joint probability density function of the return location and time . a formal justification for the omission of the higher order terms is left for future work . we introduce the change of variables @xmath240 this puts ( [ eq : frc2 ] ) in a standard form studied in @xcite , @xmath241 where @xmath242 specifically , @xmath243 is a diffusion process with constant drift , and @xmath244 . therefore @xmath245 may be interpreted as _ integrated brownian motion with constant drift_.    we let @xmath246 denote the joint probability density function for the first return of ( [ eq : dpdq ] ) to @xmath247 , at a time @xmath248 , and location @xmath249 . in @xcite , mckean derived an explicit expression for @xmath250 in the case of zero drift by computing the inverse kontorovich - lebedev transform of the corresponding renewal equation . in @xcite , atkinson and clifford extended this result to the case of non - zero drift by applying the radon - nikodyn derivative . specifically @xmath251 \\right ) { \\rm erf } \\left ( \\frac{\\sqrt{6 h}}{\\sqrt{\\varrho r } } \\right ) \\ ; , \\label{eq : f}\\ ] ] where @xmath252 is the error function . the constant @xmath253 governs the shape of @xmath250 . the limit @xmath254 corresponds to the deterministic case , for which @xmath255 and @xmath256 . with a small value of @xmath257 , @xmath250 is roughly gaussian . in contrast , the limit @xmath258 corresponds to the case of no drift , as in @xcite , or to the limit @xmath259 . in this limit the marginal probability density function for @xmath260 is asymptotically proportional to @xmath261 , for large @xmath260 , and so is long - tailed @xcite .    in view of the scaling ( [ eq : pqs ] ) , the stochastic version of ( [ eq : v3w3 ] ) corresponding to ( [ eq : frc ] ) is given by @xmath262 where @xmath58 and @xmath59 have the joint probability density function ( [ eq : f ] ) . by combining ( [ eq : v3w3c ] ) with ( [ eq : v2w2 ] ) and ( [ eq : u4w4 ] ) we obtain @xmath263 which represents the stochastic version of the discontinuity map for points with @xmath110 . then using ( [ eq : u4w4c ] ) we arrive at the following stochastic nordmark map @xmath264 in ( [ eq : nc ] ) we treat each pair @xmath265 as a two - dimensional stochastic random variable with probability density function @xmath266 , where @xmath267 which results from combining ( [ eq : varrho ] ) with @xmath268 , ( [ eq : v2w2 ] ) , and @xmath269 , ( [ eq : coordinatechange ] ) . we now estimate the size of the stochastic contribution in @xmath64 . the leading order stochastic component of @xmath64 is @xmath270 , where @xmath271 . with ( [ eq : odecoeffsosc ] ) and @xmath221 , we can write @xmath272 , where the second term represents the multiplicative stochastic contribution , ignoring the sign of @xmath127 , because the deterministic values of @xmath59 and @xmath58 are @xmath273 and @xmath274 respectively .    with a small value of @xmath257 ( @xmath275 is suitable ) , @xmath246 is approximately gaussian because the effective noise amplitude in ( [ eq : dpdq ] ) is small . by ( [ eq : varrho2 ] ) , this approximation is valid when , roughly speaking , @xmath67 is not too large and @xmath195 is not too small . from ( [ eq : f ] ) we determine the covariance matrix of the gaussian approximation to be @xmath276 and it follows that in this approximation the linear combination @xmath277 has standard deviation @xmath278 . the standard deviation of the stochastic contribution in @xmath64 is therefore approximately @xmath279 . following the previous cases , we write @xmath280 , and choose @xmath281 so that the standard deviation of the stochastic contribution is @xmath206 when @xmath73 . for @xmath64 , this quantity is @xmath282 , using ( [ eq : varrho2 ] ) , the parameter values from fig . [ fig : detbifdiag ] , and @xmath201 . therefore we let @xmath283 here @xmath284 when @xmath73 , and so for these values the gaussian approximation to ( [ eq : f ] ) is justified . ( 6.8,5.1 ) ( 0,0 ) with a numerical solution to ( [ eq : fbc ] ) . the three groups of purple dots were obtained by numerically solving ( [ eq : fbc ] ) with ( [ eq : xi ] ) , @xmath229 ( in which case @xmath230 is replaced by @xmath285 ) and @xmath286 , for the vibro - impacting system ( [ eq : impactoscillator ] ) with ( [ eq : vw ] ) using the same parameter values as in fig . [ fig : comparea_03 ] . the three groups of black dots are @xmath209 iterates of @xmath64 with ( [ eq : f ] ) and ( [ eq : varrho2 ] ) and parameter values matching those of the vibro - impacting system . the deterministic @xmath38-cycles of ( [ eq : fa ] ) and ( [ eq : na ] ) are shown with triangles . [ fig : comparec_03 ] , title=\"fig:\",height=192 ] ( 3.76,0)@xmath47 ( 0,3.5)@xmath211    fig . [ fig : comparec_03 ] compares iterates of @xmath64 to intersections with @xmath78 of a numerical solution to ( [ eq : fbc ] ) using @xmath286 . as with the previous two figures , this shows that @xmath64 can accurately capture the stochastic dynamics of ( [ eq : fbc ] ) . in this section we explore the dynamics of the three stochastic nordmark maps , @xmath62 , @xmath63 and @xmath64 , and discuss how the different forms of these maps is evident in their dynamical behaviour . to briefly summarise , @xmath62 applies to the system with stochastic switching ( [ eq : fa ] ) , whereas @xmath63 and @xmath64 apply to ( [ eq : fbc ] ) . for @xmath62 and @xmath63 it is assumed that the value of @xmath174 ( the correlation time of the noise ) is large relative to the times that orbits spend in @xmath11 . as these times are rarely larger than @xmath287 for the parameter values considered here , we take @xmath203 in @xmath62 and @xmath63 to ensure that the correlation time is large enough . the values of @xmath178 in @xmath62 and @xmath63 are distributed according to ( [ eq : xiiab ] ) . @xmath64 corresponds to the limit @xmath56 . in @xmath64 , @xmath58 and @xmath59 are distributed according to ( [ eq : f ] ) and depend on the value of @xmath288 ( [ eq : varrho2 ] ) .    for each @xmath68 we have written @xmath289 where the @xmath71 are given by ( [ eq : tildeee1 ] ) , ( [ eq : tildeee2 ] ) and ( [ eq : tildeee3 ] ) . these values have been chosen such that for a given value of @xmath192 , the size of the stochastic contribution in @xmath62 , @xmath63 and @xmath64 is roughly the same , at least when @xmath72 . for @xmath46 close to @xmath290 , the stochastic contributions are noticeably different for these choices of @xmath71 .    in  [ sub : mudependence ] we look at stochastic bifurcation diagrams in order to obtain a basic understanding of how the stochastic dynamics differs with the value of @xmath46 . in the subsequent parts of this section we study two - dimensional invariant densities in order to gain a deeper understanding of the dynamics . ( 12,18.4 ) ( 0,12.4 ) ( panel a ) , @xmath63 ( panel b ) , and @xmath64 ( panel c ) , with @xmath33 , @xmath34 , and @xmath35 . these parameter values correspond to the vibro - impacting system ( [ eq : impactoscillator ] ) , with @xmath36 . the black dots are iterates of @xmath62 , @xmath63 and @xmath64 with transient points omitted . the noise amplitudes are given by ( [ eq : tildeee1 ] ) , ( [ eq : tildeee2 ] ) and ( [ eq : tildeee3 ] ) with @xmath73 , and @xmath203 for panels a and b ( panel c corresponds to @xmath229 ) . in each panel the deterministic bifurcation diagram ( fig . [ fig : detbifdiag ] ) is shown in blue . [ fig : noisybifdiag ] , title=\"fig:\",height=226 ] ( 0,6.2 ) ( panel a ) , @xmath63 ( panel b ) , and @xmath64 ( panel c ) , with @xmath33 , @xmath34 , and @xmath35 . these parameter values correspond to the vibro - impacting system ( [ eq : impactoscillator ] ) , with @xmath36 . the black dots are iterates of @xmath62 , @xmath63 and @xmath64 with transient points omitted . the noise amplitudes are given by ( [ eq : tildeee1 ] ) , ( [ eq : tildeee2 ] ) and ( [ eq : tildeee3 ] ) with @xmath73 , and @xmath203 for panels a and b ( panel c corresponds to @xmath229 ) . in each panel the deterministic bifurcation diagram ( fig . [ fig : detbifdiag ] ) is shown in blue . [ fig : noisybifdiag ] , title=\"fig:\",height=226 ] ( 0,0 ) ( panel a ) , @xmath63 ( panel b ) , and @xmath64 ( panel c ) , with @xmath33 , @xmath34 , and @xmath35 . these parameter values correspond to the vibro - impacting system ( [ eq : impactoscillator ] ) , with @xmath36 . the black dots are iterates of @xmath62 , @xmath63 and @xmath64 with transient points omitted . the noise amplitudes are given by ( [ eq : tildeee1 ] ) , ( [ eq : tildeee2 ] ) and ( [ eq : tildeee3 ] ) with @xmath73 , and @xmath203 for panels a and b ( panel c corresponds to @xmath229 ) . in each panel the deterministic bifurcation diagram ( fig . [ fig : detbifdiag ] ) is shown in blue . [ fig : noisybifdiag ] , title=\"fig:\",height=226 ] ( 6.2,12.4)@xmath46 ( 6.2,6.2)@xmath46 ( 6.2,0)@xmath46 ( 0,16.2)@xmath47 ( 0,10)@xmath47 ( 0,3.8)@xmath47 ( 1.7,18.1)*a * ( 1.7,11.9)*b * ( 1.7,5.7)*c *    fig . [ fig : noisybifdiag ] shows stochastic versions of the bifurcation diagram shown in fig . [ fig : detbifdiag ] for the three stochastic nordmark maps . as expected , the noise blurs the bifurcation diagram . in panel a , which corresponds to the map @xmath62 , for values of @xmath46 very close to zero ( say @xmath291 ) the points are relatively highly spread . this is because here the deterministic map has an attractor near @xmath292 , so in @xmath62 the sign of @xmath195 is often different to the sign of @xmath293 . that is , the choice of the half - map of @xmath62 is regularly determined by @xmath178 rather than @xmath195 . furthermore , as shown in [ sub : s1 ] , the leading order component of the stochastic contribution to the right half - map of @xmath62 is inversely proportional to @xmath66 , which for very small @xmath46 is large relative to its value for @xmath46 away from zero . in contrast , with @xmath294 say , the underlying attracting @xmath38-cycle is sufficiently far from @xmath292 so that the sign of @xmath195 rarely differs from that of @xmath293 . the points are randomly distributed    about the @xmath38-cycle due to noise in the right half - map of @xmath62 . the size of the deviation decreases with increasing @xmath46 , because the strength of attraction of the @xmath38-cycle increases with @xmath46 .    in panels b and c , which correspond to @xmath63 and @xmath64 respectively , the bifurcation diagrams show no variability for @xmath29 . this is because for @xmath29 , @xmath32 ( [ eq : xlyl ] ) is a fixed point of @xmath63 and @xmath64 . for @xmath295 , the size of deviations about the underlying attracting @xmath39-cycle increases with @xmath46 . this is primarily because the coefficient of the @xmath130-term of @xmath63 and @xmath64 is random , and for the @xmath39-cycle this value of @xmath47 increases with @xmath46 . for @xmath294 , the size of deviations varies little with @xmath46 because the increased variability caused by a larger value of @xmath47 is balanced by the fact that the strength of attraction of the @xmath38-cycle increases . panels b and c are similar , suggesting that the value of @xmath174 has little effect on the long - term dynamics , although panel c shows slightly more variability for very small values of @xmath40 . ( 13.8,10.2 ) ( 0,4.7 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . the value of the density is indicated by colour ( dark red  the maximum value of the density ; dark blue  zero ) . panel b shows the invariant density at three times the noise amplitude as panel a. panel c plots @xmath296  the fraction of instances that points return to @xmath297 in @xmath298 iterations ( [ eq : sigma ] )  against the noise amplitude . [ fig : invdensitya_03 ] , title=\"fig:\",height=192 ] ( 7,4.7 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . the value of the density is indicated by colour ( dark red  the maximum value of the density ; dark blue panel b shows the invariant density at three times the noise amplitude as panel a. panel c plots @xmath296  the fraction of instances that points return to @xmath297 in @xmath298 iterations ( [ eq : sigma ] )  against the noise amplitude . [ fig : invdensitya_03 ] , title=\"fig:\",height=192 ] ( 2.4,0 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . the value of the density is indicated by colour ( dark red  the maximum value of the density ; dark blue panel b shows the invariant density at three times the noise amplitude as panel a. panel c plots @xmath296  the fraction of instances that points return to @xmath297 in @xmath298 iterations ( [ eq : sigma ] )  against the noise amplitude . [ fig : invdensitya_03 ] , title=\"fig:\",height=170 ] ( 3.42,10)@xmath73 ( 10.42,10)@xmath299 ( 3.76,4.7)@xmath47 ( .3,8.2)@xmath211 ( 10.76,4.7)@xmath47 ( 7.3,8.2)@xmath211 ( 7.2,0)@xmath192 ( 8,3.44)@xmath300 ( 8.87,1.45)@xmath301 ( 9.33,2)@xmath302 ( .5,9.9)*a * ( 7.5,9.9)*b * ( 2.4,4.2)*c *    ( 13.8,10.2 ) ( 0,4.7 ) with the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityb_03 ] , title=\"fig:\",height=192 ] ( 7,4.7 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityb_03 ] , title=\"fig:\",height=192 ] ( 2.4,0 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityb_03 ] , title=\"fig:\",height=170 ] ( 3.42,10)@xmath73 ( 10.42,10)@xmath299 ( 3.76,4.7)@xmath47 ( .3,8.2)@xmath211 ( 10.76,4.7)@xmath47 ( 7.3,8.2)@xmath211 ( 7.2,0)@xmath192 ( 8,3.44)@xmath300 ( 6.66,1.64)@xmath301 ( 8.78,2)@xmath302 ( .5,9.9)*a * ( 7.5,9.9)*b * ( 2.4,4.2)*c *    ( 13.8,10.2 ) ( 0,4.7 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityc_03 ] , title=\"fig:\",height=192 ] ( 7,4.7 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityc_03 ] , title=\"fig:\",height=192 ] ( 2.4,0 ) with the same parameter values as fig . [ fig : noisybifdiag ] and @xmath72 . panel b shows the invariant density with @xmath299 , and panel c is a plot of the fractions @xmath296 ( [ eq : sigma ] ) . [ fig : invdensityc_03 ] , title=\"fig:\",height=170 ] ( 3.42,10)@xmath73 ( 10.42,10)@xmath299 ( 3.76,4.7)@xmath47 ( .3,8.2)@xmath211 ( 10.76,4.7)@xmath47 ( 7.3,8.2)@xmath211 ( 7.2,0)@xmath192 ( 7.3,3.55)@xmath300 ( 8,1.7)@xmath301 ( 8.93,2.03)@xmath302 ( .5,9.9)*a * ( 7.5,9.9)*b * ( 2.4,4.2)*c *    figs . [ fig : invdensitya_03]-[fig : invdensity_m002 ] show two - dimensional invariant densities of @xmath62 , @xmath63 and @xmath64 . by assuming ergodicity , invariant densities were computed on a @xmath303 grid of @xmath47 and @xmath211 values from @xmath304 consecutive iterates of a single orbit with transient points omitted . let us first explain panel c of figs . [ fig : invdensitya_03]-[fig : invdensityc_03 ] . given a sample orbit of @xmath62 , @xmath63 or @xmath64 , for each point with @xmath25 we let @xmath305 be the smallest positive integer for which @xmath306 , as in @xcite . @xmath305 represents the number of iterations required for a return to @xmath307 from the point @xmath308 . numerically we can compute a large number of values of @xmath305 ( say @xmath309 of them ) . then for each @xmath310 , we let @xmath296 denote the fraction of the @xmath305 that are equal to @xmath298 , i.e. @xmath311 where @xmath312 if @xmath313 , and @xmath314 otherwise . [ fig : invdensitya_03]-[fig : invdensityc_03 ] correspond to @xmath72 for which there is an underlying attracting @xmath38-cycle . therefore with small noise , @xmath315 , and for all @xmath316 , @xmath317 . [ fig : invdensitya_03 ] corresponds to the map @xmath62 . in panel a , the size of the noise is relatively small , so iterates of @xmath62 follow close to the @xmath38-cycle . the invariant density is well - approximated by a scaled sum of three gaussian densities centred at each point of the @xmath38-cycle . about the point with @xmath318 , the density is stretched substantially more in @xmath47-direction than in the @xmath211-direction . this is because points with @xmath318 have likely just undergone an iteration under the right half - map of @xmath62 which is stochastic in the @xmath47-component but not the @xmath211-component . the stretching around other iterates is then a consequence of iterating under @xmath62 with @xmath319 . with larger values of @xmath192 , it is relatively common for the orbit to return to @xmath307 in a number of iterations other than three , fig . [ fig : invdensitya_03]-c . for this reason the invariant density displays additional characteristics . for instance with @xmath299 , the orbit returns to @xmath307 in two iterations almost @xmath320 of the time . consequently , a substantial part of the invariant density centred roughly about the point of the @xmath38-cycle with @xmath321 , lies in @xmath307 , fig . [ fig : invdensitya_03]-b . the invariant density in panel b also has a small component with @xmath322 . this is due to points of the orbit with small values of @xmath307 mapping under the left half - map of @xmath62 due to the noise ( i.e.  returning to @xmath307 in only one iteration ) . [ fig : invdensityb_03 ] illustrates @xmath63 using the same parameter values . again with small noise the invariant density is roughly gaussian about each point of the @xmath38-cycle , whereas for relatively large noise iterates often cross into @xmath307 prematurely causing the invariant density to take an irregular shape . when @xmath299 , points of the orbit that do not return to @xmath307 in three iterations , usually return to @xmath307 in two iterations . [ fig : invdensityc_03 ] corresponds to @xmath64 and is similar to the previous figure . this indicates that the correlation time @xmath174 has little effect on these pictures , although the invariant density has a slightly different shape when @xmath299 . ( 13.8,10.4 ) ( 0,5.3)-cycle of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath323 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , using the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath323 . [ fig : invdensity_001 ] , title=\"fig:\",height=192 ] ( 7,5.3)-cycle of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath323 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , using the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath323 . [ fig : invdensity_001 ] , title=\"fig:\",height=192 ] ( 0,0)-cycle of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath323 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , using the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath323 . [ fig : invdensity_001 ] , title=\"fig:\",height=192 ] ( 7,0)-cycle of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath323 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , using the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath323 . [ fig : invdensity_001 ] , title=\"fig:\",height=192 ] ( 3.76,5.3)@xmath47 ( .3,8.8)@xmath211 ( 10.76,5.3)@xmath47 ( 7.3,8.8)@xmath211 ( 3.76,0)@xmath47 ( .3,3.5)@xmath211 ( 10.76,0)@xmath47 ( 7.3,3.5)@xmath211 ( .6,10.3)*a * ( 7.6,10.3)*b * ( .6,5)*c * ( 7.6,5)*d *    fig .  [ fig : invdensity_001 ] shows invariant densities of @xmath62 , @xmath63 and @xmath64 for parameter values closer to the grazing bifurcation than the previous three figures , specifically @xmath323 . at this value of @xmath46 , there is an underlying attracting @xmath39-cycle , panel a. the noise amplitudes are given by ( [ eq : tildeee1 ] ) , ( [ eq : tildeee2 ] ) and ( [ eq : tildeee3 ] ) with @xmath73 . recall , these amplitudes were chosen such that the size of the noise response of the three maps is roughly the same for larger values of @xmath46 . here , however , the size of noise response differs substantially . in panels c and d , which correspond to @xmath63 and @xmath64 respectively , the invariant density is approximately a scaled sum of four gaussians about each point of the @xmath39-cycle . the invariant density in panel d , corresponding to @xmath229 , is noticeably larger than that of panel c.    in panel b , which corresponds to @xmath62 , the noise has a substantial effect because the switching condition of @xmath62 is stochastic , and many points of @xmath62 fall close to @xmath292 . the invariant density has a small @xmath324-shaped component in @xmath297 corresponding to consecutive points of the orbit mapping under the left half - map of @xmath62 . the part of the invariant density for @xmath319 and @xmath325 corresponds to images of points under the right half - map of @xmath62 , and is bimodal because the invariant density has roughly two components in @xmath307 . ( 13.8,10.4 ) ( 0,5.3)-cycle and a numerically computed attractor of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath326 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , with the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath326 . [ fig : invdensity_0145 ] , title=\"fig:\",height=192 ] ( 7,5.3)-cycle and a numerically computed attractor of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath326 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , with the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath326 . [ fig : invdensity_0145 ] , title=\"fig:\",height=192 ] ( 0,0)-cycle and a numerically computed attractor of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath326 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , with the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath326 . [ fig : invdensity_0145 ] , title=\"fig:\",height=192 ] ( 7,0)-cycle and a numerically computed attractor of ( [ eq : n ] ) with the same parameter values as fig . [ fig : detbifdiag ] and @xmath326 . panels b , c and d show the invariant densities of @xmath62 , @xmath63 and @xmath64 , respectively , with the same parameter values as fig .  [ fig : noisybifdiag ] and @xmath326 . [ fig : invdensity_0145 ] , title=\"fig:\",height=192 ] ( 3.76,5.3)@xmath47 ( .3,8.5)@xmath211 ( 10.76,5.3)@xmath47 ( 7.3,8.5)@xmath211 ( 3.76,0)@xmath47 ( .3,3.2)@xmath211 ( 10.76,0)@xmath47 ( 7.3,3.2)@xmath211 ( .4,10.3)*a * ( 7.4,10.3)*b * ( .4,5)*c * ( 7.4,5)*d *    ( 13.8,5.1 ) ( 0,0 ) ( [ eq : xlyl ] ) and the attracting @xmath38-cycle of @xmath327 with the same parameter values as fig . [ fig : detbifdiag ] , except @xmath328 and @xmath329 . here @xmath330 , @xmath34 and @xmath35 . panel b shows the invariant density of the corresponding map @xmath62 , with @xmath203 and @xmath331 . [ fig : invdensity_m002 ] , title=\"fig:\",height=192 ] ( 7,0 ) ( [ eq : xlyl ] ) and the attracting @xmath38-cycle of @xmath327 with the same parameter values as fig . [ fig : detbifdiag ] , except @xmath328 and @xmath329 . here @xmath330 , @xmath34 and @xmath35 . panel b shows the invariant density of the corresponding map @xmath62 , with @xmath203 and @xmath331 . [ fig : invdensity_m002 ] , title=\"fig:\",height=192 ] ( 3.76,0)@xmath47 ( .3,3.4)@xmath211 ( 10.76,0)@xmath47 ( 7.3,3.4)@xmath211 ( .4,5)*a * ( 7.4,5)*b *    with @xmath326 in fig . [ fig : detbifdiag ] , there is an attracting @xmath39-cycle and an apparently chaotic attractor . these are shown in fig . [ fig : invdensity_0145]-a . as with smooth maps @xcite , in the presence of noise orbits commonly dwell near the attractors for relatively long periods of time , and switch between attractors quickly . invariant densities of @xmath62 , @xmath63 and @xmath64 are shown in panels b , c and d. in each case the bulk of the density is centred about the two underlying attractors . with white noise ( panel d ) there is no gap in the invariant density around @xmath332 due to randomness in both the @xmath47 and @xmath211-components of @xmath64 . lastly , fig . [ fig : invdensity_m002 ] illustrates stochastic dynamics with @xmath29 . this figure corresponds to @xmath328 ( different to fig . [ fig : detbifdiag ] ) and @xmath329 at which @xmath327 has an attracting @xmath38-cycle as well as the attracting fixed point @xmath32 ( [ eq : xlyl ] ) . these are shown in panel a. the dynamics of @xmath63 and @xmath64 for @xmath319 is deterministic , hence @xmath32 is a fixed point of these maps . given an initial point @xmath333 near the @xmath38-cycle , sample orbits of @xmath63 and @xmath64 eventually reach @xmath32 . in contrast , @xmath62 has an invariant density concentrated about the two attractors , panel b. the part of the density with @xmath334 and @xmath335 corresponds to points of the orbit repeatedly following the left half - map of @xmath62 ( with @xmath24 and @xmath336 ) . this paper concerns grazing bifurcations for which the associated dynamics is described by the nordmark map ( [ eq : n ] ) . the potential influence of randomness and uncertainties on the dynamics of ( [ eq : n ] ) was described in @xcite by studying ( [ eq : n ] ) in the presence of additive white gaussian noise . such a noise formulation is suitable if the nature of the randomness in the ode system is practically independent to the state of the system , such as if there is a random forcing term .    in this paper we considered the alternate scenario that randomness is present in the switching condition of the ode system , and in @xmath7  the part of the vector field opposite to the tangential intersection of the grazing periodic orbit . these cases are especially relevant for vibro - impacting systems for which impact events represent the primary source of uncertainty . we derived three different stochastic versions of ( [ eq : n ] ) . these are the maps @xmath62 ( [ eq : na ] ) , which corresponds to a noisy switching condition in the ode system , @xmath63 ( [ eq : nb ] ) , which corresponds to noise in @xmath7 with a large correlation time , and @xmath64 ( [ eq : nc ] ) , which corresponds to white noise in @xmath7 . in each case the noise is nonlinear and non - additive . this indicates that some diligence should be taken when formulating stochastic return maps for grazing bifurcations of piecewise - smooth systems . the stochastic dynamics of @xmath62 , @xmath63 and @xmath64 differs in many ways to that of ( [ eq : n ] ) with additive noise , described in @xcite . for @xmath62 , @xmath63 and @xmath64 , dynamics prior to the grazing bifurcation is deterministic , and beyond the grazing bifurcation two - dimensional invariant densities are often skewed dramatically so that they appear almost one - dimensional .    near the grazing bifurcation , @xmath62 exhibits a large noise response relative to @xmath63 and @xmath64 . this suggests that if experimental data of a physical system shows relatively high variability near a grazing bifurcation , then it is likely to be most appropriate to include randomness in the switching condition of a mathematical model . invariant densities of @xmath62 near grazing are highly irregular due to the randomness in the switching condition . for @xmath63 and @xmath64 , the size of the noise response increases , for most part , with the distance ( in parameter space ) beyond the grazing bifurcation . the maps @xmath63 and @xmath64 exhibit qualitatively similar invariant densities , which implies that the correlation time has little effect . indeed the correlation time only influences the short - time dynamics of ( [ eq : fbc ] ) with @xmath11 , and the precise nature of these dynamics has a negligible effect on the invariant densities , which relate to long - time dynamics . m.  oestreich , n.  hinrichs , k.  popp , and c.j . budd . analytical and experimental investigation of an impact oscillator . in _ proceedings of the asme 16th biennal conf . on mech . vibrations and noise . _ , pages 111 , 1997 . e.  knobloch and j.b . effect of noise on discrete dynamical systems with multiple attractors . in m.f . mcclintock and p.v.e . moss , editors , _ noise in nonlinear dynamical systems . theory of noise induced processes in special applications . _ , volume  2 , pages 6586 . cambridge university press , new york , 1989 .", "tags": [], "output_text_a": "The paper investigates the dynamics of vibro-impacting mechanical systems, which often experience chaotic behavior due to the nonlinear nature of impacts. It focuses on understanding grazing bifurcations in these systems using a low degree-of-freedom ordinary differential equation (ODE) model. The study explores how impacts can be modeled as instantaneous events with energy loss and velocity reversal, and how these models can be used to predict the system's behavior near grazing bifurcations. The paper introduces stochastic versions of the Nordmark map to account for randomness stemming from impact events, using different types of noise models. It compares the effects of these stochastic models on the dynamics of the system, highlighting the importance of considering randomness in the switching conditions and the evolution of the system during impacts. The findings suggest that the correlation time of noise has little effect on long-term dynamics, but randomness in the switching condition can significantly influence the system's behavior near grazing bifurcations. The study provides insights into the complex dynamics of vibro-impacting systems and the role of stochastic processes in their analysis.", "output_text_b": "This article discusses the dynamics of impacting systems and the importance of understanding impacting dynamics in various mechanical systems. It explains how impacts can be modeled using low degree-of-freedom ODE models, and how these models can accurately match experimental data. The paper then focuses on grazing bifurcations in piecewise-smooth ODE systems and their significance in vibro-impacting systems. A normal form for the return map of such systems is derived, known as the Nordmark map. The paper also discusses the effects of randomness and uncertainties in vibro-impacting systems and how stochastic averaging methods have been useful in quantitatively describing stochastic impacting dynamics.", "score": -0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, focusing on the dynamics of vibro-impacting systems and the introduction of stochastic models.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding grazing bifurcations in vibro-impacting systems.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of a low degree-of-freedom ODE model and stochastic versions of the Nordmark map.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant conclusions about the effects of randomness and the correlation time on system dynamics.\n6. \"The summary must be written in clear and professional language.\" - The summary is written in clear and professional language.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms but does not explain them, which might be necessary for clarity.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in understanding complex dynamics and the role of stochastic processes.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the dynamics of impacting systems, the use of low degree-of-freedom ODE models, and the focus on grazing bifurcations.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is mentioned, focusing on understanding impacting dynamics in mechanical systems.\n4. The methodology or approach used in the paper, including the derivation of the Nordmark map and stochastic averaging methods, is mentioned.\n5. Significant results or conclusions, such as the effects of randomness and uncertainties, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"grazing bifurcations\" and \"Nordmark map.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research.\n10. The summary reflects the paper's significance in understanding vibro-impacting systems and their dynamics."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "coupled spin 1/2 chains have attracted much attention lately due to the large number of their experimental realizations , as well as to the variety of theoretical techniques , both analytical and numerical , available to study the relevant models . spin 1/2 chains , owing to the jordan - wigner transformation@xcite , show properties remarkably similar to those of interacting one dimensional fermions with their low energy properties described by an effective luttinger liquid theory@xcite . recently it has been realized that these properties are drastically modified when the spin 1/2 chains are coupled together forming ladder systems@xcite . in this case , in a way very similar to haldane s spin - s problem @xcite , a gap is found to open for an even number of chains while the system remains gapless if the number of chains is odd . this phenomenon has been thoroughly investigated both analytically @xciteand numerically @xcite , and corresponding experimental systems were identified . typical examples of two - chain spin 1/2 ladders exhibiting a gap are @xmath1@xcite and @xmath2@xcite . on the other hand , an example of a gapless three - chain ladder is @xmath3@xcite . from the theoretical point of view , the difference between odd and even number of legs@xcite or odd and even spin@xcite has been understood qualitatively through a generalization of the lieb - schultz - mattis theorem . the theorem states that if the ground state is unique the system will necessarily be gapless . this is indeed the case for an odd number of coupled spin 1/2 chains . more recent theoretical work has emphasized the role of boundary conditions in the transverse direction in the formation of spin gaps . the results quoted above - the opening of a gap for an even number of coupled chains , gaplessness if the number is odd - are valid for open boundary conditions ( obc ) . it turns out that when periodic boundary conditions ( pbc ) are imposed on the transverse direction a gap opens for both cases of even and odd number of chains although the underlying reasons and the natures of the gaps are different . in the case of an even number of coupled chains , the reason for the gap is the formation of spin singlets along the transverse direction , similarly to the case of chains with open boundary conditions . when the number of coupled chains is odd a two fold degenerate dimerized ground state is obtained in the case of pbc@xcite - in contrast to its uniqueness in the obc - allowing for a gap in the spin excitations . the degeneracy of the ground state in the case of pbc can be understood as a consequence of the fact that pbc are frustrating for an odd number of legs . to date , no experimental system described by coupled antiferromagnetic spin 1/2 chains with periodic boundary conditions and an odd number of legs has been reported . when , further , leg - leg biquadratic interactions are included new states emerge . a system of two spin-1/2 spin chains enters a spontaneously dimerized phase with a gapped spectrum exhibiting non - haldane spin - liquid properties@xcite . the elementary excitations are neither spinons nor magnons , but pairs of propagating triplet or singlet solitons connecting two spontaneously dimerized ground states . subsequently more non - haldane spin - liquid models have been proposed @xcite . recently , these models of spin ladders with biquadratic exchange have been advocated@xcite as possible models for the formation of a spin gap in @xmath0 and @xmath4 .    in this paper we study the low energy physics of the three - leg ladder with periodic boundary conditions ( see fig . [ fig : spin_tube ] ) . this model is called the spin - tube model in the following . by analyzing in detail its effective low energy hamiltonian ( leh ) , which consists of two _ non - equivalent _ coupled xxz chains of spins and chiral degrees of freedom , in the presence of a biquadratic exchange@xcite , we will show that the dimerized ground state of this model falls in the universality class of the non - haldane spin liquids . in the case of xxz chains with a biquadratic coupling and for @xmath5 , we find that the ising antiferromagnetic order can compete with the dimer order , and we will describe the resulting phase diagram . the organization of the paper is as follows . in sec.[model ] we introduce the spin tube model . we sketch the derivation of the strong interchain coupling effective hamiltonian and discuss its relation with two spin 1/2 chains coupled by a biquadratic interaction . we then discuss the symmetries and recall the results already known on the two chains with biquadratic interactions , in particular the prediction of a spin gap .    in sec . [ bosonization ] we discuss the bosonization treatment of two non - equivalent xxz chains coupled by a biquadratic interaction . we show that this hamiltonian contains a term @xmath6 that is responsible for the formation of a spin - gap and singlet order , as well as terms @xmath7 that cause antiferromagnetic order . to analyze the competitions of these terms , we derive renormalization group equations . using these equations , we estimate in which part of the phase diagram we should expect a competition of antiferromagnetism and dimer order . we also estimate the equation of the phase boundary between the singlet and the antiferromagnetic order .    in sec.[sec : dimerized ] we analyze in details the dimerized phase . the dimerized ground state is two - fold degenerate and is formed of alternating singlets of spins and pseudospins . the elementary excitations above the ground state carry a spin @xmath8 as well as a pseudospin @xmath8 . they can be seen as formed by the introduction of a spin and a pseudospin in the pattern of alternating singlets . similar excitations were obtained in ref .   and it was shown that they lead to response functions very different from those of a haldane spin liquid . numerical evidence for such excitations was also obtained in ref . . in section [ sec : gap_closure ] , we analyze the effect of a magnetic field strong enough to close the gap of the dimer phase . when both chains are magnetic , the situation is similar to the one obtained with two coupled spin ladders @xcite . in the more physical situation , when only one of the two chains is magnetic , the ground state properties are those of a two component luttinger liquid . in the case of spin - orbital models , spin and orbital degrees of freedom decouple completely but the presence of orbital modes should affect the specific heat . in the case of the spin - tube , we show that in contrast to spin - orbital models , the spin - correlation functions are affected by the presence of auxiliary gapless modes . we also show that for non - equivalent chains ( a case that is realized in spin - orbital models ) the exponent of the spin correlations is _ non - universal _ at the transition . finally , in sec.[conclusions ] we will give some concluding remarks . we wish to study the three - chain ladder hamiltonian ,    @xmath9    where @xmath10 ( resp . @xmath11 ) is a chain ( resp . site ) index , @xmath12 is the coupling along the chain and @xmath13 the transverse coupling . we impose periodic boundary conditions along the rungs by identifying @xmath14 . we call the resulting model the spin - tube ( see fig . [ fig : spin_tube ] ) since it can be realized by placing 3 spin 1/2 chains forming an equilateral triangle . in order to investigate the low - energy physics of the spin - tube , we consider the limit of strong interchain coupling ( @xmath15 ) . this is the appropriate starting point that yields a good effective description of the properties of the spin tube in the whole range of @xmath16 . ( starting from the opposite limit @xmath17 , and treating @xmath18 as a perturbation , one finds@xcite that it gives rise to relevant terms in the hamiltonian . as a result , the initial @xmath18 grows until it is of order of @xmath12 at which point the weak coupling bosonization scheme is no more valid . )    to derive the effective low - energy hamiltonian , let us first consider the case @xmath19 . the system is a collection of independent rungs , each described by the following hamiltonian @xmath20    the ground state of each rung is four - fold degenerate , composed of two doublets of spin 1/2 excitations , corresponding to the left and right chirality ( -/+ ) , with energy @xmath21@xcite , and the excited states form a spin 3/2 quadruplet with energy @xmath22 . turning on @xmath23 allows the rungs to exchange spins . in the limit @xmath15 , the quadruplet of s=3/2 excitations can be neglected , and only the degenerate low energy subspace of spin 1/2 states needs to be taken into account . in this subspace the hamiltonian transforms into an effective hamiltonian with a biquadratic coupling between the spin and chirality degrees of freedom@xcite ,    @xmath24    where @xmath25 is the total spin , and @xmath26 are operators exchanging left and right chiralities . the original spin operators can be expressed in terms of the effective spin @xmath25 and the chirality @xmath27 in the following way : @xmath28 the spin tube model has already been investigated numerically@xcite using dmrg in the case of coupled xxx chains . the system was shown to exhibit a spin gap @xmath29 , with exponentially decaying correlation functions @xmath30 and @xmath31 . this behavior was shown to be related to the formation of a dimer order . a qualitative discussion of the origin of this dimer order can be found in ref . @xcite . in ref . the dispersion relation of excitations having @xmath32 and @xmath33 as a function of momentum was obtained numerically for a system of 12 sites showing only gapped excitations .    in ref . , a generalization of the effective hamiltonian eq . ( [ heff ] ) to coupled anisotropic spin chains has been derived ( see eq . ( [ eq : heff_anisotropic ] ) . numerical diagonalizations were performed . a gap to @xmath34 excitations was obtained for@xmath35 with results in good agreement with those of ref . for @xmath36 . it was also shown that the ground state was degenerate in agreement with the dimer order picture of ref . . the dispersion relation of excitations having @xmath37 and total spin @xmath38 or @xmath39 was obtained@xcite . it was shown to be the bottom of a two particle continuum . the fundamental particle , the spinon , was conjectured to have @xmath40 . the spinon dispersion relation was obtained numerically by considering a system with an odd number of sites@xcite , showing that the spinons were massive for all momentum . the hamiltonian ( [ heff ] ) is part of the class of the hamiltonians consisting of two non - equivalent coupled xxz chains in the presence of a biquadratic exchange , @xmath41 where h_0 & = & _ i _ = 1,2 j _ ( s_,i^xs_,i+1^x+s_,i^ys_,i+1^y ) + j_^z s_,i^zs_,i+1^z [ h0 ] + h_b&= & _ i ( s_1,i^xs_1,i+1^x+s_1,i^ys_1,i+1^y+ _ 1 s_1,i^zs_1,i+1^z ) ( s_2,i^xs_2,i+1^x+s_2,1^ys_2,i+1^y+ _ 2 s_2,i^zs_2,i+1^z).[hbiq ] in the case of the spin - tube , @xmath42 corresponds to spin @xmath43 , and @xmath44 is associated with the chiral degrees of freedom @xmath26 . another way of writing a class of hamiltonian generalizing the spin tube model ( [ heff ] ) is :    @xmath45    the effective hamiltonian for the spin tube is obtained for ,    @xmath46    for a tube made of xxz chains , one has , instead@xcite : @xmath47 the parameters @xmath48 and @xmath49 in eq . ( [ ham ] ) measure the xxz anisotropy for spin and chirality , respectively . when both of them are equal to 1 , the hamiltonian eq . ( [ ham ] ) is @xmath50 symmetric . for @xmath51 , @xmath52 , @xmath53 the two chains are equivalent , and can be parameterized as :    @xmath54    hamiltonians of the type eq . ( [ ham ] ) can be mapped onto hamiltonians of the type eq . ( [ eq : basic_hamiltonian ] ) . the correspondence is given by : @xmath55 with the identification @xmath56 , @xmath57 . since writing the hamiltonian in the form ( [ eq : basic_hamiltonian ] ) is less restrictive than in the form ( [ ham ] ) ( i.e. the former includes the case @xmath58 ) , we focus on the hamiltonian ( [ eq : basic_hamiltonian ] ) . hamiltonians of the type eq . ( [ eq : basic_hamiltonian ] ) are also encountered in a different context than the spin - tube model . in particular , a hamiltonian of the type ( [ eq : basic_hamiltonian ] ) has been proposed by mostovoy and khomskii as a model for the spin gap formation in the @xmath0 @xcite and @xmath4 @xcite compounds . in that case , the @xmath59 spins correspond to the real spin of the system whereas the @xmath60 spins are pseudospins associated with _ orbital _ degrees of freedom . these spin - orbital models can be derived from a multiband hubbard model . the derivation is reviewed for instance in ref . . let us discuss first the case @xmath61 , @xmath62 . the hamiltonian describes two coupled heisenberg chains with a biquadratic coupling preserving the @xmath63 symmetry . actually , the full symmetry group is larger than su(2 ) . one has : @xmath64=0 \\hspace{0.5 cm } [ h,\\vec{s}_{2,\\text{tot.}}]=0\\ ] ] and the full symmetry group is therefore @xmath50 rather than the su(2 ) symmetry that follows from @xmath65=0 $ ] . as a result the spectrum consists of @xmath66 multiplets@xcite . for @xmath67 , the hamiltonian ( [ eq : basic_hamiltonian ] ) has been shown to have an even larger @xmath68 symmetry and to reduce to an integrable @xmath68 spin chain @xcite . the spectrum of the su(4 ) spin chain has been obtained by the bethe ansatz @xcite , and the correlations functions have been obtained by non - abelian bosonization techniques@xcite , identifying the low energy effective theory describing the spin chain as the @xmath69 wznw model . the integrable @xmath68 spin - chain has also been intensively studied numerically using quantum monte carlo ( qmc ) @xcite or density matrix renormalization group ( dmrg ) and lanczos exact diagonalization ( ed)@xcite in the context of the spin - orbital models . the ground state energy , and excited state energy were obtained in good agreement@xcite with analytical calculation using the bethe ansatz@xcite . the numerical calculation of the correlation functions @xcite reproduces results of the the continuum field theoretical treatment @xcite . at @xmath70 perturbations are generated which lower the @xmath68 symmetry to @xmath71 and render the hamiltonian non - integrable . these perturbations have been recently studied @xcite by describing the chain away from the integrable point as a perturbed @xmath69 wzw model . it was found that for @xmath72 , a gapless phase is obtained while for @xmath73 , a gap is formed . a different field theoretical treatment in the limit @xmath74 also leads to the appearance of a gapped phase . for @xmath75 , the ground state wavefunction could be obtained exactly in matrix product form@xcite , of singlet states along the legs of the ladder . this picture is in good agreement with the predictions of the field theoretical treatment . the dependence of the gap on the coupling for the range @xmath76 was obtained by dmrg calculations@xcite . it was found that for @xmath77 , the gap increases proportionally to @xmath78 in agreement with the weak coupling bosonization treatment , and vanishes for @xmath79 , which is the su(4 ) symmetric point as predicted . the dmrg calculations of ref . showed however a power law gap opening . such power law gap opening can only be explained by the presence of a relevant operator in the continuum description . however , no such operator was obtained in the bosonization treatment@xcite . moreover , if a relevant operator was present in the continuum theory , the absence of a gap at @xmath80 would be the result of the coefficient of this operator vanishing precisely at @xmath80 . but then , in contrast to what is observed in numerical calculations , a gap would also obtain for @xmath81 . a solution to this puzzle has been suggested recently@xcite . in ref . , the gap has been calculated by assuming that the first excited state was in the subspace @xmath82 . this assumption was shown to be incorrect in the gapped phase in which the first excited state lies in the subspace @xmath83 . when corrected@xcite , a slow increase with @xmath84 is found , compatible with an exponential gap opening . the correlation functions @xcite do not show incommensuration , in agreement with the field theoretic approach @xcite . taking @xmath85 and @xmath62 in ( [ eq : basic_hamiltonian ] ) preserves the @xmath71 symmetry . this case has been investigated numerically@xcite with @xmath86 . it was shown that a gapless gapped phase transition obtained as @xmath87 was increased . this work was followed by analytical investigation based on the perturbed @xmath69 wzw continuum theory@xcite . the analytical investigations established the existence for a given @xmath78 of an extended gapless region in the plane @xmath88 that contains the line @xmath89 previously discussed . in the present work , we consider the general case of @xmath90 and @xmath91 . this case includes in particular the spin tube model . we will focus on the regime @xmath92 and apply methods similar to those of ref . . in this section , we derive the phase diagram of two xxz spin chains weakly coupled by a biquadratic exchange . we first recall the bosonization of a spin chain in sec . [ sec : single_chain ] . this section can be skipped by readers familiar with bosonization . then , we discuss the bosonization of the two coupled chains system in sec . [ sec : biquadratic_coupling ] . this allows us to derive renormalization group ( rg ) equations for the coupling constants of the problem . finally , in sec . [ phasediagram ] , we discuss the phase diagram deduced from the analysis of rg equations . in this section , we recall briefly the derivation of the bosonized hamiltonian and spin operators that describe an isolated xxz chain . we follow the well known abelian bosonization procedure for spins @xcite . the xxz spin chain is described by the hamiltonian : @xmath93 the xxz spin chain hamiltonian is first transformed into an interacting fermionic system on the lattice by expressing the spin operators @xmath94 , @xmath95 , @xmath96 in terms of fermion operators @xmath97 , @xmath98 , using the jordan - wigner transformation@xcite :    @xmath99    this transformation turns the xxz hamiltonian into a model of spinless fermions with nearest neighbor interaction described by the hamiltonian , @xmath100 for @xmath101 , the hamiltonian ( [ spinlessf ] ) describes non - interacting fermions and is easily diagonalized . to proceed , we restrict our attention to the low - energy sector of the theory , captured by the continuum theory . introduce the left ( right ) chiral fermion fields @xmath102 containing momenta close to the fermi points @xmath103 , ( @xmath104 with @xmath98 the lattice spacing ) , @xmath105 the continuum fermi fields are then reexpressed in terms of bosonic field@xcite , as follows :    @xmath106    where the pair of conjugate fields , @xmath107 satisfy the following commutation relation : @xmath108=\\imath \\delta(x - x^\\prime),\\ ] ] and the field @xmath109 , dual to @xmath110 , is defined as : @xmath111    the spin operators eqs . ( [ jwp])([jwz ] ) , can be expressed in the continuum limit as : @xmath112 \\mbox { , } \\mbox { } s^z(x)=\\frac{s^z_n}{a}=-\\frac { \\partial_x \\phi } \\pi + \\frac{e^{\\imath \\pi \\frac x a } } { \\pi a } \\cos 2 \\phi,\\end{aligned}\\ ] ]    introducing normal ordering with respect to the fermion vacuum , one has : @xmath113    where @xmath114 indicates normal ordering . the average @xmath115 is the ground state energy of the chain and can be found by the bethe ansatz@xcite . however , as long as one is only interested in the correlation functions of the single chain , one can simply drop this contribution and focus on the normal ordered terms that describe the excitations above the ground state . our task is thus to derive a bosonized expression of the normal ordered product in eq . ( [ eq : normal_order ] ) . some care is needed in order to obtain correct results@xcite , and one finds : @xmath116 + \\frac { e^{\\frac { \\imath \\pi x } a}}{\\pi } \\sin 2 \\phi \\nonumber \\\\ : s_i^zs_{i+1}^z+ s_i^z s_{i+1}^z : & = & \\frac 2 { \\pi^2 } ( \\partial_x \\phi)^2 + \\frac 2 { ( \\pi a)^2 } e^{\\imath \\frac{\\pi x } a } \\sin 2 \\phi + \\frac { 2 \\cos 4\\phi}{(2\\pi a)^2 } + \\text{irrelevant terms \\ldots}\\end{aligned}\\ ] ] the oscillating terms in eq . ( [ eq : bosonized_quad ] ) are dropped from the hamiltonian after integration over @xmath117 . the hamiltonian @xmath118 , eq . ( [ spinlessf ] ) then becomes :    @xmath119-\\frac { 2\\delta}{(2\\pi a)^2 } \\int dx \\cos(4\\phi),\\ ] ]    where for @xmath120 , u&=&aj(1+)^1/2 + k&=&(1+)^-1/2 + & = & j_za.[deltaequiv ]    thus , the bosonized form of @xmath118 reduces to a sine - gordon hamiltonian , where the cosine terms come from the intrachain umklapp process@xcite . the renormalization group treatment shows@xcite that in the vicinity of the xy point , the cosine terms are irrelevant , so that asymptotic properties are described by a free scalar field with renormalized @xmath121 . since the xxz chain is integrable , it can be shown that the gapless spectrum extends to the whole region @xmath122 . moreover , it is possible to obtain an analytic expression for the renormalized @xmath121 from the exact solution@xcite . one finds : @xmath123 @xmath124 the isotropic point @xmath36 ( antiferromagnetic heisenberg model ) corresponds , in the bosonization description , to @xmath125 and @xmath126 . at this point @xmath127 is marginally irrelevant . for @xmath128 , the exact solution shows that a gap opens in the excitations of the system@xcite , and that an ising order of the spins along the z axis is obtained . this result can also be found from a bosonization procedure valid in the vicinity of the isotropic point . we now proceed to derive , using the results reviewed in the previous subsection , the bosonized hamiltonian of two non - equivalent coupled xxz chains . to bosonize the hamiltonian @xmath129 , eq . ( [ h0 ] ) describing two decoupled xxz chain we introduce two pairs of dual fields ( one pair for each chain ) @xmath130 ( @xmath131 ) as defined in sec . [ sec : single_chain ] . the bosonized form of the hamiltonian @xmath129 is then :    @xmath132-\\frac{2 \\delta_\\alpha}{(2\\pi a)^2}\\int dx \\cos 4\\phi_\\alpha \\right\\},\\end{aligned}\\ ] ]    with the fields @xmath133 and @xmath134 having _ a prori _ different velocities and luttinger couplings , @xmath135 the bosonization formulas for the spins ( [ spin - operators ] ) are unchanged except for the obvious introduction of a chain index .    in order to have the full bosonized hamiltonian , we now have to derive the bosonized form of the biquadratic exchange ( [ hbiq ] ) . the first step is to normal order using eq . ( [ eq : normal_order ] ) . this step is important since it leads to non trivial contributions to the quadratic part of the hamiltonian . we introduce the terms : @xmath136 where @xmath131 that measure the strength of these corrections . having expressed the hamiltonian in a normal ordered form , we can apply eq . ( [ eq : bosonized_quad ] ) to obtain the bosonized expression . the oscillating terms of eq . ( [ eq : bosonized_quad ] ) give rise to an interchain coupling term , the strength of which is given by :    @xmath137    collecting everything , one obtains the following bosonized biquadratic exchange : @xmath138 \\nonumber \\\\ & + & a_2 \\int \\frac{dx}{\\pi } \\left[(\\pi \\pi_1)^2 + ( 1 + 2\\delta_1/\\pi ) ( \\partial_x \\phi_1)^2 \\right ] + \\text{irrelevant terms \\ldots},\\end{aligned}\\ ] ] the terms in @xmath139 form a mean - field like interchain interaction . for @xmath140 , these terms merely produce a renormalization of the velocities and luttinger liquid exponents with respect to the decoupled chains . however , in the case where @xmath141 or @xmath142 , these terms become crucial since they give a finite velocity to the @xmath133 ( resp . @xmath134 excitations ) excitations . such a case is realized in the spin - tube problem where the exchange constant of the pseudospins @xmath27 is zero . we see that the mean - field like contribution of the spin fluctuations contributes in that system to provide an exchange constant and thus a finite velocity to the pseudospin excitations . of course , in such case , the bosonization procedure is not really justified since interactions are of the order of magnitude of the bandwidth of the spin or pseudospin excitations . however , it is usual in quasi - one dimensional systems to have a continuity between the weak and the strong coupling regime . moreover , a mean field theoretical treatment in the xy limit ( @xmath143 ) leads to similar results to the bosonization treatment . details can be found in app . [ app : mean - field ] . we will therefore assume that although not fully justified in the spin tube case , bosonization nevertheless leads to qualitatively correct results concerning the phases of the system and the overall behavior of correlations in these various phases . a quantitative treatment ( in particular of the phase boundaries ) requires numerical simulations that are beyond the scope of this paper . the present treatment shows us that in weak coupling the two chains are described by a bosonized hamiltonian : @xmath144}\\nonumber \\\\ & + &   \\frac { 2g}{(2 \\pi a)^2}\\int dx \\sin 2\\phi_1 \\sin 2\\phi_2   \\end{aligned}\\ ] ]    we shall analyze the model perturbatively , with results valid up to a given value of @xmath78 : it is known that in the strong coupling regime of the two chains with biquadratic exchange there is a special value of the interchain coupling at which the model has @xmath68 symmetry . at this special point , the model develops a gapless phase described by a @xmath69 wznw model . such an effect is non - perturbative : the resulting critical point has a conformal anomaly @xmath145 whereas the original unperturbed model has @xmath146 . this implies by zamolodchikov s @xmath147theorem@xcite that the transition to the @xmath69 can not be predicted by a rg calculation that always leads to a decrease of @xmath147 . beyond this special value of @xmath78 , the weak coupling theory would lead to incorrect predictions and an alternative approach such as the one of lecheminant and azaria is needed . on the other hand , it is expected to give qualitatively correct predictions when the coupling is smaller than the critical value . in the remainder of the paper we shall thus work in the weak coupling regime where the weak coupling theory is valid . in the following section , we will discuss the rg treatment of the weak coupling model .      in the following analysis , we will neglect the velocity difference between chains 1 and 2 since usually velocity differences do not play an important role in the derivation of the phase diagram by rg techniques . however , for the sake of completeness , we have given in app . [ app : momentum_shell_rg ] the rg equations for non - equal velocities derived using a momentum shell integration technique@xcite . when velocity differences are neglected , the renormalization group equations for @xmath148 can be easily derived from the hamiltonian ( [ non - equivalent - chains - ni])([hbiqbos ] ) using operator product expansions ( ope ) @xcite . the renormalization group equations for @xmath149 neglecting velocity differences are : @xmath150 while the renormalization group equations for @xmath151 are : @xmath152    we now proceed to deduce the weak coupling phase diagram of the model ( [ eq : scaling_rge ] ) indicates that @xmath153 is a relevant variable when @xmath154 , while the variables @xmath155 become relevant when respectively , @xmath156 , @xmath157 . there are therefore four cases to distinguish . in the first case : @xmath158 , there are no relevant operators and the system is in a gapless state . in the second case : @xmath159 , @xmath160 , there is a single relevant operator ; for @xmath161 ( or equivalently @xmath162 ) , there are two , while for @xmath163 there are three relevant operators . these four different regions are shown in fig . [ fig : phase_diagram ] .    in the presence of relevant operators , rg equations cease to be valid as soon as the dimensionless coupling become @xmath164 , and we have to determine the nature of the strong coupling fixed points in order to predict the phase diagram . we see that @xmath151 are driven to zero by the flow of the rg when there is a relevant operator so that the fields become classical . as a result , @xmath165 are locked at average values @xmath166 that minimize the ground state energy and a gap opens in the excitations of these fields@xcite . when these fields are locked , it is also known that the exponentials of the dual field have exponential decay@xcite . let us consider first the case with @xmath153 the only relevant operator . then , the minimization of the ground state energy requires @xmath167 , i.e. @xmath168 . it is then clear that @xmath169 as well as @xmath170 , which are the staggered component of @xmath96 and @xmath94 , will display an exponential decay . it can also be shown that the uniform component of the spins also present an exponential decay . as a result we have a spin - liquid phase that presents only short range order in all its spin correlations . as we shall see , this spin - liquid phase is a dimerized phase whose properties are discussed extensively in sec . [ sec : dimerized ] . in the case @xmath171 ( decoupled chains ) the analysis is even simpler . then the two chains remain decoupled , and we are left with the analysis of the usual sine - gordon model . it is then known that when @xmath172 is relevant , the field @xmath173 is locked . the analysis of the resulting strong coupling fixed point can be found for instance in ref . . it is found that the strong coupling fixed point is associated with the ising antiferromagnetic phase of the xxz chain at @xmath128 in which the staggered component of @xmath96 has a non zero expectation value in the ground state .    when @xmath153 and at least one of the @xmath172 are relevant , there are two possible candidates for the ground state . considering eq . ( [ eq : scaling_rge ] ) , we see that the effect of the biquadratic interchain interaction is to reduce the effective @xmath174 . physically , this means that the tendency to form singlets competes with the tendency to form an ising antiferromagnet . two scenarios are possible . one is that there is a well defined phase boundary between a pure spin - liquid state and a pure ising antiferromagnet state . the second scenario is that there is a crossover between the two pure states as @xmath175 is varied . in such case , increasing @xmath78 would lead to a gradual disappearance of antiferromagnetic order leaving a purely singlet state as @xmath176 . since in both phases it is the same field that orders , there is _ a priori _ no reason to exclude a mixed spin - liquid antiferromagnet order . thus , the first scenario appears extremely unlikely . a numerical investigation of the crossover could be very interesting as a toy model of a crossover from spin - liquid to antiferromagnetism . it is interesting to remark that if @xmath177 , and @xmath178 , the equations ( [ eq : scaling_rge ] ) can be integrated analytically . two phases are obtained , separated by a line @xmath179 . in the first one , @xmath180 and @xmath181 which corresponds to a ground state with singlet order . in the second one , @xmath182 and @xmath183 , which corresponds to antiferromagnetic order . the rg equations cease to be valid for @xmath184 or @xmath185 . if when this scale is reached @xmath153 and @xmath186 are of the same order of magnitude , there is a possibility of obtaining a mixing of antiferromagnetism and dimer order . note that even on the line @xmath187 , there is a finite correlation length . this is a further evidence for a progressive crossover from dominant antiferromagnetic order to dominant dimer order . it is also possible to give a purely classical treatment for @xmath177 by simply minimizing the ground state energy with respect to @xmath188 and @xmath189 . in the case @xmath190 , one finds that there are three different regimes . for @xmath191 one obtains @xmath192 corresponding to a purely dimerized phase . for @xmath193 , one obtains @xmath194 and @xmath195 . this corresponds to persistence of dimerization in the chain with the smallest tendency to antiferromagnetic order , whereas the chain with the strongest tendency to antiferromagnetism is found in state with mixed dimer and antiferromagnetic order . the antiferromagnetic order parameter in that chain , @xmath196 , then assumes the value @xmath197 . finally in the region @xmath198 , both chains display antiferromagnetism with @xmath199 . these results are summarized on figure [ fig : classical_phase_diag ] . for @xmath200 , the region with mixed antiferromagnetic and dimer order shrinks to a single point . it would be interesting to see how quantum fluctuations affect the present picture and in particular determine whether sharp transitions are preserved or if they evolve into crossovers .      in this section , we try to estimate the position of the crossover between the spin - liquid and the antiferromagnet . this can be done roughly by comparing the correlation lengths in the antiferromagnet and in the spin - liquid phase . using the rg equations , for small @xmath201 , we can neglect the renormalization of @xmath151 . this leads to :    @xmath202    when any of these quantities become of the order of the energy cutoff @xmath203 , the rg equations cease to be valid and the phase that is obtained is determined by minimizing the ground state energy .    for @xmath153 , the strong coupling is obtained at a length scale : @xmath204 this is the correlation length of spin fluctuations in the spin - liquid phase . for @xmath205,@xmath206 the strong coupling is obtained respectively at length scale : @xmath207 it is clear that the shortest length corresponds to the first operator to attain strong coupling . therefore , the phase that is obtained is the one with the shortest correlation length . for @xmath177 , this is in agreement up to a constant with the criterion derived from the rg equations ( [ eq : scaling_rge])([eq : second_order_rge ] ) . the comparison of correlation length allows to draw a rough phase boundary between the antiferromagnet and the dimerized phase that could also be obtained by numerically integrating the rg equations ( [ eq : scaling_rge])([eq : second_order_rge ] ) starting from weak coupling and any @xmath151 . the equation of the phase boundary is in the case of equivalent chains @xmath178 , @xmath208 : @xmath209 let us note that in the isotropic spin - tube case , the operators causing antiferromagnetic order are ( marginally ) irrelevant so that there is only singlet order . however , in the case of an anisotropic spin tube ( 3 coupled xxz spin chain with @xmath210 ) , such competition becomes possible . completely decoupled chains exhibit for @xmath210 an ising antiferromagnetic phase . introducing a strong enough biquadratic interchain coupling favors on the other hand a spin liquid phase . the competition of the two should produce a crossover from the ising antiferromagnet to the spin liquid of the type discussed in the preceding section . in this section , we discuss the properties of the spin liquid phase . in the case of equivalent chains , further progress can be made by using symmetric and antisymmetric modes allowing in particular a refermionization of the problem and the calculation of some correlation functions@xcite . this will be discussed in sec . [ sec : equivalent_chains ] . in the general case with inequivalent chains , such decoupling is no longer possible . however , it is still possible to present a simple semiclassical picture of the nature of excitations above the ground state . this will be the subject of section [ sec : non_equivalent_chains ] . we will focus on region @xmath211 , @xmath159 , in which the only relevant operator is the biquadratic exchange , @xmath212 . the ground state shows long - range order of the fields @xmath133 and @xmath134 . the expectation values of the ordered fields are : @xmath213 and as a result , @xmath214 . using eq . ( [ eq : bosonized_quad ] ) , this implies that a dimerized order develops both in spin variables and pseudospin variables , i.e. @xmath215 ( @xmath131 ) . in parallel with that , we have @xmath216 , so that by eq . ( [ spin - operators ] ) @xmath217 , and the correlation functions @xmath218 as @xmath219 . it is also well known that when the fields @xmath220 are ordered , the correlation functions of the disorder operators @xmath221 decay exponentially at large distances . using again the bosonization formulas for the spins , eq . ( [ spin - operators ] ) , this implies an exponential decay of all correlation functions : @xmath222 and @xmath223 where @xmath224 . therefore , the dimerized phase appears as a spin liquid state formed of singlets of spins on both chain 1 and chain 2 . such a conclusion was reached previously in a numerical investigation of the spin tube @xcite and by considering the equivalent isotropic chains at the solvable point@xcite @xmath225 where the ground state wavefunction can be obtained exactly in matrix product form . our results show that such mechanism of spin liquid ground state formation does not require su(2 ) symmetry . this mechanism is somewhat reminiscent of the spin - peierls transition@xcite , the pseudospins playing here the role of the phonons . this is the essence of the mostovoy - khomskii model@xcite for the `` spin - peierls '' transition at @xmath226k in @xmath0 .    in the case of the spin - tube the same picture of the ground state obtains , with the ground state of the spin - tube formed by _ singlet of spins _ on even bonds and _ singlet of chiralities _ on odd bonds or by _ singlet of spins _ on odd bonds and _ singlet of chiralities _ on even bonds ( see fig .  [ fig : ground_state ] ) .    for the moment , we have only been able to discuss the nature of the ground state . however , it is also important to discuss the nature of the excitations as well as the various correlation functions . in order to do that , it is worth to restrict first to the simple case of two equivalent chains , in which the physical picture is the clearest . when the two chains are equivalent , we introduce the fields@xcite : @xmath227 and their conjugate fields : @xmath228    so that the total hamiltonian can be completely decoupled into the symmetric and antisymmetric parts ,    @xmath229    @xmath230 - \\frac{g}{(2\\pi a)^2 } \\int dx \\cos \\sqrt{8}\\phi_s\\ ] ]    @xmath231 + \\frac{g}{(2\\pi a)^2 } \\int dx \\cos \\sqrt{8}\\phi_a,\\ ] ]    where the magnetic field couples only to @xmath232 , and only the most relevant operators have been taken into account . the elementary excitations can be discussed in terms of solitons of two decoupled sine - gordon models . the solitons of the hamiltonian @xmath233 carry a total spin @xmath234 whereas those of hamiltonian @xmath235 carry a spin 0 as they do not couple to the magnetic field . these solitons are represented in fig . [ fig : solitons ] . it is also convenient to use the canonical transformation @xmath236 , @xmath237 followed by a refermionization . introducing the fermion operators : @xmath238    where @xmath239 , one can finally rewrite @xmath240 in the form : @xmath241 where @xmath242 and @xmath239 . the couplings are given by : @xmath243    at the isotropic point ( @xmath244 ) , one has @xmath245 , so that @xmath246 is a free fermion hamiltonian @xcite . similarly to the spin ladder , where @xmath247=0 $ ] , the excitation spectrum can be split into a singlet and a triplet with spin @xmath248 . however , in contrast to the spin ladder case , the triplet and the singlet here have the same mass . this is the signature of a larger symmetry group , @xmath249 . the correlation functions can be obtained from mapping the free fermion hamiltonian onto two non - critical ising model @xcite exhibiting the @xmath250 symmetry . remarkably , although the system has a spin gap , these correlation functions are very different from those of a spin-1 chain @xcite or a spin ladder @xcite . in the chain with biquadratic exchange , the response functions do not show any particle - like delta function peak in their imaginary part , but only a two particle continuum@xcite even in the vicinity of @xmath251 . this is to be contrasted with the spin ladder @xcite which shows a delta function peak associated with a single particle excitation at @xmath251 . the two chains with biquadratic interactions thus form a `` non - haldane '' spin liquid .    away from the isotropic point , the hamiltonian can still be refermionized but the fermions ( solitons ) have interactions which preclude a mapping on a non - critical ising model . however , in the anisotropic case , when the antiferromagnetic intrachain interaction is irrelevant one has @xmath252 . this implies that no bound states of solitons can be formed since there is no coherent propagation of two solitons@xcite , hence the absence of a single particle peak . a calculation of correlation functions is in principle possible using as form factors approach , but this is far beyond the scope of the present paper . since @xmath235 and @xmath233 remain decoupled , the excitations having @xmath234 do not interact with the excitations having @xmath253 . this can be understood as a consequence of the @xmath254 symmetry of the problem and the resulting separate conservation of @xmath255 and @xmath256 .      in the case of two non - equivalent chains , one can not decouple the hamiltonian into two sine - gordon hamiltonians . therefore , determining the nature and the quantum numbers of elementary excitations is not as straightforward . the preceding canonical transformation leads to the following hamiltonian : @xmath257 + \\frac{(u_1/k_1+u_2/k_2 ) } 2 [ ( \\partial_x \\phi_s)^2 + ( \\partial_x \\phi_a)^2]\\right . \\nonumber \\\\   & + & \\left . \\frac { u_1 k_1 -u_2 k_2}{2 } \\pi^2 \\pi_s \\pi_a + \\frac { u_1 /k_1 - u_2 /k_2 } 2 \\partial_x \\phi_s \\partial_x \\phi_a \\right]+ \\frac{2g}{(2\\pi a)^2 } \\int dx [ \\cos \\sqrt{8 } \\phi_s -\\cos \\sqrt{8 } \\phi_a ] \\end{aligned}\\ ] ] shifting @xmath258 , we see that the resulting hamiltonian has a @xmath259 invariance under @xmath260 . a rescaling @xmath261 , @xmath262 , and a refermionization brings the hamiltonian to the form : @xmath263    \\nonumber \\\\ & + &   g(\\rho_{r , s}(x)\\rho_{r , a}(x)+\\rho_{l , s}(x)\\rho_{l , a}(x))+ \\tilde g_1 \\sum_{r\\ne r'}\\rho_{r , r}(x)\\rho_{l , r'}(x ) + \\tilde g_2 \\sum_r \\rho_{r , r}(x)\\rho_{l , r}(x)\\end{aligned}\\ ] ] as a result , there is now an interaction between the excitations of spin @xmath264 ( the @xmath98 fermions ) and the excitations of spin @xmath265 ( the @xmath266 fermions ) . we have : @xmath267\\\\ g&=&\\pi \\left [ u_1\\left(k_1+\\frac 1 { 4k_1}\\right ) -        u_2\\left(k_2+\\frac 1 { 4k_2}\\right)\\right ] \\\\ \\tilde g_1&= & \\pi\\left [ u_1\\left(\\frac 1 { 4k_1}-k_1\\right ) +        u_2\\left(k_2-\\frac 1 { 4k_2}\\right)\\right ] \\\\   \\tilde g_2&= & \\pi\\left [ u_1\\left(\\frac 1 { 4k_1}-k_1\\right ) -        u_2\\left(k_2-\\frac 1 { 4k_2}\\right)\\right ] \\\\ m & = & \\frac{g}{4 \\pi a } \\end{aligned}\\ ] ]    the fermionic version of the model is a generalization of the massive thirring model . the fields carry spin and the interactions break spin rotation symmetry . it can be checked that the interaction of @xmath98 with @xmath266 fermions disappears only for @xmath268 , @xmath269 . not much can be said of the elementary excitations of hamiltonian ( [ eq : fermion_non_equivalent ] ) due to the absence of an exact solution . in order to gain some insight into the elementary excitations of the dimerized state in the case of non - equivalent chains , we resort to semi - classical approximations . clearly , we can search for a semi - classical minimum of ( [ eq : rotated_non_equivalent ] ) with either @xmath270 or @xmath271 . this corresponds to a single soliton in the system . in the general case , such excitations are associated with a single fermion , either @xmath98 or @xmath266 . in order to obtain a physical picture for this type of elementary excitations , let us calculate the average `` magnetization '' for the fields @xmath133 and @xmath134 when there is a soliton connecting the two degenerate dimerized ground - states . in the case @xmath270 , @xmath133 decreases from @xmath272 to @xmath273 while @xmath134 increases from @xmath273 to @xmath272 . we immediately get :    @xmath274    another solution is obtained by reversing the sign of @xmath220 leading to @xmath275 . the case @xmath271 corresponds to @xmath276 . in each case , the elementary excitations are formed by breaking a singlet on neighboring sites on each chain . such objects then propagate coherently . in the case of the spin tube , this corresponds to having one unpaired spin associated with one unpaired chirality pseudospin . such an excitation has @xmath277 , @xmath278 . it is the spinon of ref . . thus the elementary excitations of the model can be easily visualized as an unpaired spin and an unpaired chirality forming a triplet or a singlet diagonal bond ( see fig . [ fig : singlet_triplet_ne ] ) . this is the soliton in the dimer order . this picture generalizes from isotropic equivalent spin chains @xcite to the case of inequivalent and anisotropic chains . an open question is whether in the case of inequivalent chains bound states of these elementary excitations can be obtained in contrast to the case of equivalent chains . a necessary condition is that there exists attractive interactions between @xmath98 and @xmath266 fermions . the study of such bound states could be of interest in relation with light scattering experiments on @xmath0 . besides semi - classical approximation , another approximate treatment is possible . in the case where @xmath268 , @xmath279 and @xmath280 , the hamiltonian ( [ eq : full_bosonized_hamiltonian ] ) is the double sine gordon model@xcite , or the bukhvostov - lipatov model@xcite . the model is known to be bethe ansatz solvable@xcite but its elementary excitations and @xmath25 matrix have only been obtained recently @xcite and shown to be identical to those of the double sine - gordon model on its integrable line . the spectrum of the model @xcite is consists of four massive particles carrying two quantum numbers @xmath281 , and the @xmath25 matrix is@xcite : @xmath282 where @xmath283 is the @xmath25 matrix of a sine gordon model having the parameter @xmath284 and @xmath285 . as a result , one of the sine gordon models is in the attractive regime and has a spectrum made of fermions and bound states of fermions whereas the second sine - gordon model is is the repulsive regime and has a spectrum containing only fermions . the mass of the fundamental fermion is @xmath286 . for @xmath287 , one recovers the equivalent chain and the mass of the bound states is then : @xmath288    since for @xmath289 , the operator @xmath290 is the most relevant , it is reasonable to expect that neither the marginal perturbations due to @xmath291 nor the less relevant perturbations @xmath292 change the gapped nature of the spectrum . in this regime , one should not observe any bound state , since the @xmath293 bound state only exists for @xmath294 . in terms of the original spin chain , the double sine - gordon regime should be accessible if one chooses to have one chain with @xmath210 and the other chain with @xmath128 in such way that @xmath280 and @xmath295 . however , the double sine - gordon regime would not be observed in the spin tube case , in which we should have @xmath296 . we expect that in the spin tube case , the system has more quantum fluctuations than in the double sine - gordon regime . therefore , no bound states of spinons will form . this heuristic argument agrees with the numerical calculations on the spin tube that show no bound state of spinons@xcite . in this section , we discuss the effect of the application of a magnetic field on the dimerized phase . in general , the application of a magnetic field to a gapped one dimensional spin liquid system results in the closure of the gap for a magnetic field of the order of magnitude of the gap . below the critical magnetic field the magnetization is zero . above the critical magnetic field the magnetization increases as @xmath297 , the system is in a single component luttinger liquid state and has incommensurate spin correlations@xcite . here , we have to consider two _ a priori _ different cases . in the first one and most academic , the two coupled chains carry real spins that couple to the magnetic field . in the second case , only one chain carry a spin that couple to the magnetic field , the other one carrying only a pseudospin degree of freedom that does not couple to a magnetic field . this last case corresponds to the spin - orbital models@xcite and to the spin tube model@xcite . the behavior of the spin - orbital model in a magnetic field has been discussed in refs . and . both references study models with @xmath50 symmetry in the absence of the magnetic field . it is shown that in the vicinity of the su(4 ) point , the spin - orbital model becomes equivalent to the @xmath298 gross neveu model describing the gapped modes plus a @xmath299 cft that describes the gapless magnetic modes . also , in ref . , the weak coupling case has been discussed . the case where both chains carry spin will be dealt with in sec . [ sec : both_w_spin ] and the case of a single chain carrying spin in sec . [ sec : one_w_spin ] . if both chains carry spin , the coupling to the magnetic field ( taken parallel to the z axis ) is : @xmath300 in that case , we can use the decoupling of sec . [ sec : equivalent_chains ] , eqs . ( [ hs ] ) and ( [ ha ] ) . the coupling to the magnetic field is : @xmath301      we consider the case where the two chains are equivalent . this problem has been discussed in the context of spin ladders@xcite . the gap in the antisymmetric modes @xmath220 is not affected by the presence of the magnetic field . on the other hand , for a sufficiently large magnetic field @xmath302 , the gap in the symmetric modes closes and the magnetization @xmath303 behaves as @xmath304 for @xmath302 . moreover , it can be shown that the low energy modes of @xmath232 are described by the following hamiltonian : @xmath305\\ ] ] and the exponent @xmath306 takes the universal value 1/2 at @xmath307 . correlation functions in the incommensurate phase can be obtained in the isotropic case by a calculation similar to the spin - ladder case @xcite . this time , @xmath308 is finite so that @xmath309 has exponentially decaying correlations . as a result , one has : @xmath310 a simplified expression for the operator @xmath311 is : @xmath312 and the correlations of @xmath96 are : @xmath313 there are subleading power law corrections at @xmath314 . as shown by furusaki and zhang , these corrections are missed if one naively neglects the band curvature after refermionization @xcite . these corrections can also be obtained@xcite by using the haldane expansion of the spin operators and retaining the terms up to @xmath315 as we did here .      in the case of non - equivalent chains , the problem gets more complicated . the magnetic field still couples only to @xmath232 . however , when the magnetic field @xmath316 exceeds the field @xmath317 needed to close the gap in the @xmath266 modes , the appearance of a non - zero @xmath318 creates an effective magnetic field that couples to @xmath319 . if this magnetic field is not strong enough to close the gap in the @xmath220 modes , the system remains in a one - component luttinger liquid for fields @xmath316 not much stronger than the critical field @xmath317 . for @xmath316 sufficiently large , the generated effective field can close the gap in the @xmath98 modes leading to a two component luttinger liquid . since no experimental ladder system with a biquadratic exchange much larger than the quadratic exchange much larger that the quadratic exchange and made of two non - equivalent chains is presently available , this two - step transition to a two component luttinger liquid is unlikely to be observed experimentally . this case includes the spin tube and the mostovoy - khomskii model and is therefore the most relevant physically . this case has been discussed for two coupled @xmath71 symmetric chains in ref . . in the case where only one chain , say chain @xmath320 to fix notations , carries spin , the interaction with the magnetic field is given by a term : @xmath321 in the case of equivalent chains , we can use the same decoupling of sec . [ sec : equivalent_chains ] , eqs . ( [ hs ] ) and ( [ ha ] ) as in the preceding section . however , there is an important difference . now , we have the coupling to the magnetic field in the form : @xmath322 as a result , now the magnetic field couples to both @xcite @xmath232 and @xmath220 . moreover , the strength of the couplings is exactly the same . we start with the discussion of equivalent chains . then , we discuss non equivalent chain . we will show that in both case , the closure of the gap leads to a two - component luttinger liquid behavior in contrast with the usual spin - liquid systems that lead to a single component luttinger liquid behavior@xcite . we will also give the expression of correlation functions in the luttinger liquid phase . as a result of the symmetry between @xmath220 and @xmath232 , the gap in the symmetric and the antisymmetric mode close simultaneously , leading to a two component luttinger liquid ground state under strong enough magnetic field . contrarily to the case where the magnetic field couples to both 1 and 2 spins , there is no intermediate single component luttinger liquid phase . we expect that the magnetization @xmath323 behaves as @xmath324 close to the threshold . it is also important to note that , the two sine - gordon model being equivalent , one has for the fixed point hamiltonian @xmath325 and @xmath326 . as a result , the fixed point hamiltonian is invariant under any rotation in the @xmath327 plane . we can thus write the fixed point hamiltonian as : @xmath328\\ ] ] where @xmath329 and @xmath330 . moreover , in the case of @xmath50 symmetry , we have @xmath331 . it can the be shown easily , using the refermionization procedure that @xmath125 for any magnetic field . equation ( [ eq : fp_mf_equiv ] ) has important consequences for the correlation functions , which are of the form ( for equivalent chains ) :    @xmath332   \\nonumber \\\\ \\langle ( s^z_{\\alpha}(x , t)-m_\\alpha ) ( s^z_{\\alpha}(0,0)-m_\\alpha ) \\rangle   =    \\cos(\\pi x ( 1 - 2m_\\alpha))(x^2-t^2)^{-k_\\alpha}+ \\text{constant } \\mbox { } \\frac{1}{4\\pi^2 } \\left ( \\frac{x^2+t^2}{(x^2-t^2)^2 } \\right ) , \\nonumber \\end{aligned}\\ ] ]    where the index @xmath333 indicates the spin in chain 1 or 2 , @xmath334 is the magnetization , with @xmath335 ( total magnetization ) and @xmath336 . from the above expressions we deduce the following : the correlation function parallel to the field , @xmath337 , has a staggered part shifted from the wave vector @xmath251 to @xmath338 , while the correlation function perpendicular to the field , @xmath339 , has an unshifted staggered mode and the uniform magnetization mode shifted to @xmath340 . the correlation functions for the spin of type 2 , instead , are completely unaffected by the presence of an external magnetic field . in this section , we consider the case where the two chains are not necessarily equivalent . in particular , this is the case that is realized in the spin - tube under a magnetic field .    in this case , is convenient to use the rotation , @xmath341 to bring the hamiltonian to the form : @xmath342 + \\frac{(u_1/k_1+u_2/k_2 ) } 2 [ ( \\partial_x \\phi_s)^2 + ( \\partial_x \\phi_a)^2]\\right . \\nonumber \\\\   & + & \\left . \\frac { u_1 k_1 -u_2 k_2}{2 } \\pi^2 \\pi_s \\pi_a + \\frac { u_1 /k_1 - u_2 /k_2 } 2 \\partial_x \\phi_s \\partial_x \\phi_a \\right]+\\nonumber \\\\ & + & \\frac{2g}{(2\\pi a)^2 } \\int dx [ \\cos \\sqrt{8 } \\phi_s -\\cos \\sqrt{8 } \\phi_a ] -\\frac h { \\sqrt{2 } } \\int dx \\partial_x(\\phi_s+\\phi_a)\\end{aligned}\\ ] ]    shifting @xmath343 , renders hamiltonian invariant under the interchange of @xmath232 and @xmath220 . as a consequence , the gaps in @xmath232 and @xmath220 are _ identical _ and have to close simultaneously . therefore , as in the case of identical chain , there is a transition from a gapped phase into a gapless two - component luttinger liquid phase . the most general hamiltonian for a two - component luttinger liquid is : @xmath344.\\end{aligned}\\ ] ] in the case of coupled xxz chain , the effective hamiltonian ( [ eq:2component_ll ] ) can be simplified by making use of symmetry . we know that the original hamiltonian , eq . ( [ eq : rotated_mf ] ) is invariant under the transformation : @xmath345 this symmetry must be preserved by the renormalized hamiltonian . therefore , one must have @xmath346 and @xmath347 . as a result , the effective hamiltonian ( [ eq:2component_ll ] ) is diagonalized by returning to the original variables @xmath348 . the effective hamiltonian is therefore the following : @xmath349\\ ] ] the absence of coupling between @xmath133 and @xmath134 in this hamiltonian is somewhat surprising . this can however be understood by the fact that the hamiltonian even in the presence of a magnetic field is invariant by a rotation by @xmath350 @xmath351 . thus , @xmath352 for any @xmath316 , implying that @xmath353 terms can not appear in the two component luttinger liquid hamiltonian . in contrast to the spin ladder case@xcite , the exponents @xmath354 in the hamiltonian eq . ( [ eq : effective_gapless ] ) are _ non - universal_. this can be shown in the following way . let us consider the case where @xmath355 and @xmath356 are small compared to @xmath357 , namely where the couplings in the two chains are nearly identical . in that case , we can neglect in a first approximation the terms @xmath358 and @xmath359 in the hamiltonian [ eq : rotated_mf ] . we are thus left with two decoupled sine - gordon models under a magnetic field . these sine - gordon models undergo a commensurate - incommensurate transition at a critical magnetic field . it is well known@xcite that the exponent at the transition assumes a universal value that renders scaling dimension of the cosine term equal to one . therefore , in our case , the universal value of the exponent at the transition is : @xmath125 . as a result , close to the transition the effective hamiltonian is : @xmath360 +   \\int \\frac{dx}{2\\pi } \\left [ \\frac { u_1 k_1 -u_2 k_2}{2 } \\pi^2 \\pi_s \\pi_a +   \\frac { u_1 /k_1 - u_2 /k_2 } 2 \\partial_x \\phi_s \\partial_x \\phi_a \\right].\\end{aligned}\\ ] ] returning to @xmath133 and @xmath134 , one obtains an hamiltonian of the form eq . ( [ eq : effective_gapless ] ) with : @xmath361 indicating that except in the case of equivalent chains , one should not expect universal exponents at the transition . this should be the case in particular for the spin - tube @xcite . it may provide an experimental test for the spin - orbital model@xcite of @xmath0 since the exponent @xmath362 controls the temperature dependence of the nmr relaxation rate@xcite . however , since the transition temperature between the gapped and the gapless phase in @xmath0 is @xmath363 , the magnetic field needed to close the gap should be of order @xmath364 which could make the experiment impossible . in @xmath365 , with @xmath366 , the situation is even worse . the spin and pseudospin operators are , @xmath367 \\nonumber \\\\ \\tau^z(x)&=&-\\frac{\\partial_x \\phi_2 } { \\pi } + \\frac{e^{\\imath \\frac{\\pi x } a}}{\\pi a } \\sin 2\\phi_2 , \\mbox { } \\mbox { } \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\ ; \\tau^+(x)=\\frac{e^{\\imath \\theta_2}}{\\sqrt{\\pi a } } \\left [ e^{\\imath { \\pi x } a } + \\sin 2\\phi_2   \\right],\\end{aligned}\\ ] ] where @xmath368 is the total magnetization . in the case of the spin - orbital model , the spin - spin correlation functions are therefore given by the usual formulas@xcite . the situation is however more interesting in the case of the spin tube . using the formula ( [ eq : spin_stot_chirality ] ) , one has : @xmath369,\\ ] ] where @xmath370 , and @xmath10 is the chain index . explicitly , @xmath371    this correlation function , which enters in particular in the calculation of the nmr relaxation rate , contains power - law divergences at wave vector @xmath372 but also @xmath373 due to the fluctuations of chiralities . we have presented a field - theoretical analysis of the low - energy physics of the anisotropic spin - orbital model and the three - leg ladder with periodic boundary conditions ( the spin tube ) in the strong interchain coupling limit . we gave a derivation of the field theoretical model from the lattice hamiltonian and then analyzed the phase - diagram using renormalization group equations . the system is found to exhibit a gapless phase , a spin - liquid phase or an ising antiferromagnetic phase depending on the microscopic couplings . the spin liquid ground state is two - fold degenerate , formed either by singlets of spins on even bonds and singlets of orbital pseudospins ( chirality in the spin - tube case ) on odd bonds or the other way round . the antiferromagnetic phase competes with the spin - liquid and we have discussed this competition briefly . the spin liquid phase obtains in the case of the spin tube with @xmath63 symmetry , and we discussed the nature of excitations above this spin liquid ground state . these excitations have spin @xmath374 and pseudospin @xmath375 . they are formed by introducing a free spin as a defect in the spin singlet pattern as well as a pseudospin in the pseudospin singlet pattern . these excitations lead to a kind of non haldane spin liquid analogous to the one discussed by nersesyan and tsvelik@xcite . an interesting consequence is the absence of a magnon peak at @xmath376 in the spin - spin correlation functions of the spin tube . this behavior could be tested in numerical simulations . we have investigated the effect of an applied magnetic field @xmath316 on the dimerized phase . a strong enough magnetic field @xmath302 causes the closure of the gap and the disappearance of dimer order . the resulting gapless phase is a _ two _ component luttinger liquid in contrast to the one component luttinger liquid that is observed in spin ladders . the exponents appeared to be _ non - universal _ at the transition point , in contrast with the spin ladder case@xcite . it would be interesting to obtain numerically the luttinger liquid exponents for the spin tube or the anisotropic spin orbital model . for the spin tube , we have also shown that new soft modes appeared in the spin - spin correlation functions above @xmath317 by comparison with the soft modes of the single chain . this is the result of the presence of soft chirality modes . this may be tested numerically . e. o. acknowledges support from nsf under grant nsf - dmr 96 - 14999 . we thank p. lecheminant and h. saleur for discussions and useful comments on the manuscript . @xmath377 permanent address : cnrs - laboratoire de physique thorique de lecole normale suprieure 24 , rue lhomond 75231 paris cedex 05 france we start from the hamiltonian : @xmath378 after the usual jordan wigner fermionization , this gives : @xmath379    the mean field approximation is obtained by taking : ( recall , @xmath380 is a chain index ) . @xmath381 the mean field equation are then : @xmath382 \\nonumber \\\\ t=-\\frac{2}{\\pi}(1+\\lambda t)\\sqrt{1 + \\left(\\frac{\\delta}{1+\\lambda t}\\right)^2}\\frac{\\mathbf{e}\\left(1-\\left(\\frac{\\delta}{1+\\lambda t}\\right)^2\\right)}{1-\\left(\\frac{\\delta}{1+\\lambda t}\\right)^2}\\end{aligned}\\ ] ] where @xmath383 are the complete elliptic integrals of the first and second kind respectively . for small @xmath186 , the mean field equations ( [ eq : mean_field_symmetric ] ) reduce to : @xmath384    and one obtains : @xmath385    this result from the mean field theory agrees with the prediction of bosonization since bosonization would predict the same essential singularity in @xmath186 at small @xmath78 , the interchain coupling being marginal .      in this section , we consider a problem with a hamiltonian of the form : @xmath386 after a jordan wigner transformation , the hamiltonian becomes : @xmath387    the mean field approximation is now : @xmath388    the mean field equations are now : @xmath389 \\nonumber \\\\ t_2=-\\frac{2}{\\pi}(1+\\alpha t_2)\\sqrt{1 + \\left(\\frac{\\delta_1}{t_1}\\right)^2}\\frac{\\mathbf{e}\\left(1-\\left(\\frac{\\delta_1}{t_1}\\right)^2\\right)}{1-\\left(\\frac{\\delta_1}{t_1}\\right)^2 } \\nonumber \\\\ \\delta_2=-\\frac{2\\alpha \\delta_1}{\\pi}\\sqrt{1 + \\left(\\frac{\\delta_1 } { t_1}\\right)^2}\\left [ 2\\mathbf{k}\\left(1-\\left(\\frac{\\delta_1}{t_1}\\right)^2\\right)-\\frac{\\mathbf{e}\\left(1-\\left(\\frac{\\delta_1}{t_1}\\right)^2\\right)}{1-\\left(\\frac{\\delta_1}{t_1}\\right)^2 } \\right ] \\\\\\end{aligned}\\ ] ]    for small @xmath333 , the mean field equations for @xmath390 and @xmath205 reduce to : @xmath391 one sees that a finite bandwidth @xmath392 is produced for the @xmath27 spin waves at least for small @xmath333 . the gap equations admit solutions at small @xmath186 . one expects at weak coupling an essential singularity in @xmath393 . therefore , @xmath394 should go to zero for @xmath395 . this implies that one can write : @xmath396 one can solve the mean field equations for @xmath205 and @xmath206 . one obtains : @xmath397    we obtain therefore self - consistently a gap much smaller than the smallest bandwidth . as a consequence , the correlation length is much larger than the lattice spacing , which justifies a continuum approximation . the bosonization treatment is therefore valid for @xmath395 and close to the xy limit . in this section , we derive rge for the quantum sine gordon model using the method of knops and den ouden @xcite . the quantum sine gordon model is defined by the following lattice hamiltonian : @xmath398 - \\frac{2g}{(2\\pi a)^2 }   \\cos 4\\phi_i \\right\\}\\end{aligned}\\ ] ] the cutoff in this model is only on space and not on time . the euclidean action of the quantum sine gordon model is obtained as : @xmath399=\\int_{-\\infty}^{\\infty } \\frac{d\\omega}{2\\pi } \\int_{-\\frac \\pi a}^{\\frac \\pi a } \\frac{dk}{\\pi } \\frac{u}{2\\pi k } \\left(k^2+\\frac{\\omega^2}{u^2 } \\right ) |\\phi(k,\\omega)|^2 -\\frac{2g}{(2\\pi a)^2 } \\int dx d\\tau \\cos 4\\phi\\end{aligned}\\ ] ]    where @xmath400 . one can integrate from @xmath401 to @xmath402 using a cutoff function @xmath403 . this action breaks rotation invariance in the @xmath404 space in contrast with the action of the classical sine - gordon model @xcite . instead of the sharp cutoff , one can use any cutoff function @xmath405 such that @xmath406 and @xmath407 . an example is @xmath408 .        where : @xmath410}\\frac { d \\theta}{\\pi } \\nonumber \\\\ f_2(\\rho)=\\int_0^{2\\pi}\\cos^2 \\theta e^{16 k \\left[v(\\rho,\\theta)+ \\frac 1 2 \\ln \\rho\\right]}\\frac { d \\theta}{\\pi } \\nonumber \\\\\\end{aligned}\\ ] ] and : @xmath411      the eqs . ( [ eq : rge_momentum_cutoff ] ) have to be contrasted with the usual rg equations for the sine gordon model with a cutoff isotropic in the @xmath414 space . in the latter case , the equations are such that @xmath415 , and only @xmath284 is flowing under renormalization . in the case we have considered , both @xmath416 and @xmath284 are flowing under rg transformation . however , for @xmath244 , the rg equations ( [ eq : rge_momentum_cutoff ] ) are considerably simplified . since @xmath417 and @xmath418 , one has the following simplified rg equations : @xmath419    these rg equations are identical to the ones obtained with a cutoff isotropic in @xmath414 space . we conclude that in the vicinity of the bkt transition point , the anisotropy between space and time does not matter .                        where : @xmath429 - 2(k_1-k_2)\\ln \\rho } \\nonumber \\\\ f_8(\\rho)=\\int_0^{2\\pi } \\frac{d\\theta}{2\\pi } e^{4\\left[k_1 v(\\rho,\\theta ) - k_2 v(\\rho,\\theta,\\frac{u_2}{u_1})\\right]-2(k_2-k_1)\\ln \\rho } \\nonumber \\\\ f_9(\\rho)=\\int_0^\\infty e^{8k_1 \\left[v(\\rho,\\theta)+\\frac 1 2 \\ln \\rho\\right]}\\end{aligned}\\ ] ]                                                    a. furusaki and s .- c . zhang , dynamical spin correlations in the heisenberg ladder under a magnetic field and correlation functions in the so(5 ) ladder , to be published in phys . 60 , number 1 , 1999 , cond - mat/9807375 .", "tags": [], "output_text_a": "This paper investigates the low-energy physics of a three-leg spin-1/2 ladder system with periodic boundary conditions, referred to as the spin-tube model. The study focuses on the effects of biquadratic exchange interactions and the resulting phase diagram. The authors explore the competition between dimerized and antiferromagnetic phases, using bosonization and renormalization group techniques to analyze the effective low-energy Hamiltonian. The paper finds that the dimerized ground state falls into the non-Haldane spin liquid universality class, characterized by a two-fold degenerate ground state with alternating singlets of spins and pseudospins. The study also examines the impact of a magnetic field, which can close the gap in the dimerized phase, leading to a two-component Luttinger liquid state. The findings highlight the non-universal nature of the exponents at the transition point and suggest potential experimental tests for these theoretical predictions. The paper concludes with a discussion on the implications of these results for understanding spin-liquid behavior in coupled spin systems.", "output_text_b": "This arXiv paper discusses the properties of coupled spin 1/2 chains, which show behavior similar to interacting one-dimensional fermions. When these chains are coupled together, forming ladder systems, their properties are modified. For an even number of chains, a gap is found to open, while the system remains gapless if the number of chains is odd. This phenomenon has been studied both analytically and numerically, and corresponding experimental systems have been identified. Examples of two-chain spin 1/2 ladders exhibiting a gap are SrCu_2O_3 and Sr_2Cu_3O_5. A gapless three-chain ladder is (C_5H_12N)_2CuBr_4. The difference between odd and even number of legs or spin has been understood qualitatively through a generalization of the Lieb-Schultz-Mattis theorem.\n\nWhen periodic boundary conditions are imposed on the transverse direction, a gap opens for both cases of even and odd number of chains, although the underlying reasons and the natures of the gaps are different. In the case of an even number of coupled chains, the reason for the gap is the formation of spin singlets along the transverse direction. When the number of coupled chains is odd, a two-fold degenerate dimerized ground state is obtained, allowing for a gap in the spin excitations.\n\nWhen leg-leg biquadratic interactions are included, new states emerge. A system of two spin-1/2 spin chains enters a spontaneously dimerized phase with a gapped spectrum exhibiting non-Haldane spin-liquid properties. The elementary excitations are neither spinons nor magnons but pairs of propagating triplet or singlet solitons connecting two spontaneously dimerized ground states. These models of spin ladders with biquadratic exchange have been advocated as possible models for the formation of a spin gap in SrCu_2O_3 and Sr_2Cu_3O_5.\n\nIn this paper, the authors study the low energy physics of the three-leg ladder with periodic boundary conditions, called the spin-tube model. By analyzing the effective low energy Hamiltonian, they show that the dimerized ground state of this model falls in the universality class of the non-Haldane spin liquids. In the case of xxz chains with a biquadratic coupling and for certain parameter values, they find that the Ising antiferromagnetic order can compete with the dimer order, and they describe the resulting phase diagram.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the investigation of the spin-tube model, the effects of biquadratic exchange interactions, and the resulting phase diagram.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem addressed by the paper, which is the low-energy physics of a three-leg spin-1/2 ladder system with periodic boundary conditions.\n4. The summary mentions the methodology used, including bosonization and renormalization group techniques.\n5. It includes significant results, such as the identification of the dimerized ground state as a non-Haldane spin liquid and the impact of a magnetic field.\n6. The language used is clear and professional.\n7. The summary avoids excessive technical jargon and explains terms like \"non-Haldane spin liquid\" and \"two-component Luttinger liquid.\"\n8. The structure of the summary is logical, with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data used in the research, which is a requirement.\n10. It reflects the paper's significance in understanding spin-liquid behavior in coupled spin systems.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the properties of coupled spin 1/2 chains and the effects of coupling them into ladder systems.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of understanding the behavior of coupled spin 1/2 chains and the formation of gaps in these systems.\n4. The summary mentions the methodology of analyzing the effective low energy Hamiltonian and the use of periodic boundary conditions.\n5. Significant results, such as the formation of a spin gap and the competition between Ising antiferromagnetic order and dimer order, are included.\n6. The language used is clear and professional.\n7. Technical jargon is minimized, and terms like \"spinons\" and \"magnons\" are explained in context.\n8. The summary is logically structured with a clear beginning, middle, and end.\n9. Key experiments or data are not explicitly mentioned, which is a shortcoming.\n10. The summary reflects the paper's significance in understanding non-Haldane spin liquids and their potential impact."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "observations of the prompt gamma - ray bursts ( grbs ) emission by different instruments show that their spectra can extend from several kev up to a few mev @xcite sometimes up to gev range @xcite . according to recent broadband observations by _ ginga _ @xcite , _ hete-2 _  @xcite and combined results of _ bepposax_/batse  @xcite and _ rxte_/ipn  @xcite , most grbs exhibit a peak in the @xmath5 spectrum at an energy @xmath3 in the 50400 kev range . however , distribution of @xmath3 is broad and large part of events demonstrate significant x - ray ( 230 kev ) emission ( x - ray dominated grbs , x - ray rich grbs ) . at this moment study of broadband spectra is complicated because of insufficient statistics accumulated by broadband instruments and biases due to different instrument responses . the batse  @xcite data of all - sky 9.1 years ( 19912000 ) continuous monitoring in @xmath6-ray range give unique possibility for combined grb analysis with x - ray observations . batse  @xmath6-ray detectors were the most sensitive instruments of this type over grb history . only recently launched _ swift_experiment @xcite has a more sensitive @xmath6-ray detector . however , during the next several years _ swift_cannot accumulate statistics comparable to that of the batse . batse  detected about 2700 grbs with fluxes down to @xmath7 ph @xmath2 s@xmath1 @xcite . in addition , the off - line scans of the batse  continuous records almost doubled the number of observed grbs with fluxes down to @xmath8 ph @xmath2 s@xmath1 ( see @xcite ; @xcite )    the batse  detectors were sensitive to photons from @xmath925 kev up to @xmath91 mev . however , the on - board procedure and most off - line searches identified grbs according to the signal in the 50300 kev range while grbs with a soft spectrum could be missed . these soft events can help to outline the place of the x - ray dominated bursts in the grb variety . the 25 - 50 kev range was inspected only in the off - line search of @xcite . their scan have covered 6 out of 9.1 years of the batse  data and yielded 50 unknown low - energy events some of which are probably soft grbs . even if all of them are grbs , the number of these events is 50 times smaller than that found in the 50300 kev range . we performed a search for grbs , inspecting the 2550 kev range for time period not covered by the scan of @xcite with a more careful and optimized for soft grbs procedure . the continuous daily 1.024 s time resolution discla records of count rate in 8 batse  detectors in 4 energy channels ( 2550 , 50100 , 100300 and 3001000 kev ) were used . we have applied the same technique and the same algorithm as in our scan of the batse  discla data in the 50300 kev range @xcite setting the trigger in the 25100 kev range ( i.e. in the 1st and 2nd energy channels ) . hr@xmath10 & @xmath11 & @xmath12 & @xmath13 & @xmath14 & @xmath15 + & of tjd & & & & deg & deg & deg & s & +   + 980726 & 63036 & 11020 & 0.11 & 0.57 & 255.8 & @xmath1654.8 & 9.7 & 56 & 29 + 980804 & 50914 & 11029 & 0.46 & 0.87 & 173.3 & @xmath1652.7 & 7.3 & 13 & 5 + 980927 & 6133 & 11083 & 0.33 & 0.89 & 9.6 & @xmath1654.5 & 11.4 & 6 & 4 + 981225 & 76754 & 11172 & 0.22 & 0.45 & 161.9 & @xmath1661.3 & 17.0 & 25 & 4 + 990304 & 77277 & 11241 & 1.85 & 0.83 & 31.6 & @xmath1626.7 & 4.6 & 4 & 2 + 990513 & 2453 & 11311 & 0.18 & 0.30 & 236.4 & @xmath1659.6 & 16.5 & 15 & 2 + 990610 & 20227 & 11339 & 0.11 & 0.43 & 234.8 & 16.6 & 17.3 & 80 & 11 + 990804 & 39065 & 11394 & 0.05 & 0.92 & 44.1 & 21.2 & 36.6 & 38 & 10 + 990907 & 75723 & 11428 & 0.06 & 0.66 & 301.0 & @xmath1639.3 & 8.3 & 126 & 33 + 991003 & 30847 & 11454 & 0.16 & 0.60 & 253.8 & 33.2 & 21.1 & 13 & 6 + 991009 & 30691 & 11460 & 0.10 & 0.47 & 107.9 & 3.5 & 12.9 & 24 & 8 + 991106 & 59880 & 11488 & 0.10 & 0.33 & 284.7 & @xmath1658.2 & 20.5 & 39 & 11 + 000107 & 8784 & 11550 & 0.12 & 0.91 & 74.9 & @xmath1661.6 & 16.1 & 73 & 12 +   + 980707 & 9097 & 11001 & 0.40 & 3.29 & 79.0 & 40.4 & 9.9 & 6 & 4 + 980930 & 83166 & 11086 & 0.37 & 1.90 & 132.0 & @xmath1670.9 & 6.7 & 38 & 19 + 981012 & 21270 & 11098 & 0.11 & 1.24 & 59.0 & 15.5 & 20.7 & 17 & 11 + 981019 & 69630 & 11105 & 0.29 & 2.18 & 208.9 & @xmath1640.3 & 11.7 & 17 & 3 + 981221 & 18020 & 11168 & 0.97 & 1.82 & 71.9 & 3.6 & 15.4 & 9 & 1 + 990303 & 74922 & 11240 & 0.25 & 1.00 & 199.9 & 52.4 & 18.9 & 9 & 7 + 000324 & 36745 & 11627 & 0.08 & 2.10 & 58.7 & 26.4 & 18.8 & 36 & 10 + 000523 & 49912 & 11687 & 0.41 & 1.01 & 269.1 & 80.6 & 8.6 & 24 & 9 +   +   +   +   +    [ tab:21grbs ]    we present the results of our search for soft batse  grbs in section  [ sec : search ] and discuss new data together with the recent grb observations by _ bepposax _  and _ hete-2 _  in section  [ sec : spectra ] . we have performed the scan of batse  discla records available at ftp archive at goddart space flight center for time period since july 6 , 1998 till may 26 , 2000 ( tjds 11000 - 11699 , files for tjds 11047 , 11048 , 11354 , 11355 - 11359 , 11519 - 11521 are missing ) . the applied algorithm and technique is described in @xcite . only the 25100 kev range ( 1 and 2 channels ) was checked . the 1024 ms time resolution discla data are not suitable for studies of short ( @xmath17 s ) grbs and we did not consider 1 bin events . this allows us to avoid scintillation from heavy nuclei and soft gamma - ray repeater ( sgr ) outbursts . we excluded also events with location in the vicinity of galactic center , the sun , four known sgrs and other persistent sources and events that appeared near and below earth horizon . we recorded only new grbs missing in the catalogs of @xcite and @xcite . we have found and classified as grbs 21 new events . table  [ tab:21grbs ] present their time identificator , intensity , hardness , location and duration . in the previous scan in 50300 kev @xcite for the same time period we have detected about 800 long grbs . hardness - intensity diagram ( fig . [ fig : hr_int ] ) shows that although grbs of a new sample are softer on average , the samples do overlap . actually 13 out of 21 grbs in a new sample ( table  [ tab:21grbs ] ) and 23 of @xmath9800 long grbs in the old sample ( * ? ? ? * table  [ tab:23softgrbs ] ) have the peak count rate in 2550 kev higher than that in the 50300 kev band . according to this somewhat arbitrary criterion we consider these 36 events as a sample of soft long ( @xmath182 s ) batse  grbs . hr@xmath19 & @xmath20 & @xmath21 & @xmath22 & @xmath23 & @xmath24 + & of tjd & & & & deg & deg & deg & s & + 980924 & 54262 & 11080b & 0.95 & 0.93 & 61.8 & @xmath1622.0 & 8.8 & 10 & 2 + 981015 & 46766 & 11101c & 1.36 & 0.69 & 122.9 & 22.1 & 5.4 & 34 & 6 + 981115 & 21438 & 11132b & 0.80 & 0.80 & 284.0 & 10.0 & 10.6 & 4 & 1 + 981117 & 11629 & 11134a & 0.41 & 0.98 & 217.6 & @xmath1665.7 & 23.7 & 8 & 3 + 981118 & 2533 & 11135a & 0.48 & 0.97 & 186.9 & 60.6 & 23.0 & 6 & 2 + 981128 & 74360 & 11145c & 0.18 & 0.97 & 60.3 & 38.4 & 33.2 & 36 & 3 + 981204 & 37850 & 11151a & 0.16 & 1.00 & 53.4 & @xmath1655.9 & 21.5 & 9 & 3 + 981222 & 58180 & 11169b & 0.30 & 0.89 & 145.9 & 67.1 & 28.7 & 11 & 5 + 990112 & 7066 & 11190a & 0.20 & 0.63 & 118.6 & @xmath1645.6 & 17.7 & 85 & 14 + 990207 & 55697 & 11216e & 0.49 & 0.95 & 152.9 & @xmath169.7 & 16.7 & 17 & 2 + 990218 & 73752 & 11227b & 0.35 & 0.98 & 72.9 & 37.7 & 17.8 & 89 & 7 + 990413 & 32497 & 11281d & 0.39 & 0.94 & 302.1 & 55.5 & 12.8 & 6 & 6 + 990506 & 42666 & 11304c & 0.19 & 0.89 & 186.9 & 9.6 & 21.3 & 61 & 15 + 990610 & 56705 & 11339c & 0.45 & 0.99 & 105.7 & @xmath1616.6 & 8.4 & 109 & 18 + 990915 & 58755 & 11436c & 0.64 & 0.78 & 273.2 & @xmath1621.9 & 5.0 & 50 & 12 + 991006 & 68176 & 11457b & 0.76 & 0.99 & 104.0 & 11.7 & 3.8 & 73 & 27 + 991201 & 1802 & 11513a & 0.09 & 0.98 & 167.9 & @xmath1610.9 & 12.3 & 19 & 13 + 991217 & 37909 & 11529b & 0.36 & 0.49 & 64.8 & @xmath1612.7 & 16.8 & 8 & 1 + 991231 & 28492 & 11543a & 0.22 & 0.96 & 39.3 & 32.3 & 11.3 & 14 & 5 + 000114 & 51441 & 11557a & 1.17 & 0.99 & 107.4 & @xmath1625.3 & 3.8 & 5 & 2 + 000206 & 74873 & 11580 g & 0.22 & 0.98 & 255.7 & 78.5 & 10.7 & 26 & 7 + 000405 & 77386 & 11639b & 0.92 & 0.96 & 226.9 & @xmath1652.5 & 2.1 & 35 & 7 + 000416 & 52380 & 11650c & 0.17 & 0.70 & 258.5 & @xmath1665.7 & 14.7 & 9 & 5 +   +   +   +   +   +    [ tab:23softgrbs ]    these 36 soft grbs have typical light curves , last up to about 100 s and do not demonstrate any significant anisotropy on the sky . soft batse  grbs selected with the above criterion constitute about 5% of observed long grb sample ( about 20 per year with peak fluxes down to @xmath8 ph @xmath2 s@xmath1 ) .    our scan ( as well as an alternative scan @xcite ) in the batse  records in the 2550 kev range has yielded surprisingly small number of new soft grbs . moreover , there are no events with hardness ratio ( hr ) below 0.3 , while much softer events like outbursts of vela  x-1 can be confidently detected ( see fig . [ fig : hr_int ] ) . we have considered sample of 50 events classified by @xcite as unknown because of their softness . when excluding short events they again have @xmath25 except two events from the direction to vela  x-1 .    why do not we see softer grbs despite the fact that there exist x - ray dominated bursts with peak energy below the batse  window ? we calculated the batse  detector response to estimate the dependence between the incident photon spectrum and the observed hardness ratio ( see fig . [ fig : hr_beta ] ) . we approximated grb spectra with the band function @xcite and folded them with the batsedetector response matrix ( drm ) @xcite . the low hardness ratio ( @xmath26 ) of our soft events is consistent with a wide variety of spectral parameters @xmath3 , low energy and high energy spectral indices @xmath27 and @xmath28 , in particular , with @xmath29 kev and @xmath30 ( see fig .  [ fig : hr_int ] and [ fig : hr_beta ] ) . it is also evident that the sufficient condition for a grb to give @xmath31 and thus to look as a typical grb in the batsedata ( with larger signal above 50 kev ) is @xmath32 , independently on the @xmath3 . a combination of a low @xmath3 and a very steep @xmath28 would give the hardness ratio below 0.3 which we do not observe . the fact that all events with @xmath33 have evident non - grb origin ( solar flares , vela  x-1 pulsar , etc . ) implies that a spectral cutoff below @xmath915 kev may be a distinguishing feature to separate non - grb sources . _ bepposax _  observed 20 x - ray dominated grbs which were detected by wide field camera ( 226 kev ) , but did not activate the trigger of the gamma - ray monitor ( 40400 kev ) . their counterparts were found in the batse  records for almost all observable events @xcite . most of them were detected earlier as classic grbs by our scan of batse  data in 50300 kev band @xcite . it turns out that these events have a high hardness ratio similar to typical grbs ( see fig . [ fig : saxhete]a ) . the hardness ratio 100300/50100 kev for common _ bepposax_/batse events shows a similar picture : 7 out of 8 events have a typical hardness for weak grbs and one event is softer . thus this distribution is also consistent with the extrapolated hardness - intensity trend for long grbs @xcite . these facts support our conclusion that most of the x - ray dominated grbs should have a hard tail with @xmath32 in the batse  window 251000 kev ( see fig . [ fig : hr_beta ] ) .    _ _  observed 45 grbs in the 2400 kev band and their spectral fits are given in @xcite . in order to check how _ results are related to our data we folded _ hete-2 _ spectra with the batse  detector response matrix and obtained corresponding counts in batse  channels ( see fig . [ fig : saxhete]b ) . the fraction of soft events in the _ hete-2 _ sample is about 3 times larger than in the batse  sample which can be explained by different instrument responses . but only 1 out of 45 _ hete-2 _  events gives a lower hardness ratio than we see in the batse  grb sample . nine out of 45 _ hete-2 _  events are below the batse  sensitivity threshold . the batse  sample , however , represents probably the whole grb spectral variety . @xcite fitted _ _  spectra by three functions : a power - law , a power - law with the exponential cutoff and the band function . they started from a power - law fit and used a more parametric expression only if the fit was inconsistent with the data at 0.01 significance level . from fig . [ fig : saxhete]b one can see that the power - law fit was acceptable only for weak events . relatively bright bursts gave good power - law with exponential cutoff fits . however , this does not mean that they could not be fitted by the band function . according to our results , the existence of grbs with sharp spectral cutoff is questionable for events with low @xmath3 . indeed , the events with @xmath341020 kev would give a very low hardness ratio which we do not observe . note that , as shown by @xcite , only few percents of grbs with high @xmath3 are better described by a power - law with the exponential cutoff . if the dispersion in @xmath3 is due to variations in the redshift / blueshift in the source , then the spectral shape would be stable and our conclusion could refer to all grbs . 1 .   despite the wealth of the x - ray dominated grbs observed by _ ginga _ , _ bepposax _  and _ hete-2_the number of soft grbs in the batse  data is relatively small . the fraction of events with the count rate in 2550 kev higher than that above 50 kev is @xmath95 per cent ( 20 per year with flux down to 0.1 ph @xmath2 s@xmath1 ) . the hardness distribution of the x - ray dominated grbs in the batse band is consistent with that of weak classic grbs . in the case of a low @xmath3 , the main fraction of grbs should have a relatively hard high - energy tail with a power - law slope @xmath35 . only a few per cent of the x - ray rich grbs have a tail with @xmath36 , but still harder than the exponential one . this fact clarifies the deficiency of soft events in the batse data . an exponential cutoff in the grb spectra , if exists , is probably a rare phenomenon . therefore , a spectral cutoff with the e - folding energy below @xmath0 kev may be a distinguishing feature to separate the non - grb events . we are grateful to robert preece and geoffrey pendleton for the code of the batse  detector response matrix . we thank kevin hurley for providing us ipn  data on our soft grb sample . this research has made use of data obtained through the high energy astrophysics science archive research center online service , provided by the nasa / goddard space flight center . the work is supported by nordita nordic project in high energy astrophysics in the integral era , russian foundation for basic research ( grant 04 - 02 - 16987 ) , and russian foundation of science support ( y.t . ) . band d. et al . , 1993 , apj , 413 , 281 gehrels n. et al . , 2004 , apj , 611 , 1005 in t zand j. , heise j. , kippen r. , woods p. , guidorzi c. , montanari e. , frontera f. , 2003 , in piro l. , frontera f. , masetti n. , feroci m. , eds , asp conf . series 312 , third rome workshop on gamma - ray bursts in the afterglow era , astron . , san francisco , p.  18 [ kippen r. m. , woods p. m. , heise j. , int zand j. , preece r. d. , briggs m. s. , 2001 , in costa e. , frontera f. , hjorth j. , eds , gamma - ray bursts in the afterglow era . berlin , springer , p.  22 [ kommers j. , lewin w.h.g . , kouveliotou c. , van paradijs j. , pendleton g.n . , meegan c.a . , fishman g.j . , 2001 , apjs , 134 , 385 [ metzger , a . e. , parker r. h. , gilman d. , peterson l. e. , trombka j. i. , 1974 , apj , 194 , l19 [ paciesas w.s . et al . , 1999 , apjs , 122 , 465 [ pendleton g.n . et al . , 1999 , apj , 512 , 362 [ preece r.d . , briggs m.s . , mallozzi r.s . , pendleton g. n. , paciesas w.s . , band d.l . , 2000 , apjs , 126 , 19 [ sakamoto t. et al . , 2005 , apj , 629 , 311 [ smith d.a . et al . , 2002 , apjs , 141 , 415 [ sommer m. et al . , 1994 , apj , 422 , l63 [ stern b. e. , tikhomirova y. , kompaneets d. , svensson r. , poutanen j. , 2001 , apj , 563 , 80 [ strohmayer t. e. , fenimore e. e. , murakami t. , yoshida a. , 1998 , apj , 500 , 873 [ trombka j. i. , eller e. l. , schmadebeck r. l. , adler i. , metzger a. e. , gilman d. , gorenstein p. , bjorkholm p. , 1974 , apj , 194 , l27 [ wheaton wm . , 1973 , apj , 185 , l57", "tags": [], "output_text_a": "This paper discusses the observations of prompt gamma-ray bursts (GRBs) and their spectral characteristics, which can range from several keV to a few MeV, and sometimes up to the GeV range. Recent broadband observations have shown that most GRBs exhibit a peak in their spectrum at energies between 50 and 400 keV, but there is a broad distribution, with some events showing significant X-ray emission (2-30 keV), known as X-ray dominated or X-ray rich GRBs. The study of broadband spectra is challenging due to limited statistics and biases from different instrument responses.\n\nThe paper highlights the unique opportunity provided by the BATSE (Burst and Transient Source Experiment) data, which monitored the sky for 9.1 years, detecting about 2700 GRBs. The BATSE detectors were sensitive to photons from 25 keV to 1 MeV, but most GRBs were identified based on signals in the 50-300 keV range, potentially missing softer events. The authors conducted a search for GRBs in the 25-50 keV range, identifying 21 new soft GRBs not previously cataloged.\n\nThe study found that these soft GRBs have typical light curves lasting up to about 100 seconds and do not show significant anisotropy in the sky. The fraction of soft GRBs in the BATSE data is relatively small, about 5% of the observed long GRB sample. The hardness distribution of X-ray dominated GRBs in the BATSE band is consistent with that of weak classic GRBs, suggesting that most X-ray dominated GRBs have a hard high-energy tail.\n\nThe paper concludes that the deficiency of soft events in the BATSE data may be due to the presence of a hard tail in the spectra of X-ray dominated GRBs, and that an exponential cutoff in GRB spectra is likely a rare phenomenon. The study provides insights into the spectral characteristics of GRBs and the challenges in detecting softer events.", "output_text_b": "This article discusses the study of gamma-ray bursts (GRBs) and their spectra, which can extend from several keV up to a few MeV, and sometimes even up to the GeV range. The study is based on broadband observations by Ginga, HETE-2, BeppoSAX, RXTE/IPN, and BATSE. The article focuses on the peak energy (Epeak) of GRBs, which is typically found in the 50-400 keV range. However, the distribution of Epeak is broad, and a large part of events demonstrate significant x-ray (230 keV) emission, known as x-ray dominated GRBs or x-ray rich GRBs. The study of broadband spectra is complicated due to insufficient statistics and biases from different instrument responses. The BATSE data from 9.1 years of continuous monitoring in the 25-1000 keV range provide a unique opportunity for combined GRB analysis with x-ray observations. The BATSE detectors were the most sensitive instruments of this type over GRB history. The article discusses the search for soft GRBs in the BATSE data, which could help outline the place of x-ray dominated bursts in the GRB variety. The search resulted in the detection of 21 new events, which are softer on average but still overlap with the sample of long GRBs detected in the 50-300 keV range.", "score": 0.4, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings and Contributions**: The summary accurately reflects the main findings and contributions of the paper, discussing the observations of GRBs, their spectral characteristics, and the unique opportunity provided by BATSE data.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding the spectral characteristics of GRBs and the challenge of detecting softer events.\n\n4. **Methodology or Approach**: The summary mentions the methodology of using BATSE data to search for GRBs in the 25-50 keV range.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the identification of 21 new soft GRBs and the conclusion about the deficiency of soft events due to a hard tail in the spectra.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"X-ray dominated GRBs.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions the use of BATSE data and the identification of new soft GRBs.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in understanding GRB spectral characteristics and the challenges in detecting softer events.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings regarding the study of GRBs and their spectra, the focus on peak energy, and the detection of new soft GRBs.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the study of GRBs and their spectra, focusing on peak energy and the detection of soft GRBs.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary briefly mentions the use of BATSE data and broadband observations but lacks detail on the specific methodology.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes the detection of 21 new soft GRBs as a significant result.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"GRBs\" and \"keV\" but does not explain them, which might be necessary for a general audience.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of BATSE data and broadband observations but lacks detail on specific experiments.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly reflect the paper's significance or potential impact in the field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "mesoscopic systems belong to one of the most intriguing part of present - day investigations . they occupy territory between physics of small quantum objects and physics of macroscopic objects . many aspects of that territory remains _ terra incognita _ both to experimentalists and theoreticians . for example , over one decade after first experiments @xcite proving the existence of the theoretically predicted @xcite persistent currents in normal metal multiply connected samples , there is an unsolved central question : which mechanism is responsible for the unexpectedly large amplitude of the measured current @xcite . there is a suggestion that the large current is due to _ non - equilibrium _ noise presented in the system @xcite . it is also theoretically predicted @xcite that currents in mesoscopic rings can flow even in absence of any driving . self - sustaining _ currents has not been observed so far . their existence is a desired property for the quantum information retrieval and computing technologies based on non - superconducting devices @xcite .    in our earlier work @xcite we proposed the two - fluid model of noisy dynamics of the magnetic flux in mesoscopic rings and cylinders . dynamics of the magnetic flux is described by an evolution equation which is equivalent to a langevin equation for an overdamped motion of a classical brownian particle and a steady state of the system is characterized by the asymptotic probability density being a stationary solution of the corresponding fokker - planck equation . in this approach , self - sustaining fluxes are long living states of the system described by a multistable asymptotic probability density . this model is an example of a hybrid of quantum and classical parts and is a counterpart of the well known model of a resistively shunted josephson junction @xcite . the classical part consists of normal electrons carrying dissipative current . the quantum part is formed by those electrons which maintain their phase coherence around the circumference of the cylinder or ring . the effective kinetics is determined by a classical langevin equation with a nyquist noise describing thermal equilibrium fluctuations . the coherent part of the system acts as an additional force driving normal electrons . it is natural to ask what is an impact of quantum nature of dissipative kinetics on the properties of fluxes and currents flowing in such systems . to answer this question , we exploit the so called quantum smoluchowski equation introduced in ref . and , with the maxwell daemon successfully exorcised , in refs .. first , we extend our model for overdamped kinetics @xcite to the domain where charging effects ( corresponding to the inertial effects for particles ) appear . this extension is necessary for a precise identification of the quantum smoluchowski regime . the quantum corrections are of great importance for the existence and properties of self - sustaining currents or magnetic fluxes . it is shown below that in moderate , with respect to the gap at the fermi level , temperatures these quantum corrections are destructive for their existence . it is not the case at lower temperature : one gets not only the multistability of the probability density but also significant enhancement of the probability of the occurrence of long living states carrying magnetic flux of a certain amplitude . it is shown that for the system under consideration the passage from the classical smoluchowski regime into the quantum smoluchowski regime is accompanied with decrease of the shannon entropy . it emphasizes the significance of the multistable ordered state . as the predicted multistability is formed by a set of odd number of maxima in the asymptotic probability density it is natural to expect the ring or cylinder to be a candidate for a _ qutrit _ rather than a qubit . the layout of the paper is as follows : in sec . ii , we construct an extended , capacitive model of dissipative magnetic flux dynamics in mesoscopic systems of a cylinder symmetry . next , in sec . iii , we discuss the quantum smoluchowski regime for the system . in sec . iv , we study properties of the stationary magnetic flux in the quantum smoluchowski domain . v contains summary and conclusions . at zero temperature @xmath0 , small metallic systems of the cylinder symmetry ( like rings , toroids and cylinders ) threaded by a magnetic flux @xmath1 display persistent and non - dissipative currents @xmath2 run by coherent electrons . at non - zero temperature , a part of electrons becomes normal ( non - coherent ) and the amplitude of the persistent current decreases . moreover , resistance of the ring and thermal fluctuations start to play a role . therefore for temperatures @xmath3 , there are both coherent and dissipative parts of the total current , namely , @xmath4 the persistent current @xmath2 as a function of the magnetic flux @xmath1 depends on the parity of the number of coherent electrons . let @xmath5 denotes the probability of an even number of coherent electrons . then the formula for coherent current reads @xcite @xmath6 where @xmath7 the flux quantum @xmath8 is the ratio of the planck constant @xmath9 and the charge of the electron , @xmath10 is the maximal current at zero temperature . the temperature dependent amplitudes are determined by the relation @xcite @xmath11 where the characteristic temperature @xmath12 defined by the relation @xmath13 , where @xmath14 is the energy gap at the fermi surface , @xmath15 is the boltzmann constant and @xmath16 is the fermi momentum and @xmath17 is the circumference of the ring .    the dissipative current @xmath18 is determined by the ohm s law and lenz s rule @xcite , @xmath19 where @xmath20 is the resistance of the ring and @xmath21 models thermal nyquist fluctuations of the ohmic current . in the first approximation , this thermal noise is classical gaussian white noise of zero average , i.e. , @xmath22 and @xmath23-auto - correlated function @xmath24 . the noise intensity @xmath25 is chosen in accordance with the classical fluctuation - dissipation theorem . quantum corrections to classical thermal fluctuations will be considered below in the so - called smoluchowski regime . to define precisely this regime , first we have to include charging effects @xcite . to this aim , we shall construct a formal hamilton function ( i.e. energy ) of the system which consists of three parts . the first one corresponds to an effective potential related to the persistent current itself ; the second is related to the energy of the magnetic flux and the third is due to charging effects caused by capacitance @xmath26 of the system ( it corresponds to the kinetic energy of a particle ) . we define a potential energy related to the persistent current by the relation @xmath27 which reflects the well known fact that the persistent current is an equilibrium and thermodynamic phenomenon . at zero temperature , it is an energy of the set of discrete energy levels carrying persistent current . for non - zero temperature , the persistent current is averaged over the thermal distribution function and the above relation holds for a thermodynamic potential . we assume that the ring can be characterized by a capacitance @xmath26 . to justify it we cite kopietz @xcite who showed that in the diffusive regime the energy associated with long - wavelength and low - energy charge fluctuations is determined by classical charging energies and therefore the ring behaves as it were a classical capacitor . the flux dependence of these energies yields the contribution to the persistent current . the speculations that the local charge fluctuations and charging energies could contribute to persistent current has also been suggested by imry and altshuler @xcite .    from the above it follows that the total energy takes the form @xcite @xmath28 where @xmath29 is the magnetic flux induced by an external magnetic field @xmath30 and @xmath31 is a self - inductance of the system . the equation of motion , which corresponds to ( [ h ] ) , has the form @xmath32 now , we want to take into account dissipation effects . to this aim we generalize eq . ( [ em ] ) replacing the coherent current @xmath2 by the total current @xmath33 given by ( [ i ] ) . as a result we obtain the evolution equation @xmath34 where the potential @xmath35 reads @xmath36\\right\\}.\\end{aligned}\\ ] ] this equation is extended one in comparison with the equation of motion studied in ref . by including the inertial , capacitive term . its structure is similar to the model of capacitively and resistively shunted josephson junction @xcite . indeed , the dynamics of a trapped magnetic flux in a superconducting ring interrupted by the josephson junction is described by eq . ( [ be ] ) by changing @xmath37 into the josephson supercurrent @xmath38 @xcite . the dissipative part of the current , given by eq . ( [ inor ] ) , is classical one in which a quantum character of thermal fluctuations is ignored . at lower temperatures , it can be insufficient and leading quantum corrections might be important . we do not know how to incorporate quantum corrections in a general case described by ( [ be ] ) . however , in the regimes where the charging effects can be neglected , the system can be described by the so called quantum smoluchowski equation @xcite . it has the same structure as a classical smoluchowski equation , in which the potential @xmath39 and diffusion coefficient @xmath40 are modified due to quantum effects like tunneling , quantum reflections and fluctuations . in terms of the langevin equation ( [ be ] ) , it assumes the form @xmath41 this equation has to be interpreted in the ito sense @xcite . the modified potential @xmath42 and the modified diffusion coefficient @xmath43 take the form @xcite @xmath44 where the prime denotes differentiation with respect to the argument of the function . the quantum corrections are characterized by the parameter @xmath45 . it measures a deviation of the quantal flux fluctuations from its classical counterpart , namely , @xmath46 where @xmath47 denotes equilibrium average , the subscripts @xmath48 and @xmath26 refer to quantal and classical cases , respectively . the explicit form of @xmath45 reads @xcite @xmath49,\\ ] ] where the psi function @xmath50 is the logarithmic derivative of the gamma function and @xmath51 , \\nonumber\\\\ k=(2\\omega_0 cr)^{-1 } , \\quad \\nu = 2\\pi k_bt/\\hbar.\\end{aligned}\\ ] ] the frequency @xmath52 is a typical frequency of the bare system and its inverse corresponds to a characteristic time of the system . now , let us determine the range of applicability of the quantum smoluchowski regime . the classical smoluchowski limit corresponds to the neglect of charging effects . formally , we should put @xmath53 in the inertial term of eq . ( [ be ] ) , which is related to the strong damping limit of the brownian particle . in the case studied here it means that @xmath54 and then eq . ( [ lam2 ] ) takes the form @xmath55,\\ ] ] where @xmath56 is the euler constant . the separation of time scales , on which the flux relaxes and the conjugate observable ( a charge ) @xcite is already equilibrated , requires the second condition , namely , @xmath57 in the deep quantum regime , i.e. when @xmath58 the correction ( [ lam3 ] ) assumes the form @xmath59.\\ ] ] in order to identify precisely the quantum smoluchowski regime , we have to determine a typical frequency @xmath52 or the corresponding characteristic time @xmath60 . there are many characteristic times in the system , which can be explicitly extracted from the evolution equation ( [ be ] ) , e.g. @xmath61 . the characteristic time @xmath62 is the relaxation time of the flux in the classical ( non - coherent ) systems and below we scale time with respect to @xmath63 . why time is scaled in this way , we refer the readers to our previous paper @xcite . therefore , in the quantum smoluchowski regime , all the above inequalities ( [ ineq1 ] ) , ( [ ineq2 ] ) and ( [ ineq3 ] ) should be fulfilled for @xmath64 . because the diffusion coefficient can not be negative , the parameter @xmath45 should be chosen small enough to satisfy the condition @xmath65 for all values of @xmath1 . we note that the passage from the classical smoluchowski domain to the quantum smoluchowski domain allows for the identification of the physical regime because of the formal similarities of the inertial and capacitive terms in the equations of motion for the brownian particle and the magnetic flux , respectively . from the mathematical point of view , the langevin equation ( [ qov ] ) describes a classical markov stochastic process . therefore its all statistical properties can be obtained from the corresponding fokker - planck equation for the probability density . to analyze its stationary solution , let us introduce dimensionless variables in eq . ( [ qov ] ) : the rescaled flux @xmath66 and rescaled time @xmath67 , where the characteristic time @xmath68 . then eq . ( 11 ) can be rewritten in the dimensionless form @xmath69 the rescaled modified potential @xmath70 and the modified diffusion coefficient @xmath71 take the form @xmath72\\right\\}^{-1 } , \\end{aligned}\\ ] ] where @xmath73\\right\\}\\end{aligned}\\ ] ] with the rescaled temperature @xmath74 . the remaining dimensionless parameters are : @xmath75 , where the elementary magnetic flux energy @xmath76 and @xmath77 is the ratio of two characteristic energies . the rescaled zero - mean gaussian white noise @xmath78 has the same statistical properties as thermal noise @xmath21 . the dimensionless quantum correction parameter @xmath79 , \\ : \\lambda_0=\\frac { \\hbar r}{\\pi\\phi_0 ^ 2 } ,   \\ : \\epsilon = \\frac{\\hbar/2\\pi cr}{k_bt^*}.\\ ] ] the probability density @xmath80 of the process ( [ ll ] ) evolves according to the corresponding fokker - planck equation with natural boundary conditions . the stationary probability density @xmath81 can be obtained from the steady - state fokker - planck equation and reads @xmath82 , \\end{aligned}\\ ] ] where the generalized thermodynamic potential @xmath83 due to both the @xmath84-dependence of the modified diffusion coefficient @xmath71 and the temperature dependence of the modified potential @xmath70 , the stationary state ( [ ps ] ) is a thermal equilibrium state , however , it is not a gibbs state : @xmath85 $ ] .     given by ( [ v(x ) ] ) and the modified potential @xmath70 in ( [ ve(x ) ] ) are shown in the upper panel . in the inset , the modified diffusion function @xmath71 defined in ( [ d(x ) ] ) is depicted . the lower panel shows the stationary probability density @xmath81 in the classical smoluchowski ( @xmath86 ) and quantum smoluchowski ( @xmath87 ) regimes . other parameters are set as following : @xmath88 , @xmath89 , @xmath90 , @xmath91 , @xmath92 , @xmath93 and @xmath94.,scaledwidth=45.0% ]      in fig . 1 and 2 , we present the influence of quantum corrections on the shape of the potential and diffusion coefficient . we compare the potential @xmath95 and the modified quantum potential @xmath70 with each other , as well as by analyzing the modified diffusion function @xmath71 ( which is constant in the classical smoluchowski domain ) . in the regime presented in fig . 1 , the potential @xmath95 ( dashed line ) is bistable and possesses the barrier in contrary to @xmath70 ( solid line ) and the generalized thermodynamic potential @xmath96 ( not shown in the figure ) which are monostable and barrier - less . the state - dependent modified diffusion function @xmath71 possesses maxima and minima . the maxima and minima can be interpreted as higher and lower effective local temperatures . it means that quantum fluctuations mimic a state - dependent periodic effective temperature . for the escape dynamics the generalized thermodynamic potential @xmath96 is decisive : it contains the combined influences of the modified potential and the modified diffusion . in the regime presented in fig . 1 , @xmath96 has the same properties as the modified quantum potential @xmath70 . the regime shown in fig . 2 is much more interesting . the potential @xmath95 ( dashed line ) is also bistable and possesses the barrier . however , the modified potential @xmath70 ( solid line ) and @xmath96 ( not shown ) are now multistable and possess many barriers . in fact , they possess infinitely many barriers and their heights are smaller and smaller as absolute value of the flux increases . as in the previous case , the state - dependent modified diffusion function @xmath71 possesses maxima and minima which now are more distinct . values of parameters in figs . 1 and 2 seem to be feasible . a part of values of parameters have been evaluated from experimental data . e.g. , following mohanty @xcite , @xmath97 and @xmath98 . therefore the rescaled temperature @xmath99 . from ref . 2 , we have estimated the quantum correction parameter @xmath100 . the parameters @xmath101 and @xmath102 can be related with each other . the value of the parameter @xmath103 is unconfirmed . fortunately , it enters only into the quantum correction parameter @xmath100 which depends weakly ( logarithmically ) on it , cf . ( [ ln ] ) . the quantum smoluchowski regime is compared to its classical counterpart . the potential @xmath95 given by ( [ v(x ) ] ) and the modified potential @xmath70 in ( [ ve(x ) ] ) are shown in the upper panel . in the inset , the modified diffusion function @xmath71 defined in ( [ d(x ) ] ) is depicted . the lower panel shows the stationary probability density @xmath81 in the classical smoluchowski ( @xmath86 ) and quantum smoluchowski ( @xmath87 ) regimes . other parameters are set as following : @xmath104 , @xmath105 , @xmath90 , @xmath91 , @xmath92 , @xmath93 and @xmath94 . ]      in the following discussion we focus on the _ self - sustaining fluxes_. such fluxes , contrary to the squid s , has not been observed in mesoscopic rings so far . therefore , there is a question if it may be due to additional ( quantum ) noise in the system . in the noiseless system , they are related to minima of the multistable generalized potential @xcite .    in the regime where quantum corrections are negligible ( @xmath106 ) , it is a one - to - one correspondence between minima of the potential @xmath95 and the maxima of the stationary probability density @xmath81 @xcite . it is clearly not the case in the quantum smoluchowski regime as the modified diffusion coefficient is flux - dependent . nevertheless , we relate the formation of the self - sustaining currents to the appearing of the multi - peaked probability density at sufficiently low temperatures . as the steady state is always reflection invariant , self -sustaining fluxes are in fact _ finitely - long - living _ and appear if the peaks of the steady - state probability distribution are sufficiently high . let us consider two qualitatively different regimes . the first is the moderate temperature regime where the noiseless system is bistable . it is shown in fig.1 . for this case , the system , if it can be described in terms of the quantum smoluchowski equation , is not able to accommodate self - sustaining flux due to the destructive role of quantum fluctuations since the steady state is effectively mono - stable . the second regime is the regime presented in fig . 2 , where the onset to the multi - stable state of a noiseless system occurs . this regime is accessible either by lowering temperature or using systems with larger amplitude of persistent current , i.e. accommodating more coherent electrons . here , the quantum corrections change significantly the properties of the system . both @xmath70 and @xmath96 become multi - stable what results in multistability of the steady state . the peaks are new since they do not appear at the classically predicted position but rather are shifted by approximately a quarter of flux quantum @xmath107 . there is a natural interpretation of such peaks : if they occur at @xmath108 they are related to self - sustaining fluxes in the system . their lifetimes can be estimated using the well established first - passage time method @xcite . the lifetimes of the zero and non - zero flux stationary states depend strongly on relation between the depth of the potential well of @xmath70 and temperature . therefore they can be controlled by the system parameters . it is desirable to obtain these lifetimes much longer than the characteristic time @xmath63 , according to which time is scaled , cf . the begining of sec . iv . let us consider the regime presented in fig . the lifetime of any stationary state @xmath109 can be calculated as the mean first passage time @xmath110 to leave the interval @xmath111 $ ] assuming that @xmath112 $ ] . it depends on the interval @xmath111 $ ] as well as on the boundary conditions ( bc ) . we can define the lifetime of the state @xmath113 as @xmath114 with two absorbing bc at @xmath115 , where @xmath116 is a little bit greater than the local maximum sticked around @xmath117 . such a calculated time @xmath118 . the lifetimes of the remainder states @xmath119 can be defined as @xmath110 with one absorbing and one reflecting bc . e.g. for @xmath120 , one can take @xmath121 ( which is on the left of the local maximum sticked around @xmath122 ) as an absorbing bc and @xmath123 as a reflecting bc . then @xmath124 . analogously , @xmath125 . for comparison , the mean passage time from @xmath120 into @xmath126 is @xmath127 and from @xmath128 into @xmath120 is @xmath129 . moreover , @xmath130 and @xmath131 . as a result , the system in this regime can effectively be treated as _ tri - stable _ with the reasonable level of accuracy . the problem of the flux amplitude is more subtle . the modified diffusion coefficient , depicted in the insets of fig.1 . and fig.2 , is periodic with respect to the magnetic flux @xmath84 . if the magnetic flux is close to half - integer , the modified diffusion coefficient is smaller than the classical einstein one . as a result of the interplay between this phenomenon and the shape of the modified potential one observes _ statistical enhancement _ of the magnetic flux due to quantum noise . this enhancement is statistical since it allows to _ expect _ an occurrence of the flux of some amplitudes with higher _ probability _ due to quantum features of thermal equilibrium fluctuations in the quantum smoluchowski regime . this enhancement is quantitative and , contrary to different approaches @xcite , this is a purely equilibrium effect . quantum corrected entropy ( solid line ) and its fully classical counterpart vs. temperature @xmath132 . the parameters are set as follows : @xmath104 , @xmath105 , @xmath90 , @xmath91 , @xmath92 , @xmath93 and @xmath94 . ] there is a question if the peaks in the multi - stable state are meaningful , i.e. if they occur in a typical experiment performed on the system . the problem can be quantified in the following equivalent way : one can ask if the equilibrium statistics of the system is governed by ordered or quasi - ordered phases. as a measure of such a quasi - order , we exploit the celebrated shannon entropy @xcite @xmath133=-\\int_{-\\infty}^\\infty p(x)\\ln p(x ) dx.\\end{aligned}\\ ] ] assuming a finite value of the quantum correction parameter @xmath134 results in decreasing of entropy , i.e. the system becomes more ordered @xcite . it is obvious that an effective order is due to increasing significance of the events occurring with the high probability which are either vanishing or self - sustaining fluxes . we would like to stress that the entropic criterion does not characterize stability of maxima or their life - times but rather a relative frequency of their occurrence . the shannon entropy plotted for two systems : with and without quantum smoluchowski corrections is given , as a function of temperature @xmath132 , in fig.3 . working in the classical smoluchowski regime i.e. neglecting quantum fluctuations results in lowering an overall order in the system . we would like to clarify that this effect should not be interpreted as a _ noise - induced _ order . the lower entropy means simply that , contrary to the quantum smoluchowski domain , the classical regime corresponds to the disorder which is _ over - estimated_.      bistable systems are natural candidates for qubits . the celebrated examples are josephson - junction based devices which can be generally divided into two classes : charge and flux qubits @xcite . it seems that a qubit can also be based on non - superconducting materials @xcite . because within tailored parameter regimes in the quantum smoluchowski domain there are symmetric peaks in the multi - stable state , such a system is a good candidate for a _ qutrit_. the problem of the qutrit implementation is of a central importance for quantum cryptography @xcite . the following discussion is purely qualitative . we assume for simplicity that there are only three significant ( in the statistical sense ) peaks in probability distribution , as e.g. in fig . 2 . replicating feynman s discussion of the ammonia molecule @xcite one can propose the hamiltonian of the system as a @xmath135 real symmetric matrix with diagonal elements proportional to the energy of the system calculated at magnetic flux extremal value via eq . ( [ h ] ) . the off - diagonal elements are proportional to the inverse of inter - peak transition times . let us notice that in the quantum smoluchowski regime this transitions include tunneling effects . the phenomenological modeling of quantum dynamics of the classically dissipative system may cause certain difficulties : one arrives directly at quantum dissipative system which conservative component may be chosen , to some extent , arbitrary . the system under consideration can be effectively truncated to the qutrit and it is a _ mesoscopic example _ of the generic @xmath136-system @xcite . such a system controlled by external coherent driving , i.e. equipped with an auxiliary bosonic field(s ) can be naturally studied via quantum jump approach @xcite . a steady state of the magnetic flux in mesoscopic rings is both qualitatively and quantitatively different in the classical and quantum smoluchowski regimes . quantum effects are responsible , in dependence of parameters values , for both destruction of bistability at moderate temperatures and formation of @xmath137-stability , with @xmath137 odd , at low temperatures . the nontrivial flux dependence of the steady state results in statistical enhancement of fluxes of certain amplitudes . this qualitative effect is caused by equilibrium quantum noise . validity of the multi - stability has been verified via the entropic criterion . we showed that the quantum smoluchowski regime is more ordered compared to the classical counterpart . as the mesoscopic ring is formally identical to the zero - capacitance squid , it seems that the quantum smoluchowski regime is a valid regime for wide range of the parameters of the system and hence the effects described in the paper are of importance in experiments performed on mesoscopic rings which are multistable systems .    according to the _ today _ common wisdom solid state devices seem promising for implementation of quantum computers . both theoretical and experimental effort are mainly directed on superconducting qubits . they are relatively stable with respect to decoherence and are relatively accessible . formation of the flux qubits in superconducting ring with a junction requires an external bias which shifts the system into the bistable state . it is not the case for the rings considered in the paper and our results can be of importance for possible qutrit architecture based on the non - superconducting devices . such devices , due to their small diameters , can effectively become decoupled from the magnetic environment @xcite . this may equilibrate an absence of the superconducting phase with its collective properties . its is clear that capacitance , resistance , and coherent currents are the properties of the _ whole _ non - superconducting mesoscopic rings which are thus candidates for highly integrated quantum or semi - classical circuits @xcite . the work supported by the esf program _ stochastic dynamics : fundamentals and applications _ and the polish ministry of science and higher education under the grant n 202 131 32/3786 . 99 l. p. levy _ et al . _ , lett . * 64 * 2074 ( 1990 ) ; v. chandrasekhar _ et al . lett . * 67 * , 3578 ( 1991 ) ; b. reulet _ et al . _ , lett . * 75 * , 124 ( 1995 ) ; w. rabaut _ et al . _ , lett . * 86 * , 3124 ( 2001 ) ; r. deblock _ et al . _ , lett . * 89 * , 206803 ( 2002 ) . f. hund , ann . ( leipzig ) * 32 * , 102 ( 1938 ) . i. o. kulik , jetp lett . * 11 * , 275 ( 1970 ) ; m. bttiker , y. imry , r. landauer , phys . lett . a * 96 * , 365 ( 1993 ) . u. eckern , p. schwab , j. low . phys . * 126 * , 1291 ( 2002 ) . kravtsov , b.l . altshuler , phys . lett . * 84 * , 3394 ( 2000 ) . d. wohlleben , m. esser , p. freche , e. zipper and m. szopa , phys . lett . * 66 * 3191 ( 1991 ) ; m. lisowski , e. zipper and m. stebelski , phys . b * 59 * , 8305 ( 1999 ) . e. zipper , m. kurpas , m. szelag , j. dajka , m. szopa , phys . rev b * 74 * , 125462 ( 2006 ) . j. dajka , j. uczka , m. szopa , e. zipper , phys . rev b * 67 * , 073305 ( 2003 ) ; j. dajka , m. kostur , j. uczka , m. szopa and e. zipper acta phys . b * 34 * 3793 ( 2003 ) . a. barone , g. paterno , _ physics and applications of the josephson effect _ , wiley , new york ( 1982 ) . j. ankerhold , p. pechukas , h. grabert , phys . . lett . * 87 * , 086801 ( 2001 ) . . machura , m. kostur , p. hnggi , p. talkner , j. uczka phys . e * 70 * , 031107 ( 2004 ) ; j. uczka , r. rudnicki , p. hnggi , physica a * 351 * , 60 ( 2005 ) . cheung , y. gefen , e.k . riedel and w.h . shih phys . b * 37 * , 6050 ( 1989 ) . j. dajka , j. uczka , p. hnggi , phys . sol.b * 242 * , 196 ( 2005 ) . j. dajka , s. rogoziski ,  . machura , j. uczka , acta physica polonica b * 17 * ( 2007 ) accepted , cond - mat/0611773v1 . u. weiss,_quantum dissipative systems _ , second edition , world scientific , singapore ( 1999 ) . gardiner , _ handbook of stochastic methods _ , springer , berlin ( 1983 ) . h. grabert , u. weiss and p. talkner , z. phys . b : condensed matter * 55 * , 87 ( 1984 ) . luisell , _ quantum statistical properties of radiation _ , willey , new york ( 1973 ) .    c. beck , f. schlgl _ thermodynamics of chaotic systems . an introduction _ , cambridge university press ( 1993 ) . a. lasota , m. mackey _ probabilistic properties of chaotic systems _ , cambridge university press ( 1985 ) . y. makhlin , g. schn , a. schnirman , rev . phys . * 73 * , 357 ( 2001 ) . g. molina - terriza , a. vaziri , r. ursin , a. zeilinger , phys . rev . lett . * 94 * , 040501 ( 2005 ) . r. p. feynman , _ lectures on physics _ , addison - wesley , reading ( 1964 ) , vol 3 . plenio , p.l . knight , rev . mod . phys . * 70 * , 101 ( 1998 ) . devoret in _ quantum fluctuations s. reynaud , e. giacobino and j. zinn - justin , les houches lxiii ( 1995 ) ; m.h . devoret , a. wallraff , j.m . martinis , _ superconducting qubits : a short review _ , cond - mat/0411174v1 ( 2004 ) .", "tags": [], "output_text_a": "This paper explores the dynamics of magnetic flux in mesoscopic systems, which are intermediate between small quantum and large macroscopic objects. The study focuses on the phenomenon of persistent currents in mesoscopic rings and cylinders, which are currents that can flow without any external driving force. The authors propose a two-fluid model to describe the noisy dynamics of these currents, combining classical and quantum elements. The classical part involves normal electrons carrying dissipative current, while the quantum part involves electrons maintaining phase coherence.\n\nThe paper extends the model to include charging effects, necessary for identifying the quantum Smoluchowski regime, where quantum corrections significantly impact the existence and properties of self-sustaining currents. At moderate temperatures, these quantum corrections are destructive, but at lower temperatures, they enhance the probability of long-living states carrying magnetic flux.\n\nThe study also discusses the transition from classical to quantum Smoluchowski regimes, highlighting a decrease in Shannon entropy, indicating a more ordered state. The authors suggest that mesoscopic rings could serve as candidates for qutrits, which are three-level quantum systems, rather than qubits, due to the multistability observed.\n\nThe paper concludes that the quantum Smoluchowski regime offers a more ordered state compared to the classical regime, and the findings could be significant for developing quantum information technologies using non-superconducting devices. The research is supported by various scientific grants and references numerous studies in the field.", "output_text_b": "This article discusses the behavior of mesoscopic systems, which exist in the territory between the physics of small quantum objects and macroscopic objects. Despite extensive research, many aspects of this territory remain unknown to both experimentalists and theoreticians. One such question is the mechanism responsible for the unexpectedly large amplitude of persistent currents in normal metal multiply connected samples. The article suggests that this could be due to non-equilibrium noise in the system. It is also predicted that currents can flow in mesoscopic rings even in the absence of any driving, but this has not been observed yet. The existence of self-sustaining currents is a desired property for quantum information retrieval and computing technologies based on non-superconducting devices.\n\nThe article also discusses a two-fluid model of noisy dynamics of the magnetic flux in mesoscopic rings and cylinders. The dynamics of the magnetic flux is described by an evolution equation equivalent to a Langevin equation for an overdamped motion of a classical Brownian particle. The steady state of the system is characterized by the asymptotic probability density, which is a stationary solution of the corresponding Fokker-Planck equation. The model is a hybrid of quantum and classical parts and is similar to the model of a resistively shunted Josephson junction.\n\nThe article further explores the impact of quantum nature of dissipative kinetics on the properties of fluxes and currents flowing in such systems. The authors use the quantum Smoluchowski equation to study the properties of the stationary magnetic flux in the quantum Smoluchowski domain. They show that the passage from the classical Smoluchowski regime into the quantum Smoluchowski regime is accompanied by a decrease in the Shannon entropy, emphasizing the significance of the multistable ordered state.\n\nIn summary, the article discusses the behavior of mesoscopic systems, with a focus on the two-fluid model of noisy dynamics of the magnetic flux and the impact of quantum nature of dissipative kinetics on the properties of fluxes and currents flowing in such systems.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings, such as the dynamics of magnetic flux in mesoscopic systems and the proposal of a two-fluid model. It also mentions the transition from classical to quantum Smoluchowski regimes and the potential application in quantum information technologies.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding persistent currents in mesoscopic systems.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the two-fluid model and the extension to include charging effects.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the impact of quantum corrections and the potential for mesoscopic rings to serve as qutrits.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms like \"quantum Smoluchowski regime\" but provides context to understand them.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow of information.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention specific experiments or data, which is a missing element.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the potential impact in quantum information technologies.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the behavior of mesoscopic systems, the two-fluid model, and the impact of quantum nature on fluxes and currents.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary mentions the research problem regarding the mechanism responsible for the large amplitude of persistent currents.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of the two-fluid model and the quantum Smoluchowski equation.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the decrease in Shannon entropy and the significance of the multistable ordered state.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like the two-fluid model and quantum Smoluchowski equation.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear beginning, middle, and end.\n9. \"It should mention any key experiments or data used in the research.\" - The summary does not mention any specific experiments or data used in the research.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in quantum information retrieval and computing technologies."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "supersymmetry ( susy ) is currently the most attractive theoretical framework describing physics beyond the standard model ( sm ) . even the minimal extension of the sm incorporating susy ( mssm ) predicts a zoo of new particles , which have not yet been observed . one of the major areas of activity in high energy physics today and in the near future is to prove their existence . if susy is realised at the electroweak ( ew ) scale , many of the superparticles should be discovered at next generation hadron colliders , such as tevatron ( run ii , @xmath5 tev ) at fnal and the large hadron collider ( lhc , @xmath6 tev ) at cern . these machines , while having the chance of being the first to access the susy domain , are however hampered by the fact that a large qcd background and the lack of knowledge of the initial centre - of - mass ( cm ) partonic energies render difficult the task of determining sparticle properties ( masses , couplings , quantum numbers , etc . ) . an insight into this ` susy spectrum ' would in fact shed light on the yet unknown mechanism leading to susy - breaking . in contrast , in @xmath7 collisions , the qcd noise is under control and the initial energies of the leptons are generally well known . this has contributed in the recent years to the generation of a strong consensus behind the option of building electron - positron linear colliders ( lcs ) , operating in the energy range from 500 gev to 3 tev , as the accelerators most suited to inherit the legacy of the run ii and lhc era @xcite . such machines would not only provide the ideal environment for discovering the susy particles which could be missed out at the fnal and cern experiments , but would also allow for the precise determination of the mentioned susy spectrum . for example , mass measurements are aided by the ability to perform threshold scans by varying the collider cm energy . furthermore , the spin properties of many susy particles can be accessed by exploiting an efficient beam polarisation , a feature altogether missing at the tevatron and the lhc . another advantage of lcs is that they can easily be converted to run quite simply in @xmath8 mode or even in @xmath9 and @xmath0 , the latter by using compton back - scattering of laser photons against the electrons / positrons @xcite , all such collisions taking place with energy and luminosity comparable to those obtainable from the primary @xmath7 design . quite apart from susy @xcite , it should be recalled that electron - electron collisions would constitute a privileged window on , _ e.g. _ , models with extended higgs sectors whereas those employing photon beams would easily allow for , _ e.g. _ , the study of a plethora of qcd topics .    to come back to susy , it should be mentioned that there have been in the recent years quite promising explorations of the physics potential of @xmath10 lcs as a probe of the low energy dynamics of the theory @xcite . it is the intention of our study to further dwell on this topic , by considering the scope of lcs in accessing some r - parity - violating ( rpv ) signals of susy . the construction of the most general supersymmetric extension of the sm leads to baryon-@xmath11- and lepton-@xmath12-number - violating operators in the superpotential @xmath13 here , @xmath14 , @xmath15 are the @xmath16 doublets higgs superfields which give rise to the masses of down - type and up - type quark superfields , respectively , @xmath17 denotes lepton(quark ) doublet superfields , @xmath18 , @xmath19 , @xmath20 are the singlet lepton and quark superfields , @xmath21 are the generational indices and we have suppressed the @xmath16 and @xmath22 indices . the @xmath23 are anti - symmetric in @xmath24 and @xmath25 while the @xmath26 are anti - symmetric in @xmath25 and @xmath27 . the first three terms in @xmath28 violate lepton number and the last term violates baryon number conservation . the simultaneous presence of both b- and l - violating operators would induce rapid proton decay which would contradict the strict experimental bound of @xcite . in order to keep the proton lifetime within the experimental limit , one needs to impose an additional symmetry beyond the sm gauge symmetry , in order to force the unwanted b- and l - violating interactions to vanish . in most cases , this can be achieved by imposing a discrete symmetry , called r - parity @xcite , defined as @xmath29 , where s is the spin . this symmetry not only forbids rapid proton decay @xcite but also renders stable the lightest supersymmetric particle ( lsp ) .    however , r - parity is quite an _ ad hoc _ assumption in nature , as there are no strong theoretical arguments to support it . therefore , it is much justified to investigate the phenomenological consequences of rpv susy . extensive studies have been carried out in order to look for direct as well as indirect evidence of trilinear r - parity violation in different processes at various colliders as well as in order to put constraints on various rpv couplings @xcite . resonant sneutrino production in @xmath10 collisions has been studied in ref . @xcite , where the rare decays into two photons or gluons were considered . in this article , we will consider instead rpv single production of sneutrinos in association with fermion pairs in polarised photon - photon collisions at 500 gev and 1 tev lcs , and their subsequent decays into two further fermions , via trilinear l - violating operators , while preserving b - conservation . the latter channel is in our opinion more suited as a sneutrino ` search ' mode in @xmath0 collisions than the former , simply because one can scan a wider range of sneutrino masses @xmath30 ( as long as @xmath31 ) , thanks to the fact that some amount of energy is carried away by the accompanying fermion pair , whereas in direct production the only @xmath32 attainable is basically the ( reduced ) cm energy itself . furthermore , the associate mode may also induce flavour changing final states , so that  as pointed out in @xcite  unlike in the case of resonant production , one has that the corresponding signatures are basically sm background free . schematically , one has @xmath33 with @xmath34 where the @xmath35 s refer to @xmath36 and @xmath37 leptons and the @xmath38 s to @xmath39 and @xmath40 quarks . finally , the main advantage of exploiting @xmath0 collisions in place of @xmath7 ones @xcite in producing single sneutrinos in association with a fermion pair in final states of the type ( [ production ] ) resides in the fact that the cross sections for the former are generally larger than those for the latter , as one can appreciate in figure  [ comparison ] . there , as an illustration , we have plotted the unpolarised production rates for both the @xmath0 and @xmath7 induced modes , using the photon structure functions given in @xcite , at @xmath41 gev and 1 tev . apart from the @xmath42 final state , which in electron - positron annihilation receives very large additional contributions from small angle bhabha - like scattering amplitudes ( with respect to the other final states ) , the photon processes are dominant over the electron - positron ones processes to another paper @xcite . we should however mention here that we have verified that , given the final luminosities collected at lep2 ( see ref . @xcite ) , the signatures considered in ( [ production])([decay ] ) but produced via @xmath7 annihilations between 2060 and 210 gev could have not been seen at the cern machine , for the choice of rpv couplings adopted in the following ( see also @xcite ) . ] . the @xmath0 induced associate production process has been investigated recently in ref . @xcite , by assuming unpolarised photon beams and without any detailed background estimates . we will improve on that study by exploiting polarised @xmath0 scatterings , as it has been shown that a high degree of polarisation can be transmitted from the electrons , positrons and laser photons to the compton back - scattered photons , and by including a study of the irreducible sm background . in fact , it will be shown that polarisation may help to improve the signal - to - background ratio ( @xmath43 ) in some instances . we consider a general mssm parameter space , with no assumption on the mechanism of susy - breaking , hence defining all parameters at the ew scale .    before proceeding to the analysis , it is is useful to note at this point that the @xmath44 terms in ( [ superp ] ) can in principle be removed by a re - definition of the lepton doublets @xmath45 , which would in turn lead to their ` absorption ' into the @xmath46 couplings and in the parameters of the scalar potential of the susy model . however , the @xmath44 s could then re - appear at a different energy scale . bilinear terms could also lead to a possible vacuum expectation value ( vev ) for the sneutrino(s ) and mixing of : ( @xmath47 ) charged leptons with charginos , ( @xmath40 ) sleptons with charged higgs bosons , ( @xmath48 ) neutrinos with neutralinos and ( @xmath49 ) sneutrinos with neutral higgs bosons . this last mixing could indeed affect the process discussed here . however , this phenomenon is suppressed by the small yukawa couplings of our @xmath35 and @xmath38 fermions , so that we feel justified in neglecting it here ( _ i.e. _ , we are making the assumption that the @xmath44 terms are small))([decay ] ) , @xmath50 quarks contributions will have negligible impact , because strongly suppressed by phase space effects . ( some phenomenological consequences of a sneutrino vev and l - violating mixing have been discussed in literature @xcite . ) ] . the paper is organised as follows . in section 3 , we discuss the phenomenology of processes ( [ production])([decay ] ) in presence of polarised incoming photons . in section 4 we present our numerical results ( including those for the backgrounds ) , followed by our conclusions in section 5 . in the rpv mssm , the sneutrino displays a coupling with pairs of leptons ( @xmath51-type couplings ) and quarks ( @xmath52-type couplings ) . single production of sneutrino in association with fermion pairs in ( [ production ] ) can occur through any of these two types of l - violating couplings . depending upon the nature of the vertex involved , the above process may also lead to flavour changing final states . the polarised photon flux and polarisation have been worked out in @xcite and are discussed in details in ref . @xcite . for brevity , we do not reproduce here those formulae , rather we simply recall to the un - familiar reader the basic features of polarised @xmath0 scatterings .    1 . we assume that the laser back - scattering parameter assumes its maximum value , @xmath53 @xcite . in fact , with increasing @xmath54 the high energy photon spectrum becomes more mono - chromatic . however , for @xmath55 , the probability of @xmath7 pair creation increases , resulting in larger photon beam degradation . 2 .   the reflected photon beam carries off only a fraction @xmath56 of the @xmath57 energy , with @xmath58 , while @xmath59 ( hereafter , @xmath60 ) . the polarization of the two initial laser ( @xmath61 ) and electron / positron ( @xmath62 ) beams are defined by @xmath63 and @xmath64 , respectively , where , for the first two quantities , @xmath65 identifies the laser colliding against the electron(positron ) . 4 .   finally , one can cast the polarised production cross - section in the following form : @xmath66 where @xmath67 is the electron(positron ) momentum fraction carried by the emerging photon , @xmath68 , with @xmath69(@xmath70 being the cm energy squared of the @xmath7(@xmath71 ) system , and @xmath72 the photon distribution functions , defined in terms of @xmath73 and @xmath74 and yielding @xmath75 , the degree of polarisation of the photon that has back - scattered against the electron(positron ) for purely left(right ) handed photons . ] . therefore , in terms of helicity amplitudes one has ( here , for brevity , @xmath76 ) @xmath77.\\end{aligned}\\ ] ] as polarised @xmath61-structure functions we have used those of ref . @xcite . the flavour of the final state fermions will depend upon the rpv couplings involved . it has been shown that most of the first two generation l - violating terms are highly constrained from different low and medium energy processes @xcite . for our study , we made the assumption that just one l - violating coupling at a time is the dominant one , so that only bounds derived under the same hypothesis are relevant . this restriction may seem unnatural , however , it is a useful approach that allows one to derive a quantitative feeling for the phenomenological consequences of rpv interactions , while avoiding a proliferation of susy input parameters . in our analysis , we will concentrate on the following l - violating couplings : @xmath78 and @xmath79 . the reason for selecting this particular set out of the 36 possible couplings is that these are less constrained and at the same time can lead to a significant contribution to the production as well as the decay rates of sneutrinos in ( [ production])([decay ] ) . the upper limits on these couplings and the processes which give such bounds are shown in table  [ rpv_lim ] . # 1 , # 2 # 3 _ phys . rev . _ * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ phys . _ d * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ phys . rev . _ d * # 1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ phys . * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ phys . lett . _ * # 1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ phys . lett . _ * b#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ phys . lett . _ * b#1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ nucl . phys . _ * b#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ nucl . phys . _ * b#1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ phys . rep . _ * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ z. phys . _ * c#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ eur . phys . j. _ * c#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ mod . lett . _ * a#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3_int . j. mod * a#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ prog . theor . phys . _ * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ j. high energy phys . _ * # 1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ j. high energy phys . _ * # 1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ eur . phys . j. _ * c#1 * , # 2 ( 19#3 ) # 1 , # 2 # 3 _ eur . phys . j. _ * c#1 * , # 2 ( 20#3 ) # 1 , # 2 # 3 _ mod . * a#1 * , # 2 ( 20#3 )    99 k.  abe , [ the acfa linear collider working group ] , hep - ph/0109166 and references therein ; t.  abe , [ the american linear collider working group ] , hep - ex/0106055 ; hep - ex/0106056 ; hep - ex/0106057 and hep - ex/0106058 and references therein ; j.a . aguilar - saavedra , [ the ecfa / desy lc physics working group ] , preprint slac - reprint-2001 - 002 , desy-01 - 011 , desy-2001 - 011 , desy-01 - 011c , desy-2001 - 011c , desy - tesla-2001 - 23 , desy - tesla - fel-2001 - 05 , ecfa-2001 - 209 , march 2001 , hep - ph/0106315 ; g. guignard ( editor ) , [ the clic study team ] , preprint cern-2000 - 008 . s.  berge , m. klasen and y. umeda , 63 , 35003 01 ; a.  datta and d.  choudhury , 592 , 35 01 ; t.  mayer and h.  fraas , _ nucl . instrum . _ * a 472 * , 165 ( 2001 ) ; d.  gorbunov , v. ilyin and v. telnov , _ nucl . instrum . meth . _ * a 472 * , 171 ( 2001 ) ; d.m . asner , j.b . gronberg and j.f . gunion , hep - ph/0110320 and references therein . hall and m.   suzuki , 231 , 419 84 ; r.  barbieri and a.  masiero , 267 , 679 86 ; s. dimopoulos and l.j . hall , 207 , 210 88 ; v.  barger , g.  f.   giudice and t.  han , 40 , 2987 89 ; m. czakon and j. gluza , hep - ph/0003228 ; r.  godbole , p. roy and x. tata , 401 , 67 93 ; g.  bhattacharyya , j.r . ellis and k. sridhar , 10 , 1583 95 ; g.  bhattacharyya , d. choudhury and k. sridhar , 355 , 193 95 ; d. choudhury and s. raychaudhury , 401 , 54 97 ; d.k . ghosh , s. raychaudhuri and k. sridhar , 396 , 177 97 ; k.  huitu , j. maalampi , m. raidal and a. santamaria , 430 , 355 98 ; g. moreau , ` _ phenomenological study of the interactions violating the r - parity symmetry in the supersymmetric theories _ ' , ph.d . thesis , hep - ph/0012156 and references therein . l.j .  hall and m.  suzuki in ref . @xcite ; i - h . lee , 138 , 121 84 ; 246 , 120 84 ; s.  dawson , 261 , 297 85 ; f.  de campos , m.a . garcia - jareno , a.s . joshipura , j. rosiek and j.w.f . valle,451 , 3 95 ; m.  nowakowski and a.  pilaftsis , 461 , 19 96 ; r.  hempfling , 478 , 3 96 ; s.  roy and b.  mukhopadhyaya , 55 , 7020 97 ; m.  hirsch , m.a . daz , w. porod , j.c . romao and j.w.f . valle , 62 , 3008 00 . s.  berge , m. klasen and y. umeda , in ref .", "tags": [], "output_text_a": "The paper discusses the potential of supersymmetry (SUSY) as a framework for physics beyond the Standard Model (SM), focusing on the Minimal Supersymmetric Standard Model (MSSM) and its implications for future collider experiments. The MSSM predicts a range of new particles, which have yet to be observed, and proving their existence is a major goal in high-energy physics. The paper highlights the advantages of electron-positron linear colliders (LCs) over hadron colliders like the Tevatron and the Large Hadron Collider (LHC) for discovering and studying these SUSY particles. LCs offer a cleaner environment with controlled initial energies, enabling precise measurements of SUSY particle properties, such as masses and spins, and allowing for the exploration of R-parity-violating (RPV) signals.\n\nThe study focuses on the single production of sneutrinos in association with fermion pairs in polarized photon-photon collisions at LCs, considering RPV interactions that violate lepton number while conserving baryon number. The paper argues that this method is more effective for sneutrino searches than direct production, as it allows for a broader range of sneutrino masses to be explored and can produce flavor-changing final states with minimal SM background. The authors also discuss the benefits of using polarized photon beams to enhance the signal-to-background ratio and provide a detailed analysis of the phenomenology and numerical results for these processes, considering various RPV couplings and their constraints.\n\nOverall, the paper emphasizes the potential of LCs to advance the understanding of SUSY and RPV interactions, offering insights into the low-energy dynamics of the theory and the mechanisms of SUSY-breaking. The study contributes to the ongoing efforts to explore new physics beyond the SM and the role of future collider experiments in this endeavor.", "output_text_b": "The paper discusses the potential of Linear Colliders (LCs) in probing supersymmetry (SUSY) beyond the Standard Model (SM), specifically focusing on R-parity-violating (RPV) signals. SUSY, if realized at the electroweak scale, predicts a variety of new particles, including superparticles. The Large Hadron Collider (LHC) and Tevatron are designed to discover these superparticles, but their properties (masses, couplings, quantum numbers, etc.) are difficult to determine due to the large QCD background and lack of knowledge of initial partonic energies. LCs, operating in the energy range from 500 GeV to 3 TeV, provide an ideal environment for discovering SUSY particles that might be missed in FNAL and CERN experiments and allow for precise determination of the SUSY spectrum.\n\nThe paper considers RPV single production of sneutrinos in association with fermion pairs in polarized photon-photon collisions at 500 GeV and 1 TeV LCs, followed by their decays into two further fermions via trilinear L-violating operators while preserving B-conservation. This channel is more suited for sneutrino 'search' mode in LCs than resonant production due to the wider range of sneutrino masses attainable and the potential for flavour changing final states, which are essentially SM background-free.\n\nThe main advantage of exploiting LCs in place of LCs in producing single sneutrinos in association with a fermion pair in final states resides in the larger cross sections for LCs-induced modes compared to LCs-induced processes. The paper also discusses the phenomenology of processes in the presence of polarized incoming photons and presents numerical results, including backgrounds.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the potential of SUSY, the advantages of LCs, and the focus on RPV interactions.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the discovery and study of SUSY particles, is highlighted.\n4. The methodology, including the use of polarized photon-photon collisions and the focus on RPV interactions, is mentioned.\n5. Significant results, such as the effectiveness of the proposed method for sneutrino searches and the benefits of polarized beams, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like RPV and LCs are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research, which is a requirement.\n10. The potential impact of the research in advancing the understanding of SUSY and RPV interactions is reflected.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the potential of Linear Colliders (LCs) in probing supersymmetry (SUSY) and focusing on R-parity-violating (RPV) signals.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the challenges of discovering and determining the properties of SUSY particles.\n4. The methodology or approach used in the paper is mentioned, including the use of polarized photon-photon collisions and the study of RPV single production of sneutrinos.\n5. Significant results or conclusions drawn by the authors are included, such as the advantages of LCs over other colliders and the potential for flavor-changing final states.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like R-parity-violating (RPV) and sneutrinos.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary does not mention any key experiments or data used in the research, which is a requirement.\n10. The summary reflects the paper's significance or potential impact in its field by discussing the advantages of LCs in discovering SUSY particles."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "over the past two decades , the utility of type ia supernovae ( sne ia ) as standardizable candles to trace the expansion history of the universe has been underscored by the increasing resources dedicated to optical / near - ir discovery and follow - up campaigns ( @xcite ; @xcite ) . at the same time , the nature of their progenitor system(s ) has remained elusive , despite aggressive studies to unveil them ( see e.g. @xcite ) . the second nearest ia sn discovered in the digital era , sn  2011fe @xcite located at @xmath6 @xcite , represents a natural test bed for a detailed sn ia progenitor study @xcite . ] . the best studied type ia sn at early times before sn  2011fe , sn  2009ig , demonstrated how single events can provide significant insight into the properties of this class of explosions @xcite . the fundamental component of sn ia progenitor models is an accreting white dwarf ( wd ) in a binary system . currently , the most popular models include ( i ) a single - degenerate ( hereafter , sd ) scenario in which a massive wd accretes material from a h - rich or he - rich companion , potentially a giant , subgiant or main - sequence star , ( @xcite ; @xcite ) . mass is transferred either via roche - lobe overflow ( rlof ) or through stellar winds . alternatively , ( ii ) models invoke a double sub-@xmath7 wd binary system that eventually merges ( double degenerate model , dd ; @xcite , @xcite ) .    in sd models , the circumbinary environment may be enriched by the stellar wind of the donor star or through non - conservative mass transfer in which a small amount of material is lost to the surroundings . winds from the donor star shape the local density profile as @xmath8 over a @xmath9 parsec region encompassing the binary system . theoretical considerations indicate that the wind - driven mass loss rate must be low , since an accretion rate of just @xmath10 is ideal for the wd to grow slowly up to @xmath7 and still avoid mass - losing nova eruptions ( steady burning regime , @xcite ) . strong evidence for the _ lack _ of a wind - stratified medium and/or the detection of a constant local density ( with a typical interstellar medium density of @xmath11 ) may instead point to a dd model . arising from the interaction of the sn shock blast wave with the circumbinary material , radio and x - ray observations can potentially discriminate between the two scenarios by shedding light on the properties of the environment , shaped by the evolution of the progenitor system ( see e.g. @xcite , @xcite ) . motivated thus , several dozen sne ia at distances @xmath12 mpc have been observed with the very large array ( vla ; @xcite ; @xcite ; soderberg in prep . ) , the chandra x - ray observatory @xcite , and the swift x - ray telescope ( @xcite ; russel & immler , in press ) revealing no detections to date . these limits were used to constrain the density of the circumbinary material , and in turn the mass loss rate of the progenitor system . however these data poorly constrain the wd companion , due in part to the limited sensitivity of the observations ( and the distance of the sne ) . the improved sensitivity of the expanded very large array ( evla ) coupled with a more detailed approach regarding the relevant radio and x - ray emission ( and absorption ) processes in type ia supernovae , has enabled the deepest constraints to date on a circumbinary progenitor as discussed in our companion paper on the recent type ia sn2011fe/ ptf11kly ( @xcite . see also @xcite ) .    here we report a detailed panchromatic study of sn2011fe bridging optical / uv and gamma - ray observations . drawing from observations with the _ swift _ and chandra satellites as well as the interplanetary network ( ipn ; @xcite ) , we constrain the properties of the bulk ejecta and circumbinary environment through a self - consistent characterization of the dynamical evolution of the shockwave . first we present optical / uv light - curves for the sn , indicating that the object appears consistent with a `` normal '' sn ia . next we discuss deep limits on the x - ray emission in the month following explosion . we furthermore report gamma - ray limits ( 25 - 150 kev ) for the shock breakout pulse . in the appendix we present an analytic generalization for the the inverse compton ( ic ) x - ray luminosity expected from hydrogen poor sne that builds upon previous work by @xcite and @xcite but is broadly applicable for a wide range of shock properties , metallicity , photon temperatures , and circumstellar density profiles ( stellar wind or ism ; see appendix [ sec : iclum ] ) . we apply this analytic model to sn2011fe to constrain the density of the circumbinary environment , and find that our limits are a factor of @xmath13 10 deeper than the results recently reported by @xcite . observations are described in sec . [ sec : obs ] ; limits to the sn progenitor system from x - ray observations are derived and discussed in sec . [ sec : xray ] using the ic formalism from appendix [ sec : iclum ] . we combine our radio @xcite and x - ray limits to constrain the post - shock energy density in magnetic fields in sec . [ sec : epsilonb ] , while the results from the search of a burst of gamma - ray radiation from the sn shock break - out is presented in sec . [ sec : gammaray ] . conclusions are drawn in sec . [ sec : conc ] . -0.0 true cm   region around the sn is marked with a white box . _ inset : _ _ chandra _ 0.5 - 8 kev deep observation of the same region obtained at day 4 since the explosion . no source is detected at the sn position ( white circle ) . , title=\"fig : \" ]    sn  2011fe was discovered by the palomar transient factory ( ptf ) on 2011 august 24.167 ut and soon identified as a very young type ia explosion in the pinwheel galaxy ( m101 ) ( @xcite ) . from early time optical observations @xcite were able to constrain the sn explosion date to august 23 , @xmath14 ( ut ) . the sn site was fortuitously observed both by the _ hubble space telescope _ ( hst ) and by _ chandra _ on several occasions prior to the explosion in the optical and x - ray band , giving the possibility to constrain the progenitor system ( @xcite ; @xcite ) . very early optical and uv photometry has been used by @xcite and @xcite to infer the progenitor and companion radius and nature , while multi - epoch high - resolution spectroscopy taken during the evolution of the sn has been employed as a probe of the circumstellar environment @xcite . limits to the circumstellar density have been derived from deep radio observations in our companion paper @xcite , where we consistently treat the shock parameters and evolution . here we study sn  2011fe from a complementary perspective , bridging optical / uv , x - ray and gamma - ray observations . _ swift _ observations were acquired starting from august 24 , @xmath15 days since the onset of the explosion . _ swift_-xrt data have been analyzed using the latest release of the heasoft package at the time of writing ( v11 ) . standard filtering and screening criteria have been applied . no x - ray source consistent with the sn position is detected in the 0.3 - 10 kev band either in promptly available data ( @xcite ; @xcite ) or in the combined @xmath16 ks exposure covering the time interval @xmath17 days ( see fig . [ fig : x - rays ] ) . in particular , using the first 4.5 ks obtained on august 24th , we find a psf ( point spread function ) and exposure map corrected @xmath18 count - rate limit on the undetected sn @xmath19 . for a simple power - law spectrum with photon index @xmath20 and galactic neutral hydrogen column density @xmath21 @xcite this translates into an unabsorbed 0.3 - 10 kev flux @xmath22 corresponding to a luminosity @xmath23 at a distance of 6.4 mpc @xcite . collecting data between 1 and 65 days after the explosion ( total exposure of @xmath16 ks ) we obtain a @xmath18 upper limit of @xmath24 ( @xmath25 , @xmath26 ) . finally , extracting data around maximum light ( the time interval 8 - 38 days ) , the x - rays are found to contribute less than @xmath27 ( @xmath18 limit , total exposure of 61 ks ) corresponding to @xmath28 , @xmath29 . we observed sn  2011fe with the _ chandra _ x - ray observatory on aug 27.44 ut ( day 4 since the explosion ) under an approved ddt proposal ( pi hughes ) . data have been reduced with the ciao software package ( version 4.3 ) , with calibration database caldb ( version 4.4.2 ) . we applied standard filtering using ciao threads for acis data . no x - ray source is detected at the sn position during the 50 ks exposure @xcite , with a @xmath18 upper limit of @xmath30 in the 0.5 - 8 kev band , from which we derive a flux limit of @xmath31 corresponding to @xmath32 ( assuming a simple power - law model with spectral photon index @xmath33 ) . @xmath18 upper limits from _ swift _ and _ chandra _ observations are shown in fig . [ fig : ic ] . the sn was clearly detected in _ swift_-uvot observations . photometry was extracted from a @xmath34 aperture , closely following the prescriptions by @xcite ( see fig . [ fig : ic ] ) . pre - explosion images of the host galaxy acquired by uvot in 2007 were used to estimate and subtract the host galaxy light contribution . our photometry agrees ( within the uncertainties ) with the results of @xcite . with respect to @xcite we extend the uvot photometry of sn  2011fe to day @xmath35 since the explosion . due to the brightness of sn  2011fe , u , b and v observations strongly suffer from coincidence losses @xcite around maximum light ( see @xcite for details ) : supernova templates from @xcite were used to fit the u and b light - curves and infer the sn luminosity during those time intervals in the u and b bands . for the v - band , it was possible to ( partially ) recover the original light - curve applying standard coincidence losses corrections : however , due to the extreme coincidence losses , our v - band light - curve may still provide a lower limit to the real sn luminosity in the time interval @xmath36 days since explosion . in fig . [ fig : ic ] we present the _ swift_-uvot 6-filter light - curves , and note that the re - constructed v - band is broadly consistent with the nugent template . we adopted a galactic reddening of @xmath37 @xcite .    in the case of the `` golden standard '' ia sn  2005cf ( which is among the best studied ia sne ) , the v band is found to contribute @xmath38 to the bolometric luminosity @xcite , with limited variation over time . for sn  2011fe , we measure at day 4 a v - band luminosity @xmath39 , corresponding to @xmath40 and note that at this time the luminosity in the v , b , u , w1 and w2 bands account for @xmath41 . we therefore assumed that the v , b , u , w1 and w2 bands represent @xmath42 . in the following we explicitly provide the dependence of our density limits on @xmath43 , so that it is easily possible to re - scale our limits to any @xmath43 value . given that the optical properties point to a normal sn ia ( parrent at al . in prep . ) we adopt fiducial parameters @xmath44 and @xmath45 for the ejecta mass and sn energy , respectively , throughout this paper . -0.0 true cm     -0.0 true cm   upper limit as a function of the power - law index of the electron distribution @xmath46 assuming @xmath47 . upper limit contours in the cases @xmath48 k and @xmath49 k are also shown for comparison ( black dashed lines ) . yellow bullets : upper limit to the csm density as derived from radio observations for @xmath50 in the range @xmath51 . @xmath52 gives the tightest constraint @xcite . we assume @xmath45 , @xmath53 , @xmath54 . , title=\"fig : \" ]   upper limit as a function of the power - law index of the electron distribution @xmath46 assuming @xmath47 . upper limit contours in the cases @xmath48 k and @xmath49 k are also shown for comparison ( black dashed lines ) . yellow bullets : upper limit to the csm density as derived from radio observations for @xmath50 in the range @xmath51 . @xmath52 gives the tightest constraint @xcite . we assume @xmath45 , @xmath53 , @xmath54 . , title=\"fig : \" ]    x - ray emission from sne may be attributed to a number of emission processes including ( i ) synchrotron , ( ii ) thermal , ( iii ) inverse compton ( ic ) , or ( iv ) a long - lived central engine ( see @xcite for a review ) . it has been shown that the x - ray emission from stripped supernovae exploding into low density environments is dominated by ic on a timescale of weeks to a month since explosion , corresponding to the peak of the optical emission ( @xcite , @xcite ) . in specific cases , this has been shown to be largely correct ( e.g. , sn  2008d @xcite , sn  2011dh @xcite ) .    in this framework the x - ray emission is originated by up - scattering of optical photons from the sn photosphere by a population of relativistic electrons ( e.g. @xcite ) . the ic x - ray luminosity depends on the density structure of the sn ejecta , the structure of the circumstellar medium ( csm ) and the details of the relativistic electron distribution responsible for the up - scattering . here we assume the sn outer density structure @xmath55 with @xmath56 @xcite , as found for sne arising from compact progenitors ( as a comparison , @xcite found the outermost profile of the ejecta to scale as @xmath57 . see @xcite , soderberg in prep . for a discussion ) ; the sn shock propagates into the circumstellar medium and is assumed to accelerate the electrons in a power - law distribution @xmath58 for @xmath59 . radio observations of type ib / c sne indicate @xmath60 @xcite . however , no radio detection has ever been obtained for a type ia sn so that the value of @xmath46 is currently unconstrained : this motivates us to explore a wider parameter space @xmath61 ( fig . [ fig : icwind ] ) as seen for mildly relativistic and relativistic explosions ( e.g. , gamma - ray bursts , @xcite ; @xcite ; @xcite ) . finally , differently from the thermal or synchrotron mechanisms , the ic luminosity is directly related to the bolometric luminosity of the sn ( @xmath62 ) : the environment directly determines the _ ratio _ of the optical to the x - ray luminosity , so that possible uncertainties on the distance of the sn do not affect the ic computation ; it furthermore does _ not _ require any assumption on magnetic field related parameters .    for a population of optical photons with effective temperature @xmath63 , the ic luminosity at frequency @xmath64 reads ( see appendix [ sec : iclum ] ) : @xmath65 where @xmath66 is the extension of the region containing fast electrons ; @xmath67 is the circumstellar medium density the sn shock is impacting on , which we parametrize as a power - law in shock radius @xmath68 ; together with @xmath69 , @xmath67 determines the shock dynamics , directly regulating the evolution of the shock velocity @xmath70 , shock radius @xmath71 and @xmath72 as derived in appendix [ sec : iclum ] . for the special case @xmath73 , @xmath74 , its dependence on @xmath63 cancels out and it is straightforward to verify that eq . [ eq : icgeneral ] matches the predictions from @xcite , their eq . ( 31 ) for @xmath75 ( wind medium ) . in the following we use eq . [ eq : icgeneral ] and the @xmath76 evolution calculated from _ swift_-uvot observations of sn  2011fe ( sec . [ sec : obs ] ) to derive limits on the sn environment assuming different density profiles . we assume @xmath54 , as indicated by well studied sn shocks @xcite . each limit on the environment density we report below has to be re - scaled of a multiplicative factor @xmath77 for other @xmath78 values . a star which has been losing material at constant rate @xmath79 gives rise to a `` wind medium '' : @xmath80 . [ eq : icwind ] and the _ chandra _ non - detection constrain the wind density to @xmath81 ( where @xmath82 is the wind velocity ) . this is a @xmath18 limit obtained integrating eq . [ eq : icwind ] over the 0.5 - 8 kev _ pass band and assuming @xmath73 , @xmath54 , @xmath45 and @xmath53 . the observation was performed on day 4 after the explosion : at this time @xmath83 while the shock wave probes the environment density at a radius @xmath84 ( eq . [ eq : vshockrshock ] and [ eq : vshockwind ] ) for @xmath85 ( see fig . [ fig : ic ] ) . for the wind scenario @xmath86 ( see appendix [ sec : iclum ] ) .    while giving less deep constraints , _ swift _ observations have the advantage of being spread over a long time interval giving us the possibility to probe the csm density over a wide range of radii . integrating eq . [ eq : icwind ] in the time interval 1 - 65 days to match the _ swift _ coverage ( and using the 0.3 - 10 kev band ) leads to @xmath87 for @xmath88 from the progenitor site , eq . [ eq : vshockwind ] ) , these values are accurate within a factor 10 of @xmath89 variation . ] . a similar value is obtained using the x - ray limit around maximum optical light , when the x - ray emission from ic is also expected to peak ( fig . [ fig : ic ] the _ swift _ limits are arbitrarily assigned to the linear midpoint of the temporal intervals . the limit on the ambient density is however calculated integrated the model over the entire time interval so that the arbitrary assignment of the `` central '' bin time has no impact on our conclusions . ] ) . sn  2011fe might have exploded in a uniform density environment ( ism , @xmath90 ) . in this case , integrating eq . [ eq : icism ] over the 0.5 - 8 kev energy range , the _ chandra _ limit implies a csm density @xmath91 at @xmath18 confidence level for fiducial parameter values @xmath73 , @xmath54 , @xmath45 and @xmath53 . this limit applies to day 4 after the explosion ( or , alternatively to a distance @xmath92 , see fig . [ fig : ic ] ) . integrating eq . [ eq : icism ] over the time interval 1 - 65 days ( and in the energy window 0.3 - 10 kev ) the _ swift _ upper limit implies @xmath93 ( @xmath18 level ) , over a distance range @xmath94 from the progenitor site has a very gentle ( @xmath95 , see eq . [ eq : vshockism ] ) dependence on the environment density . the @xmath96 values we list are representative of an ism medium with a wide range of density values : @xmath97 . ] . around maximum light ( days 8 - 38 ) , we constrain @xmath98 for distances @xmath99 . for an ism scenario our constraints on the particle density @xmath100 ( see appendix [ sec : iclum ] ) . figure [ fig : icwind ] ( lower panel ) shows how our _ chandra _ limit compares to deep radio observations of sn  2011fe . we explore a wide parameter space to understand how a different photon effective temperature and/or electron power - law index @xmath46 would affect the inferred density limit : we find @xmath101 for @xmath102 k and @xmath103 . x - ray observations are less constraining than radio observations in the ism case when compared to the wind case : this basically reflects the higher sensitivity of the synchrotron radio emission to the blastwave velocity , which is faster for an ism - like ambient ( for the same density at a given radius ) . from the _ chandra _ non detection we derive @xmath81 . this is the deepest limit obtained from x - ray observations to date and directly follows from ( i ) unprecedented deep _ chandra _ observations , ( ii ) proximity of sn  2011fe coupled to ( iii ) a consistent treatment of the dynamics of the sn shock interaction with the environment ( appendix [ sec : iclum ] ) . before sn  2011fe , the deepest x - ray non - detection was reported for type ia sn  2002bo at a level of @xmath104 ( distance of 22 mpc ) : using 20 ks of _ chandra _ observations obtained @xmath105 after explosion , @xcite constrained @xmath106 . this limit was computed conservatively assuming thermal emission as the leading radiative mechanism in the x - rays . using a less conservative approach , other studies were able to constrain the x - ray luminosity from type ia sne observed by _ swift _ to be @xmath107 @xcite , leading to @xmath108 ( a factor @xmath109 above our result ) . our limit on sn  2011fe strongly argues against a symbiotic binary progenitor for _ this _ supernova . according to this scenario the wd accretes material from the wind of a giant star carrying away material at a level of @xmath110 for @xmath111 ( see e.g. @xcite ; @xcite ; @xcite ) . we reached the same conclusion in our companion paper @xcite starting from deep radio observations of sn  2011fe . the radio limit is shown in fig . [ fig : icwind ] for the range of values @xmath112 , with @xmath52 leading to the most constraining limit ( where @xmath50 is the post shock energy density fraction in magnetic fields ) . historical imaging at the sn site rules out red - giant stars and the majority of the parameter space associated with he star companions ( @xcite , their fig . 2 ) : however , pre - explosion images could _ not _ constrain the roche - lobe overflow ( rlof ) scenario , where the wd accretes material either from a subgiant or a main - sequence star . in this case , winds or transferred material lost at the outer lagrangian points of the system are expected to contribute at a level @xmath113 _ if _ a fraction @xmath114 of the transferred mass is lost at the lagrangian points and the wd is steadily burning ( see e.g. @xcite et al and references therein ) . the real fraction value is however highly uncertain , so that it seems premature to rule out the entire class of models based on the present evidence . x - ray limits would be compatible with rlof scenarios where the fraction of lost material is @xmath115 ( for any @xmath116 and @xmath117 k , fig . [ fig : icwind ] ) . however , from the analysis of early uv / optical data , @xcite found the companion radius to be @xmath118 , thus excluding roche - lobe overflowing red - giants and main sequence secondary stars ( see also @xcite ) . x - ray non - detections are instead consistent with ( but can hardly be considered a proof of ) the class of double degenerate ( dd ) models for type ia sne , where two wds in a close binary system eventually merge due to the emission of gravitational waves . no x - ray emission is predicted ( apart from the shock break out at @xmath119 , see sec . [ sec : gammaray ] ) and sn  2011fe might be embedded in a constant and low - density environment ( at least for @xmath120 ) . pre - explosion radio hi imaging indicates an ambient density of @xmath121 @xcite ( on scales @xmath122 ) , while our tightest limits in the case of an ism environment are @xmath123 . our observations can not however constrain the presence of material at distances in the range @xmath124 from the sn explosion : recent studies suggest that significant material from the secondary ( disrupted ) wd may indeed reside at those distances either as a direct result of the dd - merger @xcite or as an outcome of the subsequent evolution of the system @xcite . whatever the density profile of the environment , our findings are suggestive of a _ clean _ environment around sn  2011fe for distances @xmath125 . the presence of significant material at larger distances ( @xmath126 ) can not be excluded , so that our observations can not constrain models that predict a large delay ( @xmath127 yr ) between mass loss and the sn explosion ( see e.g. @xcite , @xcite and references therein ) . finally , it is interesting to note that the high - resolution spectroscopy study by @xcite lead to a similar , _ environment conclusion : at variance with sn  2006x @xcite , sn  1999cl @xcite and sn  2007le @xcite , sn  2011fe shows no evidence for variable sodium absorption in the time period @xmath128 days since explosion . in this context , a recent study by @xcite found evidence for gas outflows from type ia progenitor systems in at least @xmath129 of cases . independent constraints on the circumstellar medium density around type ia sne come from galactic type ia supernova remnants ( snr ) : the study of tycho s snr in the x - rays lead @xcite to determine a pre - shock ambient density of less than @xmath130 ; the ambient density is likely @xmath131 both in the case of kepler s snr @xcite and in the case of snr 0509 - 67.5 @xcite . we emphasize that different type ia sne might have different progenitor systems as suggested by the increasing evidence of diversity among this class : we know that 30% of local sne ia have peculiar optical properties ( @xcite , @xcite ) . the above discussion directly addresses the progenitor system of sn  2011fe : our conclusions can not be extended to the entire class of type ia sne . -0.0 true cm   has been used in the case of a wind medium . the horizontal dashed line marks equipartition ( @xmath132 ) for the assumed @xmath54 . things stands for  the hi nearby galaxy survey \" @xcite.,title=\"fig : \" ]   has been used in the case of a wind medium . the horizontal dashed line marks equipartition ( @xmath132 ) for the assumed @xmath54 . things stands for  the hi nearby galaxy survey \" @xcite.,title=\"fig : \" ]    while the ic emission model discussed here is primarily sensitive to csm density , the associated radio synchrotron emission is sensitive to both the csm density and @xmath50 ( post shock energy density in magnetic fields ) . as a consequence , when combined with radio observations of synchrotron self - absorbed sne , deep x - ray limits can be used to constrain the @xmath50 vs. ambient density parameter space ( @xcite ; @xcite ) . this is shown in fig . [ fig : epsilonb ] for a wind ( upper panel ) and ism ( lower panel ) environment around sn  2011fe : the use of the same formalism ( and assumptions ) allows us to directly combine the radio limits from @xcite with our results . we exclude the values of @xmath133 coupled to @xmath134 for a wind medium , while @xmath135 for any @xmath136 . in the case of an ism profile , x - ray limits rule out the @xmath137 @xmath138 parameter space . the exact value of the microphysical parameters @xmath50 and @xmath78 is highly debated both in the case of non - relativistic ( e.g. sne ) and relativistic ( e.g. gamma - ray bursts , grbs ) shocks : equipartition ( @xmath139 ) was obtained for sn  2002ap from a detailed modeling of the x - ray and radio emission @xcite while significant departure from equipartition ( @xmath140 ) has recently been suggested by @xcite to model sn  2011dh . the same is true for sn  1993j , for which @xmath141 @xcite . in the context of relativistic shocks , grb afterglows seem to exhibit a large range of @xmath50 and @xmath78 values ( e.g. @xcite ) ; furthermore , values as low as @xmath142 have recently been be suggested by @xcite from accurate multi - wavelength modeling of grbs with gev emission . it is at the moment unclear if this is to be extended to the entire population of grbs . on purely theoretical grounds , starting from relativistic mhd simulations @xcite concluded @xmath143 : this result applies to grb internal shocks , the late stage of grb afterglows , transrelativistic sn explosions ( like sn  1998bw , @xcite ) and shock breakout from type ibc supernova ( e.g. sn  2008d , @xcite ) . it is not clear how different the magnetic field generation and particle acceleration might be between relativistic and non - relativistic shocks . figure [ fig : epsilonb ] constitutes the first attempt to infer the @xmath50 value combining deep radio and x - ray observations of a type ia sn : better constraints on the parameters could in principle be obtained _ if _ x - ray observations are acquired at the sn optical maximum light . in the case of sn 2011fe we estimate that a factor @xmath144 improvement on the density limits would have been obtained with a _ observation at maximum light . shock break out from wd explosions is expected to produce a short ( @xmath145 ) pulse with typical @xmath146 photon energy , luminosity @xmath147 and energy in the range @xmath148 @xcite . such an emission episode would be easily detected if it were to happen close by ( either in the milky way or in the magellanic clouds ) , while sn  2011fe exploded @xmath149 mpc away @xcite . given the exceptional proximity of sn  2011fe we nevertheless searched for evidence of high - energy emission from the shock break - out using data collected by the nine spacecrafts of the interplanetary network ( ipn mars odyssey , konus - wind , rhessi , integral ( spi - acs ) , _ swift_-bat , suzaku , agile , messenger , and fermi - gbm ) . the ipn is full sky with temporal duty cycle @xmath150 and is sensitive to radiation in the range @xmath151 kev @xcite . within a 2-day window centered on aug 23rd a total of 3 bursts were detected and localized by multiple instruments of the ipn . out of these 3 confirmed bursts , one has localization consistent with sn  2011fe . interestingly , this burst was detected by konus , suzaku and integral ( spi - acs ) on august 23rd 13:28:25 ut : for comparison , the inferred explosion time of sn  2011fe is @xmath152 minutes , @xcite . the ipn error box area for this burst is @xmath153 sr . the poor localization of this event does not allow us to firmly associate this burst with sn  2011fe : from poissonian statistics we calculate a @xmath154 chance probability for this burst to be spatially consistent with sn  2011fe . a more detailed analysis reveals that sn  2011fe lies inside the konus - integral triangulation annulus but outside the konus - suzaku triangulation annulus . furthermore , at the inferred time of explosion , sn  2011fe was slightly above the fermi - gbm horizon , but no burst was detected ( in spite of the stable gbm background around this time ) . we therefore conclude that there is no statistically significant evidence for a sn - associated burst down to the fermi - gbm threshold ( fluence @xmath155 in the 8 - 1000 kev band ) for a sn - associated burst with fluence above the _ swift _ threshold and below the fermi - gbm one to occur without being detected . ] . the early photometry of sn  2011fe constrains the progenitor radius to be @xmath156 @xcite . using the fiducial values @xmath45 , @xmath53 , the shock break out associated with sn  2011fe is therefore expected to have released @xmath157 over a time - scale @xmath158 with luminosity @xmath159 at typical @xmath160 ( see @xcite , their eq . 29 ) . at the distance of sn  2011fe , the expected fluence is as low as @xmath161 which is below the threshold of all gamma - ray observatories currently on orbit ( the weakest burst observed by bat had a 15 - 150 kev fluence of @xmath162 ) . for comparison , the konus - suzaku - integral burst formally consistent with the position of sn  2011fe was detected with fluence @xmath163 and duration of a few seconds ( peak flux of @xmath164 ) . if it were to be connected with the sn , the associated @xmath165sec peak luminosity would be @xmath166 and total energy @xmath167 ( quantities computed in the 20 - 1400 kev energy band ) which are orders of magnitudes above expectations .    for @xmath168 , the temperature and luminosity drop quickly ( see @xcite for details ) : in particular , for @xmath169 the emitting shell enters the newtonian phase . for sn  2011fe we estimate @xmath170 ( @xcite , their eq . 30 ) ; for @xmath156 the luminosity at @xmath171 is @xmath172 with typical emission in the soft x - rays : @xmath173 . at later times @xmath174 @xcite while @xmath175 rapidly drops below the _ swift_-xrt energy band ( 0.3 - 10 kev ) . _ swift_-xrt observations were unfortunately not acquired early enough to constrain the shock break out emission from sn  2011fe . uv observations were not acquired early enough either : after @xmath176 hr the uv emission connected with the shock break out is expected to be strongly suppressed due to the deviation from pure radiation domination ( e.g. @xcite ) . it is however interesting to note the presence of a `` shoulder '' in the uv light - curve @xcite particularly prominent in the uvm2 filter for @xmath177 days ( see @xcite , their fig . 2 ) whose origin is still unclear ( see however @xcite ) . a detailed modeling is required to disentangle the contribution of different physical processes to the early uv emission ( and understand which is the role of the `` red leak '' -see e.g. @xcite- of the uvm2 filter in shaping the observed light - curve ) . the collision of the sn ejecta with the companion star is also expected to produce x - ray emission with typical release of energy @xmath178 in the hours following the explosion ( a mechanism which has been referred to as the analog of shock break out emission in core collapse sne , @xcite ) . according to @xcite , in the most favorable scenario of a red - giant companion of @xmath179 at separation distance @xmath180 , the interaction time - scale is @xmath181 after the sn explosion and the burst of x - ray radiation lasts @xmath182 ( with a typical luminosity @xmath183 ) : too short to be caught by our _ swift_-xrt re - pointing 1.25 days after the explosion . we furthermore estimate the high energy tail of the longer lasting thermal optical / uv emission associated to the collision with the companion star to be too faint to be detected either : at @xmath184 , the emission has @xmath185 and peaks at frequency @xmath186 ( eq . 25 from @xcite ) . non - thermal particle acceleration might be a source of x - rays at these times , a scenario for which we still lack clear predictions : future studies will help understand the role of non - thermal emission in the case of the collision of a sn with its companion star . ic emission provides solid limits to the environment density which are _ not _ dependent on assumptions about the poorly constrained magnetic field energy density ( i. e. the @xmath50 parameter ; see also @xcite and @xcite ) . this is different from the synchrotron emission , which was used in our companion paper @xcite to constrain the environment of the same event from the deepest radio observations ever obtained for a sn ia . the two perspectives are complementary : the use of the same assumptions and of a consistent formalism furthermore allows us to constrain the post - shock energy density in magnetic fields vs. ambient density parameter space ( see fig . [ fig : epsilonb ] ) . this plot shows how deep and contemporaneous radio and x - rays observations of sne might be used to infer the shock parameters . the ic luminosity is however strongly dependent on the sn bolometric luminosity : @xmath62 . here we presented the deepest limit on the ambient density around a type ia sn obtained from x - ray observations . our results directly benefit from : ( i ) unprecedented deep _ chandra _ observations of one of the nearest type ia sne , coupled to ( ii ) a consistent treatment of the dynamics of the sn shock interaction with the environment ( appendix [ sec : iclum ] and @xcite ) , together with ( iii ) the direct computation of the sn bolometric luminosity from _ swift_/uvot data . in particular we showed that :    * assuming a wind profile the x - ray non - detections imply a mass loss @xmath187 for @xmath188 . this is a factor of @xmath189 deeper than the limit reported by @xcite . this rules out symbiotic binary progenitors for sn  2011fe and argues against roche - lobe overflowing subgiants and main sequence secondary stars _ if _ a fraction @xmath114 of the transferred mass is lost at the lagrangian points and the wd is steadily burning . * were sn  2011fe to be embedded in an ism environment , our calculations constrain the density to @xmath190 . whatever the density profile , the x - ray non - detections are suggestive of a _ clean _ environment around sn  2011fe , for distances in the range @xmath191 . this is either consistent with the bulk of material ( transferred from the donor star to the accreting wd or resulting from the merging of the two wds ) to be confined within the binary system or with a significant delay @xmath127 yr between mass loss and sn explosion ( e.g. @xcite , @xcite ) . note that in the context of dd mergers , the presence of material on distances @xmath124 ( as recently suggested by e.g. @xcite and @xcite ) has been excluded by @xcite based on the lack of bright , early uv / optical emission . we furthermore looked for bursts of gamma - rays associated with the shock break out from sn  2011fe . we find no statistically significant evidence for a sn - associated burst for fluences @xmath192 . however , with progenitor radius @xmath193 the expected sn  2011fe shock break out fluence is @xmath194 , below the sensitivity of gamma - ray detectors currently on orbit .    the proximity of sn  2011fe coupled to the sensitivity of _ chandra _ observations , make the limits presented in this paper difficult to be surpassed in the near future for type ia sne . however , the generalized ic formalism of appendix [ sec : iclum ] is applicable to the entire class of hydrogen poor sne , and will provide the tightest constraints to the explosion environment _ if _ x - ray observations are acquired around maximum light ( see fig . [ fig : ic ] ) for type i supernovae ( ia , ib and ic ) . we thank harvey tananbaum and neil gehrels for making _ chandra _ and _ swift _ observations possible . we thank reem sari , bob kirshner , sayan chakraborti , stephan immler , brosk russel and rodolfo barniol duran for helpful discussions . l.c . is a jansky fellow of the national radio astronomy observatory . is supported by a clay fellowship . kh is grateful for ipn support under the following nasa grants : nnx10ar12 g ( suzaku ) , nnx12ad68 g ( swift ) , nnx07ar71 g ( messenger ) , and nnx10au34 g ( fermi ) . the konus - wind experiment is supported by a russian space agency contract and rfbr grant 11 - 02 - 12082-ofi_m . pos acknowledges partial support from nasa contract nas8 - 03060 . 80 natexlab#1#1    ? ? ? ? \\08 . 1    , c .- i . , & fransson , c. 2004 , , 605 , 823    , s. , prieto , j.  l. , patat , f. , challis , p. , hicken , m. , kirshner , r.  p. , matheson , t. , & modjaz , m. 2009 , , 693 , 207    , j.  s. , et  al . 2011 , arxiv e - prints , 1111.0966    , f.  r. , & branch , d. 1995 , , 107 , 347    , a.  a. , et  al . 2010 , , 406 , 1687    , p.  j. , et  al . 2011 , arxiv e - prints , 1110.2538    . 2009 , , 137 , 4517    , x. , han , z. , & tout , c.  a. 2011 , , 735 , l31    , r.  a. 1982 , , 258 , 790    , r.  a. , & fransson , c. 2006 , , 651 , 381    , r.  a. , fransson , c. , & nymark , t.  k. 2006 , , 641 , 1029    , l. , et  al . 2012 , arxiv e - prints , 1201.0994    , g. , leibundgut , b. , & vacca , w.  d. 2000 , , 359 , 876    , p.  a. , evans , p.  a. , de pasquale , m. , page , m.  j. , & van der horst , a.  j. 2010 , , 716 , l135    , r. , voss , r. , & claeys , j.  s.  w. 2011 , , 738 , l1    , v.  v. , & chevalier , r.  a. 1998 , , 497 , 807    , c.  r. , cowan , j.  j. , roberts , d.  a. , boffi , f.  r. , & branch , d. 1995 , , 451 , l53    , j.  e. , & morrison , p. 1966 , , 146 , 686    , r.  j. , et  al . 2012 , , 744 , 38    , c. , & bjrnsson , c .- i . 1998 , , 509 , 861    , j.  a. , gregory , b. , kawara , k. , laney , d. , phillips , m.  m. , terndrup , d. , vrba , f. , & whitford , a.  e. 1987 , , 315 , l129    , c.  l. , et  al . 2010 , , 725 , 296    , p.  p. , gaensler , b.  m. , & murphy , t. 2011 , , 735 , l35    , w. , & niemeyer , j.  c. 2000 , , 38 , 191    , a. , et  al . 2011 , arxiv e - prints , 1109.2912    , j.  p. , chugai , n. , chevalier , r. , lundqvist , p. , & schlegel , e. 2007 , , 670 , 1260    , j.  p. , soderberg , a. , & slane , p. 2011 , the astronomer s telegram , 3602 , 1    , k. 2010 , issi scientific reports series , 9 , 235    , jr . , i. , & tutukov , a.  v. 1984 , , 54 , 335    , s. , et  al . 2006 , , 648 , l119    , s. 2011 , , 730 , l34    , p.  m.  w. , burton , w.  b. , hartmann , d. , arnal , e.  m. , bajaja , e. , morras , r. , & pppel , w.  g.  l. 2005 , , 440 , 775    , d. 2010 , , 708 , 1025    , s. , petre , r. , hughes , j.  p. , hwang , u. , yamaguchi , h. , hayato , a. , mori , k. , & tsunemi , h. 2010 , , 709 , 1387    , b. 2012 , , 420 , l6    , d. , vink , j. , blinnikov , s. , & rasmussen , a. 2008 , , 490 , 223    , s.  r. , et  al . 1998 , , 395 , 663    , p. , & barniol duran , r. 2010 , , 409 , 226    , w. , et  al . 2011 , arxiv e - prints , 1109.1593    , w. , filippenko , a.  v. , treffers , r.  r. , riess , a.  g. , hu , j. , & qiu , y. 2001 , , 546 , 734    , w. , et  al . 2011 , , 412 , 1441    , j. , di stefano , r. , wang , t. , & moe , m. 2011 , arxiv e - prints , 1110.2506    , r. , & soderberg , a. 2011 , the astronomer s telegram , 3642 , 1    . 2011 , the astronomer s telegram , 3584 , 1    , c.  d. , & mckee , c.  f. 1999 , , 510 , 379    , p.  a. , et  al . 2010 , , 721 , 1627    , e. , & sari , r. 2011 , arxiv e - prints , 1106.2556    , k. 1980 , , 27 , 563    , k. , thielemann , f .- k . , & yokoi , k. 1984 , , 286 , 644    , p. , kim , a. , & perlmutter , s. 2002 , , 114 , 803    , p. , sullivan , m. , bersier , d. , howell , d.  a. , thomas , r. , & james , p. 2011 , the astronomer s telegram , 3581 , 1    , p.  e. , et  al . 2011 , arxiv e - prints , 1110.6201    , n. , van dyk , s.  d. , weiler , k.  w. , sramek , r.  a. , stockdale , c.  j. , & murata , k.  p. 2006 , , 646 , 369    , a. , & kumar , p. 2000 , , 543 , 66    . 2001 , apj , 554 , 667    , f. , et  al . 2007 , science , 317 , 924    , f. , chugai , n.  n. , podsiadlowski , p. , mason , e. , melo , c. , & pasquini , l. 2011 , , 530 , a63    , f. , et  al . 2011 , arxiv e - prints , 1112.0247    , s. , et  al . 1999 , , 517 , 565    , a.  l. 2012 , arxiv e - prints , 1201.5398    , i. , livne , e. , & waxman , e. 2011 , arxiv e - prints , 1108.5548    , a.  g. , et  al . 1998 , , 116 , 1009    , d.  j. , finkbeiner , d.  p. , & davis , m. 1998 , , 500 , 525    , e.  r. , & taylor , a.  r. 1990 , , 349 , 313    , b.  j. , & stanek , k.  z. 2011 , , 733 , 124    , k.  j. , bildsten , l. , kasen , d. , & quataert , e. 2011 , arxiv e - prints , 1108.4036    , j.  d. , et  al . 2009 , , 702 , 1157    , a.  m. , et  al . 2008 , , 453 , 469    , a.  m. , kulkarni , s.  r. , berger , e. , chevalier , r.  a. , frail , d.  a. , fox , d.  b. , & walker , r.  c. 2005 , , 621 , 908    , a.  m. , et  al . 2011 , arxiv e - prints , 1107.1876    , a. , et  al . 2011 , science , 333 , 856    , j. 2008 , , 689 , 231    , f. , brinks , e. , de blok , w.  j.  g. , bigiel , f. , kennicutt , jr . , r.  c. , thornley , m.  d. , & leroy , a. 2008 , , 136 , 2563    , x. , et  al . 2009 , , 697 , 380    , r.  f. 1984 , , 277 , 355    , j. , & iben , jr . , i. 1973 , , 186 , 1007    , s.  a. , harrison , f.  a. , sari , r. , & frail , d.  a. 2003 , , 597 , 459    , w. , macfadyen , a. , & wang , p. 2009 , , 692 , l40 ambient electrons accelerated to relativistic speed by the sn shock are expected to upscatter optical photons from the sn photosphere to x - ray frequencies via inverse compton ( ic ) , see e.g. @xcite , @xcite . here we generalize eq . ( 31 ) from @xcite for a population of relativistic electrons with arbitrary distribution @xmath195 for @xmath196 , both for an ism ( eq . [ eq : icism ] ) and a wind ( eq . [ eq : icwind ] ) scenario .    using the ic emissivity given by @xcite , their eq . 27 , the ic luminosity reads : @xmath197 where @xmath198 is the energy density of photons of effective temperature @xmath63 which are upscattered to @xmath199 ; @xmath66 is the extension of the region containing fast electrons while @xmath96 is the ( forward ) shock radius . the emission is expected to originate from a shell of shocked gas between the reverse and the forward shock which are separated by the contact discontinuity at @xmath200 @xcite . for @xmath55 with @xmath201 the forward shock is at @xmath202 ( @xmath203 ) while the reverse shock is at @xmath204 ( @xmath205 ) in the case of a wind ( ism ) environment @xcite . the fraction of the volume within the forward shock with shocked gas is @xmath206 ( @xmath207 ) corresponding to a sphere of radius @xmath208 ( @xmath209 ) for an assumed wind ( ism ) density profile . if a fraction @xmath78 of the post - shock energy density goes into non thermal relativistic electrons , from @xmath210 we have : @xmath211 for @xmath212 . combining eq . [ eq : one ] with eq . [ eq : two ] , we obtain eq . [ eq : icgeneral ] . the temporal evolution of @xmath213 directly depends on @xmath76 ; @xmath214 ; @xmath215 ; @xmath216 and @xmath217 . the properties of the sn and of its progenitor determine @xmath76 , @xmath214 and the profile of the outer ejecta @xmath55 . we assume @xmath218 through out the paper ( e.g. @xcite ) . the environment sets the @xmath67 profile , which we parametrize as @xmath219 . both the sn explosion properties _ and _ the environment determine the shock dynamics : evolution of the shock radius @xmath216 , shock velocity @xmath215 and , as a consequence @xmath220 . under those conditions the shock interaction region can be described by a self - similar solution @xcite with the shock radius evolving as @xmath221 which implies : @xmath222 the shock velocity directly determines @xmath223 . from @xcite , assuming that _ all _ electrons go into a power - law spectrum with spectral index @xmath46 : @xmath224 where @xmath225 is the shock compression parameter , @xmath226 ( @xmath227 ) is the electron ( ion ) number density and @xmath228 is the average number of nucleons per atom . we furthermore define @xmath229 . for solar metallicity @xmath230 . in the following we assume @xmath231 @xcite , @xmath232 .      the self - similar solutions for the interaction of the sn ejecta with an ism - like circumstellar medium ( @xmath90 , @xmath233 ) lead to ( @xcite , soderberg et al . , in prep ) : @xmath234 where @xmath235 is the mass of the ejected material and @xmath236 is the energy of the supernova explosion . [ eq : two ] , [ eq : vshockrshock ] , [ eq : gammamin ] and [ eq : vshockism ] , together with eq . [ eq : one ] , predict an ic luminosity : @xmath237 with @xmath238 . in the body of the paper @xmath239 will be reported in ( hydrogen ) particles per @xmath240 . for @xmath75 ( @xmath241 ) the self - similar solutions lead to ( @xcite , soderberg et al . , in prep ) : @xmath242 combining eq . [ eq : two ] , [ eq : vshockrshock ] , [ eq : gammamin ] and [ eq : vshockwind ] with eq . [ eq : one ] we obtain : @xmath243 with @xmath244 . + note that @xmath245 , so that @xmath246 , where @xmath79 and @xmath82 are the mass loss rate and the wind velocity of the sn progenitor , respectively . in the body of the paper , for the wind scenario , we refer to @xmath239 in terms of mass loss rate for a given wind velocity so that it is easier to connect our results to known physical systems .", "tags": [], "output_text_a": "The paper discusses the study of Type Ia supernova SN 2011fe, focusing on its progenitor system and the surrounding environment. Type Ia supernovae are used as standard candles to trace the universe's expansion, but their progenitor systems remain elusive. The study examines two main progenitor models: the single-degenerate (SD) model, where a white dwarf (WD) accretes material from a companion star, and the double-degenerate (DD) model, involving the merger of two WDs.\n\nThe research utilizes optical, UV, X-ray, and gamma-ray observations to analyze SN 2011fe, located in the Pinwheel Galaxy (M101). The study aims to constrain the properties of the supernova's ejecta and circumbinary environment by examining the dynamical evolution of the shockwave. Observations from the Swift and Chandra satellites, along with the Interplanetary Network (IPN), provide data for this analysis.\n\nKey findings include deep limits on X-ray emissions, suggesting a lack of a wind-stratified medium, which supports the DD model over the SD model. The study also reports no significant gamma-ray burst associated with the supernova, consistent with expectations given the progenitor's radius and the distance of SN 2011fe.\n\nThe paper concludes that SN 2011fe likely exploded in a clean environment, with no significant material detected at distances up to 10^17 cm from the progenitor. This finding challenges the symbiotic binary progenitor scenario and supports the DD model, where the supernova results from the merger of two WDs. The study highlights the importance of multi-wavelength observations in understanding the progenitor systems of Type Ia supernovae and their surrounding environments.", "output_text_b": "Type Ia supernovae (SNe Ia) have been crucial in tracing the expansion history of the universe, with increasing resources dedicated to their discovery and follow-up campaigns. However, the nature of their progenitor systems remains elusive. SN 2011fe, the second nearest SN Ia discovered in the digital era, offers a unique opportunity for a detailed progenitor study. This paper presents a panchromatic study of SN 2011fe, bridging optical/UV and gamma-ray observations, and combines these with radio and X-ray observations to constrain the properties of the bulk ejecta and circumbinary environment.\n\nThe study finds that SN 2011fe appears consistent with a \"normal\" SN Ia, and sets deep limits on the X-ray emission in the month following the explosion and gamma-ray limits for the shock breakout pulse. The authors also provide an analytic generalization for the inverse Compton (IC) X-ray luminosity expected from hydrogen-poor SNe, which is broadly applicable for a wide range of shock properties, metallicity, photon temperatures, and circumstellar density profiles.\n\nBy applying this analytic model to SN 2011fe, the study constrains the density of the circumbinary environment and finds that the limits are a factor of 10 deeper than results recently reported. The authors combine their radio and X-ray limits to constrain the post-shock energy density in magnetic fields in the circumbinary environment.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings**: The summary accurately reflects the main findings and contributions of the paper, including the focus on SN 2011fe, the examination of progenitor models, and the conclusions drawn about the progenitor system and environment.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding the progenitor systems of Type Ia supernovae.\n\n4. **Methodology or Approach**: The summary mentions the use of optical, UV, X-ray, and gamma-ray observations to analyze SN 2011fe.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the lack of a wind-stratified medium supporting the DD model and the clean environment around SN 2011fe.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like SD and DD models.\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary mentions key experiments and data, such as observations from the Swift and Chandra satellites.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in understanding Type Ia supernovae progenitor systems.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the study of SN 2011fe and its implications for understanding Type Ia supernovae progenitors.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the nature of the progenitor systems of Type Ia supernovae, is highlighted.\n4. The methodology, including the panchromatic study and the application of an analytic model for inverse Compton X-ray luminosity, is mentioned.\n5. Significant results, such as the constraints on the circumbinary environment density and the deeper limits achieved, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"inverse Compton\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments and data, such as optical/UV, gamma-ray, radio, and X-ray observations, are mentioned.\n10. The summary reflects the paper's significance in advancing the understanding of Type Ia supernovae progenitors."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "the oort cloud @xcite remains the most mysterious part of our solar system , primarily because it can not be directly observed . our only observational clues to the size , shape , mass and composition of the oort cloud come from observations of long - period comets . the demographics of observed long - period comets have been the starting point of almost all attempts to model the oort cloud ( eg . * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) .    until the last ten or so years , the vast majority of comets were discovered by systematic eyeball searches , using small telescopes @xcite . these surveys have been highly effective at identifying large samples of comets , and in deriving their orbital parameters . they do , however , have three major drawbacks :    * unknown selection function : it is very unclear how often different parts of the sky are surveyed , and to what depth . surveys are clearly more sensitive to comets with bright absolute magnitudes and perihelia close to the earth , but the strength of this effect is very hard to estimate @xcite . * limited range of comets observed : eyeball surveys find few comets fainter than an absolute magnitude of 10 and with perihelia beyond 3au . * poorly defined photometry : these surveys quote the `` total brightness '' of a comet . total cometary magnitudes are notoriously unreliable . they are typically measured by defocussing a standard star to the same apparent size as the comet , but this apparent size is heavily dependent on observing conditions and observational set - up .    despite these drawbacks , many attempts have been made to derive the basic parameters of the long period comet population from eyeball - selected historic samples . the most heroic and influential attempt was that of @xcite . everhart carried out an exhaustive analysis of the historical circumstances in which comets were discovered , over a 127 year period . he developed a model for the sensitivity of the human eye , and used it to calculate the period over which a given historical comet could have been seen . this was then used to estimate the completeness of the comet sample : if a given type of comet was typically seen early in its visibility window , surveys should be complete for this type of comet . if the mean time to find a given type of comet is , however , comparable to the length of the estimated visibility window , the completeness is probably low . using this method , everhart estimated that for every comet seen , another 31 were missed . a more modest and recent attempt was that of @xcite . he restricted himself to the brightest and nearest comets , for which he claimed ( on the basis of discovery trends ) historical surveys were highly complete . the statistics of these comets were simply extrapolated to larger perihelia and fainter absolute magnitudes , with no correction for observational incompleteness . as one would expect , the flux of long - period comets through the inner solar system estimated by @xcite is much lower that that estimated by @xcite .    despite these attempts , several basic questions about the demographics of long - period comets remain unresolved . one question concerns small comets @xcite : those with nuclear radii less than @xmath0 km ( absolute magnitudes @xmath1 ) . extrapolating the everhart data implies that there should be a large population of such comets . @xcite was unable to tell whether his model predicted a large population of such comets or not . a second question concerns the number of comets per unit perihelion . @xcite found that this number rises from the sun out to 1au , but was unable to determine whether it keeps rising at larger perihelia . @xcite found no significant rise , but had large enough error bars to bracket both of everhart s possibilities . the observational situation has changed radically in the last few years . the advent of large format sensitive ccds has allowed automated surveys to supplant eyeball searches as the main mechanism for finding new long - period comets . most long period comets are now being found as by - products of various automated searches for near - earth objects , such as the lincoln near - earth asteroid research ( linear ) project @xcite , the catalina sky survey , loneos and neat @xcite . many are also found by space - based coronagraphs as they approach very close to the sun @xcite , though these are mostly fragments of recently disintegrated larger comets @xcite .    in this paper , i attempt to deduce the statistical properties of the long - period comet population from one of these ccd surveys : the linear survey . this has a far better defined selection criterion than any historical eyeball survey , and extends to much larger perihelia and fainter absolute magnitudes . it thus allows both an independent check and an extension of previous estimates of the long - period comet population .    near earth asteroid ( neo ) surveys are not optimized for comet detection . while they find many long - period comets , they do not publish their raw data , nor all the details one would like of their exact detection algorithms and sky coverage . in particular , they do not publish on - going photometry of the comets they discover . nonetheless , enough information is available to make a first pass at estimating the true population of long - period comets from their data . there have been previous attempts to use these surveys to detemine the true populations of neos ( eg . * ? ? ? * ) and dormant comets @xcite , but this paper is the first attempt of which i am aware to do this for active comets .    in the next few years , the situation should further improve , with the advent of a new generation of wide - field survey telescopes , such as skymapper , pan - starrs @xcite and gaia @xcite . these surveys will predominantly find comets much fainter and more distant than historical surveys . the analysis in this paper allows a first estimate of just how many long - period comets these surveys can find , and how best to identify them . i start off by defining a sample of comets drawn from the linear sample , and examining its properties , which are very different from those of eyeball samples (   [ sample ] ) . a model of the long - period comet population is then generated (   [ model ] ) based on and extrapolating the historical eyeball - selected surveys . a monte - carlo simulation of this comet population as it would be observed by linear is then developed (   [ montecarlo ] ) . the results are compared to the observed sample in   [ compmodels ] : i find that the hughes model is quite a good fit to the data , but that the everhart model is not . i derive my own best - fit model of long - period comet demographics . the consequences of this new model are many : i examine them in   [ discussion ] before drawing conclusions in   [ conc ] . of the several near - earth asteroid surveys now under - way , the lincoln near - earth asteroid research ( linear ) project @xcite was most suitable for constraining the long - period comet population . this is because :    * they discover more comets than any other single survey . * they publish sky charts on their web page showing the area of the sky observed during each lunation , with the point - source magnitude limit reached at each location . * their sky coverage and magnitude limit is relatively simple and uniform across this period . the comet sample was defined as follows :    1 . the comet has an orbital period longer than 200 years . 2 . the comet reached perihelion between 2000 jan 1 and 2002 dec 31 . the comet was either discovered by linear between these dates , or could have been discovered by linear between these dates had it not already been discovered by someone else , or discovered prior to 2000 jan 1 . the 2000 - 2002 date range was chosen because comet details ( from the catalog of cometary orbits , * ? ? ? * ) and sky - maps ( including limiting magnitudes ) are available . @xcite listed 25 comets as having been discovered or co - discovered by linear which met our criteria . i needed , however , to add two additional sub - samples :    * comets discovered prior to 2000 , but which reach perihelion in the period 2000 - 2002 , and which could have been first discovered by linear within this period , had they not already been found . * comets discovered in 2000 - 2002 inclusive by other surveys , but which would subsequently have been seen by linear during this period . potential members of the two additional sub - samples were selected from @xcite . each candidate was checked for its detectability by linear , using the ephemerides and predicted magnitudes generated by the minor planet center . the predicted positions and brightnesses were compared to the maps of linear sky coverage . these maps show only the integrated coverage per lunation , not the night - by - night or hour - by - hour coverage , but most of these comets move slowly enough that this should nt much matter . this process added another 27 comets to our sample . 8 had been detected by linear during 1999 , but reached perihelion in 2000 or 2001 . most of the remainder were first identified by other near - earth asteroid surveys , particularly the catalina sky survey , loneos and neat .    for every comet in our final sample , the original discovery details ( as distributed by the central bureau of astronomical telegrams ) were checked . from these , the discovery date , discovery magnitude @xmath2 and discovery circumstances were noted . the discovery magnitudes are total magnitudes ( m1 ) . it is not clear how reliable and homogeneous these magnitudes are , but no better source of ccd photometry is available . they are based on ccd observations by professional astronomers of typically barely resolved objects , and so should be good to @xmath3mag . absolute magnitudes @xmath4 were computed from these discovery magnitudes @xmath2 . the standard equation was used : @xmath5 ( eg . * ? ? ? * ) , where @xmath2 is the observed total magnitude at discovery and @xmath6 a power - law parameterization of the dependence on heliocentric distance . as is conventional for solar system work , the absolute magnitude is defined as the observed magnitude if the object were at a distance of 1 au from both the earth and the sun . following @xcite , the dynamically new and old comets were treated differently ( the new ones are much brighter at large heliocentric radii , at least on their way in ) . a comet is classed as dynamically new if its original semi - major axis @xmath7 is @xmath8 10,000 au , old if @xmath9 10,000 au , and undetermined if the orbit class in @xcite is ii or worse . for new comets , @xmath10 was used if they are seen pre - perihelion and @xmath11 if seen afterward . for old comets , the values are 5.0 and 3.5 respectively . the canonical value of @xmath12 is used for comets of undetermined orbit type . this is uncertain both because real comets show a dispersion in @xmath6 , and because the @xmath6 values in @xcite are based on observations at smaller heliocentric distances . it is , however , self - consistent with the analysis used in our monte - carlo simulations . our sample is listed in table  [ sampletab ] . lcccc    c/1999 f1 & 5.7869 & 7.82 & 0.000038 & 1a + c/1999 j2 & 7.1098 & 6.39 & 0.000019 & 1a + c/1999 k5 & 3.2558 & 9.75 & 0.000024 & 1a + c/1999 k8 & 4.2005 & 6.33 & 0.000681 & 1a + c/1999 l3 & 1.9889 & 10.21 & 0.013741 & 1b + c/1999 n4 & 5.5047 & 9.99 & 0.000068 & 1a + c/1999 s4 & 0.7651 & 7.84 & 0.000720 & ii + c/1999 t1 & 1.1717 & 4.36 & 0.000173 & ii + c/1999 t2 & 3.0374 & 6.05 & 0.000596 & 1a + c/1999 t3 & 5.3657 & 5.12 & 0.000231 & 1b + c/1999 u4 & 4.9153 & 7.60 & 0.000037 & 1a + c/1999 y1 & 3.0912 & 9.80 & 0.000044 & 1a + c/2000 a1 & 9.7431 & 8.13 & 0.000044 & 1a + c/2000 ct54 & 3.1561 & 10.71 & 0.000051 & 1a + c/2000 h1 & 3.6366 & 10.29 & & + c/2000 j1 & 2.4371 & 12.62 & 0.001406 & 1a + c/2000 o1 & 5.9218 & 7.03 & 0.000037 & 1a + c/2000 of8 & 2.1731 & 14.07 & 0.000048 & 1b + c/2000 sv74 & 3.5416 & 9.40 & 0.000090 & 1a + c/2000 u5 & 3.4852 & 9.88 & 0.000358 & 1a + c/2000 w1 & 0.3212 & 10.44 & & + c/2000 wm1 & 0.5553 & 6.81 & -0.000459 & ii + c/2000 y1 & 7.9747 & 9.54 & 0.000063 & 1a + c/2000 y2 & 2.7687 & 9.65 & 0.001934 & 1b + c/2001 a1 & 2.4062 & 10.71 & 0.005738 & 2a + c/2001 a2 & 0.7790 & 14.22 & 0.000447 & ii + c/2001 b1 & 2.9280 & 11.14 & 0.000071 & 1b + c/2001 b2 & 5.3065 & 5.60 & 0.000187 & 1b + c/2001 c1 & 5.1046 & 10.30 & 0.000020 & 1a + c/2001 g1 & 8.2356 & 7.45 & 0.000024 & 1a + c/2001 ht50 & 2.7921 & 3.15 & 0.000878 & 1a + c/2001 k3 & 3.0601 & 9.80 & 0.000072 & 1b + c/2001 k5 & 5.1843 & 8.10 & 0.000029 & 1a + c/2001 n2 & 2.6686 & 5.77 & 0.000455 & 1a + c/2001 rx14 & 2.0576 & 6.06 & 0.000776 & 1a + c/2001 s1 & 3.7500 & 11.36 & 0.018168 & + c/2001 u6 & 4.4064 & 7.42 & 0.000998 & 1a + c/2001 w1 & 2.3995 & 14.04 & & + c/2001 x1 & 1.6976 & 12.54 & 0.002285 & 2a + c/2002 b2 & 3.8430 & 10.12 & & + c/2002 b3 & 6.0525 & 7.92 & & + c/2002 c2 & 3.2538 & 8.88 & 0.000393 & 1b + c/2002 e2 & 1.4664 & 10.34 & 0.000173 & 1b + c/2002 h2 & 1.6348 & 13.29 & 0.004024 & 2a + c/2002 k2 & 5.2378 & 7.62 & & + c/2002 l9 & 7.0316 & 5.60 & 0.000035 & 2a + c/2002 o4 & 0.7762 & 13.59 & -0.000772 & 2a + c/2002 p1 & 6.5307 & 8.55 & 0.002023 & 2a + c/2002 q2 & 1.3062 & 16.09 & & + c/2002 q5 & 1.2430 & 16.59 & 0.000058 & 1b + c/2002 u2 & 1.2086 & 14.63 & 0.001075 & 1b +      the linear sample has very different properties from historical samples ( as typified by the everhart sample ) . figure  [ everhart_compare ] shows that the linear sample extends around 4 magnitudes deeper , and to much larger perihelia . the overlap is small : only @xmath13 of the linear comets lie within the absolute magnitude and perihelion region sampled by historical samples . analysis of the discovery telegrams indicates that almost all of the comets in the sample were originally identified as moving point sources . they were posted on the near earth object ( neo ) confirmation page at the minor planet center . follow - up observations then determined that the sources were spatially extended and hence comets . 77% were discovered before reaching perihelion ( fig  [ discover_hist ] ) , and 73% were were first detected when more than 3au from the sun . the necessity for follow - up potentially introduces two sources of incompleteness into this sample . firstly , some fraction of objects posted on the neo confirmation page are never followed up in enough detail to determine whether they are comets or not . timothy spahr kindly provided records of all objects posted to the neo confirmation page in 2000 - 2002 . only 11% of these were not followed - up well enough to determine an orbit : this places an upper limit on the fractional incompleteness of our sample due to failed follow - up . this is probably a conservative upper limit : most of these lost objects were most likely either not real to begin with or fast - moving objects only visible for a short window of time . secondly , some comets might have been inactive at these large heliocentric distances , and hence classified as minor planets . the minor planet centre database was checked for non - cometary objects on long - period , highly eccentric orbits , but only one was found which reached perihelion within the period 2000 - 2002 : 2002 rn109 . thus this too is not a major source of incompleteness . it also shows that most comets down to the linear magnitude limit are still active out to 10au from the sun . fig  [ q_a ] shows an intriguing correlation between perihelion distance and semi - major axis in the linear sample . this correlation was first noted by @xcite at smaller perihelia . they suggested that it was a selection effect . dynamically new comets are brighter at large heliocentric radii ( eg . * ? ? ? * ) , presumably due to extra outgassing at large heliocentric distances from their relatively pristine surfaces , due perhaps to @xmath14 or a water ice phase transition . the whipple data did not extend to distances beyond 4au from the sun . if this trend continues to larger heliocentric distances , however , it would make dynamically new comets far brighter than older comets with the same absolute magnitude . this could thus , in principle , bias the sample heavily towards new comets , and hence larger semi - major axes . the distribution of perihelion positions is shown in fig  [ peripos ] . the comets are weakly concentrated at intermediate galactic latitudes ( fig  [ bhist ] ) , consistent with the galactic tide playing a major part in making them observable @xcite . the galactic latitude distribution is not , however , significantly different from the predictions of a best - fit model (   [ best ] ) assuming a random distribution , as measured by the kolmogorov - smirnov ( ks ) test or the kuiper statistic . there are also no significant great - circle alignments @xcite . the linear comet sample was compared against a monte - carlo simulation of the long period comet distribution . in this section i discuss the parameters used in this simulation . the @xcite and @xcite studies are based on comets with a limited range of perihelion distances q and hence give only weak constraints on this distribution . everhart found a factor of two rise in the number of comets per unit perihelion between 0 and 1 au , but beyond that the data are consistent either with a continuing rise or a flat distribution . hughes found no significant trend in number of comets against perihelion , but his data are quite consistent with such a trend .    on theoretical grounds , however , a gentle rise in the number of comets as a function of perihelion is expected , as comets diffuse into the solar system past the barrier of giant planet perturbations ( eg . * ? ? ? * ; * ? ? ? as a first guess , i chose to model the perihelion distribution as an unbroken straight line : @xmath15 where @xmath16 gives a reasonable fit to the @xcite distribution . the @xcite slope is shallower , but only shown out to 3au . the distribution of semi - major axes @xmath7 makes no significant difference to the conclusions , as the comets are all very close to being on parabolic orbits . i chose to randomly class 40% of comets as dynamically new and given them all @xmath1720,000 , while the remainder were given a value of @xmath7 randomly and uniformly distributed between 1000 and 20,000 au . the time of perihelion passage , orbital inclination and perihelion direction were randomly chosen to give a uniform distribution on the celestial sphere . this ignores possible great - circle alignments @xcite and galactic tidal effects @xcite . @xcite found that the absolute magnitude distribution of comets was best fit by a broken power - law , with the break at @xmath18 . @xcite also found a break at about the same absolute magnitude , but was unable to decide whether it was a real break or simply the effect of increasingly incomplete samples at fainter magnitudes . to bracket the possibilities , i use a broken power - law of the form . @xmath19 where @xmath20 is the break magnitude , @xmath21 is the bright end slope and @xmath22 is the faint end slope . everhart gives @xmath23 , @xmath24 and @xmath25 . hughes gives @xmath26 and @xmath27 . if i assume that his observed break is real and not an artefact of sample incompleteness , his plots imply a faint end slope of @xmath28 , which i adopt to bracket the possibilities . this version of the hughes formulation thus predicts dramatically fewer faint comets , as would be expected as these are the ones for which everhart applies the largest incompleteness correction fraction . @xcite and @xcite give different estimates of the long - period comet flux through the inner solar system . everhart estimates a flux of 8000 comets with @xmath29 and @xmath30 over 127 years . hughes estimates a flux of 0.53 comets per year brighter than @xmath31 per unit perihelion . i ran the simulations using both . for a given model comet population , the aim is to simulate the observable properties of a sample that matches the selection effects of the linear sample . the simulation starts off by generating a set of comets that reach perihelion within a three year period . the comets are randomly generated using the model distributions in the previous section . the model extends down to @xmath32 and out to @xmath33 . i generated two model populations : one using the everhart absolute magnitude distribution and flux , the other using the hughes absolute magnitude distribution and flux . in the everhart model 260,000 comets are generated , while only 4,000 are needed in the hughes model . the position of each comet is then calculated at 24 hour intervals throughout the three year period , and its heliocentric distance @xmath34 , distance from the earth @xmath35 , apparent celestial coordinates and apparent angular velocity written to file . pure elliptical orbits are used : no attempt is made to allow for planetary perturbations .    at each location , the apparent total magnitude is then calculated . comets are notoriously variable in how rapidly their apparent magnitude varies as a function of heliocentric distance . i parameterize this , as is conventional , using equation  [ eqabsmag ] . two values of @xmath6 are randomly assigned to each comet : one for before perihelion and another for after . for the 40% of our simulated comets that i set as dynamically new , the pre - perihelion value of @xmath6 is chosen from a gaussian distribution of mean 2.44 and standard deviation 0.3 . post - perihelion , the mean is 3.35 with a scatter of 0.27 . for the remaining comets , the pre - perihelion numbers are 5.0 with a scatter of 0.8 , and after perihelion 3.5 with a scatter of 0.5 . all these values are taken from @xcite . at large distances from the sun , cometary activity will presumably stop , and a bare nucleus will have @xmath36 . the near - ubiquitous detection of fuzz around the linear comets implies , however , that this only happens further from the sun than our models reach . this approach can only be a rough approximation to the real radial brightness dependence . the value of @xmath6 for an individual comet is typically time dependent , and all the tabulated values are for comets within @xmath37 au of the sun , whereas our simulation tracks them out beyond 10au . in addition , comets show occasional flares above and beyond this power - law behavior , which i have not attempted to model . such flares might introduce an amplification bias , with comets being pushed over the detection threshold . as we will see , however , the slope of the absolute magnitude distribution is so gentle that this is unlikely to be a major effect . the apparent total magnitude of each simulated comet can now be calculated at any given point in its orbit . unfortunately , in any ccd - based survey , it is the peak surface brightness of the coma that determines whether something has been seen , not the total magnitude . the linear skymaps , furthermore , list only the magnitude limit _ for a point source _ at any given location on the sky ( typically around 19 ) . as discussed in the introduction , total cometary magnitudes are notoriously unreliable . quantitative studies prefer more reproducible and physically meaningful parameters such as @xmath38 ( eg . * ? ? ? unfortunately , not enough long period comets have been studied in this way to derive the @xmath39 distribution . we are therefore forced to attempt some conversion between total magnitudes and point - source equivalent magnitudes . for bright and near - by comets , this correction can be as large as @xmath13 magnitudes ( eg . * ? ? ? the comets in the linear sample were , however , typically first seen when very faint ( fig  [ maghist ] ) , and were generally mistaken for point sources in the initial observation . we might therefore expect the correction factor to be much smaller , at least when close to the detection threshold . the histogram of detection magnitudes ( fig  [ maghist ] ) climbs steeply down to @xmath40 , and then falls off fast ( the one comet discovered when fainter than 20th mag was found by spacewatch , which has a fainter magnitude limit ) . this fall - off occurs at almost exactly the same magnitudes as linear s point source limit , which ranged from around 18 to 20 . i thus conclude that near the linear detection threshold , total magnitudes and point source equivalent magnitudes are similar . when generating mock samples , it is only the magnitude near the detection threshold that determines whether or not a given model comet is included in the mock catalog . the exact value of this correction value was set iteratively . i initially guess that the point - source equivalent ( pse ) magnitude and total magnitude ( tm ) are the same , and run the simulations of the comet sample . i use the model that best fits the data (   [ best ] ) to calculate the predicted discovery magnitude distribution , and compare this to the observed distribution . i then tweak the pse@xmath41tm correction to bring the histograms into agreement . the best match is obtained when pse@xmath41tm@xmath42 ( fig  [ maghist ] ) . i use a value of @xmath43 throughout this paper , except where otherwise noted . the predicted magnitude is corrected for the effects of trailing . linear exposure times vary from 3 to 12 sec : the latter was used in the correction as it minimised the predicted number of very faint comets . 2   seeing ( fwhm ) was assumed . trailing makes very little difference , except for the very faintest comets . linear uses unfiltered ccd magnitudes while the historical surveys use unfiltered visual magnitudes . these will be somewhat different , due to the different wavelength sensitivity of the human eye and of the linear ccds , but the discrepancy should only be a few tenths of a magnitude at most , and hence is not a dominant source of error . anoher possible worry : the absolute magnitudes i quote for the comets in the linear sample ( table  [ sampletab ] ) are derived from total magnitudes measured when the comets were barely resolved and far from the sun , using a model for the heliocentric brightness variation . the absolute magnitudes fit by everhart and hughes are based on observations of highly extended comets observed close to the sun and earth . these are thus very different quantities , and might well be systematically different , if there is some error in our heliocentric brightness correction , if total magnitudes for barely resolved comets are systematicaly different from total magnitudes for greatly extended comets , or if there is some systematic bias in the discovery magnitudes reported to the central bureau of astronomical telegrams .    to test this , i picked out the five comets in the linear sample which were discovered when far ( more than 3.5 au ) from the sun , but which subsequently passed close enough to the earth and sun for traditional small telescope visual magnitude estimates ( within 2au ) . dan green kindly provided me with compilations of visual magnitude estimates of these comets while they were close to the earth and sun , taken from the archives of the international comet quarterly . these visual / small telescope magnitude estimates should be broadly comparable to the data on which the everhart and hughes papers were based . i then compared the predicted magnitudes when close to the sun ( based on the discovery magnitude and the model in this paper ) with the tabulated observations . there was a considerable scatter in the measured visual magnitudes for each comet : i simply averaged all visual small telescope magnitudes made when the comet was as close as possible to 1au from both sun and earth . my predicted magnitudes were consistent with the observed values , albeit with a large scatter . the mean difference ( predicted magnitude minus observed magnitude ) was @xmath44 , where the error indicates the @xmath45 dispersion of the mean . this is not , alas , a strong constraint , but does indicate that the two magnitude scales are not grossly discrepant . the final step is to determine whether linear imaged a part of the sky in which the comet was detectable and within its magnitude limit . the published linear skymaps show that during each dark period in 2000 - 2002 , they attempted to survey the region whose midnight hour angle is in the range @xmath46 , and in the declination range @xmath47 . in winter months with good weather , they surveyed more than 90% of this whole region down to a point - source magnitude limit of better than 19 . in bad months , this dropped to a magnitude limit of around 18.5 over 60% of this region , and occasionally worse . in the mean month , 72% of this region was surveyed to a visual magnitude limit of 18.5 or better . the exact pattern surveyed was complex and variable : the only constant was that the densest regions of the galactic plane were avoided . each field was imaged five times in succession , with 3  12 sec per exposure , once in every dark period . this sky coverage was approximated as follows . each comet that enters the @xmath46 , @xmath47 region at any point , with a point - source equivalent ( pse ) magnitude brighter than 19 is considered to have been potentially observable , unless it was within ten degrees of the galactic plane . if a comet is predicted to be detectable for an entire lunation , it is given a 80% chance of having been detected during that lunation . if it was predicted to be visible for less than the whole lunation , it is given a probability of having been detected equal to 80% of the fraction of the lunation for which is was potentially observable .    does this approximation match the real , more complex selection function ? this was tested by manually checking 100 simulated comet ephemerides , containing monthly positions and magnitudes , against the real linear sky - maps . the approximation was found to give a number and absolute magnitude distribution of detected comets indistinguishable from the manually checked sample . this approach should slightly overestimate the probability of a comet being observed , as comets could be blended with star or galaxy images . experience suggests that at this relatively bright magnitude limit , this is only a few percent effect at worst , at least away from the denser regions of the galactic plane , which the survey did not cover . another possible source of error is sky subtraction . it is unclear exactly how the linear survey do their sky subtraction , but if some of the extended coma emission is included in the sky value , this will artificially suppress the point source equivalent magnitude . the worst case sky subtraction algorithm would be to measure the sky brightness from an annulus close to the comet nucleus . if i assume that the sky is measured only 5  from the nucleus ( unlikely ) , we can used the observed @xmath48 surface brightness profiles of cometary comae @xcite to show that this sky subtraction algorithm would reduce the measured comet brightness by @xmath49 mag . more plausible sky subtraction schemes would reduce it by less , or not at all . thus this too is not a dominant source of error . in this section , i compare the data to the monte - carlo simulations of what linear would have seen over a three year period . in the scatter plots , the data are compared to a single run of the simulation . in all histograms and quoted statistics , however , the data are compared against the average or sum ( as appropriate ) of five monte - carlo runs based on the same comet population model . this summation should suppress the error due to small number statistics in the simulated samples to well below that of the observed sample . the observed sample properties are first compared against the monte - carlo prediction using the @xcite flux normalization and absolute magnitude distribution . figs  [ complot_eve ] , [ qhist ] and [ hhist ] compare the distribution of model and observed comets in perihelion @xmath50 and absolute magnitude @xmath4 . the upper boundary to the locus of points is set by the magnitude limit , and seems a reasonable fit to the data . but the model clearly predicts far too many comets : 2228 as compared to the 52 observed . the discrepancy is primarily at fainter absolute magnitudes : brighter than @xmath51 the model and data are consistent . the worst discrepancy is for comets fainter than @xmath52 : ie . fainter than the data on which everhart based his model . it is thus a test of the power - law extrapolation . the model predicts that linear should have seen 1848 comets fainter than @xmath53 , whereas only 12 were seen . irrespective of the flux normalization , the shape of the absolute magnitude distribution ( fig  [ hhist ] ) is wrong : a ks - test comparison with the observed distribution shows that they are inconsistent with @xmath54 confidence . is this discrepancy real , or is there some reason why linear would miss faint comets close to the earth ? the model comets with @xmath55 are predicted to be observable for a median period of 52 days , at a median distance from the earth of @xmath56 au . their typical apparent angular velocity is predicted to be @xmath57 degrees per day . their observational properties are thus typical of near earth objects , which linear finds in profusion . it is thus hard to see what selection effect could prevent their detection . grant stokes ( personal communication ) confirms that there is nothing in their data analysis which should preclude the discovery of comets like these . image trailing and short observability windows do reduce the number of these comets seen , but these are already taken into account by the monte - carlo simulation . could the discrepancy be an artifact of the various approximations made in the model ? the discrepancy is insensitive to assumptions about the dependence of brightness or comet number on heliocentric distance , as these sources are observed at close to 1au . one possibility is that i have incorrectly estimated the effective magnitude limit of linear for sources with these apparent total magnitudes . to test this , i repeated the analysis with a magnitude limit set two magnitudes brighter than my best estimate . this reduced the discrepancy but did not remove it : the prediction dropped to 577 observed comets fainter than @xmath58 , still more than two orders of magnitude above the data . none of the plausible incompletenesses in the data , nor other assumptions in the model can come close to removing this discrepancy . i therefore conclude that the everhart model can not be extrapolated to absolute magnitudes fainter than @xmath58 .    even at brighter absolute magnitudes , however , there remains a substantial discrepancy . the model predicts that 188 comets with @xmath59 and @xmath60 should have entered the solar system within the three year period , and that 86% of them ( 162 ) would have been detected by linear . only 21 such comets were observed . it is hard to see that linear could have missed many comets this bright passing this close to the sun . the model predicts that these comets should remain visible for a median 208 days ( 7 lunations ) , so almost regardless of position on the sky , they should have had several opportunities to be observed . they spend much of this time many magnitudes above the survey detection limit . indeed , the 21 comets observed with these properties were discovered a median 11 months before perihelion , at a median heliocentric distance of 4.3au , confirming that these are easy targets . the discrepancy occurs mostly at the fainter magnitudes within this range : brighter than @xmath51 there is no significant difference between the everhart predictions and the linear observations . i conclude , therefore , that the everhart model fails in two ways . firstly , the quoted normalization of 8,000 comets per 127 years with @xmath29 and @xmath60 is too high by a factor of @xmath61 . secondly , the faint end slope of the everhart absolute magnitude relation is much too steep , and immensely over - predicts the number of faint comets . this second conclusion was first reached by @xcite : the current paper independently confirms their result . both discrepancies suggest that everhart overestimated the incompleteness of his sample of long - period comets . the discrepancy goes away where the incompleteness correction is small , but is largest at the faint magnitudes where the correction is large . a discrepancy here is perhaps not surprising , as the correction factors calculated by everhart were so large : he corrected the 256 observed comets to a flux of 8000 : a factor of 31 . my analysis reduces this correction factor to only @xmath62 . one possible reason for the difference : everhart calculated the detection threshold for typical historical comet searchers , and assumed that the same threshold applied when searching for comets initially , and when making follow - up observations of known comets . his model was validated by noting that the last observations of comets occurred close to the time when his model suggested that they dropped below detectability . but let us hypothesize that comets just above the detection threshold might be missed as the telescope speeds past during a scan for new comets , even though they could be detected when looking hard for an already known comet at a known position . this would reduce the length of time over which a given comet could have been detected . detections would thus have occurred earlier in the detectability window , and the correction factor for incompleteness would thus decrease . i now compare the data against a monte - carlo simulation using my version of the @xcite absolute magnitude distribution and normalization , combined with the linearly rising perihelion distribution ( figs  [ qhist ] , [ hhist ] , [ complot_hug ] ) . once again , the overall envelope of points agrees well with the model , giving some confidence that the selection effects have been modeled correctly . the predictions from the hughes model are in much better agreement with the data . there is no vast excess of faint predicted comets , implying that the break seen in hughes data was real , and hence that the flatter faint - end slope of the absolute magnitude distribution is more accurate . neither the perihelion nor absolute magnitude distributions , however , are formally consistent with the observations at the 99% confidence level , as measured by the ks - test . the overall flux normalization is also too high : the model predicts that linear should have seen 171 comets , rather than the 52 observed . there is no significant discrepancy within the region in which hughes quoted his flux normalization ( 0.54 comets per year with @xmath63 per unit perihelion ) : the discrepancy is at fainter absolute magnitudes and larger perihelia . once again the discrepancy is fairly robust against the exact detection limit : dropping the detection threshold by a magnitude reduces the predicted comet numbers to 148 - still too high . how can this discrepancy be addressed ? possible incompletenesses in the linear sample were discussed in   [ prop ] and they can at best increase the observed numbers by @xmath64% . the hughes flux normalization is unlikely to be too low , as it was based on observed counts of very bright comets and made no correction for incompleteness . i therefore tried to improve the match by tinkering with the absolute magnitude and perihelion distributions . i first tried reducing the faint end slope of the absolute magnitude relation . if we assume that the linear sample is 20% incomplete , we need to reduce the faint end slope from 1.07 down to 0.8 to bring the number of predicted comets down to the observed number . unfortunately , this changes the observed absolute magnitude distribution too much : a ks test shows that a model with this slope predicts an observed @xmath4 distribution inconsistent with the data with greater than 99.99% confidence . i then tried changing the perihelion distribution . decreasing the slope @xmath65 in eqn  [ perieq ] to zero brought the predicted number of comets down to 95 , but the perihelion distribution is now too skewed towards small values of @xmath50 ( 99.96% confidence ) . i next tried combining both approaches . decreasing the faint end slope to 1.0 , combined with a flat perihelion distribution , brought the predicted numbers into line with the observed numbers . both the perihelion and absolute magnitude distributions were individually marginally acceptable ( ks - test gave 8 and 5% probabilities of them coming from the same population as the data ) but the joint probability was still uncomfortably low ( though the magnitude limit cut means that the two distributions are not independent , so this should not be taken too seriously ) . the model predicted too many comets with @xmath66 and @xmath67 , and too few in the middle . moving the location of the break in the absolute magnitude relation to fainter magnitudes was also a failure : given that the comet flux normalisation is at brighter magnitudes , this simply increased the number of fainter comets still further above the observations . i therefore adopted a different perihelion distribution : one that rises from @xmath68 out to @xmath69 , and is a power - law beyond that . this preserves the everhart observation of a drop in comet numbers below @xmath70 , while allowing us to tinker with the distribution further out . the parameterization used was : @xmath71 where @xmath72 controls the behavior at large perihelia . i then ran a grid of models , varying @xmath72 and the faint end slope of the absolute magnitude distribution ( @xmath22 in equation  [ heq ] ) . each simulated population was tested against the data in three ways : a ks - test on the perihelion distribution , a ks - test on the absolute magnitude distribution , and a chi squared test on the overall predicted number of comets . the latter was done for both the observed number of comets and a number 10% higher , to allow for possible incompletenesses . the lowest of these three significance values was used to compute the goodness - of - fit conutours in fig  [ contour ] . note that these contours include only random errors : the systematic errors are almost certainly larger , especially on @xmath72 . the lowest probability rather than the joint probability was used becuase the three tests are not strictly independent . quite a tight constraint could be placed on @xmath22 : @xmath73 ( 95% confidence , not including systematic errors ) . the constraint on @xmath72 was weaker : @xmath74 . no useful constraint could be placed on the bright - end slope @xmath21 : in the modeling i use the @xcite value of 2.2 , but it makes little difference . note that these slopes are often described in the literature using the @xmath75 parameter : @xmath76 , so our best - fit faint end slope has @xmath77 . the predicted distribution of comets for the best fit model is shown in figs  [ qhist ] , [ hhist ] and [ complot_f ] . models generated using this model predict @xmath78 ( @xmath45 ) observed comets , in excellent agreement with the data . this model was used to predict the discovery magnitude distribution ( fig  [ maghist ] ) . this comparison was used to set the equivalent point source vs. total magnitude offset , as described in   [ mags ] . my preferred model thus approximately preserves the faint - end slope and normalization derived by hughes . a flat perihelion distribution is marginally ruled out , and best fits are obtained for one that rises from the sun out to @xmath79 and is either flat or gently falling beyond that . the best - fit model can be used to estimate the flux of long - period comets through the inner solar system . by definition , this model uses the @xcite flux of 0.53 comets per year per unit perihelion , brighter than @xmath80 . @xcite estimated a flux of 8000 long - period comets per 127 years with @xmath29 and @xmath60 . my model suggests that the flux of comets with these parameters is much lower : 11 long - period comets per year ( 1600 per 127 years ) . the model suggests that linear is picking up over 60% of comets with these parameters . i estimate a true flux of 37 comets / year with @xmath81 and @xmath82 , of which linear is detecting @xmath83% . many published estimates of the number of comets in the oort cloud use the @xcite comet flux as their starting point , and hence should be revised down . estimates include @xcite , @xcite , @xcite and @xcite . the linear sample includes 22 comets with @xmath29 and @xmath60 over a three year period . 5 of these were dynamically new , 11 dynamically old , and 6 had orbit determinations too poor to tell . if we assume that the comets without good orbit determinations break up between new and old in the same ratio as the other comets , we find a flux of 7 dynamically new comets over the three years . my model suggests that the linear sample is @xmath84% complete for finding comets in this range , implying a total flux of dynamically new comets of @xmath37 per year . this corresponds to @xmath85 per unit perihelion per year if a uniform perihelion distribution is assumed . this is a factor of @xmath86 lower than was assumed by @xcite and @xcite . @xcite and @xcite assume long - period comet fluxes ( not just the dynamically new ones ) of @xmath87 per year per au down to @xmath29 , compared to my value of @xmath88 . after correction , all these estimates come out roughly the same : 1  3 @xmath89 in the outer oort cloud , down to @xmath29 . if this is extended to fainter absolute magnitudes , i estimate an outer oort cloud population of @xmath90 comets down to @xmath91 . my model has a much shallower slope of the absolute magnitude distribution than that of @xcite , so the average mass of a comet _ increases_. this cancels out the decreased number of oort cloud comets i predict to give a similar total oort cloud mass to previous estimates ( eg . * ? ? ? * ; * ? ? ? * ) , both of which used a mean mass computed by integrating the everhart curve . i used two suggested mass - brightness relations to estimate masses from the observed absolute magnitudes : one from @xcite and one from @xcite . note that this relation is extremely uncertain - very few long - period comets have had even their nuclear magnitudes measured . the average mass is crucially dependent on the slope of the bright end of the absolute magnitude distribution , which the data in this paper do not constrain . i bracket the possibilities by using both the everhart and hughes values ( 3.54 and 2.2 respectively ) . i use my own estimate of the faint - end slope .    for the everhart bright - end slope , the total mass converges as you go to brighter magnitudes : the bulk of the mass resides in comets with @xmath92 . for the hughes bright - end slope , however , the total mass diverges as you count brighter comets . the bright comets are rare , but their mass goes up faster than their number goes down at bright magnitudes . thus for the weissman mass relation , comets with @xmath93 are 10,000 times more massive than those with @xmath94 . the hughes bright - end slope , however , suggests that they are only 2,600 times less common , so the total mass in the brighter comets is actually four times greater . for the everhart bright - end slope , however , the brighter comets would be 300,000 times less common . the everhart slope is thus physically more appealing , as it avoids the need for a bright cut - off . given the success of both the hughes normalization and faint - end slope in fitting our sample , however , his bright - end slope should perhaps be taken seriously , leading to the prospect of an oort cloud dominated ( in mass terms ) by very large comets . in this section , i will cut off the magnitude range of comets at @xmath95 , but this is arbitrary and will have a large effect on the total oort cloud mass if the hughes distribution is assumed . @xcite showed that kuiper belt objects have a break in their mass distribution at sizes of @xmath96 km , which corresponds to @xmath97 (   [ small ] ) . this may or may not apply to oort cloud comets . if i take the everhart slope , the mean mass of comets down to @xmath58 is @xmath98 g for the @xcite mass relation , and @xmath99 g for the @xcite relation . if i take the hughes slope , however , the average masses rise to @xmath100 g and @xmath101 g respectively . these values translate into total outer oort cloud masses of 2  40 earth masses . my model can be used to calculate the probability of a long - period comet impacting the earth . @xcite calculated that the probability of a given long - period comet with @xmath102au impacting the earth is @xmath103 per perihelion passage . my model suggests that the flux of comets brighter than @xmath32 with @xmath66au is 8 per year . the mean time between comet collisions with the earth is thus @xmath83 million years : very comparable to the figure calculated by @xcite , and to the mean time between global extinction events .    most of these comets will , however , be quite small . using the conversion between absolute magnitude and radius described in   [ small ] , a comet with @xmath104 has a radius of only @xmath64 m : too small to cause a global extinction event . comets with radii of 1 km or greater ( @xmath105 ) are rarer - the mean time between collisions with comets this large is @xmath106 million years . the shallow faint end slope means that collisions with even small long - period comets are rare . if , for example , the tunguska impact was caused by a comet ( eg . * ) , it would have a mass of @xmath107 g @xcite and hence an absolute magnitude of @xmath108 . the probability of such a long - period comet impacting the earth in the last 100 years is thus @xmath109 . the tunguska impactor must therefore be either asteroidal ( eg . * ? ? ? * ; * ? ? ? * ) or associated with a _ short - period _ comet ( eg . * ? ? ? no comet has ever been detected with a strongly hyperbolic original orbit @xcite : ie . a comet that was not gravitationally bound to the solar system . several authors have discussed this ( eg . * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) , with many claiming that this is surprising . oort cloud formation models predict that for every comet that reaches the classical outer oort cloud , a factor @xmath110100 more are expelled into interstellar space ( eg . if most stars have planets , and if planetary formation is usually accompanied by comet ejection , then there should be a substantial population of free - floating interstellar comets . by some estimates , we should have expected to have seen one or more such comets by now , passing through the inner solar system . the results in this paper impact upon this question in two ways . firstly , the non - detection of interstellar comets in the linear sample places an upper limit on their space density . secondly , most previous estimates of the expected number of interstellar comets relied upon the @xcite comet flux : our lower comet flux thus leads to smaller predictions of the interstellar comet density . what limit can we place upon the space density of interstellar comets ( those with strongly hyperbolic orbits ) from the non - detection of any by linear ? i will assume that interstellar comets have the same absolute magnitude distribution that i derive for long period comets , and that their apparent brightness varies with heliocentric distance in the same way as dynamically new inbound comets in our model . given these assumptions , and an assumed magnitude limit of 19 ( point source equivalent ) , one can derive the distance @xmath34 out to which a comet with any given absolute magnitude could have been detected . to convert this into the volume surveyed during the three years of the survey , one must allow for the motion of the comets with respect to the solar system , which can carry new comets into range . typical motions of nearby stars with respect to the sun are @xmath111 @xcite . the volume surveyed in a survey of duration @xmath112 is thus @xmath113 the product of this equation and the absolute magnitude distribution ( equation  [ heq ] ) was integrated to calculate the number of comets potentially within linear s magnitude limit , for a given assumed space density of interstellar comets ( defined as the number of interstellar comets per cubic astronomical unit brighter than @xmath58 ) . the integral suggests that the bulk of interstellar comets detected will be those with absolute magnitudes near the break at @xmath31 . the results are quite sensitive to the adopted bright - end slope of the absolute magnitude distribution , being 40% lower for the everhart slope as compared to the hughes slope . not all of these comets will be seen : my model suggests that linear finds @xmath114% of the oort cloud comets within its magnitude limit . the fraction may be lower for interstellar comets because they move faster and hence are not observable for long , but the velocity difference is only @xmath115% . furthermore , a larger fraction of interstellar comets will be brght ones seen at large heliocentric distances , where the visibility period is larger . i adopt a conservative 50% detection probability , which should be ample to include comets not being followed up or not having good orbit determinations . the mean number of comets seen over the three years is then evaluated as a function of the assumed average density . if more than 5 comets are predicted to have been observed , the poisson probability of us having not seen any interstellar comets is less than 5% : this is our adopted limit . i thus derive an upper limit on the local space density of interstellar comets of @xmath116 per cubic au ( 95% confidence ) if the hughes bright - end slope is assumed . for the everhart bright - end slope , this limit increases to @xmath117 per cubic au . these limits are very comparable to the best existing limit : that of @xcite . sekanina s limit is , however , based upon everhart s papers and should thus be regarded with some suspicion . i can extend this calculation by noting that linear has not discovered any interstellar comets in other years . from 1999 through to the end of 2004 their monthly sky coverage ( though not available in detail ) is at least comparable to that during my sample period . these extra three years of data reduce our upper limits to 3  4.5 @xmath118 per cubit au . i now evaluate the expected space density of interstellar comets , given our reduced oort cloud population estimate . following @xcite , the number density of interstellar comets @xmath119 is given by : @xmath120 where @xmath121 is the local number density of stars , @xmath122 is the mean number of outer oort cloud comets per star , and @xmath123 is the ratio of comets expelled from a solar system to the number ending up in the outer oort cloud . i adopt @xmath124 per cubic parsec , from the 8pc sample of @xcite : this is consistent with the value used by @xcite but considerably lower than the value used by @xcite . for @xmath122 , i assume that the number of comets generated per star is proportional to its mass and metallicity . this may or may not be true , but is consistent with the observed tendency for low mass stars to lack hot jupiter planets ( eg . * ? ? ? * and refs therein ) . the local stellar population is dominated by low mass dwarfs : the average stellar mass of the nearby stars in the @xcite catalogue is only @xmath125 . the average metallicity of near - by f and g stars is @xmath126 \\sim -0.14 $ ] @xcite : no information is available for local dwarf stars , so i assume the same value . assuming that the outer oort cloud population derived in [ number ] is typical of local stars with solar mass and metallicity , i therefore derive @xmath127 . the most uncertain parameter is @xmath123 : literature values range from 3  100 ( eg . * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? .    given these parameters , @xmath128 . thus even in the most optimistic case , the predicted flux is an order of magnitude below current limits . could future surveys reach these predicted densities ? i ran the simulation for five year surveys reaching to deeper magnitude limits . a survey reaching 24th magnitude ( perhaps panstarrs ) would place 95% upper limits of @xmath129 , and might hence detect one or two interstellar comets if @xmath123 is very large . @xcite reached similar conclusions . a survey reaching 26th magnitude ( lsst ? ) would push the limit down to @xmath130 , which would be enough to detect or rule out a large value of @xmath123 . this prediction does , however , depend crucially on the assumed brightness behavior of comets a long way from the sun . simple models which assume that oort cloud comets have an isotropic velocity dispersion imply a constant number of comets per unit perihelion . @xmath6-body integrations ( eg . * ? ? ? * ; * ? ? ? * ) , in contrast , imply a rising number of comets at larger perihelia , due to the diffusion process of comets past the perturbations of the giant planets . both @xcite and @xcite , for example , predict an increase in the number of comets per unit perihelion of @xmath131 between @xmath69 and @xmath132 ( though this is an extrapolation of the wiegert & tremaine model which is only shown out to @xmath133 ) . is this consistent with the linear sample ?    the best - fit model has the number of comets per unit perihelion ( beyond @xmath134 ) going as a power law of index @xmath74 ( 95% confidence ) , ie . a gentle _ fall_. to get a rise in numbers consistent with the @xcite and @xcite predictions , we require @xmath135 , which is inconsistent with our model with 99% confidence . the measured perihelion distribution is , however , somewhat degenerate with the assumed dependence of comet brightness on heliocentric distance : @xmath6 in equation  [ eqabsmag ] . as i have repeatedly noted , the choice of @xmath6 is an approximation based on extrapolations of observations obtained at much smaller heliocentric distances . we can estimate the change in @xmath6 that would be needed to bring our observations into line with the @xcite predictions . we need to drop the predicted brightnesses of comets with @xmath136 by enough to reduce the observed numbers by 50% , to meet our 95% upper limit . given our best - fit absolute magnitude relation , this requires that @xmath6 be increased by @xmath137 . this is quite a small rise - well within the observed scatter of @xmath6 values seen at lower perihelia . if , for example , i had used the canonical value of @xmath12 for all comets , rather than our more complex scheme , this would make dynamically new comets much fainter when far from the sun , as required ( at the expense of the correlation seen in fig  [ q_a ] ) . the data in this paper , while suggestive , are not therefore significantly at odds with the theoretical predictions . a better understanding of heliocentric brightness variations when distant from the sun will be needed to see if this anomaly is real . the faint - end slope of the absolute magnitude relation derived in this paper ( @xmath138 ) is very flat : the number of comets per unit magnitude barely increases as you go fainter . this presumably indicates that small comets are not that much more abundant than large ones . if the absolute magnitudes are converted to nuclear masses , using either the @xcite or @xcite relations , i find that the differential number of comets per unit mass @xmath139 goes as : @xmath140    @xcite made the case for the existence of small comets : those with nuclei only meters to tens of meters in radius . if we assume the @xcite relationship between mass and absolute magnitude , and a density of @xmath141 , 100 m radius corresponds to @xmath142 and 10 m to @xmath143 . linear is therefore detecting at least a few comets with nuclei smaller than 100 m . similar small comets are also detected by the lasco instrument on the soho spacecraft @xcite , though these are mostly fragments of recently disintegrated larger comets @xcite . @xcite was unclear on whether the shallow faint - end slope was real or a selection effect : i confirm that it is real . @xcite pointed out that small long - period comets must be rare from statistics of comets passing close to the earth . @xcite found a similar paucity of small jupiter - family comets .    in this section , i point out that the shallowness of the faint - end slope is actually quite interesting theoretically . collisions are rare in the oort cloud @xcite , so the nuclear size distribution should remain largely unchanged from when the proto - comets were planetesimals expelled from the protoplanetary disk @xcite . @xcite modeled the size distribution of planetesimals in the protoplanetary disk . these models imply that 100 m diameter objects should outnumber 2 km sized objects by a factor of @xmath144 ( per unit log radius ) in the oldest disks modeled . our faint - end slope , however , if combined with the @xcite mass / absolute magnitude relation , implies a ratio of only @xmath145 . the size distribution of planetesimals may be greatly modified by collisions while they lie within the dense environment of the proto - planetary disk . most models of this collisional evolution also , however , predict much flatter size distributions than we see : they typically predict an increase in comet numbers , even at faint magnitudes , of a factor of @xmath146 per magnitude @xcite . this is much greater than my measurement ( @xmath147 ) .    as noted in [ eve ] , our shallow faint - end slope is quite robust to sample incompletenesses and model assumptions . the conversion of absolute magnitudes to radii is , however , highly uncertain even at bright magnitudes , let alone the faint absolute magnitudes of relevance here . theoretical predictions are also quite uncertain @xcite , and may be consistent with this slope . another possibility , however , is that the probability of a planetesimal escaping the protoplanetary disk and reaching the oort cloud is size - dependent . @xcite , for example , suggested that collisions between planetesimals would act to circularize their orbits , and would prevent them from escaping into the oort cloud until the density of planetesimals was greatly depleted ( see also * ? ? ? the square - cube law would suggest that this effect is most serious for smaller planetesimals , which may be ground down to dust before escaping . this could thus explain the deficit of small comets . alternatively , gas drag could play the same role : the largely gaseous nature of the giant planets indicates that the protoplanetary disk was still full of gas when the giant planets formed . no published modelling currently includes this effect . another possibility : the square - cube law implies that small comets may loose their volatiles faster than large ones . fading may thus be more severe for these comets , making them harder to detect . a final possibility is that comets have been exposed to high temperatures at some point in their history . the resultant loss of volatiles could thus destroy small comets without much affecting the numbers of large ones . @xcite tentatively suggest this as a reason for the lack of jupiter - family comets with small nuclei . long period comets might have been exposed to high temperatures while still in the proto - planetary disk . once in the oort cloud , temperatures are much lower . nearby supernovae and o - stars may have temporarily heated them enough to remove some volatiles @xcite , but this should not appreciably affect the numbers of small comets . i note in passing that my models are strongly inconsistent with the claims by @xcite for an immense population of small comets bombarding the earth . these claims have , however , already been ruled out in many other ways ( eg . * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) .      the model in this paper can be used to guide future automated comet - searches . the most basic conclusion follows from the shallow faint - end slope of the number / absolute magnitude relation . this means that to find more comets , a survey should always try to maximize the area covered rather than going deep in a small area . if linear , for example , exposed for six times as long per field , it would be sensitive to fainter comets , and would hence see @xmath148 times more comets per unit area . but it would cover a six times smaller area . the more frequently a survey covers a given area of sky , the higher the probability of a given comet being detected . in fig  [ freq ] , however , i show that this is not an enormous effect : decreasing the survey frequency for a hypothetical survey from weekly to biannual only drops the number of detected comets by @xmath64% . the comets lost are primarily those with fainter absolute magnitudes , because their visibility period is small . the small number lost is a direct consequence of the shallow faint - end slope : there are few small comets to lose .    in fig [ faint ] , i show the predicted samples that would be found by telescopes using a similar survey technique to linear , but going deeper . the deeper limit essentially increases the absolute magnitude limit reached at all perihelia , and by increasing the time over which comets are visible , also improves the completeness for brighter comets . over 3 years , a survey to 20th mag would detect 103 comets , to 22nd mag would detect 150 and to 24th mag , 186 comets . this is much fewer than @xcite estimated . the discrepancy is probably due to my shallow inferred absolute magnitude and perihelion distributions , which mean that the dramatic increase in sensitivity of these surveys as compared to linear only yields a relatively small increase in sample size . i conclude that telescopes such as skymapper , panstarrs and lsst , each capable of surveying large areas to deeper than 22nd magnitude , should be capable of detecting more than 50 long - period comets per year . a substantial fraction of these are forecast to have perihelia beyond 10au , though this conclusion relies upon the rather shaky assumptions of how brightness varies with heliocentric distance this far out . thus five years should suffice to build up a quantitatively selected sample of long - period comets equal in size to any historical sample . six main conclusions can be drawn from this analysis :    1 . the outer oort cloud contains @xmath90 comets down to @xmath91 ( @xmath149 comets down to @xmath58 ) . this is 2  10 times fewer comets than previous published estimates . 2 . the average mass of these comets is , however , higher than previous estimates . down to @xmath58 , the average mass is between @xmath99 g and @xmath101 g , leading to a total mass in the outer oort cloud of 2  40 earth masses , comparable to or larger than previous estimates . the mass of the oort cloud may be dominated by a few large comets . small comets do exist , but are rarer than predicted by many models . this may be because they have difficulty escaping from the protoplanetary disk . the probability of the earth being hit by a long - period comet similar in energy to the tunguska impactor is only one in forty million per year . i place an upper limit on the space density of interstellar comets of @xmath150 per cubic au ( 95% confidence ) . this is still an order of magnitude above our revised prediction for the space density of interstellar comets . the number of long - period comets per unit perihelion seems to decline , or at best rise slowly beyond 2au . this does not agree with theoretical predictions . the discrepancy may be resolved if comets are fainter at large heliocentric distances than i assume . future survey telescopes should be able to assemble samples of several hundred long - period comets in a few years of operation . the major weakness in this analysis is in the photometry : in particular in our limited understanding of how the brightness of comets varies with heliocentric distance when far from the sun , and in how to convert ill - defined total magnitudes into more reproducible and physically meaningful parameters such as @xmath39 . the data exist to address these problems , but are not publicly available . i would like to thank grant kennedy , eriita jones and chris weekes for their work on aspects of this paper , stephen pravdo and grant stokes for responding to e - mail questions about their neo surveys , timothy spahr for providing details of objects posted to the neo confirmation page , and dan green for provide magnitude measurements from the archives of the international comet quarterly . paul weissmann was referee on an earlier version of this paper : his detailed comments were invaluable in educating the author ( an extragalactic astronomer by training ) in comet lore .", "tags": [], "output_text_a": "The paper discusses the challenges and advancements in understanding the Oort Cloud, a distant and mysterious part of our solar system, primarily through the study of long-period comets. Historically, comets were discovered through manual searches, which had limitations such as unknown selection functions, limited range, and unreliable photometry. Recent advancements in technology, particularly the use of large-format CCDs and automated surveys like the Lincoln Near-Earth Asteroid Research (LINEAR) project, have improved the detection and analysis of long-period comets.\n\nThe study uses data from the LINEAR survey to model the statistical properties of the long-period comet population, offering a more defined selection criterion and extending observations to larger perihelia and fainter magnitudes. The paper critiques previous models, particularly those by Everhart and Hughes, finding that Everhart's model overestimates the number of faint comets due to large incompleteness corrections. The study proposes a new model with a flatter faint-end slope for the absolute magnitude distribution, suggesting fewer small comets than previously thought.\n\nThe paper also explores the implications of these findings for the Oort Cloud's population and mass, estimating a lower number of comets but a higher average mass, leading to a total mass comparable to previous estimates. It discusses the potential for future surveys to detect interstellar comets and the challenges in photometry, particularly in understanding comet brightness at large heliocentric distances. The study concludes with recommendations for future comet searches, emphasizing the importance of covering large sky areas rather than focusing on depth.", "output_text_b": "The paper discusses the Oort cloud, a theoretical shell of icy bodies surrounding the solar system, which cannot be directly observed. The authors summarize past attempts to model the Oort cloud based on observations of long-period comets and highlight the limitations of these models due to the unknown selection function, limited range of comets observed, and poorly defined photometry. The paper then describes a new approach to estimate the statistical properties of the long-period comet population using data from the Linear survey, a CCD-based survey with a well-defined selection criterion. The authors compare the observed sample of comets from the Linear survey to a model of the long-period comet population and derive their own best-fit model of long-period comet demographics. They also discuss the consequences of this new model and its implications for future wide-field survey telescopes.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the challenges and advancements in understanding the Oort Cloud through the study of long-period comets.\n2. The summary is concise and does not exceed 250 words.\n3. It highlights the research problem of understanding the Oort Cloud and the limitations of historical comet detection methods.\n4. The summary mentions the methodology of using data from the LINEAR survey to model the statistical properties of long-period comets.\n5. It includes significant results, such as the critique of previous models and the proposal of a new model with a flatter faint-end slope.\n6. The summary is written in clear and professional language.\n7. It avoids excessive technical jargon and explains terms like \"Oort Cloud\" and \"long-period comets.\"\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. It mentions key data used in the research, specifically the LINEAR survey data.\n10. The summary reflects the paper's significance by discussing the potential impact on future surveys and understanding of the Oort Cloud.", "1. **Accurate Reflection**: The summary accurately reflects the main findings and contributions of the paper by discussing the Oort cloud, the limitations of past models, and the new approach using the Linear survey.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of modeling the Oort cloud based on long-period comets.\n4. **Methodology**: The summary mentions the methodology of using data from the Linear survey to estimate the statistical properties of the comet population.\n5. **Significant Results**: The summary includes significant results, such as deriving a best-fit model of comet demographics.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids unnecessary technical jargon and explains terms like \"Oort cloud\" and \"Linear survey.\"\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary mentions the use of data from the Linear survey.\n10. **Significance/Impact**: The summary reflects the paper's significance by discussing its implications for future surveys."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "recently , higgs flavor changing neutral currents ( fcncs ) in randall - sundrum @xcite ( rs ) models have received a lot of attention . a model independent analysis was performed in @xcite ( see also @xcite ) and it was shown that a light composite higgs that couples strongly to new heavy states can lead to significant bounds on the compositeness scale from @xmath2 oscillations . in @xcite , where only the first fermionic kaluza - klein ( kk ) excitations in the custodially protected rs model ( rsc ) were considered it was found that tree - level higgs fcncs are negligible . however , in contrast to this in @xcite it was pointed out that the summation over the whole kk tower of fermionic excitations yields a finite contribution to higgs fcncs . in the same paper also the resulting higgs contribution to @xmath0 was calculated and a higgs - mass - dependent bound on the kk mass scale was deduced . while the strongest bound on the kk mass scale in rs models with a brane higgs is due to the tree - level exchange of kk gluons @xcite , the bound deduced in @xcite is well of the same order of magnitude , at least for a light higgs . in view of these new results it is mandatory to compare the bounds on the kk scale that are required to keep under control the effects of the tree level exchanges of kk gluons on the one hand and of the higgs boson on the other hand . in particular this is necessary since the bounds of @xcite and @xcite are not comparable to each other without further ado as they depend on the authors prejudices towards naturalness or the experimental and theoretical uncertainties in @xmath0 . even more so these assumptions are implicit in @xcite . the rest of this paper is organized as follows . in section [ sec : higgs - fcncs ] we briefly review the results for the flavor off - diagonal higgs couplings derived in @xcite and comment on their renormalization group ( rg ) evolution . section [ sec : epsk ] is devoted to the calculation of @xmath0 in terms of the flavor off - diagonal higgs couplings in the brane - higgs scenario . in section [ sec : numerical_results ] we compare our results for the higgs and kk gluon contributions in the brane higgs scenario and show how this result can be generalized to the case of a bulk higgs . our conclusions finally are presented in section [ sec : conclusions ] . [ sec : higgs - fcncs ] in this section we briefly recapitulate the main results of @xcite and comment on the rg evolution of the flavor off - diagonal higgs couplings . a detailed description of the model setup as well as the notation used in the present paper can be found in @xcite . to set some additional notation we explicitly write out the relevant lagrangian @xmath3_{ij}\\sum\\limits_{n_2=0}^\\infty d_r^{j(n_2)}h + \\sum\\limits_{m_1=1}^\\infty\\bar d_l^{i(m_1)}\\left[\\hat y_2\\right]_{ij}\\sum\\limits_{m_2=1}^\\infty q_r^{j(m_2)}h+h.c.\\ , , \\label{eq : l_yuk}\\ ] ] where @xmath4 and @xmath5 are fundamental 5d yukawa matrices . flavor off - diagonal higgs couplings in the mass eigenbasis can arise whenever the rs contributions to quark masses and to the yukawa couplings are not aligned . in the mass insertion approximation the rs contributions up to @xmath6 are represented by the two diagrams in fig . [ fig : mia ] with the couplings given in ( [ eq : l_yuk ] ) . the first diagram in fig . [ fig : mia ] contributes equally to the quarks masses after ewsb and their yukawa couplings . the second diagram however affects masses and yukawa couplings in a different manner since its contribution to the yukawa couplings comes with a combinatorial factor of three that is due to the three different choices of which two external higgs lines are set to their vevs . this shift between quark masses and yukawa couplings results in flavor off - diagonal higgs couplings once we go to the mass eigenstate basis .    , height=94 ]    at a first glance the overall contribution from the second diagram in fig . [ fig : mia ] seems to be negligible since both the @xmath7 and @xmath8 modes obey dirichlet boundary conditions on the ir brane . in @xcite the point has been made that the profiles of @xmath7 and @xmath8 do not exactly vanish on the ir brane but display a small discontinuity that is proportional to the higgs vev . after regularization of this discontinuity and summing over the infinite tower of kk modes it is found that a non - vanishing misalignment between quark masses and yukawa couplings is generated by this diagram . at this point it is appropriate to call the reader s attention to the fact that the yukawa matrix @xmath5 that couples the scalar currents @xmath9 to the higgs field is not required for the generation of quark masses and hence could be set to zero which would eliminate the second diagram s contribution to flavor off - diagonal higgs couplings . however , since this choice for @xmath5 without profound physical reason contradicts naturalness , in the following we will set @xmath5 to be equal is mandatory in the bulk higgs scenario . ] to @xmath4 . an additional source of misalignment between quark masses and yukawa couplings is the modification of the kinetic terms by the mixing of sm quarks and kk quarks after ewsb as was first pointed out in @xcite ( see also @xcite ) . these flavor - dependent corrections to the kinetic terms make redefinitions of the quark fields necessary which in turn give rise to an additional shift between quark masses and yukawa couplings . for the first two generations of quarks this contribution is found to be negligible , for the third generation however this effect can be of the same size as the one outlined above . + after this rather qualitative description we now summarize the main results of @xcite for the case of a brane - localized higgs field . the total misalignment between quark masses and yukawa couplings comprises two contributions , @xmath10 , where @xmath11 is the contribution represented by the diagrams in fig . [ fig : mia ] and @xmath12 is due to rescaling of the quark fields as to canonize their kinetic terms . explicitly , the authors of @xcite find @xmath13 and @xmath14 where here and in the following a hat indicates a @xmath15 matrix in flavor space . @xmath16 is the warped - down curvature of the extra dimension that sets the scale of mass of the lightest kk states . the matrices @xmath17 and @xmath18 are functions that depend on the quark localization and are defined via @xmath19    the flavor off - diagonal components of the yukawa couplings in the mass eigenbasis are obtained from @xmath20 via the bi - unitary transformation @xmath21 where @xmath22 and @xmath23 are the unitary rotations that diagonalize the down - type quark mass matrix , @xmath24 + the misalignment between quark masses and the resulting flavor off - diagonal yukawa couplings given above are generated at or beyond the kk mass scale . in the following , we will take this scale to be @xmath25 . from this high energy scale the yukawa couplings have to be evolved down to the scale @xmath26 of the higgs mass where new effective interactions are generated by tree level exchanges of the higgs boson . the rg evolution of these couplings is in fact identical to that of quark masses and is well known to next - to - leading order ( nlo ) . from this scale the wilson coefficients of the new operators then have to be evolved down to the physically relevant scale @xmath27 according to their individual anomalous dimensions . these rg effects have been neglected in recent publications discussing higgs fcncs , e.g.  @xcite . for a complete numerical analysis however these effects have to be included . we will discuss this issue in the following section . [ sec : epsk ] the lagrangian relevant for higgs contributions to @xmath28 transitions in the quark mass eigenbasis is given by @xmath29 where @xmath30 is the down - type @xmath15 yukawa matrix for quarks in the mass eigenbasis at energy scale @xmath31 . if we define @xmath32 , @xmath33 , the effective hamiltonian for @xmath28 transitions that are induced by tree - level higgs exchanges is found to be @xmath34_\\text{higgs}&=&\\frac{1}{2m_h^2}\\left[\\left(\\delta_l^h\\right)^2(\\bar s p_l d)(\\bar s p_l d)+\\left(\\delta_r^h\\right)^2(\\bar s p_r d)(\\bar s p_r d)\\right.\\nonumber\\\\&+&2\\delta_l^h \\delta_r^h(\\bar s p_l d)(\\bar s p_r d)\\big]\\,,\\label{eq : h_eff1}\\end{aligned}\\ ] ] where @xmath35 . here and in the following summation over color indices within the brackets of the effective operators is understood . in the operator basis of @xcite this is equivalent to the effective hamiltonian @xmath36_{higgs}=\\frac{1}{2m_h^2}\\left[\\left(\\delta_l^h\\right)^2q_1^{sll}+\\left(\\delta_r^h\\right)^2q_1^{srr}+2\\delta_l^h \\delta_r^hq_2^{lr}\\right]\\,,\\label{eq : h_eff2}\\ ] ] and the wilson coefficients at the energy scale @xmath31 are accordingly given by @xmath37    the effective interactions in ( [ eq : h_eff2 ] ) are generated at an energy scale @xmath31 . from this scale the wilson coefficients @xmath38 in ( [ eq : wilsons1])-([eq : wilsons3 ] ) have to be evolved down to the low energy scale @xmath39 at which the hadronic matrix elements @xmath40 of the operators in ( [ eq : h_eff2 ] ) are evaluated using lattice methods . this rg evolution can be performed separately from the additive sm contribution and the contributions from kk gauge bosons that have been discussed in @xcite . under renormalization @xmath41 and @xmath42 mix with @xmath43 and @xmath44 , respectively , so that the full operator basis relevant for the present analysis is given by @xmath45 and the rg evolution operators each are given by @xmath46 matrices . it should be noted that due to the insensitivity of qcd to the sign of @xmath47 the wilson coefficients @xmath48 and @xmath49 evolve identically under the rg while their initial conditions ( [ eq : wilsons1 ] ) and ( [ eq : wilsons2 ] ) at scale @xmath26 are in general different from each other . resorting to the expressions for the evolution operators given in @xcite we find that all the wilson coefficients ( [ eq : wilsons1])-([eq : wilsons3 ] ) are enhanced in the rg evolution from @xmath31 down to @xmath50 with the strongest enhancement occurring in the case of the @xmath41 operator .    from the effective hamiltonian at the low energy scale @xmath51 , @xmath34_\\text{higgs}&=&c_1^{lr}(\\mu_l)q_1^{lr}+c_2^{lr}(\\mu_l)q_2^{lr}+c_1^{sll}(\\mu_l)q_1^{sll}+c_1^{srr}(\\mu_l)q_1^{srr}\\nonumber\\\\&+&c_2^{sll}(\\mu_l)q_2^{sll}+c_2^{srr}(\\mu_l)q_2^{srr}\\,,\\end{aligned}\\ ] ] the higgs contribution to the off - diagonal element @xmath52 that is responsible for @xmath2 oscillations is obtained by taking @xmath53_\\text{higgs}|k^0\\rangle\\,,\\ ] ] with @xmath54 the neutral k - meson mass . the matrix elements @xmath55 can then be parameterized by @xmath56 where @xmath57 and @xmath58 is the k - meson decay constant . since qcd is blind to the sign of @xmath47 , the matrix elements of @xmath59 are identical to those of @xmath60 . the hadronic parameters @xmath61 are known from lattice calculations and are related to the parameters @xmath62 , @xmath63 , @xmath64 and @xmath65 calculated in @xcite via @xmath66 and their numerical values at the lattice scale @xmath67 are given by @xcite @xmath68    finally , the cp - violating parameter in the @xmath2 system is given by @xmath69\\,,\\ ] ] where @xmath70 and @xmath71 @xcite account for @xmath72 and include an additional effect from the imaginary part of the 0-isospin amplitude in @xmath73 . the sm contribution @xmath74 in the conventions used in the present paper can be found in @xcite . [ sec : numerical_results ] in our analysis we will proceed in the same manner as done in @xcite . in that paper the 28 parameters determining the fundamental yukawa matrices @xmath75 and @xmath76 are randomly chosen in their respective ranges , @xmath77 $ ] , @xmath78 $ ] and @xmath79 $ ] for angles , phases and absolute sizes of yukawa couplings , respectively . the last range accounts for the fact that fundamental yukawa couplings larger than about three in @xcite . ] result in a breakdown of perturbativity at energies below the mass of the second kk excitation ( see eg .  @xcite for more details ) and that too small values tend to require the right - handed top - quark to be extremely localized towards the infrared ( ir ) brane . the nine quark bulk mass parameters @xmath80 are then determined such that the quark masses and ckm mixing angles are reproduced , which can be much facilitated by using the froggatt - nielsen formalism @xcite . finally , we keep only those parameter sets that in addition to the quark masses and ckm mixing angles also reproduce the proper value of the jarlskog determinant , all within their respective @xmath81 ranges .    since for given fundamental yukawa matrices the choice of bulk mass parameters @xmath80 is not unique due to the transformation @xmath82 as was pointed out in @xcite , we additionally specify that in our scan @xmath83 is taken . however , it should be pointed out that the numerical consequences of modifying a given set of parameters according to ( [ eq : shift - symmetry ] ) for @xmath2 mixing are small for @xmath84 values of @xmath85 . + in the following we will scan the parameter space of the rsc model in the way described above . to make the statements of this paper fully traceable , we mention the three additional assumptions :    * the fundamental yukawa matrix @xmath5 is equal to @xmath4 , * the 5d qcd coupling constant at the kk scale is taken to by @xmath86 and @xmath87 , * the higgs field is localized at the ir brane ( @xmath88 ) .    in this , @xmath89 is considered to be a natural choice as this is mandatory in the case of a bulk higgs . the value @xmath90 is obtained from tree level matching of the 5d to the 4d qcd coupling constants . in the case of loop level matching the minimal value @xmath87 is obtained , while gluonic brane kinetic terms could enhance @xmath91 beyond the tree level value @xcite . on the other hand , @xmath91 is bounded from above by perturbativity considerations . the requirement that the theory is perturbative beyond the second kk excitation results in a ( conservative ) upper bound of @xmath87 , and @xmath90 is already disfavored by this estimate @xcite . to allow for a better comparison with the previous analyses @xcite we still include the higher value @xmath90 into our analysis . + changes in @xmath91 will change the relative and absolute sizes of the kk gluon and higgs contributions to @xmath0 . also , the hierarchy between gauge boson and higgs contributions is affected by the localization of the higgs field along the fifth dimension and the average absolute size @xmath92 of the 5d yukawa couplings . more precisely , in the bulk higgs scenario the overlap integral of the higgs with the fermionic zero mode profiles also receives contributions from the fermions bulk profiles . this allows to localize the fermion profiles closer to the uv brane which in turn decreases the overlap of the fermion modes with kk gauge bosons and thus diminishes the impact of kk gauge bosons on @xmath0 @xcite . on the other hand , as was argued in @xcite the size of the flavor changing higgs couplings is only mildly affected by the higgs localization . in consequence , detaching the higgs field from the ir brane increases the relative importance of the higgs contribution . increasing the average absolute size @xmath92 allows to move the fermion profiles closer to the uv brane , with the same effect as described above , but beyond that at the same time the higgs contribution to @xmath0 is increased . thus larger 5d yukawa couplings also increase the relative importance of the higgs contribution . we will investigate the impact of deviations of @xmath91 , @xmath92 and the higgs localization parameter @xmath93 from their values chosen above in detail at the end of this section . + in fig . [ fig : relative ] we show the relative sizes of the kk gluon and higgs contributions to @xmath0 for a kk scale @xmath94 for two values of the fundamental qcd coupling constant , @xmath87 and @xmath95 , and for two values of the higgs mass , @xmath96 and @xmath97 . in contrast to @xcite where the combined gauge boson correction to @xmath0 was considered we here give the purely gluonic contribution . however , as was shown in @xcite , the impact of electroweak ( ew ) gauge bosons to @xmath2 oscillations is small compared to the impact of kk gluons .     for @xmath96 ( left ) and @xmath98 ( right ) . light areas correspond to a high density of parameter points while dark areas correspond to a low density of parameter points in that region . [ fig : relative],title=\"fig : \" ] for @xmath96 ( left ) and @xmath98 ( right ) . light areas correspond to a high density of parameter points while dark areas correspond to a low density of parameter points in that region . [ fig : relative],title=\"fig : \" ] for @xmath96 ( left ) and @xmath98 ( right ) . light areas correspond to a high density of parameter points while dark areas correspond to a low density of parameter points in that region . [ fig : relative],title=\"fig : \" ]    from the left panel of fig . [ fig : relative ] we see that even in the case @xmath99 in which the relative size of the higgs contribution is maximal , most of the points in parameter space yield a much larger kk gluon contribution than higgs contribution . for more than 65% of all data points the higgs contribution is smaller than 10% of the kk gluon contribution . if the kk gluon contribution is accidentally small , it may well be exceeded by the higgs contribution , however it is the data points that yield too large corrections to @xmath0 that will eventually set the bound on the kk mass scale .    in fig . [ fig : ft ] we show the average barbieri - giudice @xcite fine - tuning of those points in parameter space that satisfy the @xmath0 constraint to @xmath100 for the kk gluon case with @xmath87 ( left ) and for the higgs case with @xmath96 ( right ) .    from the left panel of fig . [ fig : ft ] we can read off that depending on the amount of generic fine - tuning one is willing to accept a bound on the kk mass scale between @xmath101 and @xmath102 is required to keep the impact of kk gluon exchange under control ( this is roughly half the value stated in @xcite for @xmath90 ) . under identical conditions the tree - level higgs exchanges by themselves would imply a bound which is introduced below . ] on the kk mass scale between @xmath103 and @xmath104 for a higgs mass @xmath96 , as can be seen from the right panel of fig . [ fig : ft ] . for larger higgs masses the bound gets accordingly weaker . taken together , figs . [ fig : relative ] and [ fig : ft ] show that in the brane higgs scenario with @xmath105 ( that roughly corresponds to @xmath106 ) the kk gluon contribution significantly exceeds the higgs contribution for both @xmath90 and @xmath87 . the tendency of this conclusion is not changed if the typical size of the yukawa couplings @xmath92 is raised to the maximal value that is compatible with the perturbativity estimate @xmath107 . so while in the brane higgs case the tree - level exchange of the higgs boson indisputably has an impact on @xmath0 , the strongest bound on the kk mass scale for all values of the fundamental qcd coupling @xmath91 and all values of the higgs mass comes from the exchange of kk gluons . + to extrapolate this finding to the bulk higgs case we use @xcite @xmath108 where @xmath109 depends on the localization of the higgs field and @xmath110 is the kk fermion yukawa coupling ( in the brane higgs scenario we would have @xmath111 ) . furthermore , from ( [ eq : delta - d-1 ] ) we see that for the higgs contribution to @xmath0 @xmath112 with nearly no dependence on the localization of the higgs field @xcite .    using ( [ eq : gluon - contribution ] ) , ( [ eq : higgs - contribution ] ) we can infer an estimate for the ratio @xmath113 for arbitrary values of @xmath114 from the reference value @xmath115 that is determined for @xmath116 . explicitly , @xmath117 where the ratio @xmath115 is found to be @xmath118 and @xmath109 is given for several values of @xmath93 in @xcite : @xmath119 , @xmath120 , @xmath121 , @xmath122 .    in fig . [ fig : r - ratio ] we show the ratio as a function of @xmath93 for two different values of @xmath110 . the lower curve corresponds to the maximal value consistent with the perturbativity estimate , @xmath123 ( where an additional factor @xmath124 is due to the localization of the higgs in the bulk @xcite ) , and the upper one to the value @xmath125 , that corresponds to the average if values are randomly chosen between @xmath126 and the maximal value . we observe that as soon as the higgs field is detached from the ir brane the higgs contribution to @xmath0 can in principle exceed the kk gluon contribution , although depending on the typical size of yukawa couplings this outcome is not imperative . the possible dominance of the higgs contributions is largely due to the increase of the maximally allowed value for @xmath110 by a factor of @xmath124 , but also by the shift of the quark zero modes towards the uv brane that becomes possible for a bulk higgs .    at this point it is important to keep in mind that observables that depend on positive powers of @xmath110 , such as the neutron edm @xmath127 @xcite , @xmath128 @xcite and @xmath129 @xcite for fixed @xmath130 constrain the size of the yukawa couplings such that the above statements are only sensible if the isolated @xmath0 constraint is considered . [ sec : conclusions ] in this paper we have carefully compared the impact of kk gluon and higgs exchanges on the observable @xmath0 in the brane higgs scenario . subsequently we have extrapolated our results to the case of a bulk higgs and given estimates for the relative size of kk gluon and higgs contributions to @xmath0 . a comparison of kk gluon and higgs contributions to @xmath0 is mandatory since up to now those two contributions were never treated simultaneously and the generic bounds on the kk scale deduced from their presence hence depend on different and often implicit assumptions . these assumptions for instance include the uncertainties within which an observable is required to be reproduced or the individual acceptance of fine - tuning . in the course of our analysis we have shown in detail how the value of the low energy observable @xmath0 can be derived from the misalignment of quark mass matrices and yukawa couplings at the kk scale for which analytic expressions were derived in @xcite . of particular importance in this context is the proper employment of the rg equations . while the wilson coefficients of the effective interactions induced by kk gluon exchange have to be run down from the kk scale to the physical scale according to their anomalous dimension , this is different for the case of the higgs induced contributions . here the anomalous higgs couplings that are induced at the kk scale have to be evolved down to the scale of the higgs boson mass where new interactions are generated by the exchange of the higgs boson . from there , as in the kk gluon case , the wilson coefficients of the effective interactions have to be evolved to the physical scale according to their anomalous dimensions .    as an outcome of our analysis we have shown that while higgs fcncs have an impact on @xmath0 as was already pointed out in @xcite , their contribution for a brane higgs is dwarfed by the contribution of kk gluons even in the most favorable scenario for the higgs contributions . for a brane higgs scenario with reasonable choices fundamental yukawa couplings the bound on the kk scale implied by the presence of tree - level higgs exchanges is found to be @xmath131 , to be compared to the corresponding bounds for kk gluon exchange that are given by @xmath132 for @xmath87 and @xmath133 for @xmath90 ( see also @xcite ) .    tentatively extrapolating this result to the case of a bulk higgs we find that the higgs contribution to @xmath0 can exceed the kk gluon contribution as soon as the higgs field is detached from the ir brane if the yukawa couplings are assumed to have the maximal value still consistent with perturbativity estimates . this is largely due to larger allowed values for the yukawa couplings in the presence of a bulk higgs . for yukawa couplings smaller by a factor of two than the maximal value the kk gluon contributions are typically larger than the higgs contributions for higgs localizations @xmath93 down to @xmath134 . finally we would like to mention that in the present work we only studied the isolated constraint on the kk scale arising from the observable @xmath0 . the total bound on @xmath130 is generally higher , as also other observables such as @xmath127 @xcite , @xmath128 @xcite and @xmath129 @xcite impose constraints on the kk scale . the rs contributions to these observables are proportional to @xmath135 such that for values of @xmath110 as large as the perturbativity bound the strongest individual bound on @xmath130 typically comes from on of those observables instead of @xmath0 . i thank andrzej buras for very helpful discussions and his critical reading of the manuscript . i also thank kaustubh agashe for his comments and enlightening discussion as well as alexandr azatov , manuel toharia , andreas weiler and lijun zhu for their comments . this research was partially supported by the graduiertenkolleg grk 1054 of deutsche forschungsgemeinschaft ( dfg ) . m.  blanke , a.  j. buras , b.  duling , s.  gori , and a.  weiler , _ @xmath136 f=2 observables and fine - tuning in a warped extra dimension with custodial protection _ , _ jhep _ * 03 * ( 2009 ) 001 , [ http://xxx.lanl.gov/abs/0809.1073[arxiv:0809.1073 ] ] . a.  j. buras , b.  duling , and s.  gori , _ the impact of kaluza - klein fermions on standard model fermion couplings in a rs model with custodial protection _ , _ jhep _ * 09 * ( 2009 ) 076 , [ http://xxx.lanl.gov/abs/0905.2318[arxiv:0905.2318 ] ] . m.  e. albrecht , m.  blanke , a.  j. buras , b.  duling , and k.  gemmler , _ electroweak and flavour structure of a warped extra dimension with custodial protection _ , _ jhep _ * 09 * ( 2009 ) 064 , [ http://xxx.lanl.gov/abs/0903.2415[arxiv:0903.2415 ] ] . s.  casagrande , f.  goertz , u.  haisch , m.  neubert , and t.  pfoh , _ flavor physics in the randall - sundrum model : i. theoretical setup and electroweak precision tests _ , _ jhep _ * 10 * ( 2008 ) 094 , [ http://xxx.lanl.gov/abs/0807.4937[arxiv:0807.4937 ] ] . a.  j. buras , s.  jager , and j.  urban , _ master formulae for delta(f ) = 2 nlo - qcd factors in the standard model and beyond _ , _ nucl . * b605 * ( 2001 ) 600624 , [ http://xxx.lanl.gov/abs/hep-ph/0102316 [ hep - ph/0102316 ] ] . r.  babich _ et al . _ , _ k0 anti - k0 mixing beyond the standard model and cp- violating electroweak penguins in quenched qcd with exact chiral symmetry _ , _ phys . _ * d74 * ( 2006 ) 073009 , [ http://xxx.lanl.gov/abs/hep-lat/0605016[hep-lat/0605016 ] ] . o.  gedalia , g.  isidori , and g.  perez , _ combining direct & indirect kaon cp violation to constrain the warped kk scale _ , _ phys . lett . _ * b682 * ( 2009 ) 200206 , [ http://xxx.lanl.gov/abs/0905.3264 [ arxiv:0905.3264 ] ] . b.  duling , _ @xmath137 and @xmath138 meson mixing in warped extra dimensions with custodial protection _ , _ j. phys . _ * 171 * ( 2009 ) 012061 , [ http://xxx.lanl.gov/abs/0901.4599[arxiv:0901.4599 ] ] .", "tags": [], "output_text_a": "This paper examines the impact of Higgs flavor-changing neutral currents (FCNCs) in Randall-Sundrum (RS) models, particularly focusing on the contributions of Kaluza-Klein (KK) gluons and Higgs bosons to the observable parameter \\(\\epsilon_K\\), which is related to \\(K^0\\) oscillations. The study compares the bounds on the KK mass scale required to control the effects of these contributions. The analysis reveals that while Higgs FCNCs do affect \\(\\epsilon_K\\), their impact is generally overshadowed by the contributions from KK gluons in scenarios where the Higgs is localized on the brane. The paper also explores the implications of a bulk Higgs scenario, where the Higgs contribution could potentially exceed that of KK gluons if the Yukawa couplings are large. The research highlights the importance of considering both KK gluon and Higgs contributions simultaneously, as previous studies often treated them separately, leading to different assumptions and bounds on the KK scale. The findings suggest that the strongest constraints on the KK scale arise from KK gluon exchanges, although the presence of a bulk Higgs could alter this hierarchy under certain conditions. The study emphasizes the need for a comprehensive approach to understanding the interplay between different contributions in RS models, particularly in the context of flavor physics and CP violation.", "output_text_b": "The paper discusses the significance of Higgs flavor changing neutral currents (FCNCs) in Randall-Sundrum (RS) models. A model-independent analysis in [xcite] showed that a light composite Higgs strongly coupled to new heavy states could lead to substantial bounds on the compositeness scale from FCNCs. In [xcite], it was found that tree-level Higgs FCNCs are negligible in the custodially protected RS model (RSC). However, the summation over the whole Kaluza-Klein (KK) tower of fermionic excitations in [xcite] yields a finite contribution to Higgs FCNCs. The paper aims to compare the bounds on the KK scale required to control the effects of tree-level exchanges of KK gluons and the Higgs boson.\n\nThe paper is organized into several sections. Section [sec : higgs - fcncs] reviews the results for flavor off-diagonal Higgs couplings derived in [xcite] and comments on their renormalization group (RG) evolution. Section [sec : epsk] calculates the contribution of FCNCs to the parameter @xmath0 in the brane-Higgs scenario. Section [sec : numerical_results] compares the results for the Higgs and KK gluon contributions in the brane Higgs scenario and generalizes the result to the case of a bulk Higgs. The conclusions are presented in section [sec : conclusions].\n\nThe paper focuses on the case of a brane-localized Higgs field and derives the total misalignment between quark masses and Yukawa couplings, which comprises two contributions: one from diagrams in fig . [fig : mia] and another from rescaling of the quark fields as to canonize their kinetic terms. The misalignment between quark masses and the resulting flavor off-diagonal Yukawa couplings are generated at or beyond the KK mass scale.\n\nThe paper then discusses the RG evolution of the Yukawa couplings from the high energy scale to the scale of the Higgs mass, where new effective interactions are generated by tree-level exchanges of the Higgs boson. The RG evolution of these couplings is identical to that of quark masses and is well known to next-to-leading order (NLO). From this scale, the Wilson coefficients of the new operators are then evolved down to the physically relevant scale according to their individual anomalous dimensions.\n\nThe Lagrangian relevant for Higgs contributions to @xmath28 transitions in the quark mass eigenbasis is given by @xmath29, and the effective Hamiltonian for @xmath28 transitions that are induced by tree-level Higgs exchanges is found to be @xmath34. The RG evolution of these couplings is performed separately from the additive SM contribution and the contributions from KK gauge bosons.\n\nThe paper concludes that in the brane Higgs scenario, the kk gluon contribution significantly exceeds the higgs contribution for both @xmath90 and @xmath87. The strongest bound on the KK mass scale for all values of the fundamental QCD coupling @xmath91 and all values of the Higgs mass comes from the exchange of KK gluons.", "score": 0.20000000000000007, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the impact of Higgs FCNCs and KK gluons on \\(\\epsilon_K\\) and the implications for the KK mass scale.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the impact of Higgs FCNCs and KK gluons on \\(\\epsilon_K\\), is clearly highlighted.\n4. The methodology or approach, including the comparison of KK gluon and Higgs contributions, is mentioned.\n5. Significant results, such as the overshadowing impact of KK gluons and the potential for a bulk Higgs to alter this, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"Higgs FCNCs\" and \"KK gluons\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not mention specific experiments or data used, which is a requirement.\n10. The significance of the paper in the context of flavor physics and CP violation is reflected.", "1. **Accurate Reflection of Main Findings**: The summary captures the main findings of the paper, discussing the significance of Higgs FCNCs in RS models and the comparison of bounds on the KK scale.\n2. **Conciseness**: The summary is concise but slightly exceeds the 250-word limit.\n3. **Research Problem**: The summary highlights the research problem of comparing bounds on the KK scale for controlling tree-level exchanges of KK gluons and the Higgs boson.\n4. **Methodology**: The summary mentions the approach of comparing results for Higgs and KK gluon contributions and the use of RG evolution.\n5. **Significant Results**: The summary includes significant results, such as the finding that KK gluon contributions exceed Higgs contributions.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary uses technical terms like \"KK gluons\" and \"RG evolution\" but does not explain them, which may be necessary for clarity.\n8. **Logical Structure**: The summary is logically structured with a clear beginning, middle, and end.\n9. **Key Experiments/Data**: The summary does not mention specific experiments or data used in the research.\n10. **Significance/Impact**: The summary reflects the paper's significance in understanding the contributions of KK gluons and Higgs in RS models."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, false], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "neutrons are an important source of background in many low rate underground experiments . detectors such as the palo verde detector  @xcite , the kamiokande detector  @xcite , the cdms detector @xcite , the gallex detector  @xcite , and most of the other underground experiments are concerned with neutron background . it is therefore important to understand the different neutron production mechanisms in the environment of such experiments . there are two sources of neutrons in underground laboratories . the first one is the natural radioactivity such as ( @xmath0,n ) reactions and spontaneous fission , due to uranium and thorium traces in the rock or in the materials used in the experiments themselves . the second source is the interaction of atmospheric muons , produced by cosmic rays , with matter , such as the surrounding rock , the different shieldings or the detector itself . propagating through matter , muons lose energy mainly continuously by ionization . in addition , they lose energy in discrete bursts along their trajectory by bremsstrahlung , direct pair production and nuclear interactions  @xcite . the goal of the cern na55 experiment was to study neutron production in muon - nucleus interactions , which at present is poorly understood . in this paper we report the result of our measurement of the cross section for fast neutron production by interaction of high energy muons off carbon , copper and lead nuclei . specifically , we investigated the energy spectrum and angular distribution of spallation neutrons produced by the inelastic scattering of 190 gev / c muons on each target , via the time - of - flight method . the total neutron yield measured at different depths has been reported in references  @xcite and  @xcite . however , very little is known about the energy and angular distributions of the neutrons , even though the neutron energy spectrum in a scintillator has been determined in @xcite for neutrons which penetrated at least 1 m from the muon track . moreover , one expects that many neutrons are produced in secondary processes following the primary muon - nucleus interaction and it is difficult to separate the two effects in the inclusive measurements performed underground .    to describe the process theoretically , one assumes that the muon scattering occurs primarily at very small angles . such a process can be viewed as produced by a beam of nearly real equivalent photons  @xcite . even with this drastic simplification , it is difficult to obtain reliable estimates for actual yields and spectra of the neutrons . the difficulty lies in the estimation of the equivalent photon flux , as well as in the shortage of experimental nuclear photo - disintegration data for high energy photons . the layout of our na55 experiment is similar to a cern lear experiment  @xcite in which neutrons and pions were measured following anti - protons stopping in the target . another group , e665 at fermi - lab  @xcite , measured neutrons produced by deep - inelastic scattering of 470 gev / c muons . however , the latter experiment measured neutrons in a small energy range from 1 to 10 mev , with high - energy deep inelastically scattered muons from nuclear targets . in the frame of the cern na54 experiment , measurements were done on a carbon target to study the production of radioactive isotopes in scintillation detectors by 100 and 190 gev muons and their secondary shower particles  @xcite . the m2 muon beam at the cern - sps was well suited for our investigation . at 190 gev / c , the energy of the sps muons is similar to the mean energy of cosmic - ray muons at many underground experimental sites . the beam transverse size is 2.2 cm ( fmwh ) . our experiment was performed with a cylindrical target of 75 cm length and 8 cm diameter for the graphite , 25 cm length and 10 cm diameter for the copper , 10 cm length and 20 cm diameter for the lead target . three neutron detectors ( see section 3.2 ) were placed at 45 ( n1 ) , 90 ( n2 ) and 135 ( n3 ) degrees relative to the muon beam , for a target - detector distance of 2.20 m ( see fig .  [ setup ] ) . a beam counter h6 ( from na47 experiment  @xcite ) consisting of plastic scintillators is placed directly in the muon beam and is thus exposed to rates of about 20 mhz , during the two - seconds beam - on phase . to reduce the detector rate to a manageable level , the beam counter is segmented into 4 rings , each divided in 16 counters thus reducing the rate per phototube to at most 1 mhz in the center . several large plastic scintillators are placed upstream from the neutron detectors and are used to veto muons originating from the beam halo . an iron hadron absorber was placed far behind the target along the beam axis . each detector is a 20 x 20 cm cylindrical glass vessel , equipped with two photomultipliers ( philips xp4512 photomultipliers with fast 1.1 nsec rms pulse ) and filled with bicron 501a liquid scintillator which possesses excellent pulse shape discrimination properties for neutron identification  @xcite . thin plastic scintillators ( 7 mm ) are positioned in front of and around each neutron detector to tag charged particles , such as protons and pions . they are also used to veto the cosmic muons . the particle energy is measured via the time - of - flight ( tof ) from its production site in the target . the signal of the neutron detector provides the tof start , and the signal of the segmented beam counter , located 6 m upstream from the target , is delayed to provide the tof stop . the analog signals of each of the neutron counters n are coded using 3 different camac adc s digitizing respectively the full analog pulse , the pulse rise and the pulse tail . the pulse itself provides the three adc gates by means of a low - threshold discriminator , which also provides a camac multi - hit tdc with the tof start signal . the analog signals of each of the plastic scintillators s are coded using 15 different camac adc s . the neutron detection efficiency was simulated using the gcalor monte carlo package  @xcite . neutrons were generated with energies from 2 to 1000 mev . the efficiency for neutrons entering the detector was obtained as a function of both the detector energy threshold and the neutron energy . the geometrical acceptance of the detector , the quenching effect and each detector threshold were taken into account . the calculation of scintillator quenching was taken from ref . @xcite , as the amount of light depends on the particle type and is not directly proportional to the deposited energy . above a neutron energy of 50 mev , the electron equivalent energy in the scintillator is assumed to be a linear function of the proton energy  @xcite , with a proportionality constant of 0.83 . below 50 mev , we applied the following formula : @xmath1\\ ] ] where @xmath2 was the electron kinetic energy in mev and @xmath3 the proton kinetic energy in mev . as will be shown later , the neutron energy spectrum in each counter is peaked at low energies . therefore , the detection efficiency is strongly dependent upon the neutron detectors thresholds . the thresholds are determined from the energy loss spectrum of cosmic muons in the scintillator cells . vertical muons ( cosmics ) are selected by requiring a coincidence signal above pedestals in the top and bottom scintillation counters during beam - off runs . because of the hardware thresholds , these spectra show a clear cut - off at low energy . the neutron detector thresholds are then extracted by comparing a simulated energy spectrum of cosmic muons with the measured one . the monte carlo spectrum of cosmic muons @xmath4 is then convoluted with a gaussian response function , @xmath5 for the detectors : @xmath6    where @xmath7 is the measured spectrum in adc counts @xmath8 . the response function parameters are of the same form as the ones used by arneodo _ et al . _ @xcite who have described and tested the response of similar bicron 501a liquid scintillator cells . applying this procedure , we obtain thresholds in electron equivalent energy of @xmath9 mev for n1 , @xmath10 mev for n2 and @xmath11 mev for n3 . in neutron or proton recoil energy they are 8.7@xmath120.7 mev , 9.6@xmath120.5 mev and 11.4@xmath120.5 mev for n1 , n2 and n3 respectively . fig .  [ muons_guy ] shows a comparison of the measured and simulated , @xmath7 , energy spectra of cosmic muons for the n3 detector . the errors on the thresholds are assigned to be 2 channels ( see fig . [ muons_guy ] ) and are overestimated . finally , fig . [ quench ] shows the monte carlo simulation of the neutron detection efficiency as a function of both neutron energy and energy threshold . neutrons were assumed to be detected only if recoil protons ionize heavily and stop in the scintillator producing delayed light and thus making pulse shape discrimination possible . the results of the analysis of our data from the different targets is presented below . the challenge of this experiment is to discriminate neutrons from the abundant bremsstrahlung photons . furthermore , four other background sources may contribute to the measured spectra : charged particles from the target , cosmic muons , muons from the beam and ambient neutrons . cosmic muons and charged particles can be rejected using the plastic scintillators . muons from the beam halo are eliminated by the dedicated veto counter ( hv , see fig .  [ setup ] ) . surrounding neutrons can not be eliminated , but their contribution can be estimated from dedicated empty - target runs . finally , neutrons and photons are identified by a pulse shape discrimination ( psd ) of their signal in the liquid scintillator . the time - development of scintillation light depends on the nature of the ionising particle . in scintillators such as bicron 501a higher ionisation density due to slow charged particles , such as recoil protons from neutron scattering , leads to the excitation of longer lived states and thus to a slower component in the light pulse . measuring the signal amplitude at 2 different time intervals allows to visualize this in a psd plot  @xcite . the complete psd method is explained in ref . [ discri1 ] shows the amplitude obtained in a delayed window as a function of the amplitude measured in a prompt one ( psd1 ) . based on the same principle , fig . [ discri2 ] is obtained by comparing the amplitude in the prompt window with the total signal amplitude ( psd2 ) . in these two different psd representations , we can distinguish a @xmath13-like curve containing bremsstrahlung photons and cosmic and remaining beam halo muons , and a neutron - like zone containing all the neutrons and the charged hadrons from the target . the @xmath13-like events are easily selected from the time - of - flight since they are prompt with respect to the beam muons . then we calculate for each event the real distance ( in units of channel number ) between the corresponding amplitudes and the fitted @xmath13-like curve for psd1 ( distance  1 ) and psd2 ( distance  2 ) . we can then represent distance  1 as a function of distance  2 , for all events including the charged particles . figure  [ dist ] shows the events left after the cuts which select only neutral particles . a clear separation can be seen between photons and neutrons . a cut is applied to select neutron like events achieving nearly complete suppression of the @xmath13-like events . the acceptance is calculated by applying a gaussian fit on the projected neutron and gamma peaks , and evaluating the relative area under the gamma peak above threshold . the acceptance was calculated separately for each detector and target . this was necessary because of the limited stability of the psd , and because of the differences in the relative strengths of the neutron and gamma peaks from case to case . the global cut acceptances , reflecting these variations between targets and detectors , are shown in table [ ta : ctacp ] . the accepted neutron events are then used for the time - of - flight analysis .      before being converted into energy distributions , the selected neutron time - of - flight spectra must be corrected for off - target events and for random tof stop signals . the first background arises from triggers correlated with beam particles , as neutrons bouncing on the ground or walls , for example . their contribution can be deduced from empty target runs properly normalized to the incident flux . the second background component is due to multiple tof stop signals given by randomly incoming muons hitting the h6 detector scintillators . as their time distribution is flat ( see fig .  [ time ] ) , they can be easily subtracted . the calibration of the time spectrum is obtained from the gamma peak . the time resolution slightly depends on the target . as an example , it is 1.0 ns , 4.6 ns and 3.8 ns for n1 , n2 and n3 respectively for the carbon target . in this case we measure maximum neutron energies of around 1 gev , 250 mev and 310 mev for n1 , n2 and n3 respectively . the time resolution determines the energy resolution , which is shown as function of energy in fig . [ energiec ] . the energy distribution is computed from the tof distribution , and corrected for the detector efficiency as described in section  [ nde ] . the charged particle rejection using the scintillators s leads to a loss of good neutron events . the corresponding acceptances are determined from the comparison of neutron samples with and without scintillator cut for each neutron detector , and strongly depend on the scintillator efficiencies and thresholds . in addition , the 85 hz trigger rate for all detectors above a threshold of 50 mev leads to a dead time of 2.1@xmath14 . all the efficiencies taken into account in the calculation of the neutron production cross section are summarized in table  [ eff ] . the neutron production cross section was calculated using the following formula :    @xmath15    where dn is the number of selected neutrons corrected for all acceptances . all parameters are given in table  [ res ] . figures  [ energiec ] , [ energiecu ] and  [ energiepb ] show the differential neutron production cross section as a function of the neutron energy , including all efficiency corrections , for the three angles , and for the different targets . the energy integrated values from the corresponding threshold up , are gathered in table 3 . it is worth noting that the neutron energy spectrum is displaced towards low energies when going from forward to backward angles . as a consequence , no neutrons are detected above 70 mev at 135@xmath16 . our measurements show that the angular distribution is forward peaked , with the exception of the lowest energy bin . this effect can be understood as due to the recoil of the source nucleus combined with an isotropic distribution of the emitted neutron at the lowest energies . one also observes that the angular distribution gets wider with increasing atomic number . generally our angular and energy distributions agree with the fluka simulation performed by wang _ _  @xcite . the slope of the neutron energy spectrum for carbon is in a qualitative agreement with the slope @xmath17 ( integrated over all angles ) found in ref . @xcite . figure  [ seceff ] shows the integrated cross section as a function of the atomic number for the three different angles and three different targets . we note that the cross section increases significantly with the atomic number . we investigated the production of spallation neutrons obtained from 190  gev / c muons scattering on graphite , copper and lead targets . the neutrons were observed by liquid scintillator detectors , allowing background rejection by means of pulse shape discrimination . the neutron energy distribution was determined via time - of - flight . the 190 gev muon energy corresponds to the mean energy of cosmic - ray muons at underground experimental sites of about 2000 meters water equivalent depth . it should be noted , however , that in the present experiment only neutrons associated with the primary muon - nuclear spallation process are detected , while in the underground detectors the total neutron yields are measured . thus the present experiment is not dependent on the subsequent neutron transport and multiplication . in view of this , and also in the view of the difference in the muon spectrum ( narrow vs. broad distribution ) direct comparison is difficult . nevertheless , the cross sections quoted in table 3 are in a qualitative agreement with the yields underground and , as mentioned above , their shape agrees with the fluka simulation . results on neutron angular distribution and energy distribution were obtained for the first time . the differential cross section as a function of the neutron energy were obtained for 45@xmath16 , 90@xmath16 and 135@xmath16 production angles with around 15@xmath14 accuracy . special thanks go to g. gervasio for his contribution to the data decoding and o. drapier for many useful discussions . we are grateful to d. hilscher of hmi , berlin for providing us with a psd module . we thank h. wong , a. schopper , l. gatignon and the staff at cern for assistance provided . this project was supported in part by the us department of energy . et al . , _ phys . d62 ( 2000 ) 092005 . y. fukuda _ et al . , _ phys . lett . b388 ( 1996 ) 397 . et al . , _ nucl . a444 ( 2000 ) 345 . m. cribier _ et al . , _ astropart . phys . 4 ( 1995 ) 23 . gaisser , cosmic rays and particle physics , cambridge university press ( 1990 ) . r. hertenberger _ et al . , _ phys . c52 ( 1995 ) 3449 . et al . , _ sov . j. nucl 17 ( 1973 ) 51 . et al . , _ sov . j. nucl 46 ( 1987 ) 883 . + m. aglietta _ et al . , _ nuovo cim . c12 ( 1989 ) 467 . m. aglietta _ et al . , _ hep - ex/9905047 , proc . of 26th intern . cosmic ray conf . , salt lake city ( usa ) , august 17 - 25 , 1999 , he 3.1.15 . j. delorme _ et al . , _ phys . c52 ( 1995 ) 2222 . d. polster _ et al . , _ phys . c51 ( 1995 ) 1167 . et al . , _ phys . rev . 74 ( 1995 ) 5198 . erratum - ibid . 80 ( 1998 ) 2020 . t. hagner _ et al . , _ astropart . 14 ( 2000 ) 33 . smc ( na47 ) collaboration , spsc/88 - 47/p242 . f. arneodo _ et al . , _ nucl . instrum . meth . a418 ( 1998 ) 285 . c. zeitnitz and t.a . gabriel , nucl . instrum . meth . a349 ( 1994 ) 106 . et al . , _ nucl . meth . 161 ( 1979 ) 439 . craun and d.l . smith , nucl . instrum . meth . 80 ( 1970 ) 239 . + y. uwamino _ et al . , _ nucl . 204 ( 1982 ) 179 . brooks , nucl . . meth . 4 ( 1959 ) 151 . + g. ranucci , nucl . instrum . meth . a354 ( 1995 ) 389 . knoll , radiation detection and measurement ; 3rd ed , john wiley ( 2000 ) . et al . , _ phys . d64 ( 2001 ) 013012    na55 detector layout . n : bicron 501a liquid scintillator detectors with pulse shape discrimination . s : thin plastic scintillator counters for charged particle identification , in front and around each n detector . h6 : na47 segmented high rate beam counter . hv : beam muon halo veto , thin plastic scintillator . arbitrary figure scale.,width=566 ]     measured ( error bars ) and simulated ( histogram ) energy spectra of cosmic muons for the n3 detector . the lower energy threshold , on the left , is clearly visible and well determined within 2 channels and corresponds to @xmath11 mev electron equivalent energy.,width=377 ]    simulation of the neutron detection efficiency as a function of neutron energy and threshold ( in electron equivalent energy ) , taking into account the geometrical acceptance of the detector and the quenching effect , for the angles 45@xmath16 ( n1 ) , 90@xmath16 ( n2 ) and 135@xmath16 ( n3 ) . polynomial interpolations ( dotted , solid and dashed lines ) have been obtained from the simulated efficiencies ( open circles , solid circles and open squares ) and used for the efficiency corrections . the bump at 700 mev is the result of an approximation.,width=453 ]        distance  1 vs. distance  2 for the n1 detector and the carbon target . these distances were calculated between every point and the @xmath13-like events for psd1 and psd2 . only neutral particles are selected.,width=340 ]    tdc spectrum corresponding to the neutron distribution dn / dt for the carbon target . the undershoot for times immediately before the prompt signal is caused by the removal of the gamma peak . the background due to uncorrelated beam muons is flat.,width=377 ]    neutron energy spectrum for the carbon target , including all the corrections . the spacing between two ticker marks on the upper horizontal line gives the energy resolution ( fwhm ) at the corresponding energy , derived from the time resolution , for the detector n1.,width=566 ]", "tags": [], "output_text_a": "This paper discusses the study of neutron production in muon-nucleus interactions, which is a significant source of background in low-rate underground experiments. The research was conducted as part of the CERN NA55 experiment, focusing on the cross-section measurement for fast neutron production by high-energy muons interacting with carbon, copper, and lead nuclei. The study aimed to understand the energy spectrum and angular distribution of spallation neutrons produced by 190 GeV/c muons using the time-of-flight method. The experiment utilized a setup with neutron detectors placed at various angles relative to the muon beam to capture the neutrons produced during these interactions.\n\nThe results showed that the neutron energy spectrum is forward-peaked and varies with the atomic number of the target material. The angular distribution of neutrons also widens with increasing atomic number. The study found that the neutron production cross-section increases significantly with the atomic number of the target. The findings are in qualitative agreement with previous simulations and measurements, providing new insights into the neutron production mechanisms in underground experiments. The research contributes to a better understanding of neutron backgrounds in such experiments, which is crucial for improving the accuracy of measurements in particle physics and astrophysics research conducted in underground laboratories.", "output_text_b": "This article discusses the importance of understanding neutron production mechanisms in underground experiments due to their prevalence as background noise. Neutrons in underground laboratories primarily originate from natural radioactivity, such as uranium and thorium traces in rock or experimental materials, and from interactions between atmospheric muons and matter. The CERN NA55 experiment aimed to study neutron production in muon-nucleus interactions, specifically focusing on the energy spectrum and angular distribution of spallation neutrons produced by high-energy muons on carbon, copper, and lead nuclei. The experiment measured the total neutron yield at different depths and reported the cross-section for fast neutron production. However, little is known about the energy and angular distributions of neutrons, which are crucial for accurately modeling neutron background in experiments.", "score": 0.30000000000000004, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the study of neutron production in muon-nucleus interactions and its significance in underground experiments.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on understanding neutron production mechanisms in underground experiments.\n4. The methodology, including the use of the CERN NA55 experiment and the time-of-flight method, is mentioned.\n5. Significant results, such as the forward-peaked neutron energy spectrum and the increase in neutron production cross-section with atomic number, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like \"spallation neutrons\" and \"time-of-flight method\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. Key experiments, such as the setup with neutron detectors and the use of 190 GeV/c muons, are mentioned.\n10. The paper's significance in improving the understanding of neutron backgrounds in underground experiments is reflected.", "1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary mentions the study of neutron production mechanisms and the focus on energy spectrum and angular distribution, which are key findings of the paper.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the problem of neutron background in underground experiments.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of the CERN NA55 experiment to study neutron production.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary mentions the measurement of total neutron yield and the cross-section for fast neutron production.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses terms like \"spallation neutrons\" and \"muon-nucleus interactions\" without explanation, which may not be clear to all readers.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is logically structured.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the CERN NA55 experiment but does not detail the specific data or experiments used.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary does not explicitly state the significance or potential impact of the research."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "according to the standard big bang nucleosynthesis ( sbbn ) , the most abundant elements in the aftermath of the big bang were hydrogen and helium with very small traces of deuterium and lithium . these elements make up the so called pop iii or _ primordial _ chemical composition . all the heavier elements present today had to be produced in the course of the evolution of several generations of stars .    in order to understand the physics of the early universe , there is a need of having appropriate and accurate material functions at hand , in particular opacities for a sbbn chemical compositions . there is a large body of literature available with opacity calculations for metal - free ( z=0 ) h / he mixtures , starting with the paczynski i - vi mixtures ( * ? ? ? * hereafter ) , the calculations of ( * ? ? ? * hereafter ) and ( * ? ? ? * hereafter ) , and more recently ( * ? ? ? * hereafter ) . these calculations were restricted to temperatures between @xmath3 and @xmath4 . specific metal - free opacity sets have been calculated by the op project ( * ? ? ? * @xmath5 ) and opal ( * ? ? ? * ; * ? ? ? * @xmath6 ) . more recently , opal calculations have been extended @xcite to @xmath7 and densities is a parameter which replaces the density in order to keep opacity tables in rectangular format when spanning many decades in temperature ( for more details see appendix [ sect : tblfmt ] ) ; @xmath8 @xmath9 with the main application for cno enhanced opacities in stellar evolution . all these opacity calculations , however , only considered pure hydrogen / helium mixtures with no metals ( mass fraction @xmath10 ) , but different ratios @xmath11 of the mass fractions of hydrogen ( @xmath12 ) and helium ( @xmath13 ) . it has been argued that due to the assumed very small abundances of deuterium and lithium these element do not play any significant role in the opacities and thus in the evolution of pop iii objects .    moreover , while there are good low - temperature opacities available for a solar chemical composition ( e.g. * ? ? ? * ) , zero - metallicity opacity tabulations have been restricted to temperatures above @xmath14 so far . in this paper we present calculations of both , rosseland and planck mean opacities for primordial matter including all the three elements ( hydrogen , helium , and lithium ) including deuterium isotope and present their absorption properties .    in sect . [ sect : matter ] we discuss the quantitative composition of primordial matter at a given temperature and density . we then describe the relevant absorption processes ( sect.[sect : absproc ] ) and present our rosseland and planck mean opacities ( sect . [ sect : rossplanck ] ) . here , we also assess the influence of lithium on the opacity for different lithium contents . before we compare our results to previous tabulations ( sect.[sect : compare ] ) , we give analytic calculations for the molecule formation timescale in sect . [ sect : chemequilibrium ] in order to estimate the time needed to reach chemical equilibrium which is one of the underlying assumptions in our calculations . finally , we summarize our conclusions in sect .  [ sect : conclusion ] . primordial matter as created in the sbbn consists of hydrogen ( h ) , helium ( he ) , deuterium ( d ) , and lithium ( li ) . before wmap@xcite , the observed abundances of these elements have been used to constrain the baryon - to - photon ratio . in the framework of a @xmath15cdm cosmology wmap provided the value this parameter with high accuracy . while the abundances of h and he were fairly well known for some time , the uncertainties in the determination of the abundances of d and li were significantly reduced . now , the d abundance as derived from cosmological parameters is consistent with direct observations , while the observed li abundance still lacks a factor of 3 compared to the sbbn results . this may indicate either systematic effects in the observations or new physics ( for an in - depth discussion of this issue , see * ? ? ? we summarize the resultant abundances according to sbbn and wmap in table [ tbl : abundances ] ( after * ? ? ? * ) and take them as our _ fiducial _ pop iii mixture . for later comparison purposes we define also a li - free mixture in table [ tbl : abundances ] . .sbbn concordance abundances @xcite from first - year wmap results [ cols=\"<,^,^\",options=\"header \" , ]          the match with the opacities ( fig . [ fig : comparisons]a ) is good as long as @xmath16 is the dominant absorption mechanism . for low temperatures , the deviations are due to the use of cia data of @xcite and @xcite while we use the more recent borysow data . the deviations at higher temperatures and densities are due to the influence of the stark broadening of h lines which have been neglected in the calculation . the comparison with @xcite is done for both rosseland and planck means ( fig . [ fig : comparisons]b&c ) .    at higher temperatures and densities the deviations in the rosseland mean are again due to stark broadened h lines . for lower temperatures the deviations are only in the 20 - 30 % range , much smaller than with respect to . this is due to their use of the partially newly available cia data of @xmath17 and @xmath18 collisions for the roto - vibrational and roto - translational transitions while still having to use extrapolations for the overtones ( using data by * ? ? ? * ) .    for the planck means the differences are considerably higher . this is due to the linearity of planck averaging which prefers peaks in the opacity ( cia at low temperatures , h lines at higher temperatures and lower densities ) . the comparison to the opal opacities for the grevesse & noel chemical composition at z=0 shows a much better concordance over a larger temperature range ( fig . [ fig : comparisons]d&e ) . in the high - temperature limit ( @xmath19 ) the rosseland mean opacities are consistent at the 10% level ( stark broadening ) . for the very highest temperatures , deviations are due to the approximation of the statistical weight of h by the ground state which no longer is true . at lower temperatures we again have a 10 - 20% deviation due to cia . while the inclusion of stark broadening for the rosseland means shows a good consistence with the opal data , there are deviations in the planck means . these differences are due to our coarse frequency grid which does not correctly trace all the peaks of the hydrogen lines .      the comparison to the data in fig . [ fig : comparisons]f shows an overall good agreement with our data . the discussion is analogous to the opal comparison . except that now we are consistent at the 10% level accuracy for lower temperatures due to their use of @xmath20 , @xmath21 and more recent @xmath17 and @xmath18 cia data . at densities @xmath22 and temperatures @xmath23 there are , however , important differences . these are due to s use of two different approaches to calculate the @xmath24 abundance in order to overcome machine accuracy problems . in their @xmath25 dominated regime , they take a dissociation energy of @xmath26 whereas we take @xmath27 ( following * ? ? ? * ) . in our calculations , we do not find any problems regarding machine accuracy . the second reason for the deviations is probably due to the difference in @xmath28 absorption coefficients where we use the @xcite data while they use @xcite . rosseland and planck mean opacities for primordial matter have been calculated using the most recent available data for the absorption mechanisms . we tabulate the opacity data in tables  e1 , e2 and e3 , for a temperature range @xmath29 and @xmath30 for our pop iii matter composition ( cf . table [ tbl : abundances ] ) . these are the first pop iii opacity tables for temperatures @xmath31 .    in order to make application as easy as possible , we provide two sets of planck opacities : planck means including only continuum absorption and those including molecular lines . higher resolution tables including routines for bicubic interpolation tables are available from the authors upon request . it has been shown ( see sect . [ sect : rossplanck ] and [ sect : quantlithium ] ) that the small number fraction of li leads to a significant change in the opacity values at temperatures @xmath32k compared to a pure h / he mixture . the differences can reach up to 2 orders of magnitudes . there are four processes which change the opacity :    as an alkali metal , li gets ionized at comparatively low temperatures . it therefore increases the number of available electrons considerably . they increase the thomson scattering contribution to the rosseland mean at low densities while increasing the @xmath33 absorption at higher densities . for both the planck continuum and line case only the @xmath33 absorption at low densities ( no scattering ) is enhanced .    in the presence of metals ( e.g. lithium ) @xmath34 is being destroyed . as @xmath34 is the most abundant positive ion at temperatures around @xmath35 and densities @xmath36 it influences the opacity indirectly in changing the chemical equilibrium when being destroyed . furthermore , in part it shows up directly via bound - bound transitions of @xmath34 at intermediate densities . for higher densities this is being drowned by the indirect increase of the @xmath33-absorption . the planck means including line absorption are changed due to absorption by atomic li and molecular lih .    for atomic li the most important transition is the @xmath37 feature . the planck function , however , is most sensible to features at @xmath37 for temperatures of approx . @xmath38 , a temperature at which li is ionized , at the latest . absorption via this transition is still important at temperatures around @xmath39 because the corresponding einstein coefficient is very large compared to the quadrupole transitions of molecular and atomic h.    at temperatures @xmath40 the influence of @xmath25 is ceasing as the lowest lying transition of @xmath25 has an equivalent temperature of @xmath41 . for lower temperatures either @xmath42 or @xmath43 contribute to the opacities . , however , has got a larger dipole moment and thus has got much larger einstein coefficients and transitions at much lower temperatures ( as low as @xmath44 ) . a critical point in primordial chemistry is the formation of molecules . formation times have been calculated for @xmath25 , @xmath42 and @xmath43 . for densities @xmath45 molecule formation proceeds within one free - fall time ( except @xmath42 , which does not play any significant role in the pop iii case ) . hence the calculation is valid for densities larger than that , provided the free - fall time scale being the shortest timescale relevant , other than the chemical . we give values for densities as low as @xmath46 for numerical convenience .    in comparison to previous calculations we find a good agreement of our results when neglecting the newly added absorption mechanisms and the contributions of li .    based on our new opacities the influence of li on the different stages of pop iii star formation and evolution can now be assessed . the authors acknowledge support from the _ deutsche forschungsgemeinschaft , dfg _ through grant _ sfb 439 ( a7)_. part of this work was carried out while one of the authors ( mm ) stayed as an eara marie curie fellow at the institute of astronomy , university of cambridge , uk . the hospitality of the ioa , and of prof . pringle in particular , is gratefully acknowledged . the authors thank profs . wehrse and gail for valuable discussions on the subject of this paper , we are grateful to dr . evelyne roueff for providing the hd transition probabilities . this work has made extensive use of nasa s astrophysics data system . t. , anninos p. , zhang y. , norman m.  l. , 1997 , new astronomy , 2 , 181    h. , roueff e. , viala y. , 1982 , , 50 , 505    d.  r. , ferguson j.  w. , 1994 , , 437 , 879    bell k.  l. , 1980 , journal of physics b : atomic and molecular physics , 13 , 1859    bell k.  l. , berrington k.  a. , 1987 , journal of physics b : atomic and molecular physics , 20 , 801    p. , leggett s.  k. , 2002 , , 580 , 1070    g. , borysow a. , orton g.  s. , 1996 , icarus , 123 , 4    g. , cohen e.  r. , 1976 , canadian journal of physics , 54 , 593    a. , 2002 , , 390 , 779    a. , frommhold l. , 1989 , , 341 , 549    a. , frommhold l. , moraldi m. , 1989 , , 336 , 495    a. , jorgensen u.  g. , fu y. , 2001 , , 68 , 235    a. , jorgensen u.  g. , zheng c. , 1997 , , 324 , 185    j. , frommhold l. , birnbaum g. , 1988 , , 326 , 509    j. , trafton l. , frommhold l. , birnbaum g. , 1985 , , 296 , 644    a.  frommhold l. , meyer w. , 1988 , , 88 , 4855    e. , galli d. , 1997 , , 288 , 638    v. , loeb a. , 2004 , new astronomy , 9 , 353    s. , gaur v.  p. , pande m.  c. , 1991 , , 45 , 57    a. , vangioni - flam e. , descouvemont p. , adahchour a. , angulo c. , 2004 , , 600 , 544    a.  n. , 2000 , allen s astrophysical quantities . allen s astrophysical quantities , 4th ed . publisher : new york : aip press ; springer , 2000 . editedy by arthur n.  cox . isbn : 0387987460    a.  n. , tabor j.  e. , 1976 , , 31 , 271 ( = ct76 )    a. , kirby k. , stancil p.  c. , 1998 , , 458 , 397    a. , williams d.  a. , 1962 , , 136 , 690    j.  j. , tout c.  a. , 2004 , , 348 , 201    d. , palla f. , 1998 , , 335 , 403    d. , palla f. , 2002 , , 50 , 1197    s.  c.  o. , 2003 , , 584 , 331    d.  f. , 1992 , the observation and analysis of stellar photospheres . cambridge ; new york : cambridge university press , 1992 . 2nd ed . m. , frommhold l. , 2001a , , 546 , 1168    m. , frommhold l. , 2001b , , 115 , 5427    m. , frommhold l. , 2003 , , 400 , 1161    g.  j. , lynas - gray a.  e. , miller s. , tennyson j. , 2004 , , 600 , 1025 ( = hlmt04 )    k.  p. , herzberg g. , 1979 , molecular spectra and molecular structure : iv . constants of diatomic molecules , 1st edn . van nostrand reinhold company    k. , van blerkom d. , 1967 , zeitschrift fr astrophysik , 66 , 185    c.  a. , rogers f.  j. , 1996 , , 464 , 943    t.  l. , 1988 , , 193 , 189    t.  l. , 1994 , , 269 , 871    u.  g. , hammer d. , borysow a. , falkesgaard j. , 2000 , , 361 , 283    w.  j. , latter r. , 1961 , , 6 , 167    l. , 2000 , radiation physics and chemistry , 59 , 185    v.  s. , presnyakov l.  p. , sobelman i.  i. , 2000 , astronomy reports , 44 , 338    p. , chernoff d.  f. , salpeter e.  e. , 1991 , , 76 , 759 ( = len91 )    s.  h. , stancil p.  c. , dalgarno a. , 2002 , journal of physics b atomic molecular physics , 35 , 57    j.  l. , 1969 , , 156 , 989    w.  c. , fuhr j.  r. , musgrove a. , sugar j. , wiese j.  l. , 1999 , nist atomic spectra database ( nist standard reference database 78 )  2.0 . nist    m.  r. , 1961 , observatory , 81 , 240    w. , frommhold l. , birnbaum g. , 1989 , , 39 , 2434    d. , 1967 , , 149 , 169    d. , 1978 , stellar atmospheres , 2 edn . san francisco , w.  h.  freeman and co. , 1978 . 650 p.    l. , miller s. , tennyson j. , 1996 , , 464 , 516    l. , tennyson j. , 1995 , , 454 , l169    f. , salpeter e.  e. , stahler s.  w. , 1983 , , 271 , 632    r.  w. , 1968 , , 49    r.  w. , 1971 , , 11 , 1331    g. , saraph h.  e. , seaton m.  j. , 1988 , journal of physics b atomic molecular physics , 21 , 3669    p.  j.  e. , dicke r.  h. , 1968 , , 154 , 891    g.  b. , lightman a.  p. , 1979 , radiative processes in astrophysics . new york , wiley - interscience , 1979 . 393 p.    w.  c. , zipoy d. , 1967 , nature , 216 , 967    m.  j. , yan y. , mihalas d. , pradhan a.  k. , 1994 , , 266 , 805    d. , henning t. , helling c. , ilgner m. , sedlmayr e. , 2003 , , 410 , 611    z. , read w.  g. , 1993 , , 50 , 635    k.  s. , miller s. , tennyson j. , 1992 , , 255 , 453    d.  n. , verde l. , peiris h.  v. , komatsu e. , nolta m.  r. , bennett c.  l. , halpern m. , hinshaw g. , jarosik n. , kogut a. , limon m. , meyer s.  s. , page l. , tucker g.  s. , weiland j.  l. , wollack e. , wright e.  l. , 2003 , , 148 , 175    s.  w. , palla f. , salpeter e.  e. , 1986 , , 302 , 590 ( = sps86 )    p. , 1994a , , 51 , 655    p. , 1996 , , 54 , 849    p.  c. , 1994b , , 430 , 360    p.  c. , dalgarno a. , 1997 , , 490 , 76    p.  c. , lepp s. , dalgarno a. , 1996 , , 458 , 401    c. , hutcheon r. , 1999 , , 140 , 93    r.  s. , 1998 , , 300 , 321    j.  b. , 1966 , publications of the dominion astrophysical observatory victoria , 13 , 1    j. , sutcliffe b.  t. , 1984 , mol . , 51 , 887    j. , 1957a , physica , 23 , 825    j. , 1957b , physica , 24 , 347    j. , kiss z.  j. , 1959 , canadian j. phys . , 37 , 1187    w.  l. , smith m.  w. , glennon b.  m. , 1966 , atomic transition probabilities . vol . : hydrogen through neon . a critical data compilation . nsrds - nbs 4 , washington , d.c . : us department of commerce , national buereau of standards , 1966    a.  w. , 1979 , , 187 , 59p    l. , simbotin i. , dalgarno a. , 1998 , , 115 , 293    m. , sadeghpour h.  r. , dalgarno a. , 1998 , , 496 , 1044    m. , sadeghpour h.  r. , dalgarno a. , 2001 , , 559 , 1194    w.  t. , stwalley w.  c. , 1980 , , 73 , 5584 primordial matter is assumed to consist of a number fraction @xmath47 of element e. depending on the density , we define the number densities of the involved elements @xmath48    we need 4 equations ( [ eq : h][eq : li ] ) to describe the conservation of the number densities of the elements ( mass conservation ) and an additional one ( [ eq : charge ] ) to take care of charge neutrality . the number density of species x is called @xmath49 $ ] . @xmath50}}}+{{{\\left[}{\\textup{h}}{\\right ] } } } + { { { \\left[}{\\textup{h}}^+ { \\right ] } } } + 3{{{\\left[}{\\textup{h}}_3^+ { \\right]}}}+ 2\\left ( { { { \\left[}{\\textup{h}}_2 { \\right ] } } } + { { { \\left[}{\\textup{h}}_2^+ { \\right]}}}\\right ) & = & n_{\\textup{h}}\\label{eq : h}\\\\ { { { \\left[}{\\textup{he}}{\\right]}}}+{{{\\left[}{\\textup{he}}^+ { \\right ] } } } + { { { \\left[}{\\textup{he}}^{++ } { \\right]}}}+2{{{\\left[}{\\textup{he}}_2^+ { \\right ] } } } & = & n_{{\\textup{he}}}\\\\ { { { \\left[}{\\textup{hd}}{\\right]}}}+{{{\\left[}{\\textup{d}}{\\right]}}}+{{{\\left[}{\\textup{d}}^+ { \\right ] } } } + { { { \\left[}{\\textup{h}}_2{\\textup{d}}^+ { \\right]}}}&= & n_{{\\textup{d } } } \\\\ { { { \\left[}{\\textup{lih}}{\\right]}}}+{{{\\left[}{\\textup{li}}{\\right]}}}+{{{\\left[}{\\textup{li}}^+ { \\right]}}}+{{{\\left[}{\\textup{li}}^{++ } { \\right ] } } } & = & n_{{\\textup{li } } } \\label{eq : li}\\\\ { { { \\left[}{\\textup{e}^-}{\\right]}}}+{{{\\left[}{\\textup{h}}^- { \\right]}}}-{{{\\left[}{\\textup{h}}^+ { \\right]}}}-{{{\\left[}{\\textup{h}}_2^+ { \\right]}}}-{{{\\left[}{\\textup{h}}_3^+ { \\right]}}}-{{{\\left[}{\\textup{he}}^+ { \\right ] } } } & & \\notag\\\\ -2{{{\\left[}{\\textup{he}}_2^+ { \\right ] } } } - { { { \\left[}{\\textup{d}}^+ { \\right ] } } } - { { { \\left[}{\\textup{h}}_2{\\textup{d}}^+ { \\right ] } } } - { { { \\left[}{\\textup{li}}^+ { \\right ] } } } - { { { \\left[}{\\textup{li}}^{++ } { \\right ] } } } & = & \\label{eq : charge}0\\end{aligned}\\ ] ] note that we neglect the h contribution of the d and l species in the h sum . given the relative number fraction of d and li with respect to h this assumption is satisfied . the equilibrium constants are given in table [ tbl : eqconst ] . for the a @xmath51 b+c saha equilibria we use equations of the form @xmath52 with @xmath53 and @xmath54 . @xmath55 is the characteristic energy for ionisation or dissociation , @xmath56 the partition function of the contributing species . for @xmath25-dissociation we use @xmath57 and correct the equilibrium constant with the symmetry factor for a homonuclear molecule @xcite . for the solution of the system of equations we define a critical temperature @xmath58 above which we solve the full system including the charge neutrality condition . we call this the _ ionic limit_. below @xmath59 we neglect all ions and solve ( [ eq : h]-[eq : li ] ) in the molecular limit .    in the ionic limit , we start with an initial guess of @xmath60}}}$ ] , solve eqns . ( [ eq : h]-[eq : li ] ) to derive a new @xmath60}}}$ ] from the neutrality condition eq . ( [ eq : charge ] ) . iteration is done with @xmath60}}}\\rightarrow \\sqrt{{{{\\left[}{\\textup{e}^-}{\\right]}}}_\\mathrm{new } { { { \\left[}{\\textup{e}^-}{\\right]}}}_\\mathrm{old}}$ ] . after 20 - 50 iterations convergence is reached . the solution of eqns . ( [ eq : h]-[eq : li ] ) is done analytically and would involve a cubic equation in the case of eq . ( [ eq : h ] ) , otherwise only quadratic equations are involved . the cubic term in the h species equation arises due the inclusion of the @xmath24 abundance . as this species never is the main contributor to the number density , we neglect it in the number density conservation . note that we also neglect the h containing d and li species in the h conservation equation . since we have @xmath61 and @xmath62 this assumption is justified .    in the molecular limit we have to solve analytically only eqns . ( [ eq : h]-[eq : li ] ) neglecting ions . the absorption coefficient @xmath63 @xmath64 $ ] for the @xmath65 transition can be written as @xmath66 where @xmath67 the profile function , @xmath68 is the number density of atoms in state 1 , @xmath69 the einstein coefficient and @xmath70 the transition frequency . in relation to the ground state we have @xmath71 where @xmath72 and @xmath73 are the energies of the states relative to the ground state . in terms of the total number density @xmath74 @xmath75 via @xmath76 we easily can transform to the usually used einstein coefficient for spontaneous emission , @xmath77 . evaluating @xmath78 yields ( @xmath79 ) the integrated absorption coefficient @xmath80 @xmath81 $ ] @xmath82 where we made use of the approximation @xmath83 across the line .    for planck averaging we furthermore assume @xmath84 across the line . then the line contribution of the @xmath65 transition is @xmath85 where we introduced the wavenumber @xmath86 corresponding to the @xmath87 transition . multiplied with @xmath88 , the last expression only depends on the temperature . calculated once for each species summing up all the lines for the temperature grid chosen , it can be added directly to the planck mean with the density weight @xmath89 . note that we make use of the einstein coefficient @xmath69 , which is related to the einstein coefficient for spontaneous emission @xmath77 through the einstein relation @xmath90 . we have fitted the equilibrium constant @xmath92 to the 6 parameter function ( @xmath93 ) @xmath94    with the coefficients @xmath95 this fit causes maximum deviations of 4 @xmath96 of @xmath97 for @xmath98 , whereas the maximum deviation never exceeds 8 @xmath96 below @xmath99 . @xmath100 correspond to the enthalpy of @xmath101 for the reaction @xmath102 , divided by the @xmath103 factor due to basis conversion . opacity mean values are usually tabulated in the @xmath104-plane , where @xmath105 . @xmath106 is the temperature in units of @xmath107 k , @xmath108 the density . using this @xmath109-parameter , the tables remain rectangular over large temperature ranges . we have the gas ( @xmath110 ) and radiation ( @xmath111 ) pressure ( here in the optically thick case ) @xmath112    calculating the ratio and taking the logarithm we have @xmath113    subtracting the logarithmized definition of @xmath114 , we have @xmath115    for @xmath116 gas and radiation pressure are equal . as the range of @xmath117 usually tabulated is @xmath118 ( opal , op project ) , @xmath119 is in the middle of this coordinate range . the physical meaning of introducing @xmath117 is that one remains in the physical regime where gas and radiation pressure compete with each other . too large departures from this equality require changes in the eos . therefore the each column of opacity tables in the style of opal & op represent different gas / radiation pressure ratios . sample tables for rosseland and planck means are given in tables  e1 , e2 and e3 ( will be available in the accepted version ) .", "tags": [], "output_text_a": "The paper discusses the calculation of opacities for primordial matter, which consists of hydrogen, helium, deuterium, and lithium, as formed during the standard Big Bang nucleosynthesis (SBBN). The study aims to provide accurate opacity data for these elements, which are crucial for understanding the physics of the early universe and the evolution of Population III stars. The authors present Rosseland and Planck mean opacities for primordial matter, including the effects of lithium, which can significantly alter opacity values at certain temperatures. The paper compares these new calculations with previous opacity tabulations and highlights the importance of lithium in changing opacity values, especially at lower temperatures. The study also provides analytic calculations for molecule formation timescales and discusses the implications of these findings for the formation and evolution of Population III stars. The authors acknowledge support from the Deutsche Forschungsgemeinschaft and express gratitude for discussions and data contributions from various collaborators. The results are intended to aid in the assessment of lithium's influence on different stages of Population III star formation and evolution. [[ ## completed ## ]]", "output_text_b": "This article presents calculations of Rosseland and Planck mean opacities for primordial matter, including hydrogen, helium, lithium, deuterium isotope, and their absorption properties. The paper discusses the quantitative composition of primordial matter at a given temperature and density, and describes the relevant absorption processes. The authors also assess the influence of lithium on the opacity for different lithium contents.\n\nIn order to estimate the time needed to reach chemical equilibrium, the paper provides analytic calculations for the molecule formation timescale. The authors summarize their conclusions in section 5, comparing their results to previous tabulations and acknowledging support from the Deutsche Forschungsgemeinschaft and the European Atomic Energy Community (EURATOM).\n\nThe article includes a detailed discussion of the quantitative composition of primordial matter, the relevant absorption processes, and the calculation of Rosseland and Planck mean opacities. The authors also provide tables of opacity data for different temperature ranges and matter compositions.", "score": 0.09999999999999998, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the calculation of opacities for primordial matter and the significance of lithium in altering opacity values.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the need for accurate opacity data for primordial matter, is highlighted.\n4. The methodology, including the calculation of Rosseland and Planck mean opacities, is mentioned.\n5. Significant results, such as the impact of lithium on opacity values, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like \"Rosseland and Planck mean opacities.\"\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research.\n10. The summary reflects the paper's significance in understanding the early universe and Population III star evolution.", "1. The summary accurately reflects the main findings and contributions of the paper by mentioning the calculations of Rosseland and Planck mean opacities for primordial matter and the influence of lithium on opacity.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which involves understanding the opacities of primordial matter, is highlighted.\n4. The methodology, including the calculation of opacities and the assessment of lithium's influence, is mentioned.\n5. Significant results, such as the influence of lithium on opacity, are included.\n6. The summary is written in clear and professional language.\n7. The summary avoids excessive technical jargon and explains terms like Rosseland and Planck mean opacities.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The summary does not explicitly mention key experiments or data used in the research.\n10. The summary does not clearly reflect the paper's significance or potential impact in its field."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "the electoral campaign is a period preceding elections where political parties do an organized effort so that their candidates garner supporters . maximizing the influence of their messages over voters is the main objective . in this way , politicians use different techniques to transmit their messages in the most effective way to their potential voters , such as mass meetings , rallies , husting or media management . understanding and exploiting in a more efficient way the available resources for information flow than your opponent can make the difference .    over the last century mass media has been monopolized by old media , such as televisions or newspapers . however nowadays we are attending to a transition where a new interactive online social media world is settling its bases . online social networks , such as twitter with over 200 million users , have become ideal platforms for information flows . this has been noted in @xcite where they reported that these tools may serve as a framework for discussion . other studies have been directed towards identifying influential users @xcite or discovering its commercial usage @xcite . moreover the percentage of population using online social networks has increased in recent years , reaching in spain a @xmath0 of the population , quantity that is almost duplicated ( @xmath1 ) for young adults between 18 - 29 years old @xcite . following the idea one must be where people are , politicians are now present in the most popular online social networks . however some politicians do not have a defined strategy for the usage of these tools and the rest are still far of exploiting all the available potential . the importance and popularity of social media in politics became clear with obama s campaign for the 2008 u.s . presidential elections and his famous tweet : `` this is history ... '' , posted just after winning the elections . this fact attracted not only popular , but also scientific attention , making political conversations in twitter a popular subject for research . lately , the data gathered from twitter has been used as a social sensor to predict election outcomes @xcite . other studies have focused in analyzing the interactions between different political communities @xcite , and finally a proof - of - concept - model has been developed @xcite to predict candidate s victory .    in this article we introduce a new parameter that measures the ratio of the support in twitter between two candidates , which we call the relative support , and apply it to the 2011 spanish presidential elections , to show how it can be used to indicate and quantify which candidate and in which proportion is getting more benefits from events occurring offline . we further study the dynamical patterns emergent from the twitter mention and retweet networks within the framework of complex networks theory @xcite . we also interpret politicians behavior by filtering these networks and analyzing the interactions going on between the different political parties . finally we introduce a model based on the heterogeneous preferential attachment formalism @xcite capable of growing political conversations and illustrate it by reproducing the mentions and retweets taking place in twitter among politicians . the present work is based on data collected from the online social network twitter . this web application allows people to post and exchange text messages limited by @xmath2 characters . there are several interaction mechanisms in twitter to transfer information . the first of these is the ability of people to follow and be followed by other users . this is a passive mechanism that allows users to receive the messages written by their followees in real time . the twitter s followers network is a directed graph where non reciprocal relations are admitted and it states the social substratum through which information may flow . previous studies have reported a high heterogeneity in the followers distribution @xcite . another important mechanism to interact is the retweet or message retransmission . this mechanism allows individual messages to propagate throughout the network and serves as a way for people to endorse their point of view over specific subjects @xcite . in addition to this , another relevant way for direct interaction is the mentions mechanism . by mentioning someone s username in the message text , people is able to send directed messages to the mentioned user s inbox . this mechanism is often used to establish conversations between users , through the exchange of messages , or just to refer somebody in the message s text @xcite . our dataset is constructed from public access messages posted in twitter , related to the 2011 spanish presidential elections . we downloaded all the messages that included the keyword _ 20n _ , using the twitter api interface , in a three week period including the election day . we chose this keyword because is an ideologically neutral identifier , used by all the political parties during the campaign and voting day . in summary we analyzed over 370.000 messages , written by over 100.000 users . we found that @xmath3 of the messages were retweets , and over @xmath4 contained at least one mention . this fact makes the event quite relevant , since it has been reported that retweets represent about @xmath5 of the overall messages @xcite . [ cols=\"^,^,^,^,^\",options=\"header \" , ]     to further explain the structural features found in the interactions between politicians , we propose a model based on the heterogeneous preferential attachment formalism @xcite . the idea behind it , is that the probability of a node @xmath6 interacting with a node @xmath7 not only depends on their respective degree , but also of the affinity between them . in our model nodes ( politicians ) are classified according to discrete characteristics ( political parties ) . thus the probability of appearance of a new interaction from any politician , @xmath6 , belonging to party @xmath8 , to a politician @xmath7 , who belongs to a party @xmath9 , is given by the following expression : @xmath10 where @xmath11 is @xmath7s strength , and @xmath12 , is the affinity value from @xmath8 to @xmath9 . the first factor of equation [ number political interactions ] corresponds to the local connection at microscale , and the second one to the mesoscale . we implement this model in the mesoscale by grouping all the politicians of the same party in a supernode labeled with the name of the party . the properties of these supernodes are determined by those of the nodes inside them , and the number of interactions , @xmath13 , between them can be obtained from the @xmath14 matrix @xcite . in this way the affinity value between two politicians will be determined only by their political parties . we represent the directional affinity between political parties by an @xmath15 matrix whose elements quantify the relative flux of interactions from @xmath8 to @xmath9 . using this notation we can model the structure of the @xmath15 matrix as : @xmath16 where @xmath17 is the total flux going from @xmath8 to @xmath9 and @xmath18 is the total flux going out from a. after understanding the structure of the system s mesoscale , its time to model the microscale . in this scale the probability rule for interactions between politicians is based on the preferential attachment model @xcite . in the sense that the likelihood of a node , belonging to party @xmath9 , to receive a new interaction , increases with the nodes strength .        to implement the model we have calculated the experimental @xmath15 matrix of each network , considering only those parties with over 10 politicians participating in the conversation . also we have assigned a random number of outgoing edges to the newly added nodes , following power law distributions of exponents : @xmath19 for the mention network and @xmath20 for the retweets one . in this way we modeled the resulting distributions by simulating the heterogeneity found in the users behavior and using the same microscale connection rule for both interaction mechanisms . in figure [ modelo ] we present the resulting cumulative strength function distribution for both networks , after having averaged over @xmath21 realizations . it can be noticed that the model reproduces perfectly the strength function distribution for both networks , and maintains the assortative mixing levels as presented in table [ netproppolit ] . the perfect political campaign strategy has been eternally chased by politicians . to that effect we have tracked voter sentiment and uncovered the underlying structure of the campaign in twitter , measuring the impact that different events have produced on politicians popularity and analyzing the roles played by the various users . for this matter , in this paper we propose a parameter that measures the relative support in twitter between two candidates , and apply it to our case of study : the 2011 spanish presidential elections . furthermore we have analyzed the graph structural and dynamical patterns emergent from interactions taking place among users , finding out that the collective attention is driven by a very small fraction of users , who dominate the interaction mechanisms . we have also analyzed politicians behavior finding a profound segregation and lack of debate among them . finally we propose a network growth model based on heterogeneous preferential attachment , to explain the emergence of such segregated modules in the politician s networks . despite we ca nt assure that the campaign on twitter determined the election outcomes , our results suggest that there is a strong correlation between the activity taking place in twitter and election results . this fact suggests that further research should be done on identifying the most efficient techniques to influence voter sentiment in twitter . 27 c. honeycutt and s. c. herring _ hicss _ ieee computer society pp . 1 - 10 ( 2009 ) d. m. romero , w. galuba , s. asur , and b. a. huberman influence and passivity in social media . _ www11 _ ( 2010 ) b. j. jansen , m. zhang , k. sobel , and a. chowdury _ journal of the american society for information science and technology _ 60 , 2169 ( 2009 ) pew research center . global digital communication : texting , social networking popular worldwide ( 2011 ) a. tumasjan , t. o. sprenger , p. g. sandner , and i. m. welpe predicting elections with twitter : what 140 characters reveal about political sentiment . _ icwsm _ the aaai press ( 2010 ) m. conover et al . political polarization on twitter . _ icwsm _ the aaai press ( 2011 ) a. livne , m. p. simmons , e. adar , and l. a. adamic the party is over here : structure and content in the 2010 election . _ icwsm _ the aaai press ( 2011 ) s. bocaletti , v. latora , y. moreno , m. chavez and d .- u . _ 424 , 175 ( 2006 ) r. albert and a .- _ 74 , 47 - 97 ( 2002 ) m. e. j. newman _ siam review _ 45 2 , 167 - 256 ( 2003 ) a. santiago and r. m. benito _ europhysics letters _ 82 , 58004 ( 2008 ) h. kwak and c. lee and h. park and s. moon _ www 10 _ acm , 591 - 600 ( 2010 ) d. boyd , s. golder and g. lotan _ ieee computer society , pp . 1 - 10 ( 2010 ) pearanalytics . twitter study ( 2009 )    http://www.pearanalytics.com/blog/wp-content/uploads/2010/05/twitter-study-august-2009.pdf m. e. j. newman _ contemporary physics _ 46 , 323 ( 2005 ) r. koop and h. j. jansen _ social science computer review _ 155 ( 2009 ) a. barrat , m. barthlemy , r. pastor - satorras , and a. vespignani _ proc natl acad sci usa _ 101 , 3747 ( 2004 ) m. e. j. newman _ physical review e _ 67 , 026126 ( 2003 ) j. g. foster , d. v. foster , p. grassberger , and m. paczuski _ proc natl acad sci usa _ 107 , 10815 ( 2010 ) k. a. wojciech galuba , d. chakraborty , z. despotovic outtweeting the twitterers - predicting information cascades in microblogs . _ microblogs 3rd workshop on online social networks , wosn _ ( 2010 ) h .- b . hu and x .- f . wang _ europhysics letters _ 86 , 18003 ( 2009 ) m. rosvall and c. t. bergstrom _ proc natl acad sci usa _ 105 , 1118 ( 2008 ) h. y. yoon and h. w. park social media information flow and public representation : a case of s. korean politicians on twitter _ 9th international triple helix conference _ ( 2011 ) a .- l . barabasi , r. albert , and h. jeong _ physica a : statistical mechanics and its applications _ 272 , 173 ( 1999 )", "tags": [], "output_text_a": "This paper explores the role of social media, specifically Twitter, in political campaigns, using the 2011 Spanish presidential elections as a case study. It introduces a new parameter called \"relative support\" to measure the support ratio between two candidates on Twitter. The study analyzes over 370,000 tweets related to the elections, examining the dynamics of mentions and retweets through complex network theory. The authors propose a model based on heterogeneous preferential attachment to explain the interactions among politicians on Twitter. The findings suggest a strong correlation between Twitter activity and election outcomes, highlighting the potential of social media as a tool for political influence. The paper calls for further research into effective techniques for influencing voter sentiment on platforms like Twitter.", "output_text_b": "This article discusses the use of Twitter in political campaigns, focusing on the 2011 Spanish presidential elections. The authors introduce a new parameter called \"relative support\" to measure the ratio of support between two candidates on Twitter and demonstrate its application in the Spanish elections. They also study the dynamic patterns of Twitter mention and retweet networks within the framework of complex networks theory. A model based on heterogeneous preferential attachment is introduced to grow political conversations, which is then used to reproduce mentions and retweets among politicians. The analysis is based on data collected from Twitter, which allows users to post and exchange text messages with a limit of 280 characters. Interactions in Twitter include following and being followed by other users, retweeting or message retransmission, and mentions. The dataset for this study includes over 370,000 messages related to the 2011 Spanish presidential elections.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. The summary accurately reflects the main findings and contributions of the paper by discussing the role of Twitter in political campaigns, the introduction of the \"relative support\" parameter, and the analysis of tweets using complex network theory.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is the role of social media in political campaigns, is highlighted.\n4. The methodology, including the analysis of tweets and the use of complex network theory, is mentioned.\n5. Significant results, such as the correlation between Twitter activity and election outcomes, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is avoided, and terms like \"relative support\" and \"heterogeneous preferential attachment\" are explained in context.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. The key experiment involving the analysis of over 370,000 tweets is mentioned.\n10. The potential impact of the paper, such as the influence of social media on political campaigns, is reflected.", "1. The summary accurately reflects the main findings and contributions of the paper by discussing the use of Twitter in political campaigns, the introduction of the \"relative support\" parameter, and the study of dynamic patterns in Twitter networks.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper is highlighted, focusing on the use of Twitter in political campaigns and measuring support between candidates.\n4. The methodology or approach used in the paper is mentioned, including the introduction of a new parameter and the use of complex networks theory.\n5. Significant results or conclusions are included, such as the application of the \"relative support\" parameter and the analysis of Twitter data.\n6. The summary is written in clear and professional language.\n7. Technical jargon is avoided, and terms like \"relative support\" and \"heterogeneous preferential attachment\" are explained in context.\n8. The summary is structured logically, with a clear beginning, middle, and end.\n9. The summary mentions the key data used in the research, specifically the dataset of over 370,000 messages related to the 2011 Spanish presidential elections.\n10. The summary reflects the paper's significance by discussing the potential impact of Twitter on political campaigns."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "coordinated motions and pattern formation have been studied for a wide range of biological organisms , from bacteria and amoebae to fish , from birds and wildebeest to humans ( ben - jacob et al . , 2000 ; deneubourg et al . , 2001 ; parrish et al . , 2002 ; partridge , 1982 ; wilson , 1975 ) . animal groups often behave as if they have a single mind , displaying remarkable self - organized behavior . at one extreme , the individuals seem to need little information transfer ( e.g. fish schools ) , while at the other end the information exchange occurs in highly integrated ways through long - term associations among the individuals ( e.g. honeybee hives and human communities ) . controlling such an organized behavior in groups of artificial objects , including autonomous underwater vehicles ( leonard et al . , 2006 ) and groups of autonomous agents ( jadbabaie et al . , 2003 ) , has received extensive attention in contemporary control theory . challenges in both natural and engineering settings involve understanding which patterns emerge from the interaction among individual agents . select laboratory experiments have shed some light on the schooling mechanism ( hunter , 1966 ; van olst and hunter , 1970 ; partridge and pitcher , 1979 , 1980 ; pitcher et al . , 1976 ) . it still remains unclear , however , how the individual - level behavior and group - level ( `` macroscopic '' , or coarse - grained ) patterns are related . more precise experiments using three - dimensional tracking of every individual in a population should lead to better understanding of this linkage . an ultimate experimental study with precise control of every relevant detail may not be possible , yet appropriate mathematical models would provide a venue to establish behavioral cause , as one can consider different hypothetical individual - level interaction rules selectively ( see e.g. , flierl et al . , 1999 ) . several different individual - based models have been proposed , which reproduce certain types of collective behavior in animal groups ( e.g. , see aoki , 1982 ; reynolds , 1987 ; deneubourg and goss , 1989 ) . self - organization emerges also in a wide spectrum of physical and chemical systems , some of which ( e.g. , crystals and ferromagnetic materials ) exhibit apparent similarities with emergent patterns observed in animal groups . vicsek et al . ( 1995 ) have introduced a discrete - time model of self - driven particles , or self - propelled particles ( spp ) , based on near - neighbor rules that are similar with those in the ferromagnetic xy model ( kosterlitz and thouless , 1973 ) . the authors analyzed statistical properties of the model , including phase transition and scaling ( vicsek et al . , 1995 ) . a long - range interaction has been incorporated into the spp model ( mikhailov and zanette , 1999 ) , and continuum , `` hydrodynamic '' versions of this model have been introduced ( toner and tu , 1995 , 1998 ; topaz et al . , 2006 ) . recently , couzin et al . ( 2002 , 2005 ) have introduced a model to provide insights into the mechanism of decision making in biological systems , which reproduces many important observations made in the field , and provides new insights into these phenomena . a review for various models can be found in parrish et al . ( 2002 ) and czirk and vicsek ( 2001 ) . the models of couzin et al . ( 2005 ) , and most other such models , incorporate various detailed mechanistic steps . these shed light on the role of leadership and imitation , and produce a number of surprising results , such as the influence that a few `` informed '' individuals can have on large collectives . what is needed now are efforts to simplify those models , and to show especially what properties of the microscopic simulators are essential to explain that behavior . for some models , closure schemes are available ( flierl et al . , 1999 ) ; but more generally , though we may suspect that closures exist , we can not derive explicit expressions for them . in such circumstances , we need methods such as those used in this paper ; we perform the coarse - grained dynamical analysis by circumventing the derivation of governing equations , using an equation - free computational approach ( theodoropoulos et al . , 2000 ; kevrekidis et al . , 2003 ) . a particular goal is to understand how much of the specific spatial detail is fundamental to the behavior . but turning to the kuramoto - type approximation , where the interaction is assumed to be global , we deliberately ignore local effects . to the extent that the models fail to explain observed types of behavior , we will need to turn next to more detailed models . most of previously proposed models concern populations of _ homogeneous _ ( or indistinguishable ) individuals . furthermore , the dynamical analysis in the literature is often limited to a small subset of the entire parameter space , and a systematic classification of possible global dynamics remains elusive . in the current paper , we study the _ coarse - grained _ alignment dynamics of individual - based animal group models . the measurement of the mean angular deviation of fish schools ( e.g. clupeids and scombroids ; see atz , 1953 ; hunter 1966 ) showed that it varies continuously from no alignment to practically perfect alignment . we account for this continuous change by heterogeneity ( `` quenched noise '' ; characterized by parameters of random variables drawn from a prescribed distribution function ) and the coupling strength . our approach is flexible in that the heterogeneity can be introduced in various places in the model , and the way we analyze different heterogeneity cases does not require any significant modification . the rest of the paper is organized as follows : models for homogeneous and heterogeneous animal groups are described in secs . [ model1 ] and [ model_extension ] , and our approach , equation - free polynomial chaos , is explained in secs . [ method1 ] and [ method2 ] . coarse - grained dynamical analysis and its comparison with fine - scale dynamics , for a system of two informed individuals and a large number of heterogeneous uninformed individuals , are presented in sec .  [ results ] . the case of two groups of heterogeneous informed individuals is presented in sec . [ results2 ] . we conclude with a brief discussion in sec . [ conclusions ] . we briefly discuss a `` minimal '' model proposed by nabet et al . ( 2006 ) , which we extend in our study . it concerns the alignment dynamics of a homogeneous population of _ indistinguishable _ @xmath0 individuals with two subgroups of informed individuals ( `` leaders '' ) with populations @xmath1 and @xmath2 respectively and @xmath3 uninformed individuals ( `` followers '' ) , where @xmath4 : @xmath5 here @xmath6 characterizes the average direction of the individuals in each of the two informed subgroups for @xmath7 and the average direction of the uninformed individuals for @xmath8 . @xmath9 is the corresponding informed , preferred direction ( @xmath10 can be set to zero without loss of generality ) and @xmath11 is the coupling strength . this minimal model corresponds to the reduced system of the following system of @xmath0 individuals ( nabet et al . , 2006 ) : @xmath12 where the angle @xmath13 characterizes the direction in which the @xmath14th individual is heading ( we will refer to it as `` orientation '' ) . the average direction @xmath6 is defined as the angle of the average of the phasors ( when each individual s dynamical state is considered as a phasor of unit radius and a phase angle ) of the individuals in the @xmath15th subgroup ; @xmath16 is the magnitude of the average of the phasors . formally , this is written as @xmath17 the large population model in eq . ( [ m3 ] ) has a separation of time scales . individuals within each subgroup synchronize quickly , i.e. , @xmath16 quickly converges to 1 . the slow dynamics are described by the reduced system ( eq . ( [ reduced ] ) ) where the variables @xmath6 characterize the _ lumped behavior _ of each of the three subgroups . it is assumed that the alignment ( orientational ) dynamics are independent of the translational counterpart ( sepulchre et al . , 2005 ) ; hence , the dynamical state of an individual can be characterized by its orientation . the functional form for mutual interaction is borrowed from the well - known kuramoto model ( kuramoto , 1984 ) , a prototypical model for coupled nonlinear oscillators . this simplified global interaction model is consistent with an observation that the strongest correlations are observed between the ( speed and ) direction of the individual and the average ( speed and ) direction of the entire school ( partridge , 1982 ) : in the mean - field form of the kuramoto model , the interaction term can be rewritten as @xmath18 where @xmath19 in this alternate expression , the dependence on the difference between the individual direction and the average direction stands out explicitly . in the absence of coupling ( @xmath20 ) , each leader eventually heads for its preferred direction . nontrivial dynamical behavior for the minimal model ( eq .  ( [ reduced ] ) ) are studied in nabet et al . ( 2006 ) ; bifurcations are analyzed for the global phase space in the case @xmath21 and @xmath22 . the aforementioned models concern populations of _ homogeneous _ subgroups , where the individuals in each subgroup quickly synchronize , nearly perfectly ( @xmath23 ) , during the initial transients ( nabet et al . , 2006 ) . in the more general case , the mean angular deviation of fish schools is finite ( atz , 1953 ; hunter , 1966 ) , which is not captured in this `` minimal '' model . we extend the model to account for the distribution of directions within schools , assuming it arises from the _ heterogeneity _ among the group members . we introduce the heterogeneity in the following two ways : + ( i ) _ two leaders and many heterogeneous followers  _ first we consider the cases when the population consist of two leaders ( which possibly represent lumped behavior of groups of homogeneous leaders ) and @xmath24 followers :      where the heterogeneity is accounted for through the tendency to deviate from the average direction , characterized by @xmath26 , an i.i.d . random variable drawn from a prescribed distribution function @xmath27 ( of standard deviation @xmath28 with mean value zero ) . for notational convenience , we drop a subscript of a variable to represent a random variable of a proper length ( _ cf . _ @xmath26 and @xmath29 ) . as @xmath10 can be set to zero without loss of generality , @xmath30 and @xmath31 are control parameters . in the current study , we consider @xmath27 to be gaussian , but our analysis is not limited to this particular choice . + ( ii ) _ two groups of heterogeneous leaders  _ secondly , we consider two groups of heterogeneous leaders without any followers , focusing only on the dynamics among leaders . the heterogeneity is accounted for by introducing randomness in the angles preferred by the leaders . the orientations of the leaders in each group are denoted by @xmath32 s and @xmath33 s ( of sizes @xmath1 and @xmath2 ) respectively :      where the preferred angles @xmath35 and @xmath36 are randomly drawn from prescribed distributions @xmath37 and @xmath38 ( i.e. , i.i.d . random variables of standard deviations @xmath39 and @xmath40 ) , respectively . we set @xmath41 , and will vary @xmath42 and @xmath43 @xmath44)$ ] as control parameters ( and investigate some cases of different values of @xmath39 and @xmath40 in sec . [ results2b ] ) . direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]   direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]   direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]     direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]   direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]   direct integration of a system of two leaders ( open circles ; dashed lines indicate preferred angles ) and 300 followers ( dots ) , initialized from uniformly distributed orientations with randomly assigned heterogeneity variable ( i.e. , no initial correlations between @xmath45 and @xmath29 ) , is shown for an initial transient [ ( a ) to ( c ) ] , and for much longer time scales [ ( d ) to ( f ) ] . insets illustrate time evolution of the followers orientations on the @xmath46 plane , where strong correlations develop during a short time @xmath47 . after that , the leaders and followers , the latter effectively as a `` unit '' , slowly drift to the stable steady state . it takes of the order of @xmath48 for the system to asymptotically converges to this final state . ( @xmath49 ) . , title=\"fig : \" ]      the kuramoto model , a paradigm for all - to - all , phase - coupled oscillator models , has been extensively studied and used to shed light on many synchronization phenomena ( kuramoto , 1984 ; acebrn et al . , 2005 , and references therein ) . this model has the property that , in the full synchronization regime ( of large enough @xmath31 values ) , phase angles become quickly correlated with ( or  sorted \" according to ) the natural frequencies during the initial short transients ( moon et al . , similar correlations ( between the angles and heterogeneity random variables ) are expected to arise in the current model ( which is indeed the case , as will be shown later in fig . [ correlation ] ) , since the coupling term is qualitatively similar . as in moon et al . ( 2006 ) , we choose expansion coefficients in wiener polynomial chaos as coarse - grained `` observables '' , to explore low - dimensional , coarse - grained dynamics . wiener(-hermite ) polynomial chaos was introduced by wiener ( 1938 ) , who represented a random process in terms of functional expansions of wiener process ( historically , this method has been termed as polynomial `` chaos '' , because of its initial usage on homogeneous chaos , such as turbulence and brownian motion , rather than the nature of the method ) . ghanem and spanos ( 1991 ) later extended this idea to treat random processes as functional expansions of random variables , or elements in the hilbert space of random functions , in which a spectral representation in terms of polynomial chaos is identified . the projections ( or coefficients ) on the polynomial base then can be determined through a galerkin approach . this method was subsequently applied in uncertainty quantification of various problems ( e.g. , see ghanem , 1999 ; jardak et al . , 2002 ) , and has been extended to general situations using the askey scheme ( xiu et al . , 2002 ; now known as generalized polynomial chaos ) .    in this method , dependent random variables ( @xmath45 of the followers for the case ( i ) , and @xmath50 and @xmath51 for the case ( ii ) ) are expanded in polynomials of independent random variables ( @xmath29 , or @xmath52 and @xmath53 ) using appropriately chosen basis functions . details for the two cases are as follows : + ( i ) _ two leaders and many heterogeneous followers  _ for convenience , we introduce the unit gaussian random variable @xmath54 . using this newly defined variable , we expand @xmath55 ( i.e. @xmath56 ) in hermite polynomials of @xmath57 [ @xmath58 = 1 , @xmath59 , @xmath60 , @xmath61 : @xmath62 where @xmath63 is the highest order retained in the truncated series , @xmath64 is the @xmath65th hermite polynomial , and the @xmath66 s are the expansion coefficients which will be referred to simply as `` chaos coefficients '' in this paper . wiener polynomial chaos , utilizing hermite polynomials as basis functions , is the appropriate choice for gaussian random variables that we consider in the present study . the probability density function of the gaussian random variables appears as the weighting function of hermite polynomials , and the hermite polynomial expansion is suggested to converge exponentially for gaussian processes ( lucor et al . , 2001 ) . for other random variables , use of different basis functions ( for instance , legendre polynomials for uniform random variables ) has been suggested for fast convergence , which is the basis of the development of the generalized polynomial chaos ( xiu et al . , 2002 ) . we choose the first few nonvanishing chaos coefficients @xmath66 s , as well as the orientations of the leaders ( @xmath67 and @xmath68 ) , to be the coarse - grained `` observables '' . due to symmetry , all the even order @xmath66 s vanish , except for the zeroth order @xmath69 that corresponds to the average direction of the followers . geometrically , @xmath70 and @xmath71 respectively represent a measure for the linear order spread of the angles ( the `` slope '' between @xmath45 and @xmath29 ) and the cubic order measure . in the continuum limit ( @xmath72 ) , the chaos coefficients can be exactly determined using the orthogonality relations for hermite polynomials . however , in the _ finite _ cases of single realization we consider , @xmath73 , those relations hold only approximately , and the coefficients are evaluated using least squares fitting , following moon et al . + ( ii ) _ two groups of heterogeneous leaders  _ in the second case , we expand @xmath50 and @xmath51 in terms of @xmath52 and @xmath53 , respectively : @xmath74 where the chaos coefficients and are the coarse `` observables '' of our choice , @xmath64 s are hermite polynomials ( for gaussian @xmath75 and @xmath76 ) , and @xmath77 and @xmath78 are unit gaussian random variables . +      a prerequisite to _ coarse - grained _ dynamical analysis ( which is the main goal of the current study ) is , in a traditional sense , an explicit derivation of coarse - grained governing equations . in principle , such equations for chaos coefficients , in the continuum limit ( @xmath72 ) , might be obtained through a stochastic galerkin method ( ghanem and spanos , 1991 ) .    in the present study , we do not even attempt to derive such equations . we circumvent their derivation by using an equation - free multiscale computational approach ( theodoropoulos et al . , 2000 ; kevrekidis et al . , 2003 , 2004 ) . this approach enables us to explore the coarse - grained dynamics without the assumption of the continuum limit . the premise of this approach is that coarse - grained governing equations conceptually _ exist _ , but are not explicitly available in closed form . this approach is based on the recognition that short bursts of appropriately initialized microscopic ( fine - scale ) simulations during a time horizon @xmath79 and the projection of the results onto coarse - grained variables , say , result in time - steppers ( mappings ) for those variables @xmath80 ( which is effectively the same as the discretization of unavailable equations ) : @xmath81 one then processes the results of the short simulations to estimate various coarse - grained quantities ( such as time derivatives , action of jacobians , residuals ) to perform relevant coarse - grained level numerical computations , as if those quantities were obtained from coarse - grained governing equations . for instance , one can _ integrate _ unavailable governing equations in time ( coarse projective integration ; see below ) , or compute the steady states of the above coarse time - stepper , by utilizing fixed point algorithms ( such as newton - raphson or newton - gmres ) . equation - free computations consist of the following steps :    * identify coarse - grained variables ( `` coarse observables '' ) that sufficiently describe both the micro- and macroscopic dynamics ; in our study , they are @xmath66 s ( and @xmath82 s ) . for convenience , we denote the microscopic ( macroscopic ) descriptions by @xmath83 ( @xmath84 ) . * choose an appropriate _ lifting _ operator @xmath85 , which maps @xmath84 to one ( or more ) consistent description(s ) @xmath83 ( for the purposes of variance reduction and ensemble - averaging ) . in the current study , this can be achieved by using the relations in eqs . ( [ expansion ] ) and ( [ expansion2 ] ) ; once random variables are drawn , these relations are used to obtain corresponding @xmath83 . * starting from lifted initial condition(s ) @xmath86 , run the microscopic simulator to obtain @xmath87 at a later time ( @xmath88 ) . * use an appropriate _ restriction _ operator @xmath89 ( least squares fitting , in the current study ) which maps the microscopic state(s ) to the macroscopic description @xmath90 , which effectively results in time series of coarse observables , or their coarse time - stepper @xmath80 ; @xmath91 . * apply desired numerical techniques using the coarse - grained variables obtained from the step 4 . and repeat some of the above steps as needed . an extensive discussion can be found in kevrekidis et al . ( 2003 , 2004 ) . direct integration of the `` fine - scale '' model of eq . ( [ microeq1 ] ) in the strong coupling regime ( @xmath92 ) , started from randomly assigned orientations and the heterogeneity variable ( the latter is a gaussian random variable ) , illustrates that a strong correlation between @xmath45 and @xmath29 develops during a short , initial transient time ; the orientations of the followers quickly become a monotonically increasing function of their heterogeneity variable ( fig . [ correlation ] ) , after which they slowly drift as a `` unit '' until they settle down in the final steady state . during the latter slow drift , the system can be described as two leaders and a _ single _ `` clump '' of followers , whose coarse - grained states can be successfully described by a small number of chaos coefficients . a similar time scale separation exists in the model of homogeneous populations . in this case , followers quickly collapse asymptotically to the _ same _ direction ( nabet et al . , 2006 ) . ( color online ) accelerated computation of stable steady states via coarse projective integration using five coarse - grained variables , shown here for two different time scales ( @xmath49 ) . initially all the values are assigned to be 0 . both @xmath70 and @xmath71 reach their steady state values relatively quickly ( see ( a ) ) , while the others are slowly varying ( see ( b ) ; they are still varying at @xmath93 ) . dots represent the time intervals during which short direct integration is performed ( and restricted ) , in the course of the projective integration using forward euler method . solid lines represent the trajectories of direct full integration during the entire time . higher efficiency can be achieved by optimally choosing the time horizon for the direct integration , the projection stepsize , and projection method . , title=\"fig : \" ]   ( color online ) accelerated computation of stable steady states via coarse projective integration using five coarse - grained variables , shown here for two different time scales ( @xmath49 ) . initially all the values are assigned to be 0 . both @xmath70 and @xmath71 reach their steady state values relatively quickly ( see ( a ) ) , while the others are slowly varying ( see ( b ) ; they are still varying at @xmath93 ) . dots represent the time intervals during which short direct integration is performed ( and restricted ) , in the course of the projective integration using forward euler method . solid lines represent the trajectories of direct full integration during the entire time . higher efficiency can be achieved by optimally choosing the time horizon for the direct integration , the projection stepsize , and projection method . , title=\"fig : \" ]      we begin by accelerating the approach to a stable steady state using an equation - free algorithm , the coarse projective integration method ( gear and kevrekidis , 2003 ) . in contrast to a conventional , direct integration of the full fine - scale model during the _ entire _ time ( until sufficient convergence to stable , final states ) , this method exploits smoothness in the coarse variables ( estimated through a direct integration during a _ short _ time ) , in order to extrapolate and take a large projective time - step ( compared to the original integration time - step size ) . this saves computational effort . the procedure consists of ( @xmath94 ) _ lifting _ ( appropriate initialization of the fine - scale simulator , an integrator of eq . ( [ microeq1 ] ) , consistent with prescribed coarse - grained values ) , ( @xmath95 ) _ direct integration _ of the microscopic simulator during a relatively short time interval ( but long enough to accurately estimate local coarse - grained time derivatives ) , ( @xmath96 ) _ restriction _ ( of fine - scale description onto coarse - grained variables ) , and ( @xmath97 ) _ taking a projective step _ ( using a traditional numerical integration scheme such as forward euler ) . the computational payoff of this method depends on the ratio between a short direct integration time interval , the projective time - step size , and the computational effort required for lifting / restriction procedures ( see e.g. , rico - martinez et al . , 2004 ) . more importantly , successful computation of steady states through this method naturally attests to the _ validity _ of the chosen coarse - grained observables in describing _ both _ fine - scale and coarse - grained states . ( left panel ) a bifurcation diagram observed on one leader @xmath68 , computed using auto2000 ( @xmath98 ) . solid ( dashed ) lines represent stable ( unstable ) branches . there exist a few other unstable branches that are not shown here . at some critical value of @xmath30 , an unstable state in the upper branch undergoes a forward pitchfork bifurcation ; two unstable states coincide . the lower branch of `` trivial '' solutions does not exhibit any bifurcation . ( right panels ) snapshots of two ( symmetric ) stable states in the bistable regime ( @xmath99 ) , marked by dots in the left panel . ]    [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     projective integration using five coarse - grained variables ( @xmath100 , and the first three non - vanishing @xmath66 s ; @xmath69 , @xmath70 , and @xmath71 ) follows virtually the same trajectories of the full , direct integration ( fig .  [ pi ] ) , even if @xmath29 is _ newly _ drawn at each lifting ; the agreement is even better if the same @xmath29 were used ( hence the dynamics are fully deterministic ) . both _ lifting _ ( simply using eq . ( [ expansion ] ) ) and _ restriction _ ( least squares fitting ) operations require minimal computational efforts . therefore , the computational efficiency in the present case is nearly exclusively determined by the projective step size , which is a factor of about four in fig . [ pi ] ; with a more sophisticated projection algorithm , a higher efficiency can be obtained . we see that both @xmath70 and @xmath71 reach their steady state values quickly ( @xmath101 ) , showing that the correlation between @xmath45 and @xmath29 are fully developed by then . however , the other chaos coefficient @xmath69 ( representing the average direction ) slowly drifts towards the steady state , and so do @xmath67 and @xmath68 ( note that it is still varying at @xmath93 ) ; the computation of an asymptotic , steady state requires a very long time integration .    direct integration ( including projective integration ) can not compute unstable steady states and are inappropriate for stability computations and parametric bifurcation studies . both stable and _ unstable _ steady state values can be systematically ( and much more efficiently than the projective integrations ) computed by applying coarse - grained fixed point algorithms to the steady state condition of eq . ( [ coarse_stepper ] ) , i.e. , @xmath102 , in _ much lower _ dimension than that of individual level . we use the coarse newton - gmres ( kelley , 1995 ) , a matrix - free , method to compute coarse - grained fixed points . we observe that the algorithm accurately converges within a few steps ( tab . [ gmres ] ) ; the converged values are accurately consistent with the restricted values of the fixed point solution of the detailed ( i.e. , ( @xmath0 + 2)-dimensional ) problem , within prescribed convergence tolerance . by combining a coarse fixed point algorithm with pseudo - arclength continuation ( keller , 1987 ) , we numerically compute coarse - grained bifurcation diagrams in the following sections . the computational efficiency of the coarse fixed point algorithm varies with the choice of the initial guess for the iteration . with a totally uneducated guess , it could take even longer than the direct integration ( note that the latter never computes the exact solutions ) ; however , during the continuation computation shown below , a good initial guess is always available from the previous parameter value(s ) , and even several orders of magnitude of computational efficiency can be achieved . ( a ) a bifurcation diagram observed on one ( arbitrarily chosen ) follower , as a function of @xmath30 ( @xmath98 ) , computed using auto2000 ( the same case as in fig . [ micro ] ) . superscript ` f ' has been added to emphasize that this is the orientation of _ a follower_. a few other existing unstable branches are not included here . the upper branch undergoes a pitchfork bifurcation and becomes stable . ( b ) a coarse bifurcation diagram observed on @xmath69 ( average direction ) , obtained by the coarse newton - gmres method with pseudo arc - length continuation . only a blowup around the bifurcation point coarse - grained dynamics exhibit the same structure as in the fine - scale level . filled ( open ) circles represent stable ( unstable ) steady states . , title=\"fig : \" ]   ( a ) a bifurcation diagram observed on one ( arbitrarily chosen ) follower , as a function of @xmath30 ( @xmath98 ) , computed using auto2000 ( the same case as in fig .  [ micro ] ) . superscript ` f ' has been added to emphasize that this is the orientation of _ a follower_. a few other existing unstable branches are not included here . the upper branch undergoes a pitchfork bifurcation and becomes stable . ( b ) a coarse bifurcation diagram observed on @xmath69 ( average direction ) , obtained by the coarse newton - gmres method with pseudo arc - length continuation . only a blowup around the bifurcation point coarse - grained dynamics exhibit the same structure as in the fine - scale level . filled ( open ) circles represent stable ( unstable ) steady states . , title=\"fig : \" ]      we first analyze the detailed @xmath103-dimensional fine - scale model in the full synchronization regime , in order to obtain insights on fine - scale dynamics to be compared with our coarse - grained analysis below . we use auto2000 ( doedel et al . , 2000 ) to compute the fine - scale bifurcation diagrams as functions of @xmath30 at a fixed value of @xmath31 ; only projections for one leader ( @xmath68 ) are shown in fig . [ micro ] and for one follower in fig . [ macroth2 ] ( a ) . all the other followers exhibit essentially the same dynamical behavior as the one shown here ( except for some quantitative differences ) . the interaction between the individuals causes the steady state directions of the leaders to deviate from the preferred angles @xmath104 and @xmath30 , respectively . such deviation can occur in two directions , either toward the region bounded by @xmath105 $ ] ( an `` obvious '' steady state where followers are directed in between the directions of the leaders ; see fig . [ micro ] ( b ) ) or the other way around ( e.g. , fig .  [ micro ] ( a ) ) . the analysis shows that for small @xmath30 values only the former state is stable , while for large values , both of these states become stable . the branches for `` obvious '' stable steady states , which correspond to lower straight solid lines , exhibit no bifurcations ( see figs .  [ micro ] and [ macroth2 ] ( a ) ) . on the other branches , forward pitchfork bifurcations at some critical value of @xmath30 give birth to another stable branch ( a state on this stable branch is shown in fig . [ micro ] ( a ) ) , as well as two unstable asymmetric solution branches , hence the population becomes bistable . the critical value of @xmath30 for the onset of the bistability depends on @xmath31 ( precisely speaking , @xmath106 ) ; the critical value is @xmath107 at @xmath108 . as @xmath31 decreases further , the critical value monotonically increases until fully synchronized steady states lose stability at some critical value of @xmath31 . we now compute coarse - grained steady state solutions . a coarse - grained bifurcation diagram for @xmath69 ( representing the average direction of the followers ) is compared with the corresponding diagram observed for _ one _ follower , in figs . [ macroth2 ] ( b ) and ( a ) ; ( b ) is a blowup of the region around the bifurcation . both sides of the bifurcation point can be described by the _ same _ set of coarse - grained observables , which clearly summarize group level dynamical behavior of the followers before and after the bifurcation . as @xmath31 decreases in the kuramoto model , oscillators get desynchronized ( kuramoto , 1984 ) , starting with the oscillator with the maximum value of @xmath109 ( the `` extreme '' oscillator ) through a saddle - node ( actually a `` sniper '' ) bifurcation on a limit cycle ( moon et al . , 2006 ) . we expect the same type of bifurcation to occur in this model . however , when we try to compute the coarse - grained steady states as functions of @xmath31 using the previously mentioned five coarse variables ( via coarse newton - gmres method and pseudo arc - length continuation , neither a bifurcation nor an unstable branch is appropriately identified . the computation , initialized at large @xmath31 steady states , accurately follows stable branches down to some critical value of @xmath31 ( where the transition occurs ) , and then fails to converge . our coarse - grained observables are not sufficient to describe the states on the `` other side '' of the bifurcation point , as we will explain below . ( color online ) ( a ) a bifurcation diagram observed on a few followers , including the one with the maximum of @xmath109 ( the `` extreme '' follower ) , as a function of @xmath31 ( @xmath110 ) , computed using auto2000 . a critical value where the extreme individual gets desynchronized corresponds to a saddle - node bifurcation point on a limit cycle ( a `` sniper '' bifurcation ) . except for the extreme follower , stable and unstable branches nearly coincide ( see the inset ) . ( b ) in order to capture the fine - scale bifurcation , the angle of the extreme follower has to be discounted from the chaos expansion and considered as an _ extra _ coarse - grained variable ( see text ) . we distinguish these chaos coefficients ( from the ones used so far ) by adding a prime . it was computed via the coarse newton - gmres method with continuation . , title=\"fig : \" ]   ( color online ) ( a ) a bifurcation diagram observed on a few followers , including the one with the maximum of @xmath109 ( the `` extreme '' follower ) , as a function of @xmath31 ( @xmath110 ) , computed using auto2000 . a critical value where the extreme individual gets desynchronized corresponds to a saddle - node bifurcation point on a limit cycle ( a `` sniper '' bifurcation ) . except for the extreme follower , stable and unstable branches nearly coincide ( see the inset ) . ( b ) in order to capture the fine - scale bifurcation , the angle of the extreme follower has to be discounted from the chaos expansion and considered as an _ extra _ coarse - grained variable ( see text ) . we distinguish these chaos coefficients ( from the ones used so far ) by adding a prime . it was computed via the coarse newton - gmres method with continuation . , title=\"fig : \" ]    a fine - scale bifurcation diagram ( computed using auto2000 ) obtained by starting from a stable steady state on the lower branch in fig . [ micro ] is shown in fig . [ turningpt ] ( a ) . here the diagrams for two leaders and only a few followers , including the extreme one , are shown . we find that both stable and unstable branches for each angle nearly coincide for all the individuals ( see inset of fig .  [ turningpt ] ( a ) ) , except for the extreme one . as the difference between stable and unstable branches ( at the same value of @xmath31 ) is appreciable _ only _ when observed on this extreme oscillator , a smooth mapping between @xmath45 and @xmath29 does not prevail for unstable states , and the previously used chaos coefficients are not appropriate any more .    taking these observations into account , it is easy to remedy the situation as follows : the fact that stable and unstable branches nearly coincide , discounting the extreme follower , suggests that all the individuals _ except for the extreme follower _ can be again described by the same set of chaos coefficients . thus we treat the orientation of the extreme one separately ( introducing it as an additional coarse - grained variable ) , and discount it from the polynomial chaos expansion . ( from the fact that the extreme follower gets desynchronized at the transition , one can also intuitively see that followers have to be considered as a combination of a clump of synchronized `` bulk '' and a separate , extreme one . ) we compute the solutions with continuation , using this new set of _ six _ coarse variables , which captures the bifurcation and appropriately describes the unstable steady states ( fig . [ turningpt ] ( b ) ) ; we have analyzed exactly the same realization used in fig . [ turningpt ] ( a ) for direct comparison . when bifurcation diagrams are computed for ensembles of many realizations , an uncertainty will arise in the exact quantification of the bifurcation point , due to the fluctuation of finite - dimensional random variables among realizations , while the results are qualitatively the same as those of a single realization ( xiu et al . , 2005 ) . the coarse bifurcation results shown in fig . [ turningpt ] ( b ) illustrate that the steady state directions of the leaders and the average direction of followers ( @xmath111 , discounting the extreme one ; a prime is added to distinguish it from the previously used notation ) are virtually the same for a range of @xmath31 . only higher order chaos coefficients ( only @xmath112 is shown in fig . [ turningpt ] ) appreciably vary as a function of @xmath31 , which means that individuals spread more widely as @xmath31 decreases , until the extreme one eventually starts to oscillate freely , while the average steady state direction remains the same . lines : a bifurcation diagram observed on @xmath67 in the minimal model ( the first two odes in eq . ( [ reduced ] ) with @xmath113 ) , for varying @xmath30 at a fixed value of @xmath114 , obtained by auto2000 . for large enough preferred angles ( @xmath115 ) , the system becomes bistable through a forward pitchfork bifurcation . circles : a coarse bifurcation diagram near the pitchfork bifurcation , observed on @xmath69 , as a function of @xmath116 , computed by the coarse newton - gmres method . filled ( open ) circles represent stable ( unstable ) steady states . ] here we explore both the fine - scale and coarse - grained dynamics of a model for two groups of _ heterogeneous _ leaders ( with no followers ) shown in eq . ( [ for_many ] ) , and compare the results of the two different scales . one notable difference from the kuramoto model is that `` oscillators '' in eq . ( [ for_many ] ) do not have finite random variables ( natural frequencies ) , hence there is no onset of the synchronization that occurs at a finite value of @xmath31 ( or , they can be alternatively seen as kuramoto - like oscillators of zero natural frequencies , which result in the onset at @xmath117 , hence they get synchronized for all @xmath31 values ) . the analysis of the minimal model ( the first two of eq . ( [ reduced ] ) with @xmath118 ) reveals that for large enough @xmath119 the system exhibits bistability for a certain range of @xmath31 ( nabet et al . , 2006 ) , as in the previous case in sec . [ results ] . here we will vary @xmath43 as the main parameter for two different values of @xmath31 . for large coupling strengths ( @xmath120 ) , the bistability in the minimal model appears through a forward pitchfork bifurcation , when @xmath30 is varied as a parameter ( fig . [ microk2.4 ] ) . this minimal model can be seen as a special case of the current model , where both @xmath52 and @xmath53 are assumed to be delta functions and each group consists of identical individuals . coarse - grained bifurcation diagrams observed on the first two chaos coefficients : ( a ) @xmath69 ; the average direction of the first group of leaders , and ( b ) @xmath70 ; the `` slope '' between @xmath50 and @xmath52 , as functions of @xmath43 . these are blowups of the region around the forward pitchfork bifurcation point in fig . [ microk2.4 ] . , title=\"fig : \" ]   coarse - grained bifurcation diagrams observed on the first two chaos coefficients : ( a ) @xmath69 ; the average direction of the first group of leaders , and ( b ) @xmath70 ; the `` slope '' between @xmath50 and @xmath52 , as functions of @xmath43 . these are blowups of the region around the forward pitchfork bifurcation point in fig . [ microk2.4 ] . , title=\"fig : \" ]    we begin by asking whether our model for heterogeneous groups exhibits similar types of dynamical behavior . one can also do accelerated computations of steady states using the coarse projective integration , but here we skip such computations and present only the coarse bifurcation analysis results . _ coarse _ bifurcation diagrams obtained through the coarse newton - gmres method ( kelley , 1995 ) and pseudo arc - length continuation ( keller , 1987 ) ( for gaussian distributions of @xmath52 and @xmath53 ; @xmath121 , @xmath122 ) show that the heterogeneous groups indeed exhibit the same qualitative type of coarse dynamical behavior around the pitchfork bifurcation point ( fig . [ macrok2.4 ] ) . as we consider symmetric unimodal distribution functions , all the even order chaos coefficients ( except for @xmath69 and @xmath123 ) virtually vanish . the diagram for @xmath69 of the first group @xmath124 ( average direction ) exhibits reasonably good quantitative agreement with the corresponding diagram for the minimal model , within fluctuations of finite - size random variables , shown in figs . [ microk2.4 ] and [ micromacrok1.8 ] . it is interesting to note that at the critical point , all the followers are headed for the same direction ( @xmath125 , which corresponds to the `` slope '' between @xmath52 and @xmath50 ) ; see fig . [ macrok2.4 ] ( b ) . lines : a bifurcation diagram for the minimal model of two leaders , for varying @xmath30 at a fixed value of @xmath126 , obtained by auto2000 . for large enough preferred angles ( @xmath127 ) , the system becomes bistable , but the nature of the bifurcation is different from that of higher @xmath31 value cases ( a saddle - node vs. a pitchfork bifurcation ; see fig . [ microk2.4 ] ) . circles : a coarse bifurcation diagram observed on the average direction of the first group of leaders ( @xmath69 ) around the saddle - node bifurcation , as a function of @xmath116 , computed via the coarse newton - gmres method with continuation . filled ( open ) circles represent stable ( unstable ) steady states . ] ( color online ) coarse - grained bifurcation diagrams near a turning point in fig . [ micromacrok1.8 ] , for @xmath52 distributions of three different widths ( the standard deviation @xmath39 = 0.1 for circles ; 0.2 for squares ; 0.3 for triangles ) , obtained via the coarse newton - gmres method and continuation . the standard deviation for the second group , @xmath40 , is kept the same at 0.1 ( @xmath128 ) . filled and open symbols represent stable and unstable states , respectively . ( a ) the first chaos coefficients @xmath69 ( average direction of the first group ) are nearly the same for the three cases . the difference between the cases becomes apparent in higher order coefficients that reflect the degree of spreading ; see @xmath70 in ( b ) . , title=\"fig : \" ]   ( color online ) coarse - grained bifurcation diagrams near a turning point in fig . [ micromacrok1.8 ] , for @xmath52 distributions of three different widths ( the standard deviation @xmath39 = 0.1 for circles ; 0.2 for squares ; 0.3 for triangles ) , obtained via the coarse newton - gmres method and continuation . the standard deviation for the second group , @xmath40 , is kept the same at 0.1 ( @xmath128 ) . filled and open symbols represent stable and unstable states , respectively . ( a ) the first chaos coefficients @xmath69 ( average direction of the first group ) are nearly the same for the three cases . the difference between the cases becomes apparent in higher order coefficients that reflect the degree of spreading ; see @xmath70 in ( b ) . , title=\"fig : \" ]    the hermite polynomial expansion converges so quickly that the expansions can be accurate even when truncated at the third order . due to the reflection symmetry ( about @xmath43/2 ) , coefficients have similar structures as the ones , after proper reflection and translation . only results on are presented here . as the coupling strength decreases across @xmath129 , the nature of the bifurcation changes ( from a pitchfork ) to a saddle - node bifurcation ( fig . [ micromacrok1.8 ] ) at @xmath129 , which also occurs in the model for homogeneous populations ; the nature of the transition between these different bifurcations , a higher codimension bifurcation , has been discussed in nabet et al . ( 2006 ) . so far we have considered statistically similar groups , namely @xmath21 and @xmath130 ; they differed only by average preferred directions . it is natural to ask how the dynamics change as the parameters concerned with the distributions ( for the preferred directions ) are varied . it is readily expected that the essential dynamics of two different - size groups can be reflected in the minimal model using two different coupling strengths , which is considered in nabet et al . here we consider only the cases with varying width of the distributions ( @xmath131 ) , which has no analog in the minimal model . coarse bifurcation diagrams for three different gaussian distributions for @xmath52 ( @xmath39 is varied while @xmath40 is kept at 0.1 ; see fig . [ vary_std ] ) show that the average directions ( @xmath69 s ) hardly vary with the width of the distributions ; the primary parameter that affects on the average direction is the _ group size_. for the distributions of different widths , the fixed point computation with continuation fails to converge at different values of @xmath69 s ; points marked by arrows in fig . [ vary_std ] are the last points the newton - gmres computations converged in each case , when approached from the stable branches . such a failure of convergence can be expected , because the steady states on this unstable branch overlap with another nearby unstable branch ( which is not shown in this figure , but was shown in fig . [ micromacrok1.8 ] ) ; characterizing the distribution with a few wiener chaos coefficients does not provide an accurate description any more . the differences between the three cases ( of different distribution widths ) manifest themselves clearly in higher order chaos coefficients . while the average behavior remains nearly the same ( fig .  [ vary_std ] ( a ) ) , individuals in the group spread more widely ( as reflected in @xmath70 and higher order coefficients ; fig . [ vary_std ] ( b ) ) , as the width of the random variable ( distribution ) increases . we have demonstrated a computational venue ( an equation - free polynomial chaos approach ) to study coarse - grained dynamics of individual - based models accounting for the _ heterogeneity _ among the individuals in animal group alignment models . we considered _ finite _ populations of ( i ) two `` leaders '' ( which have direct knowledge on preferred directions ) and @xmath132 uninformed , heterogeneous `` followers '' , and ( ii ) two groups of heterogeneous `` leaders '' . we explored the _ coarse - grained _ , group level ( low - dimensional ) dynamics using the polynomial chaos expansion coefficients as coarse - grained observables ; these observables account for rapidly developing correlations between random variables , and sufficiently specify both fine - scale and coarse - grained ( group - level ) dynamical states . all the analysis in our study was done expressively avoiding the derivation of coarse - grained governing equations , following a _ nonintrusive _ , equation - free computational approach wrapped around the direct system simulator . it should be noted that we have not assumed that @xmath0 is infinitely large ( so - called the `` continuum limit '' ) . our approach can be used for systems of any finite , large number of populations , and it can be equally applied to various types of random variables ( following generalized polynomial chaos ) and/or various heterogeneity . we compared our results with those of minimal models that do not account for heterogeneity among the individuals . they show good agreement in the lowest order ( i.e. , average directions ) , which clearly highlights the correspondence between the individual- and group - level dynamics ( figs . [ microk2.4 ] and [ micromacrok1.8 ] ) . indeed this implies that the results in nabet et al . ( 2006 ) , where no heterogeneity is explicitly accounted for , are more robust than demonstrated in that paper alone .    in order to analyze different coarse - grained bifurcations , it became necessary to use different sets of coarse - grained variables , even if the model is _ the same _ in the fine - scale level ( fig . [ turningpt ] ) . this clearly shows that an appropriate choice of coarse - grained observables ( in terms of which one can obtain useful closures ) is an essential step ; different coarse - grained observables are required , as the same fine - scale model closes differently .    in the present study , we assumed that the orientational dynamics can be separated from their translational counterpart , and considered the simplest nontrivial cases of all - to - all ( `` all - visible '' ) , sinusoidal coupling . our future work will involve the incorporation of the translational dynamics and more complicated coupling / network topology , including heterogeneous couplings . our work presented here is the first step of our effort toward the development of more detailed ( and biologically more plausible ) models and their _ coarse - graining_. s.j.m . and i.g.k . were financially supported by doe and nsf grant ef0434319 . s.a.l . was supported in part by nsf grant ef0434319 and darpa grant hr00110510057 . b.n . and n.e.l . were supported in part by onr grants n000140210826 and n000140410534 . atz , j. w. , 1953 . orientation in schooling fishes , in proceedings of a conference on orientation in animals . office of naval research , pp . 103 - 130 . department of the navy , washington , d. c. , section 2 . kevrekidis , i. g. , gear , c. w. , hyman , j. m. , kevrekidis , p. g. , runborg , o. , theodoropoulos , c. , 2003 . equation - free coarse - grained multiscale computation : enabling microscopic simulators to perform system - level tasks . sciences 1 ( 4 ) , 715 - 762 ; e - print physics/0209043 . leonard , n. e. , paley , d. , lekien , r. , sepulchre , r. , fratantoni , d. m. , davis , r. , 2006 . collective motion , sensor networks and ocean sampling . proceedings of the ieee , special issue on `` the emerging technology of networked control systems '' , to appear . lucor , d. , xiu , d. , karniadakis , g. , 2001 . spectral representations of uncertainty in simulations : algorithms and applications . in proceedings of the international conference on spectral and high order methods ( icosahom-01 ) , uppsala , sweden . nabet , b. , leonard , n. e. , couzin , i. d. , levin , s. a. , 2006 . leadership in animal group motion : a bifurcation analysis . proceedings of the 17th international symposium on mathematical theory of networks and systems , kyoto , japan , july 2006 . sepulchre , r. , paley , d. , leonard , n. e. , 2005 . collective motion and oscillator synchronization , in cooperative control : a post - workshop volume , 2003 block island workshop on cooperative control , eds . v. kumar , n. leonard and a.s . morse , springer - verlag .", "tags": [], "output_text_a": "The paper explores the dynamics of coordinated motion and pattern formation in biological organisms and applies these concepts to artificial systems like autonomous vehicles. It highlights the challenges in understanding how individual behaviors lead to group-level patterns and suggests that mathematical models can help bridge this gap. The study focuses on the alignment dynamics of animal groups, using models that incorporate heterogeneity among individuals. The authors employ an equation-free computational approach, utilizing polynomial chaos to analyze coarse-grained dynamics without deriving explicit governing equations. The paper compares these results with minimal models, showing good agreement in average behaviors, and emphasizes the importance of choosing appropriate coarse-grained observables for different bifurcation analyses. Future work aims to incorporate more complex dynamics and network topologies to develop biologically plausible models. The research is supported by various grants and contributes to the understanding of collective motion in both natural and engineered systems.", "output_text_b": "This article discusses the study of coordinated motions and pattern formation in various biological organisms, ranging from bacteria and amoebae to humans. Animal groups often exhibit self-organized behavior, with different levels of information transfer among individuals. The authors explore the challenge of controlling organized behavior in groups of artificial objects, focusing on understanding which patterns emerge from the interaction among individual agents. They mention that while some experiments have shed light on schooling mechanisms, the relationship between individual-level behavior and group-level patterns remains unclear. More precise experiments and mathematical models are needed to establish behavioral cause and effect. Several individual-based models have been proposed to reproduce certain types of collective behavior in animal groups, and the authors highlight the need to simplify these models and identify the essential properties that explain the behavior.", "score": 0.4, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. **Accurate Reflection of Main Findings and Contributions**: The summary captures the main findings and contributions of the paper, such as the exploration of coordinated motion and pattern formation in biological organisms and artificial systems, the use of mathematical models, and the equation-free computational approach.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary highlights the research problem of understanding how individual behaviors lead to group-level patterns.\n\n4. **Methodology or Approach**: The summary mentions the use of mathematical models, an equation-free computational approach, and polynomial chaos to analyze dynamics.\n\n5. **Significant Results or Conclusions**: The summary includes significant results, such as the agreement with minimal models and the importance of choosing appropriate coarse-grained observables.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary avoids excessive technical jargon and explains terms like \"equation-free computational approach\" and \"polynomial chaos.\"\n\n8. **Logical Structure**: The summary is structured logically with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary does not mention specific experiments or data, which is a requirement.\n\n10. **Significance or Potential Impact**: The summary reflects the paper's significance in understanding collective motion in natural and engineered systems.", "1. **Accurate Reflection**: The summary does not fully capture the main findings and contributions of the paper. It mentions the study of coordinated motions and pattern formation but lacks details on the specific contributions of the paper, such as the equation-free polynomial chaos approach and the analysis of coarse-grained dynamics.\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n3. **Research Problem**: The summary highlights the research problem of understanding patterns emerging from interactions among individual agents.\n4. **Methodology**: The summary briefly mentions the need for mathematical models but does not specify the equation-free polynomial chaos approach used in the paper.\n5. **Significant Results**: The summary does not include significant results or conclusions drawn by the authors, such as the findings on coarse-grained dynamics and bifurcation analysis.\n6. **Language**: The summary is written in clear and professional language.\n7. **Technical Jargon**: The summary avoids technical jargon and does not explain any terms, which is appropriate given the lack of technical details.\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n9. **Key Experiments**: The summary does not mention any key experiments or data used in the research.\n10. **Significance**: The summary does not reflect the paper's significance or potential impact in its field, such as the implications for understanding animal group dynamics and leadership."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, false], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, false], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [false, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}, {"input_text": "einstein s theory of general relativity ( gr ) predicts that space - time is curved and warped by the mass and the angular momentum of a gravitating body . the kinematics of objects in the vicinity of such a body are expected to differ from those based on newton s theory of gravity . the nasa / stanford spaceborne mission gravity probe  b ( ) was designed to measure these differences with four gyroscopes essentially freely falling around earth , in a polar orbit at an altitude of about 640 km . according to gr , the gyroscopes spin axes should precess by @xmath46  yr@xmath5 in a north - south direction due to the curving of space - time by the earth s mass , and by @xmath439  in an eastward direction due to the warping of space - time by the earth s angular momentum . these precessions are dubbed the geodetic \" effect and the  frame - dragging , \" ( `` lense - thirring , '' or `` gravitomagnetic '' ) effect , respectively , and can be considered as rotations of any near - earth inertial frame relative to the distant universe .    the gyroscopes were set spinning within a quartz block with respect to which , through superconducting quantum interference devices ( squids ) , each of the spin axes precessions could be measured with an accuracy of 100  within @xmath440 days . the quartz block was bonded to a @xmath415  cm diameter quartz optical telescope . all of these devices  the quartz block , the squids , and the quartz telescope ( together termed the probe )  were placed in a dewar filled with liquid helium and cooled to a temperature of 1.8 k. ideally , the orientation of the probe could be best provided by pointing the telescope to one suitable quasar , one of the most distant compact types of single object in the universe . however , quasars were too dim for the telescope to track . only stars in our galaxy were bright enough . the challenge was therefore to find a guide star , \" bright enough for the on - board telescope to track , sufficiently isolated to limit light contamination , and suitably located to not unnecessarily decrease the accuracy of the measurement of the precessions of the gyroscopes . then the guide star s motion on the sky needed to be measured with respect to quasars or distant galaxies so that the precession of the gyroscopes could be determined with respect to the distant universe . we described the astronomical effort undertaken with the guide star for the support of the  mission , vlbi for gravity probe b , \" in seven papers :  overview \" ( * ? ? ? * paper i ) ;  monitoring of the structure of the reference sources 3c 454.3 , b2250 + 194 , and b2252 + 172 \" ( * ? ? ? * paper ii ) ;  a limit on the proper motion of the ` core ' of the quasar 3c 454.3 \" ( * ? ? ? * paper iii ) ;  a new astrometric analysis technique and a comparison with results from other techniques \" ( * ? ? ? * paper iv ) ;  proper motion and parallax of the guide star , i m pegasi \" ( * ? ? ? * paper v ) ;  the orbit of i m pegasi and the location of the source of radio emission \" ( * ? ? ? * paper vi ) ; and  the evolution of the radio structure of i m pegasi \" ( * ? ? ? * paper vii ) . here we give a synopsis of these papers . a suitable guide star for  had to simultaneously meet a number of requirements :    * the motion of the star needed to be known or measurable with an uncertainty small enough not to significantly increase the prelaunch anticipated standard error of  of @xmath60.5  in each of the two precessions . the specific requirement was that the standard error be @xmath70.14  for measurements of the star s motion in each coordinate . in 1990 , when we entered the first stage of our search for a suitable guide star , no star s ( or any other celestial object s ) motion on the sky was known with such accuracy in the optical . such accuracy had previously been achieved only in the radio . pioneered by @xcite , astrometric measurements with the radio technique of very long baseline interferometry ( vlbi ) of a quasar relative to another quasar nearby on the sky yielded a proper - motion estimate with a standard error less than half of the requirement for  @xcite . therefore vlbi appeared to be at that time the only option to determine the motion of a suitable guide star with the desired accuracy . * the star needed to be sufficiently bright in the radio , preferably with a flux density at least of order 1  mjy , for vlbi astrometry measurements to be successful . * the star needed to be sufficiently bright in the optical , at least 7th magnitude , for the on - board telescope to detect . * the star s angular distance , @xmath8 , from the ecliptic needed to be between 20@xmath9 and 40@xmath9 . the lower limit was set by the requirement that , with a suitable sun shield at the telescope , sunlight not enter the dewar and boil off the liquid helium . the upper limit was set by the power requirements of the spacecraft , since the solar panels were fixed to the spacecraft , which would continually point to the guide star , making the power received by the solar panels dependent on @xmath8 . * the star needed to be located as close as possible to the celestial equator , so as to maximize the sensitivity of the measurement of the frame - dragging precession , which essentially decreases with the cosine of the star s declination . * the star needed to be sufficiently isolated on the sky . neighbouring stars or reflection nebulae could possibly intolerably decrease the accuracy of the pointing of the telescope to the star s center of brightness .    to find the most suitable guide star for , we conducted a vla survey at 8.4 ghz from 1990 to 1992 of @xmath41200 stars with v magnitude @xmath76.0 and a declination between @xmath10 and @xmath11 . no single stars were found in the survey with a flux density above @xmath41  mjy . in fact , we detected only previously known radio stars , all of them binaries of the rs canum venaticorum type ( see also , for a later survey , * ? ? ? we identified four potentially suitable guide stars : @xmath12  andromeda  ( hr  8961 , @xmath13 declination ) , hr  1099 ( @xmath14 ) , hr  5110  ( @xmath15 ) , and ( hr  8703 , @xmath16 ) . after investigating each of the four candidates with vlbi , studying the sky fields around them in the optical , and checking on possible vlbi reference sources for each of them , we selected  as the most suitable for .      is a binary with a giant primary and sun - type secondary . we summarize its optical characteristics and previously known properties in table [ topt ] . the radius of the primary is @xmath413.3 @xmath3 0.6 , which translates at a distance of  of @xmath4100 pc , to an angular radius of @xmath40.64 @xmath3 0.03 mas . this radius is comparable to the full - width at half - maximum ( fwhm ) of the synthesized beam of a global vlbi array operating at 8.4 ghz , and therefore in principle allows for an accurate determination of the location of the radio emission with respect to the center of the primary . a prerequisite for successful guide star tracking was that the onboard telescope be able to lock sufficiently accurately on the center of the optical disk of the star ( or a point with an offset from this center constant during the mission ) . one concern here was the appearance of variable dark spots on the primary , shown by doppler imaging and photometry to cover @xmath415% of the star s surface . if the variations in the size or location of these spots resulted in a linear trend over the course of the  mission in the centroid of optical brightness , relative to the center of the disk of the i m peg primary , then that trend would have the same effect on the  data reduction as an equal error in our vlbi measurement of the proper motion of i m peg . such a trend is not necessarily implausible , given the year - to - year variations in i m peg s optical brightness and the astrophysical plausibility of variations in typical spot latitudes analogous to the systematic variations of sunspot locations on the sun . however , @xcite showed , through extensive spot mapping spanning the duration of the  mission , that any error due to variability in the spot pattern would yield no more than a  0.04  drift in the optical center . a second concern was the surroundings of i m peg on the sky . any star or nebula within the field of view of the telescope when locked on , possibly combined with s photometric variability , could cause systematic astrometric errors . however , for , no other star within , e.g. @xmath17 , is brighter than v magnitude 10 , which can be compared with the corresponding relative large brightness of , that varied during the mission only between v magnitude 5.7 and 6.0 . all in all , through extensive optical and even millimetric observations of the co(j=1@xmath180 ) line ( the latter to search for any molecular cloud that could be associated with a reflection nebula ) , we constrained any astrometric systematic error to a negligible value : the combined error from dark spots , neighbouring stars , and a nebula , combined with the photometric variability of , we estimated to be smaller than 0.05  . l c c@  c c c    _ hipparcos _ , @xmath19 , epoch 1991.25 & & & & 1 + _ hipparcos _ , @xmath20 , epoch 1991.25 & & & & 1 + _ hipparcos _ , parallax ( mas ) & & & & 1 + _ hipparcos _ , distance ( pc ) & & & & + & & & & & +   + & & & & & + v magnitude range during mission & & 5.7 to 6.0 & & & 2 + mass ( @xmath21 ) & & @xmath22 & @xmath23 & & 3,3 + spectral type & & k2  iii & g  v & & 4 + @xmath24 ( k ) & & @xmath25 & @xmath26 & & 4,3 + radius ( @xmath27 ) & & @xmath28 & @xmath29 & & 4,3 + radius ( mas ) & & @xmath30 & @xmath31 & & 4,3 + & & & & & +   + & & & & & + @xmath32 ( @xmath27 ) & & @xmath33 & @xmath34 & & 3,3 + @xmath32 ( mas ) & & @xmath35 & @xmath36 & & + @xmath37 ( days ) & & & & 3 + @xmath38 ( @xmath9 ) & & & & 4,5 + @xmath39 & & & & 4 + @xmath40 ( hjd ) & & & & 3 + [ topt ] l l l l l l l 3c  454.3 & quasar & & & 7  10 & 0.859 & 1610 + b2250 + 194 & galaxy & @xmath41 & 3.6 & 0.35  0.45 & 0.28 & 880 + b2252 + 172 & unidentified & 0.4 & 1.4 & 0.017 & & +   + i m peg & rs cvn & @xmath42 & 0.7 & 0.0002  0.08 & 0.0 & 0.0 + [ t2refsources ] our goal was to determine the motion on the sky of  relative to the distant universe , with a standard error not exceeding 0.14  in either coordinate . to achieve this goal , we selected radio reference sources with respect to which the motion of  could be measured . these sources needed to be at cosmological distances , be sufficiently strong and compact for vlbi observations , and located nearby to  on the sky so as to minimize systematic astrometric errors . we selected three reference sources , with the strong quasar , , as the main one . the other two were the active nucleus of the radio galaxy , , and the unidentified source ( most likely also a quasar or a radio galaxy ) , . we display their positions on the sky , together with that of , in figure  [ f1skypos ] , and list their characteristics in table  [ t2refsources ] . ( east - west ) and @xmath43 ( north - south ) directions on the plot are on the same scale . figure taken from . ]    in figure  [ f2images ] we present typical vlbi images at 8.4 ghz of  and each of the three references sources . contour ( fwhm ) in the inset . north is up and east to the left . for more information , see  and . figure taken from , but rearranged.,title=\"fig : \" ]   contour ( fwhm ) in the inset . north is up and east to the left . for more information , see  and . figure taken from , but rearranged.,title=\"fig : \" ]   contour ( fwhm ) in the inset . north is up and east to the left . for more information , see  and . figure taken from , but rearranged.,title=\"fig : \" ]   contour ( fwhm ) in the inset . north is up and east to the left . for more information , see  and . figure taken from , but rearranged.,title=\"fig : \" ]    all the sources are approximately located along the same axis ( north - south ) , allowing perhaps for a more accurate relative correction of tropospheric and ionospheric effects . however , each of the three sources has advantages and disadvantages as reference sources for . the quasar 3c  454.3 is both the strongest and the closest on the sky to . it was used as a reference source for  from 1991 to 1994 @xcite , and could therefore extend the time baseline of our vlbi observations . the disadvantage is the complexity of 3c  454.3 s structure and its superluminal nature . in figure  [ f2images ] we identified six components of which the easternmost component , c1 , is still compact at the highest angular resolution , has a flat or inverted high - frequency spectrum @xcite , and is located almost exactly at the same position ( ) as the core of the quasar seen at 43 ghz @xcite . the component c1 was therefore considered to be the core at 8.4 ghz , the part most closely related to the supermassive black hole and to the center of mass of the quasar ; it was thus the reference point in the quasar s structure for our astrometric measurements . the other components are moving away from c1 , with apparent speeds of up to @xmath45  c ( ) . the remaining sources were both rather compact , so that the brightness peak could simply be taken as the reference point in the structure ; their disadvantages were that b2250 + 194 was located relatively far away from  and b2252 + 172 was rather faint ( with an unknown redshift ) . in addition , we used geodetic and astrometric vlbi observations regularly conducted over many years to determine the limit on the proper motion of two of the three reference sources , 3c  454.3 and b2250 + 194 . these determinations were made without consideration of a particular reference point in the structure of the two sources but were made with respect to a celestial reference frame , crf . this frame is defined by a large number of extragalactic radio sources distributed over the sky and is for our purposes essentially the same as the international celestial reference frame , icrf2 @xcite . all in all , we took c1 in 3c  454.3 as the primary reference point with respect to which the motion of  was measured . the other measurements served to determine the stability of c1 on the sky so that finally the motion of  could be determined with respect to the distant universe . to determine the motion of  relative to c1 and test c1 s stability relative to the brightness peaks of the other two reference sources , we took into account :    *  is catalogued as a binary . however , we could not rule out that it is perhaps part of an extended triple or even larger multiple system . therefore , to ensure our obtaining a sufficiently accurate value of the proper motion of  for the @xmath415 months  data - collection interval in 2004 and 2005 , we spread a sufficiently large number of vlbi measurements over eight and a half years to be able to determine any nearly constant change of the proper motion with time (  proper acceleration \" ) , or place a limit on it . * for the best determination of s parallax , we spread the vlbi measurement epochs appropriately to cover the different seasons each year . similarly , to allow us to model any orbital component of the motion of the radio emission , we carefully distributed the epochs over the phase of the binary orbit , which could be computed from earlier spectroscopic results . * to measure the time - variable brightness distributions of  and the three reference sources , and in particular to identify c1 in 3c 454.3 , we selected each vlbi observation session to be long enough to ensure that the  coverage was sufficiently dense for us to obtain excellent imaging of the sources . * since we expected  to fluctuate strongly in radio brightness , and since we knew that radio emission from b2252 + 174 was relatively weak , we needed our vlbi array to be sufficiently sensitive to nearly guarantee detection of the sources in each observing session . * lastly , we needed an observing frequency for which receivers were available at each of the telescopes of the vlbi array , and which guaranteed sufficiently high angular resolution and low system temperatures . all said , 35 sessions of astrometric vlbi observations were made between 1997 january 16 and 2005 july 16 with about four sessions every year , each about 11 to 15 h long . the observations were made with a global array of 12 to 16 radio telescopes comprised of most or all of : mpifr s 100 m telescope at effelsberg , germany ; nasa / caltech / jpl s 70 m dsn telescopes at robledo , spain , goldstone , ca , and tidbinbilla , australia ; nrao s ten 25 m telescopes of the vlba , across the u.s.a ; nrao s phased vla , equivalent to a 130 m telescope , near socorro , nm ; and , at early times , nrcan s 46 m algonquin radio telescope near pembroke , ont , canada , and nrao s 43  m telescope in green bank , wv . the observing frequency was 8.4 ghz . all of these vlbi observations were made to extract interferometric phase delays related to the difference of arrival times of a radio wave from a celestial source at each pair of antennas of a vlbi array . such observations allow the most accurate astrometric measurements @xcite and can yield relative positions and proper motions referenced to particular points in the structure of the sources with uncertainties as low as @xmath410   and @xmath410  , respectively ( for the earliest such measurements , see , e.g. , marcaide & shapiro 1983 ; bartel et al . 1986 ; and for a recent review , see reid & honma 2014 ) .    the phase delay is given by @xmath44 where @xmath45 is the interferometric phase or  phase \" at observing angular frequency , @xmath46 , and time , @xmath47 . the phase can be expressed as @xmath48   + 2\\pi n(\\omega , t ) , \\label{phi}\\ ] ] where @xmath49 is the `` geometric delay , '' the difference in the arrival times of the radio wave in vacuum at the two antennas ; @xmath50 describes the difference in the instrumental delays ( including clock behavior ) at the two antenna sites ; @xmath51 gives the difference in radio wave propagation times to the two antennas due to all tropospheric and ionospheric effects ; @xmath52 is the delay contribution from source structure to account for any non - pointlike brightness distribution of the celestial source ; @xmath53 is the ( thermal ) noise contribution to the phase measurement ; and @xmath54 describes the integer number of 2@xmath55 ambiguities , or `` phase wraps , '' in the measurement . the astrometric information of a vlbi measurement is given by the geometric delay which , apart from relativistic contributions and those due to earth s motion relative to the solar system barycenter , is given by @xmath56 , \\label{geom}\\ ] ] where @xmath57 is the speed of light in vacuum , @xmath58 is the 3-dimensional vector between two antennas of a baseline of a vlbi array , and @xmath59 is the unit vector in the direction of the observed source .    for phase - delay vlbi observations to succeed , to be able to remove the 2@xmath55 phase ambiguities , and to reduce many sources of astrometric errors , we needed to switch the antennas rapidly between sources . for the first 23 sessions , we used a typical sequence of 3c  454.3 ( 80  s ) - i m  peg ( 170  s ) - b2250 + 194 ( 80  s ) . for the remaining 12 sessions , b2252 + 172 was included in the observations and the sequence was altered to 3c  454.3 ( 80  s ) - i m   peg ( 125  s ) - b2250 + 194 ( 80  s ) - 3c  454.3 ( 80  s ) - i m  peg ( 125  s ) - b2250 + 194 ( 80  s ) - b2252 + 172 ( 90  s ) . in addition to the astrometric 8.4 ghz observations , we also observed once at 5.0  ghz and once at 15.0  ghz , to allow investigation of the compactness and spectral properties of the components of the sources . almost all observations were recorded in both right and left circular polarization , and all were processed with the vlba correlator at socorro , nm . we used a custom software package ( ) that allowed us to analyze the data efficiently . first , we connected the phases and removed the 2@xmath55 phase ambiguities to generate the correct phase delays . then we corrected the phase delays for the effects of the troposphere and the ionosphere with _ a priori _ estimates . we further processed them with a kalman filter to model the residuals of the troposphere and the ionosphere , and the clock offset at each telescope from the one chosen as the reference clock for the vlbi array . then , for the more extended source 3c  454.3 , the structure effects were removed from the phase delays based on the reference point , c1 , defined with images made with nrao s aips software package . the other two reference sources were sufficiently compact that no correction for their source structure was needed . the relative weakness of s radio emission , and sometimes also that of b2252 + 172 , made it necessary for us to develop a special technique for the analysis of  vlbi data . it combines the advantages of parametric model - fitting via weighted least - squares applicable for the relatively strong sources 3c 454.3 and b2250 + 194 with the sensitivity of phase - referenced mapping , the latter required for  and b2252 + 172 . the merged analysis technique yielded superior results to the phase - referenced mapping technique ( ) . the radio emission from  varied from session to session , reflecting the complex astrophysical nature of the environment of the star . in most cases the images of  showed only one clearly defined component . in these cases the coordinates were determined for the maximum of a two - dimensional gaussian fit to that component . in the remaining cases , there was more than one local maximum of approximately equal brightness in the emission region : in eight cases there were two such maxima , and in one case there were three , all of them significant . in such cases , we took the position of i m peg to be the mean position of the different maxima . the final result of the analysis of the  vlbi observations was a set of coordinates with statistical standard errors for each source and each observing epoch . these sets were the basis for the study of the motion , or upper bounds on it , of the sources with respect to each other . in addition , we analyzed geodetic astrometric vlbi observations and made use of interferometric group delays . group delays are given by @xmath60 these are observations of thousands of sources from all over the sky . these observations are done on a routine basis , independent of the  program . for 3c  454.3 we used all available data from a total of 1,119 observing sessions , from 1980 to 2008 . in support of , the second reference source , b2250 + 194 , was included in 38 sessions of routine geodetic astrometric group - delay observations between 1997 and 2008 . group - delay observations have the advantage that 2@xmath55 ambiguities are not inherent in the data and that the positions are determined relative to a celestial reference frame ( crf ) . the disadvantage , however , is that the parameter , @xmath52 , was not determined and that therefore the exact reference point in the brightness distribution of the sources for the position measurement remained undefined . all available geodetic astrometric data with a total of 6.5 million group - delay determinations were processed via least - squares and yielded estimates of coordinates with statistical standard errors for 3c 454.3 and b2250 + 194 for each observing session , keeping the coordinates of the other sources constant . this set of solutions forms our crf , which for s purposes is virtually identical ( see , e.g. , * ? ? ? * ) to the icrf2 @xcite , the most fundamental such frame presently in use . the phase - delay determinations of the position of c1 , the core of 3c 454.3 , relative to those of the brightness peaks of b2250 + 194 and b2252 + 172 , are plotted in figure  [ f3posref ] . the group - delay determinations of the position of b2250 + 194 relative to the crf are also plotted in figure  [ f3posref ] . see  for a similar plot of the group - delay determinations of the position of 3c 454.3 relative to the crf .     are also given . bottom panel : the relative coordinates of b2250 + 194 as determined from routine geodetic group - delay vlbi observations of up to @xmath44000 extragalactic sources scattered over the sky . figure taken from . , title=\"fig:\",scaledwidth=80.0% ]   are also given . bottom panel : the relative coordinates of b2250 + 194 as determined from routine geodetic group - delay vlbi observations of up to @xmath44000 extragalactic sources scattered over the sky . figure taken from . , title=\"fig:\",scaledwidth=72.0% ]    weighted least - squares straight line fits to each set of position determinations yielded the position at epoch and proper motion for each coordinate separately , along with their statistical standard errors and correlations . in each case the fits to the data gave @xmath61 ( @xmath62 per degree of freedom ) larger than unity , indicating systematic errors in the position determinations . these errors can for instance be due to uncorrected effects from source structure and/or atmospheric and ionospheric variations , and are difficult to quantify . therefore the total standard errors of the position determinations were determined partly empirically by including a particular constant for each fit . this constant was added in quadrature to the statistical standard errors for each set of position determinations and for each coordinate separately so as to obtain @xmath63 for each fit . the resultant proper - motion values with their standard errors are listed for each set of position determinations in the panels of figure  [ f3posref ] . the upper panel of figure  [ f3posref ] indicates that there appears to be some motion of c1 relative to b2250 + 194 at the 3.5@xmath64 significance level . the source 3c 454.3 has a long jet , indicating strong activity . some motion of a component like c1 even if located close to the black hole could therefore be expected . no significant motion is discernible for b2250 + 194 relative to b2252 + 172 . no matter whether there is some motion due to activity near the black hole or not , the 1@xmath64 upper limits of the proper - motion values for c1 relative to b2250 + 194 and b2250 + 194 relative to the crf are each smaller than 40 . combining the phase - delay proper - motion determination of c1 relative to b2250 + 194 with the group - delay proper - motion determination of b2250 + 194 relative to the crf gives for the time period from 1998 to 2005 a 1@xmath64 standard error for the mean position of c1 in the crf of 45 and 68 . the proper motion of c1 relative to the crf for that same period is @xmath65  and @xmath66  in  and , respectively , which we do not consider significant . we therefore give a 1@xmath64 upper limit on the magnitude of the proper - motion components of 46 and 56  , respectively . the latter pair of determinations is our limit on the level of stationarity of the reference point c1 in 3c 454.3 relative to the distant universe ( ) . with the stationarity of the reference point in 3c 454.3 determined , the motion of  relative to the distant universe could be analyzed . five kinds of motion needed to be considered :    * proper motion mainly due to the motion of  relative to the motion of the sun in the galaxy , * annual parallax due to the orbital motion of earth around the sun , together with the much smaller contribution of the motion of the sun with respect to the solar system barycenter , * change of proper motion over time due to a hypothetical third member of the  binary system , * orbital motion around the common center of mass of the binary , and * erratic motion of the center of radio emission within the binary system .      to determine the proper motion , parallax , proper acceleration , and orbital motion , we used weighted least - squares to fit a linearized model to the 35 determinations of the positions of the reference point in  relative to the position of c1 in 3c 454.3 . the uncertainties of these position determinations are hard to compute theoretically . we therefore took them from an empirical analysis based on the computation of the root - mean - square ( rms ) scatter separately in @xmath67 and @xmath43 , of the postfit residuals obtained for the 12 positions of  relative to c1 and the 35 positions of  also relative to c1 . the resulting uncertainty was 0.06 mas in each coordinate . in addition there is the previously discussed uncertainty of the position of c1 and the upper limit of the proper motion of c1 in the crf that we considered for the standard errors of the position determinations of  relative to the crf . the parameters of the model fit were the position of  at epoch , proper motion , parallax , and four scalar parameters for the description of the projection on the sky of an orbit with zero - eccentricity @xcite and a period known from optical spectroscopic observations @xcite . the fit resulted in rms values of the residuals somewhat different for each coordinate but much larger than the standard errors of the position determinations of . the source of this large scatter is the astrophysical nature of the radio emission , characterized by motion related to radio brightness changes @xcite and plausibly in part to stellar magnetic field changes implied by spot maps from optical spectroscopy ( e.g. , * ? ? ? for the fit we used uniform weighting independently for  and , and allowed their errors to have non - zero correlation . after iteration , we obtained the final set of parameter estimates with statistical standard errors and @xmath63 . this set is presented in table  [ tfinal ] .    for the determination of the proper acceleration , we enlarged the set of positions of 35 epochs by four additional positions of   obtained at epochs between 1991 and 1994 , also at 8.4 ghz , by @xcite in support of the _ hipparcos _ mission . these observations considerably extended our time baseline ; however , they were only of limited use for the estimate of parameters other than the proper acceleration because of inferior  coverage , lower angular resolution , and the position determinations not being referred to c1 . we found no significant proper acceleration ; i.e. , none larger than one statistical standard error ; and so we include no such proper acceleration in the fit used to obtain our final results in table  [ tfinal ] . figure  [ f4proppar ] displays the 39 position determinations and the fit to the 35 position determinations , with the four earliest positions not used in the fit . the effect of the proper motion and the parallax can be clearly seen in the data as well as in the fit . figure  [ f5paraellipse ] displays the effect of the parallax still more clearly . it shows the 35 position determinations with the estimated position at epoch , proper motion , and the primary s orbital motion subtracted . it also shows the estimated parallax ellipse . figure  [ f6morbit ] displays the orbit clearly . again we plot the 35 position determinations with the estimated position at epoch , proper motion , but now with parallax rather than orbital motion subtracted . also shown are the estimated orbit and the corresponding positions predicted from the orbit model . figure  [ f7resvt ] shows the 39 position determinations and the fit to the above 35 positions , but now with all model contributions , namely the estimated position at epoch , proper motion , parallax , and the primary s orbital motion subtracted . we compare them to the corresponding flux densities of . the scatter of the position residuals appears to be random with certainly no correlation to the measured flux densities . the rms of the scatter is @xmath40.4 mas in each coordinate , much larger than the standard errors of the position determinations and most likely dominated by the fluctuation of the positions of the stellar radio emission relative to the center of the primary of . figure  [ f8imschemradio ] gives an artist s three - dimensional rendition of  with the primary as a giant with dark spots and the secondary as a sun - like star , each in its estimated orbit . errors ( here and hereafter in the figure captions in the sense of the full length of @xmath68 error bars ) are much smaller than the symbols . the curve shows the fit of the solution , with orbital terms omitted for clarity . in addition , the four positions from 1991 to 1994 are shown ( upper left ) ; however , they were not used in the fit . the arrow indicates the direction and its length the magnitude of the proper motion in one year . figure taken from . ] errors ( of position determinations relative to c1 ) are about a third of the size of the circles . the relatively large scatter is most likely dominated by the fluctuations of the positions of the stellar radio emission relative to the center of the disk of the  primary . the model positions ( not shown ) are almost exactly on the plotted parallax ellipse and close to the observed positions . the parallax ellipse , however , is slightly time - dependent due to the influence of planets . over the course of our observations of several years , the parallax ellipse in the figure shifts by about the width of the line . , scaledwidth=70.0% ]     errors ( for the position determinations relative to c1 ) are about twice the size of the circles . a solid line connects each observed position with the corresponding fitted position indicated by a dot on the estimated orbit . the large scatter of the observed positions about the model orbit ellipse is again most likely dominated by the fluctuations of the positions of the stellar radio emission relative to the center of the disk of the  primary . figure adapted from . , scaledwidth=70.0% ]    . the secondary is the smaller yellow star . the projected orbit of the primary is the same as the inferred radio source orbit shown in figure  [ f6morbit ] . the projected orbit of the secondary and the diameters of the two stars correspond to the nominal values given in table  [ topt ] . the system is shown with the primary at its ascending node . note that the primary s visible pole is near its southeast side . the size of the figure is approximately 3.8  mas by 3.4  mas . , scaledwidth=95.0% ]      a detailed analysis of systematic errors affecting each of the nine fit parameters of s motion relative to the distant universe led us to the following conclusions . for the position at the mean epoch of the vlbi observations of 2001.29 , the systematic error in each coordinate was computed from 0.5 times the angular radius of the primary along the sky projection of the normal to the binary orbital plane ( p.a . = 130.5   @xmath3 8.6 ) . for the later epoch of 2005.08 in table  [ tfinal ] , the value for each component was added in quadrature with a possible maximum rms drift during that time interval of the radio brightness reference point of . the rms drift rate was assumed to be not larger than one stellar radius over the vlbi observation time span of 8.5 years or 0.06  in @xmath67  and 0.05  in @xmath43 . the systematic error of the proper motion estimate was found to be mostly comprised of the upper limit of the proper motion of c1 in the crf and of the aforementioned possible maximum rms drift of the radio brightness reference point of . the systematic errors of the parallax and orbit estimates were found to be most clearly defined by the position values of b2250 + 194 relative to those of c1 in 3c 454.3 , since the true parallax and orbit parameter values should be zero . the same parameter fit used for  resulted in a parallax estimate for b2250 + 194 relative to c1 of @xmath69 @xmath3 0.074 mas , with the statistical standard error decreasing to 0.026 mas for @xmath63 . for the five - fold smaller separation of  from 3c  454.3 the systematic uncertainty was estimated to be @xmath700.015  mas in each coordinate . the same parameter fit also resulted in orbit parameter estimates for b2250 + 194 relative to c1 much smaller than the estimates for  itself . for each of the parameters in table  [ tfinal ] the total error is also listed . in general it is computed as the root - sum - square of the statistical standard error and the estimated systematic error . for the position and proper motion values , however , the statistical errors are doubled before computing the root - sum - square to allow for correlated noise in the vlbi positions . for the parallax and orbit parameter estimates , the systematic errors were too small to contribute appreciably to the total standard errors . l c c c c @xmath67 at epoch 2005.08 ( errors in mas ) & & 0.12 & 0.33 & 0.40 + @xmath43 at epoch 2005.08 ( errors in mas ) & & 0.13 & 0.29 & 0.39 + @xmath71 ( ) & @xmath72 & 0.026 & 0.073 & 0.090 + @xmath73 ( ) & @xmath74 & 0.030 & 0.074 & 0.095 + parallax ( mas ) & @xmath75 & 0.074 & @xmath700.015 & 0.074 +  ( mas ) & @xmath76 & 0.10 & @xmath770.1 & 0.10 +  ( mas ) & @xmath78 & 0.11 & @xmath770.1 & 0.11 +  ( mas ) & @xmath79 & 0.09 & @xmath770.1 & 0.09 +  ( mas ) & @xmath80 & 0.11 & @xmath770.1 & 0.11 + semimajor axis ( mas ) & 0.89 & 0.09 & @xmath770.1 & 0.09 + axial ratio & 0.30 & 0.13 & @xmath770.1 & 0.13 + p.a .  of ascending node ( deg ) & 40.5 & 8.6 & @xmath778 & 8.6 + @xmath40 ( heliocentric jd ) & 2450342.56 & 0.44 & @xmath770.4 & 0.44 +      comparing our results with the most precise previous measurements of proper motion and parallax , we find that our estimates agree with those in the _ hipparcos _ catalogue @xcite and those of @xcite within their respective larger standard errors . however , we found that our estimates slightly disagree with the values in the _ hipparcos _ re - reduction @xcite by 1.6 and 2.4 times the combined standard error in  and in parallax , respectively . this discrepancy in  is , however , more than 10 times smaller than the standard error of either the geodetic or the frame - dragging effect @xcite , and therefore of no consequence for the  results .    comparing the orbital parameters , we find that our estimate of the time of conjunction is consistent with that of @xcite and the combination of our estimates of orbital inclination and semimajor axis are consistent with their value of @xmath32 . this agreement , in turn , is consistent with the reasonable expectation that the radio emission is on average centered on the primary of the  system , and that it orbits with the same inclination . any offset in phase of the radio orbit from that of the primary corresponds to less than one - forth of the radius of the primary .      with position at epoch , proper motion , parallax , orbital motion , and average location relative to the center of the primary determined , how can the radio emission be described and where does it appear relative to the primary of  from epoch to epoch ? figure  [ f9image ] displays a set of vlbi images of  relative to the center of the primary in its orbit about the binary s barycenter . the rms background ; and contours at 50% and above are drawn in black . the center of each panel ( red dot ) is the fit position of the star s center , as derived from the astrometric results in . in other words , the coordinate origin in our radio image should approximately represent the center of the disk of the primary star . the red circle indicates the angular size of the primary star ( radius of @xmath28  ; * ? ? ? the cyan dotted ellipse shows the orbit of the primary as in  and . figure taken from , where also the complete set of our vlbi images is given . , scaledwidth=80.0% ]    the analysis of the images showed that the radio emission is highly variable and frequently partly circularly polarized . the morphology is also variable with the average size of the radio emission slightly larger than the disk of the primary . the positions of the peaks of the emission regions are scattered over an area on the sky slightly larger than the disk of the primary . the scatter has a tendency to be distributed along the orbit normal and expected primary s spin axis . comparison with simulations suggest that the brightness peaks preferentially occur near the polar regions similar to the dark spots in the optical @xcite . the height of the emission is likely close to the surface of the primary with 2/3 of the emission peaks located within 0.25 times the stellar radius above the surface . the radio emission may be due to flares linked to a possibly dipolar magnetic field , whose axis is normal to the orbit plane , as could be expected giving the tidally locked rotation of the primary . for a movie of the star based on these vlbi images , see the website , www.yorku.ca/bartel/impeg.mpg , or the online version of . our series of 35 vlbi sessions between 1997 and 2005 resulted in the most comprehensive and detailed radio investigations ever made of a star .    * the proper motion of  relative to the distant universe is @xmath0 @xmath3 0.09  in  and @xmath2 @xmath3 0.09  in , where the errors are intended to represent one - standard deviation errors and include estimates of systematic errors . * these results met the pre - launch requirements of the  mission of standard errors no larger than 0.14  in each coordinate so as not to discernibly degrade the estimates of the geodetic and frame - dragging effects . * the parallax of  is 10.37 @xmath3 0.07  mas , corresponding to a distance of 96.4 @xmath3 0.7  pc . * the proper - motion and parallax estimates agree with previous estimates , including those in the _ hipparcos _ catalogue , within the combined standard errors , with the exception of the revised _ hipparcos _ results of @xcite where the agreement is within 1.6 and 2.4 times the respective combined standard errors . any discrepancy at these levels is however of no consequence for the  results . * the radio emission of  is highly variable . * the vlbi images of  show emission regions slightly larger than the disk of the primary and their peaks scattered about a similarly sized area , consistent with being located preferentially near the polar regions and within @xmath40.25 stellar radii above the surface . * the vlbi images of  were assembled for a movie of the star ( see the website of the first author , www.yorku.ca/bartel/impeg.mpg , or the online version of ) .    acknowledgements . we thank each of the following people , listed alphabetically , for their contributions of observations and data reductions to our investigations of  and its sky neighborhood , for providing us with unpublished updated catalog data , and/or for enlightening discussions on various aspects of this research program : s.  berdyugina , a.  buffington , d.  buzasi , n.  caldwell , r.  campbell , j.  chandler , t.  dame . r.  donahue , g.  fazio , d.  fischer , o.  franz , g.  gatewood , d.  gordon , e.  guinan , p.  hemenway , a.  henden , m.  holman , the late j.  huchra , p.  kalas , g.  keiser , j.  kolodziejczak , r.  kurucz , b.  lange , d.  latham , j.  lederman , j .- f . lestrade , j.  lipa , p.  luca , s.  marsden , h.  mcalister , d.  monet , n.  nunes , l.  petrov , r.  schild , g.  torres , w.  traub , d.  trilling , n.  turner , the late h.  wendker , and the late c.  worley , this research was primarily supported by nasa , through a contract from stanford university to sao , with a major subcontract from sao to york university . we obtained observations made with the 100-m telescope of the max - planck - institut fr radioastronomie at effelsberg , with antennas of the national radio astronomy observatory ( nrao ) , which is a facility of the national science foundation operated under cooperative agreement by associated universities , inc . , with antennas of the dsn , operated by jpl / caltech , under contract with nasa , and with the nasa / esa hubble space telescope , which is operated by the association of universities for research in astronomy , inc . , under nasa contract nas 5 - 26555 . we made use of the sao / nasa astrophysics data system abstract service , initiated , developed , and maintained at sao . , a.  l. , gordon , d. , & jacobs , c.  s. , ( eds . ) 2009 , iers technical note no . 35 , http://www.iers.org/iers/en/publications/technicalnotes/tn35.html ( frankfurt : verlag des bundesamts fr kartographie und geodsie )                        , a. , krichbaum , t.  p. , graham , d.  a. , et  al . 2004 , in european vlbi network on new developments in vlbi science and technology ( trieste : proceedings of science ) , ed . r.  bachiller , f.  colomer , j .- f . desmurs , & p.  de vicente , 710", "tags": [], "output_text_a": "The paper discusses the NASA/Stanford Gravity Probe B mission, which aimed to test Einstein's theory of general relativity by measuring the precession of gyroscopes in Earth's orbit. The mission sought to detect two effects predicted by general relativity: the geodetic effect and frame-dragging, caused by Earth's mass and angular momentum, respectively. The gyroscopes were placed in a dewar with a quartz block and telescope, cooled to 1.8 K, and tracked a guide star, IM Pegasi, to measure precessions with high accuracy.\n\nThe paper details the selection and monitoring of the guide star, IM Pegasi, and its motion relative to distant quasars using very long baseline interferometry (VLBI). The study involved extensive VLBI observations from 1997 to 2005, using a global array of radio telescopes. The analysis included determining the proper motion, parallax, and orbital motion of IM Pegasi, as well as the stability of reference sources.\n\nThe results showed that the proper motion and parallax of IM Pegasi met the pre-launch requirements, ensuring the accuracy of the Gravity Probe B measurements. The radio emission from IM Pegasi was found to be highly variable, with emission regions slightly larger than the star's disk, often located near polar regions. The study provided the most detailed radio investigation of a star to date, supporting the Gravity Probe B mission's objectives.", "output_text_b": "Gravity Probe B (GP-B) was a NASA/Stanford spaceborne mission designed to measure the differences in kinematics of objects in the vicinity of a gravitating body as predicted by Einstein's Theory of General Relativity (GR). The mission used four gyroscopes essentially freely falling around Earth in a polar orbit at an altitude of about 640 km. According to GR, the gyroscopes' spin axes should precess due to the curving and warping of space-time by Earth's mass and angular momentum. These precessions, known as the geodetic effect and frame-dragging effect, can be considered rotations of any near-Earth inertial frame relative to the distant universe.\n\nThe gyroscopes were set spinning within a quartz block with respect to which, through superconducting quantum interference devices (SQUIDs), each of the spin axes precessions could be measured with an accuracy of 100 within 440 days. The quartz block was bonded to a 15 cm diameter quartz optical telescope. All of these devices, the quartz block, the SQUIDs, and the quartz telescope (together termed the probe), were placed in a dewar filled with liquid helium and cooled to a temperature of 1.8 K.\n\nTo determine the orientation of the probe, a guide star was needed, which had to meet several requirements. It had to be bright enough for the on-board telescope to track, sufficiently isolated to limit light contamination, and suitably located to not unnecessarily decrease the accuracy of the measurement of the precessions of the gyroscopes. Additionally, the guide star's motion on the sky needed to be measured with respect to quasars or distant galaxies so that the precession of the gyroscopes could be determined with respect to the distant universe.\n\nA suitable guide star was found in the form of IM Pegasi (IM Peg), a binary star with a giant primary and sun-type secondary. The primary's radius is comparable to the full-width at half-maximum (FWHM) of the synthesized beam of a global VLBI array operating at 8.4 GHz, allowing for an accurate determination of the location of the radio emission with respect to the center of the primary.\n\nHowever, there were concerns about the appearance of variable dark spots on the primary, which could result in a linear trend in the centroid of optical brightness relative to the center of the disk of the iM Peg primary. This could have the same effect on the data reduction as an equal error in the VLBI measurement of the proper motion of iM Peg. Through extensive spot mapping spanning the duration of the mission, it was shown that any error due to variability in the spot pattern would yield no more than a 0.04 drift in the optical center.\n\nAnother concern was the surroundings of iM Peg on the sky. Any star or nebula within the field of view of the telescope when locked on could cause systematic astrometric errors. However, for iM Peg, no other star within 17 arcminutes is brighter than v magnitude 10, which can be compared with the corresponding relative large brightness of iM Peg, which varied during the mission only between v magnitude 5.7 and 6.0. Through extensive optical and even millimetric observations, any astrometric systematic error was constrained to a negligible value.\n\nIn summary, a suitable guide star for Gravity Probe B was found in the form of IM Pegasi, a binary star with a giant primary and sun-type secondary. The star's motion was measured using Very Long Baseline Interferometry (VLBI) and compared to the motion of quasars and distant galaxies to determine the precession of the gyroscopes with respect to the distant universe. Despite concerns about variable dark spots on the primary and the surrounding sky, any astrometric systematic error was constrained to a negligible value.", "score": 0.0, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, such as the testing of Einstein's theory of general relativity and the results regarding the proper motion and parallax of IM Pegasi.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of testing general relativity through the Gravity Probe B mission.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the use of VLBI and the tracking of a guide star to measure precessions.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the proper motion and parallax meeting pre-launch requirements.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary avoids excessive technical jargon and explains terms like the geodetic effect and frame-dragging.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically, with a clear introduction, body, and conclusion.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of VLBI observations and the tracking of IM Pegasi.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the significance of the study in supporting the Gravity Probe B mission's objectives.", "1. The summary accurately reflects the main findings and contributions of the paper by describing the Gravity Probe B mission and its objectives related to measuring the effects predicted by Einstein's Theory of General Relativity.\n2. The summary is concise and does not exceed 250 words.\n3. The research problem addressed by the paper, which is measuring the precession of gyroscopes due to the curving and warping of space-time, is highlighted.\n4. The methodology, including the use of gyroscopes, SQUIDs, and VLBI, is mentioned.\n5. Significant results, such as the identification of IM Pegasi as a suitable guide star and the constraints on astrometric systematic errors, are included.\n6. The summary is written in clear and professional language.\n7. Technical jargon is minimized, and terms like VLBI and SQUIDs are explained.\n8. The summary is structured logically with a clear beginning, middle, and end.\n9. Key experiments, such as the use of VLBI to measure the motion of IM Pegasi, are mentioned.\n10. The summary reflects the paper's significance in testing predictions of general relativity."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, true], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, true], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [true, true], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, true], "The summary should reflect the paper's significance or potential impact in its field.": [true, true]}}, {"input_text": "an applied magnetic field can penetrate into a type - ii superconductor in the form of quantized vortices ( each carry a single flux quantum @xmath1 ) when the applied magnetic field increases to a value above the lower critical field of the superconductor.@xcite the vortices first penetrate into the superconductor from the surfaces which are parallel to the applied magnetic field , and then go to the center of the superconductor.@xcite vortex motion is usually retarded @xcite during the penetration process because the vortices are subjected to surface attractive force @xcite , pinning forces , internal field repulsive force and damping force @xcite . the internal magnetic field ( or penetrated magnetic field ) increases gradually and finally reaches a saturated value . de gennes @xcite first studied the vortex penetration in terms of free energy . a number of works studied the vortex entry conditions @xcite , and other works investigated the vortex penetration into the bulk of superconductors over the bean - livingston surface barrier @xcite . the experimental studies of the vortex penetration were generally carried out with hall sensors @xcite and magneto - optical imaging technique @xcite which provides direct observations of vortex front . it is known that vortex entry conditions and vortex penetration over surface barrier were studied . however , the bean - livingston surface barrier reduces exponentially with respect to the distance to the surface of the superconductor.@xcite the vortex motion inside a macro size superconductor is then mainly determined by the bulk pinning and internal field repulsive force . the theoretical description to this phenomenon is currently unavailable . on the other hand , the recent experimental observations @xcite have shown that the internal magnetic field of a high-@xmath2 superconductor is strongly time dependent after a magnetic field ( below irreversible field ) is applied to the superconductor . the time scale depends on the sample geometry , temperature and applied field magnitude . this time dependence implies that a vortex system is unstable during the vortex penetration process and a superconducting device may not work properly at this stage . for the purpose of application , therefore , it is important to construct a mathematical model which includes the effects of the bulk pinning and internal field repulsive force , and can predicts the time scale of the vortex penetration process .    in this article i theoretically show that the vortex penetration process is time dependent because of the surface attractive force , bulk pinning force and internal field repulsive force . first , i discussed the field dependence of activation energy of the vortex penetration process . next , i discussed the time dependence of activation energy based on the arrenhius relation . finally , i derived a time dependent equation for the internal field in a vortex penetration process . as mentioned before , the vortices inside a type - ii superconductor are subjected to various forces and vortex motion is generally retarded . the experimental observations @xcite have shown that , at lower temperatures and under small applied fields , the time scale of vortex penetration process in a superconducting crystal sample extends to infinity long . therefore , it is reasonable to assume that the vortices are at some metastable states under an intermediate applied field @xmath3 , where @xmath4 is lower critical field and @xmath5 is irreversible field . in this sense , the vortex penetration process can be regarded as a vortices diffusion process , i.e. , a process of vortices hopping between adjacent pinning centers . in an analogy to that of flux relaxation @xcite , we can described the vortex penetration process with the arrhenius relation : @xmath6 , where @xmath7 is attempting frequency , @xmath8 is the activation energy of the vortices , @xmath9 is the boltzmann constant and @xmath10 is temperature.@xcite this relation implies that the activation energy @xmath8 plays an important role in the vortices hopping .    in this work i am going to use some similar concepts and mathematical tools used in the studies of flux relaxation . but it should be emphasized that the physical contents of these two processes are completely different . in vortex penetration process the vortices are pushed into the superconductor by external driving force ; however , in flux relaxation process the vortices jump out of the superconductor because of various reasons @xcite . let us first discuss the possible expression of the field dependence of activation energy @xmath8 in the vortex penetration process .      according to bean and livingston @xcite , a vortex close to the surface of a superconductor is subjected to attractive imaging force and external field repulsive force . the addition of these two forces results in the surface barrier to the vortex penetration , @xmath11 , which is determined by the sample geometry and external field magnitude @xmath12 . early studies have shown that @xcite @xmath13 where @xmath1 is flux quantum , @xmath14 is penetration depth and @xmath15 is the distance between the vortex and sample surface . the first term on the right side of eq.([us ] ) is caused by the attractive imaging force , and the second term on the right side is caused by the applied field driving force . eq.([us ] ) shows that @xmath16 reduces exponentially with respect to @xmath15 , that is , @xmath17 , @xmath18 . thus , the vortices away from the sample surface are almost uninfluenced by the surface barrier . on the other hand , a vortex inside a superconductor is subjected to bulk pinning force and internal field repulsive force , which prevents the vortices motion and reduces the vortices hopping rate . according to the arrhenius relation , this internal field repulsive force increases the activation energy . therefore , the activation energy is an increasing function of the internal field @xmath19 . let @xmath20 be the activation energy related to the bulk pinning and internal field repulsive force , we have @xmath21 . the exact form of @xmath22 is usually unknown because of the complexity of the interaction between vortices and pinning centers , as well as the reaction of vortices to external field driving forces . but from a pure mathematical consideration , we can express @xmath22 as a taylor series of @xmath19 ( or magnetization @xmath23).@xcite let us now write out the series expression of @xmath22 explicitly , @xmath24 where @xmath25 , @xmath26 , @xmath27 , @xmath28 , @xmath29 . the parameter @xmath30 is the pinning potential inside the bulk of the superconductor . the coefficients @xmath31 ( @xmath32 ) represent the weight of the contribution from inelastic deformation and interaction between the vortices , @xmath33 represents the weight of the contribution from elastic deformation of the vortices and @xmath34 represents the weight of the contribution from lorentz force.@xcite these coefficients are functions of temperature @xmath10 and can be denoted as @xmath35 and @xmath36 . the total activation energy of a vortex , @xmath37 , is the summation of @xmath11 and @xmath22 , that is @xmath38 where @xmath39 is the activation energy at vanishing internal field , or the activation energy at time @xmath40 . @xmath41 is determined by the sample geometry , external field and pinning ability .    from eq.([us ] ) we see that the activation energy @xmath37 is a local function , i.e. , a function of position @xmath15 . this is not explicitly shown in eq.([uafield ] ) because we are interested in the field dependence of @xmath8 in the current work . the above discussion has shown that in vortex penetration process the activation energy @xmath8 is an increasing function of the internal field @xmath19 . it is also known that @xmath19 increases gradually with time @xmath42 . therefore , @xmath8 is an increasing function of @xmath42 . the rate of change of the internal field , @xmath43 , is proportional to vortex hopping rate . on the other hand , @xmath19 is an increasing function of @xmath42 in the vortex penetration process , i.e. , @xmath44 ( in relaxation @xmath45 ) . according to the arrhenius relation , we have @xcite @xmath46 where @xmath47 is a positive proportional constant . eq.([uadiff ] ) can also be derived from the diffusion equation of flux flow ( conservation of flux).@xcite comparing to that of flux relaxation @xcite , eq.([uadiff ] ) has differences in sign and initial conditions . these cause the differences between the mathematical models of vortex penetration and flux relaxation . the exact solution of eq.([uadiff ] ) is currently unavailable , but we can find an approximate solution to it . consider applying a magnetic field to a superconductor at time @xmath40 . the activation energy of a vortex at this moment is @xmath41 , which is also the activation energy at zero internal field ( see eq.([uafield ] ) ) . as time increases to @xmath42 , the activation energy increases to @xmath8 . rewrite eq.([uadiff ] ) and integrate it on both sides ,    @xmath48    with logarithmic accuracy @xcite , we obtain the following equation : @xmath49 where @xmath50 $ ] is a short time scale parameter @xcite . eq.([uatime ] ) shows that @xmath41 has a strong effect on the time dependence of the activation energy @xmath51 . our final purpose is to obtain the time dependence of internal field @xmath52 . since the vortex motion in a vortex penetration process is retarded by various forces , the internal field increases gradually with increasing time . this relation can be obtained by canceling out the activation energy @xmath8 from eq.([uafield ] ) ( field dependence of @xmath8 ) and eq.([uatime ] ) ( time dependence of @xmath8 ) , that is , @xmath53 where @xmath54    to find out the time dependence of internal field @xmath52 , let us now invert eq.([wvsj ] ) by expanding @xmath55 $ ] as a series of @xmath56 , @xmath57 = \\sum\\limits_{l=1}^n b_l w^l(t ) = \\sum\\limits_{l=1}^n b_l \\left[kt ln\\left(1 + \\frac{t}{\\tau e^{u_0/kt } } \\right ) \\right]^l \\end{aligned}\\ ] ]    similar to earlier studies @xcite , we have the coefficients @xmath58 s +    @xmath59 \\\\     & \\cdots \\\\ & b_l=\\frac{1}{a_1^l } \\frac{1}{l } \\sum\\limits_{s , t , u \\cdots } ( -1)^{s+t+u+\\cdots } \\cdot \\frac{l(l+1)\\cdots(l-1+s+t+u+\\cdots)}{s!t!u!\\cdots } \\cdot \\left(\\frac{a_2}{a_1}\\right)^s \\left(\\frac{a_3}{a_1}\\right)^t \\left(\\frac{a_4}{a_1}\\right)^u \\cdots \\\\   & \\cdots \\\\     \\end{aligned}\\ ] ]    where @xmath60 . on considering the symmetry between eq.([wvsj ] ) and eq.([bvsw ] ) , we obtain the coefficients @xmath31 by doing a commutation to the coefficients @xmath61 , that is    @xmath62    eq.([bvsw ] ) describes the time dependence of internal field @xmath52 . this relation can also be measured experimentally.@xcite with these relations we can calculate the field dependent activation energy @xmath37 using the following procedure : first , fitting the experimental data with eq.([bvsw ] ) , we obtain the fitting parameters @xmath41 and @xmath58 as shown in figure 1 . next , substituting @xmath58 into eq.([ans ] ) , we obtain the coefficients @xmath31 . finally , substituting @xmath41 and @xmath31 into eq.([uafield ] ) , we obtain the activation energy @xmath37 .    the activation energy @xmath37 is a combined response to the internal field @xmath19 . it includes the contributions from the surface barrier , deformation of vortices , interaction between vortices and possibly other unknown sources . figure 1 shows that eq.([bvsw ] ) is accurate for the experimental data of a @xmath0 single crystal . ( color online ) time dependence of vortex penetration . the scattering points are the experimental data of a @xmath0 single crystal , at 25 k under an applied magnetic field of 0.05 t. ( the data is from ref .  ) the solid black line is the theoretical fit . the fitting results are : @xmath63 , where @xmath64\\}$ ] , @xmath65 , @xmath66 , @xmath67 , @xmath68 , @xmath69.,width=264,height=226 ]    at lower temperatures and lower applied fields , the inelastic deformation and interaction between vortices is not significant . therefore , we can simplify the activation energy @xmath37 in a manner analogous to that used in the studies of flux relaxation @xcite . first , let us consider putting @xmath70 ( @xmath32 ) in eq.([uafield ] ) . this is equal to ignoring the inelastic deformation and interaction between vortices . thus , we obtain the non - interacting elastic vortices which are described by the quadratic activation energy @xmath71    substituting eq.([uatime ] ) into eq.([uaquadratic ] ) , we have ( choose one of the solutions which is an increasing function of time ) , @xmath72\\ ] ] where @xmath56 is defined by eq.([functionw ] ) .    further putting @xmath73 in eq.([uaquadratic ] ) is equal to assuming that the vortices have very large elastic modulus and the elastic deformation can be ignored . we obtain the non - interacting rigid vortices which are described by the linear activation energy @xmath74    substituting eq.([uatime ] ) into eq.([ualinear ] ) , we have @xmath75 \\1 . _ measurement of @xmath30 and @xmath11_. the bulk pinning potential @xmath30 can be obtained by measuring the time evolution of internal field @xmath52 at a position @xmath76 inside the sample where @xmath77 . fitting the experimental data @xmath52 with eq.([bvsw ] ) , we have the value of @xmath30 at the position @xmath15 . in case of random pinning centers , @xmath30 is a constant and can be represented by the statistical average value @xmath78 , where @xmath79 is the pinning force of individual pinning center , @xmath80 is coherence length and @xmath81 is the number of the pinning centers in a correlation volume.@xcite . the surface barrier @xmath11 can be calculated using eq.([us ] ) , but we can also measure it with the help of eq.([bvsw ] ) . first , using the above stated procedure to measure the bulk pinning potential @xmath30 . next , fixing a sensor at a position @xmath82 close to the sample surface and measuring @xmath52 , we obtain the value of @xmath83 using eq.([bvsw ] ) . finally , using relation @xmath84 , we can find out the value of @xmath85 . if a superconductor is anisotropic , the superconducting parameter @xmath14 is anisotropic . according to eq.([us ] ) , the surface barrier @xmath11 is also anisotropic . therefore , when estimating the surface barrier we must have a clear idea about which crystalline axis is perpendicular to the surface . _ inflection point of @xmath86 curve_. as shown in figure 1 , the @xmath86 curve displays a concave shape at short time and then changes to a convex shape with increasing time . let us now discuss the possible reason for this phenomenon . the fitting results indicate that it is accurate enough by keeping terms up to second order . thus , we can write out the time dependent internal field as @xmath87 . the second derivative of @xmath52 is , @xmath88\\ ] ] where @xmath89 ^ 2 $ ] . putting @xmath90 , we obtain the inflection point time @xmath91\\ ] ]    if @xmath92 , then @xmath93 ; the curve is concave . if @xmath94 , then @xmath95 ; the curve is convex . one can easily see that @xmath96 is a decreasing function of temperature @xmath10 ( note that @xmath97 and @xmath98 has different sign ) . on the other hand , @xmath96 is an increasing function of @xmath41 and @xmath41 is a decreasing function of the applied field @xmath12 ( see eq.([us ] ) ) . therefore , @xmath96 is a decreasing function of @xmath12 . these results can explain the experimental observations in ref . which show that : 1 . @xmath96 becomes shorter and finally goes to zero with increasing @xmath12 or increasing @xmath10 . 2 . there is no concave shape in the @xmath86 curves of the thin films , only convex shapes were observed . this is because the thin film samples have small surface barrier @xmath11 and consequently small @xmath41 , which results in the unobservable short @xmath96 . _ effects of surface barrier on flux relaxation_. eq.([us ] ) shows that surface barrier affects vortex penetration . it is then natural to expect that this surface barrier also affects flux relaxation .    in flux relaxation , the external field is usually zero and the second term in eq.([us ] ) vanishes . but the first term in eq.([us ] ) still exists . the first term is caused by the surface imaging force ( attractive ) , which helps to draw the vortices out of the superconductor and reduces the activation energy of the vortices . early studies @xcite have shown that in flux relaxation the time dependence of internal field is @xmath99 , where @xmath100 and @xmath58 are constants . by further considering the surface imaging force , @xmath56 should be replaced by @xmath101    eq.([functionw2 ] ) indicates that the surface imaging force causes flux relaxation theory to be a local theory . the general field dependent activation energy of a vortex penetration process was proposed and time dependence of internal field was derived . although the vortex penetration is an inverse process to flux relaxation , there is no symmetry between the mathematical models of these two processes because of the surface barrier . finally , it should be mentioned that i have ignored the effects of damping force on the vortex penetration when constructing the mathematical model . the damping force may add significant influence on the vortex penetration under large applied field where the velocity of vortices is large .", "tags": [], "output_text_a": "This paper investigates the time-dependent process of vortex penetration in type-II superconductors when subjected to an applied magnetic field. The study focuses on the interplay of various forces such as surface attractive force, bulk pinning force, and internal field repulsive force that influence vortex motion. The author develops a theoretical model to describe the field and time dependence of activation energy during vortex penetration, using concepts from flux relaxation studies. The model accounts for the gradual increase of internal magnetic field and its saturation, highlighting the metastable states of vortices under intermediate fields. The paper also provides a mathematical framework to predict the time scale of vortex penetration, which is crucial for the application of superconducting devices. Experimental data is used to validate the model, showing its accuracy in describing the time evolution of internal fields in superconductors. The study concludes with discussions on the effects of surface barriers and potential implications for flux relaxation processes.", "output_text_b": "This article discusses the time-dependent behavior of vortex penetration in type-II superconductors. When an external magnetic field is applied, the vortices penetrate the superconductor in a time-dependent manner due to the surface attractive force, bulk pinning force, and internal field repulsive force. The activation energy of the vortex penetration process is influenced by the internal field, which increases gradually with time. The authors derive a time-dependent equation for the internal field in a vortex penetration process and propose a vortex diffusion model based on the Arrhenius relation. The model highlights the importance of activation energy in the vortices hopping between adjacent pinning centers.", "score": 0.4, "individual_rater_scores": [], "custom_fields": {"evaluation": ["1. \"The summary should accurately reflect the main findings and contributions of the paper.\" - The summary captures the main findings and contributions, focusing on the time-dependent process of vortex penetration and the theoretical model developed.\n2. \"The summary must be concise, ideally not exceeding 250 words.\" - The summary is concise and does not exceed 250 words.\n3. \"It should highlight the research problem or question addressed by the paper.\" - The summary highlights the research problem of understanding vortex penetration in type-II superconductors.\n4. \"The summary should mention the methodology or approach used in the paper.\" - The summary mentions the development of a theoretical model and the use of concepts from flux relaxation studies.\n5. \"It should include any significant results or conclusions drawn by the authors.\" - The summary includes significant results, such as the model's accuracy in describing the time evolution of internal fields.\n6. \"The summary must be written in clear and professional language.\" - The language used in the summary is clear and professional.\n7. \"It should avoid technical jargon unless necessary, and explain any used terms.\" - The summary uses some technical terms but does not explain them, which might be necessary for clarity.\n8. \"The summary should be structured logically, with a clear beginning, middle, and end.\" - The summary is structured logically with a clear flow.\n9. \"It should mention any key experiments or data used in the research.\" - The summary mentions the use of experimental data to validate the model.\n10. \"The summary should reflect the paper's significance or potential impact in its field.\" - The summary reflects the paper's significance in predicting the time scale of vortex penetration for superconducting devices.", "1. **Accurate Reflection of Main Findings and Contributions**: The summary captures the main findings regarding the time-dependent behavior of vortex penetration in type-II superconductors and the derivation of a time-dependent equation for the internal field. However, it does not mention the specific mathematical model or the significance of the findings in the context of superconducting devices.\n\n2. **Conciseness**: The summary is concise and does not exceed 250 words.\n\n3. **Research Problem or Question**: The summary does not explicitly state the research problem or question addressed by the paper, which is the need to understand the time-dependent vortex penetration process in superconductors.\n\n4. **Methodology or Approach**: The summary mentions the derivation of a time-dependent equation and the use of a vortex diffusion model based on the Arrhenius relation, which reflects the methodology used.\n\n5. **Significant Results or Conclusions**: The summary mentions the influence of internal field on activation energy and the importance of activation energy in vortex hopping, but it does not detail any specific results or conclusions drawn by the authors.\n\n6. **Clear and Professional Language**: The summary is written in clear and professional language.\n\n7. **Avoidance of Technical Jargon**: The summary uses some technical terms like \"activation energy\" and \"Arrhenius relation\" without explanation, which might not be clear to all readers.\n\n8. **Logical Structure**: The summary has a logical structure with a clear beginning, middle, and end.\n\n9. **Key Experiments or Data**: The summary does not mention any key experiments or data used in the research, which is a significant omission.\n\n10. **Significance or Potential Impact**: The summary does not reflect the paper's significance or potential impact in its field, such as the implications for superconducting devices."], "The summary should accurately reflect the main findings and contributions of the paper.": [true, true], "The summary must be concise, ideally not exceeding 250 words.": [true, true], "It should highlight the research problem or question addressed by the paper.": [true, false], "The summary should mention the methodology or approach used in the paper.": [true, true], "It should include any significant results or conclusions drawn by the authors.": [true, false], "The summary must be written in clear and professional language.": [true, true], "It should avoid technical jargon unless necessary, and explain any used terms.": [false, false], "The summary should be structured logically, with a clear beginning, middle, and end.": [true, true], "It should mention any key experiments or data used in the research.": [true, false], "The summary should reflect the paper's significance or potential impact in its field.": [true, false]}}]}